{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the repo! Getting started Installation conda create -n sequel python = 3 .10 -y conda activate sequel pip install -r requirements.txt Launching the docs Build docs from scratch Launching already built docs # navigate to the root of the repo, i.e, # where the file `mkdocs.yml` resides. mkdocs serve # Docs are launched in http://127.0.0.1:8000/ # navigate to the `site/` directory # The directory contains the file 'index.html' # serve the website python3 -m http.server # The website is hosted in http://127.0.0.1:8000/ Project layout mkdocs.yml # The configuration file for the documentation. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. sequel/ # The source code lies here. algos/ # The Continual Learning Algorithms, e.g. EWC. backbones/ # The Neural Net classes. benchmarks/ # The benchmarks such as SplitMNIST. utils/ # Utility functions such as logging, callbacks etc. Examples The API for both JAX and PyTorch is the same. In the following example, we only need to change pytorch to jax and define the optimizer in a framework-specific way. PyTorch JAX from sequel import benchmarks , backbones , algos , loggers , callbacks import torch # define the Continual Learning benchmark. benchmark = benchmarks . PermutedMNIST ( num_tasks = 3 , batch_size = 512 ) # define the backbone model, i.e., the neural network, and the optimizer backbone = backbones . pytorch . MLP ( width = 256 , n_hidden_layers = 2 , num_classes = 10 ) optimizer = torch . optim . SGD ( backbone . parameters (), lr = 0.1 ) # initialize the algorithm algo = algos . pytorch . EWC ( backbone = backbone , optimizer = optimizer , benchmark = benchmark , callbacks = [ callbacks . PyTorchMetricCallback (), callbacks . TqdmCallback (), ], loggers = [ loggers . WandbLogger ()], # algorithm-specific arguments ewc_lambda = 1 , ) # start training algo . fit ( epochs = 1 ) from sequel import benchmarks , backbones , algos , loggers , callbacks import optax as tx # define the Continual Learning benchmark. benchmark = benchmarks . PermutedMNIST ( num_tasks = 3 , batch_size = 512 ) # define the backbone model, i.e., the neural network, and the optimizer backbone = backbones . jax . MLP ( width = 256 , n_hidden_layers = 2 , num_classes = 10 ) optimizer = tx . inject_hyperparams ( tx . sgd )( learning_rate = 0.1 ) # initialize the algorithm algo = algos . jax . EWC ( backbone = backbone , optimizer = optimizer , benchmark = benchmark , callbacks = [ callbacks . JaxMetricCallback (), callbacks . TqdmCallback (), ], loggers = [ loggers . WandbLogger ()], # algorithm-specific arguments ewc_lambda = 1 , ) # start training algo . fit ( epochs = 1 )","title":"Welcome to the repo!"},{"location":"#welcome-to-the-repo","text":"","title":"Welcome to the repo!"},{"location":"#getting-started","text":"","title":"Getting started"},{"location":"#installation","text":"conda create -n sequel python = 3 .10 -y conda activate sequel pip install -r requirements.txt","title":"Installation"},{"location":"#launching-the-docs","text":"Build docs from scratch Launching already built docs # navigate to the root of the repo, i.e, # where the file `mkdocs.yml` resides. mkdocs serve # Docs are launched in http://127.0.0.1:8000/ # navigate to the `site/` directory # The directory contains the file 'index.html' # serve the website python3 -m http.server # The website is hosted in http://127.0.0.1:8000/","title":"Launching the docs"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file for the documentation. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. sequel/ # The source code lies here. algos/ # The Continual Learning Algorithms, e.g. EWC. backbones/ # The Neural Net classes. benchmarks/ # The benchmarks such as SplitMNIST. utils/ # Utility functions such as logging, callbacks etc.","title":"Project layout"},{"location":"#examples","text":"The API for both JAX and PyTorch is the same. In the following example, we only need to change pytorch to jax and define the optimizer in a framework-specific way. PyTorch JAX from sequel import benchmarks , backbones , algos , loggers , callbacks import torch # define the Continual Learning benchmark. benchmark = benchmarks . PermutedMNIST ( num_tasks = 3 , batch_size = 512 ) # define the backbone model, i.e., the neural network, and the optimizer backbone = backbones . pytorch . MLP ( width = 256 , n_hidden_layers = 2 , num_classes = 10 ) optimizer = torch . optim . SGD ( backbone . parameters (), lr = 0.1 ) # initialize the algorithm algo = algos . pytorch . EWC ( backbone = backbone , optimizer = optimizer , benchmark = benchmark , callbacks = [ callbacks . PyTorchMetricCallback (), callbacks . TqdmCallback (), ], loggers = [ loggers . WandbLogger ()], # algorithm-specific arguments ewc_lambda = 1 , ) # start training algo . fit ( epochs = 1 ) from sequel import benchmarks , backbones , algos , loggers , callbacks import optax as tx # define the Continual Learning benchmark. benchmark = benchmarks . PermutedMNIST ( num_tasks = 3 , batch_size = 512 ) # define the backbone model, i.e., the neural network, and the optimizer backbone = backbones . jax . MLP ( width = 256 , n_hidden_layers = 2 , num_classes = 10 ) optimizer = tx . inject_hyperparams ( tx . sgd )( learning_rate = 0.1 ) # initialize the algorithm algo = algos . jax . EWC ( backbone = backbone , optimizer = optimizer , benchmark = benchmark , callbacks = [ callbacks . JaxMetricCallback (), callbacks . TqdmCallback (), ], loggers = [ loggers . WandbLogger ()], # algorithm-specific arguments ewc_lambda = 1 , ) # start training algo . fit ( epochs = 1 )","title":"Examples"},{"location":"examples/","text":"How to get started Examples The API for both JAX and PyTorch is the same. In the following example, we only need to change pytorch to jax and define the optimizer in a framework-specific way. PyTorch JAX from sequel import benchmarks , backbones , algos , loggers , callbacks import torch # define the Continual Learning benchmark. benchmark = benchmarks . PermutedMNIST ( num_tasks = 3 , batch_size = 512 ) # define the backbone model, i.e., the neural network, and the optimizer backbone = backbones . pytorch . MLP ( width = 256 , n_hidden_layers = 2 , num_classes = 10 ) optimizer = torch . optim . SGD ( backbone . parameters (), lr = 0.1 ) # initialize the algorithm algo = algos . pytorch . EWC ( backbone = backbone , optimizer = optimizer , benchmark = benchmark , callbacks = [ callbacks . PyTorchMetricCallback (), callbacks . TqdmCallback (), ], loggers = [ loggers . WandbLogger ()], # algorithm-specific arguments ewc_lambda = 1 , ) # start training algo . fit ( epochs = 1 ) from sequel import benchmarks , backbones , algos , loggers , callbacks import optax as tx # define the Continual Learning benchmark. benchmark = benchmarks . PermutedMNIST ( num_tasks = 3 , batch_size = 512 ) # define the backbone model, i.e., the neural network, and the optimizer backbone = backbones . jax . MLP ( width = 256 , n_hidden_layers = 2 , num_classes = 10 ) optimizer = tx . inject_hyperparams ( tx . sgd )( learning_rate = 0.1 ) # initialize the algorithm algo = algos . jax . EWC ( backbone = backbone , optimizer = optimizer , benchmark = benchmark , callbacks = [ callbacks . JaxMetricCallback (), callbacks . TqdmCallback (), ], loggers = [ loggers . WandbLogger ()], # algorithm-specific arguments ewc_lambda = 1 , ) # start training algo . fit ( epochs = 1 )","title":"How to get Started"},{"location":"examples/#how-to-get-started","text":"","title":"How to get started"},{"location":"examples/#examples","text":"The API for both JAX and PyTorch is the same. In the following example, we only need to change pytorch to jax and define the optimizer in a framework-specific way. PyTorch JAX from sequel import benchmarks , backbones , algos , loggers , callbacks import torch # define the Continual Learning benchmark. benchmark = benchmarks . PermutedMNIST ( num_tasks = 3 , batch_size = 512 ) # define the backbone model, i.e., the neural network, and the optimizer backbone = backbones . pytorch . MLP ( width = 256 , n_hidden_layers = 2 , num_classes = 10 ) optimizer = torch . optim . SGD ( backbone . parameters (), lr = 0.1 ) # initialize the algorithm algo = algos . pytorch . EWC ( backbone = backbone , optimizer = optimizer , benchmark = benchmark , callbacks = [ callbacks . PyTorchMetricCallback (), callbacks . TqdmCallback (), ], loggers = [ loggers . WandbLogger ()], # algorithm-specific arguments ewc_lambda = 1 , ) # start training algo . fit ( epochs = 1 ) from sequel import benchmarks , backbones , algos , loggers , callbacks import optax as tx # define the Continual Learning benchmark. benchmark = benchmarks . PermutedMNIST ( num_tasks = 3 , batch_size = 512 ) # define the backbone model, i.e., the neural network, and the optimizer backbone = backbones . jax . MLP ( width = 256 , n_hidden_layers = 2 , num_classes = 10 ) optimizer = tx . inject_hyperparams ( tx . sgd )( learning_rate = 0.1 ) # initialize the algorithm algo = algos . jax . EWC ( backbone = backbone , optimizer = optimizer , benchmark = benchmark , callbacks = [ callbacks . JaxMetricCallback (), callbacks . TqdmCallback (), ], loggers = [ loggers . WandbLogger ()], # algorithm-specific arguments ewc_lambda = 1 , ) # start training algo . fit ( epochs = 1 )","title":"Examples"},{"location":"installation/","text":"Installation conda create -n sequel python = 3 .10 -y conda activate sequel pip install -r requirements.txt","title":"Installation Guide"},{"location":"installation/#installation","text":"conda create -n sequel python = 3 .10 -y conda activate sequel pip install -r requirements.txt","title":"Installation"},{"location":"reproducibility/","text":"Go back to Home . Click me to open as a standalone page. iframe { width: 100%; height: 500px; border: 2px solid #ccc; border-radius: 10px; padding: none; }","title":"Reproducibility"},{"location":"algos/base_algo/","text":"BaseAlgorithm Bases: BaseStateManager , BaseCallbackHook , BaseCallback Base class for Trainer component. Handles all the engineering code. Connects the algorighm with callback and logging functionallities. The class also inherits from BaseCallback and the user can implement desired functionalities either as standalone callbacks or by overwriting the parent callback hooks of the algorithm. Attributes: Name Type Description metric_callback_msg Optional [ str ] A message set by the MetricCallback that informs about the progress of training/validation etc. Can be used by other callbacks, e.g., TqdmCallback, to display such information in the console. num_tasks int number of tasks. Set by parse_benchmark . classes_per_task int the number of classes per task. For the moment, all tasks should have the same number of classes. Set by parse_benchmark . episodic_memory_loader torch . utils . data . DataLoader The dataloader for the memory. Applies to methods that utilize memoreis, such as GEM. episodic_memory_iter Iterable [ torch . utils . data . DataLoader ] An iterator for episodic_memory_loader loss Union [ torch . Tensor , numpy . array ] The loss of the current batch. current_dataloader torch . utils . data . DataLoader The current training/validation/testing dataloader. x Union [ torch . Tensor , numpy . array ] The input tensors of the current batch. Set by unpack_batch . y Union [ torch . Tensor , numpy . array ] The targets of the current batch. Set by unpack_batch . t Union [ torch . Tensor , numpy . array ] The task ids of the current batch. Set by unpack_batch . bs int The size of the current batch. Set by unpack_batch . epochs int The epochs each task is trained for. Source code in sequel/algos/base_algo.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 class BaseAlgorithm ( BaseStateManager , BaseCallbackHook , BaseCallback ): \"\"\"Base class for Trainer component. Handles all the engineering code. Connects the algorighm with callback and logging functionallities. The class also inherits from BaseCallback and the user can implement desired functionalities either as standalone callbacks or by overwriting the parent callback hooks of the algorithm. Attributes: metric_callback_msg (Optional[str]): A message set by the MetricCallback that informs about the progress of training/validation etc. Can be used by other callbacks, e.g., TqdmCallback, to display such information in the console. num_tasks (int): number of tasks. Set by [`parse_benchmark`][sequel.algos.base_algo.BaseAlgorithm.parse_benchmark]. classes_per_task (int): the number of classes per task. For the moment, all tasks should have the same number of classes. Set by [`parse_benchmark`][sequel.algos.base_algo.BaseAlgorithm.parse_benchmark]. episodic_memory_loader (torch.utils.data.DataLoader): The dataloader for the memory. Applies to methods that utilize memoreis, such as GEM. episodic_memory_iter (Iterable[torch.utils.data.DataLoader]): An iterator for `episodic_memory_loader` loss (Union[torch.Tensor, numpy.array]): The loss of the current batch. current_dataloader (torch.utils.data.DataLoader): The current training/validation/testing dataloader. x (Union[torch.Tensor, numpy.array]): The input tensors of the current batch. Set by [`unpack_batch`][sequel.algos.base_algo.BaseAlgorithm.unpack_batch]. y (Union[torch.Tensor, numpy.array]): The targets of the current batch. Set by [`unpack_batch`][sequel.algos.base_algo.BaseAlgorithm.unpack_batch]. t (Union[torch.Tensor, numpy.array]): The task ids of the current batch. Set by [`unpack_batch`][sequel.algos.base_algo.BaseAlgorithm.unpack_batch]. bs (int): The size of the current batch. Set by [`unpack_batch`][sequel.algos.base_algo.BaseAlgorithm.unpack_batch]. epochs (int): The epochs each task is trained for. \"\"\" metric_callback_msg = None episodic_memory_loader = None episodic_memory_iter = None def __init__ ( self , backbone : Union [ PytorchBaseBackbone , JaxBaseBackbone ], benchmark : Benchmark , optimizer : Union [ torch . optim . Optimizer , optax . GradientTransformation ], callbacks : Iterable [ BaseCallback ] = [], loggers : Optional [ Iterable [ Logger ]] = None , lr_decay : Optional [ float ] = None , grad_clip : Optional [ float ] = None , reinit_optimizer : bool = True , ) -> None : \"\"\"Inits the BaseAlgorithm class. Handles all the engineering code. Base classes for algorithms in Pytorch and Jax inherit from this class. Args: backbone (Union[PytorchBaseBackbone, JaxBaseBackbone]): The backbone model, e.g., a CNN. benchmark (Benchmark): The benchmark, e.g., SplitMNIST. optimizer (Union[torch.optim.Optimizer, optax.GradientTransformation]): The optimizer used to update the backbone weights. callbacks (Iterable[BaseCallback], optional): A list of callbacks. At least one instance of MetricCallback should be given. Defaults to []. loggers (Optional[Logger], optional): A list of logger, e.g. for Weights&Biases logging functionality. Defaults to None. lr_decay (Optional[float], optional): A learning rate decay used for every new task. Defaults to None. reinit_optimizer (bool): Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True. \"\"\" install_logging () self . benchmark = benchmark self . parse_benchmark () self . backbone = backbone self . callbacks = self . check_and_parse_callbacks ( callbacks ) self . loggers = loggers self . optimizer = optimizer self . lr_decay = lr_decay self . reinit_optimizer = reinit_optimizer self . grad_clip = grad_clip if self . grad_clip is not None : logging . info ( f \"Gradient clipping has been set to { self . grad_clip } .\" ) logging . info ( f \"The backbone model has { self . count_parameters () / 1e6 : .3f } m parameters\" ) def check_and_parse_callbacks ( self , callbacks : Iterable [ BaseCallback ]) -> Iterable [ BaseCallback ]: \"\"\"Checks that the callbacks is a list containing exaclty one MetricCallback. Args: callbacks (Iterable[BaseCallback]): list of callbacks Returns: Iterable[BaseCallback]: the parsed list of callbacks. \"\"\" from sequel.utils.callbacks.metrics.metric_callback import MetricCallback assert isinstance ( callbacks , list ), \"The callbacks should be given as a list.\" assert ( sum ([ isinstance ( c , MetricCallback ) for c in callbacks ]) == 1 ), \"Exactly one instance of MetricCallback should be given.\" # make sure that the MetricCallback is last. parsed_callbacks = [ c for c in callbacks if not isinstance ( c , MetricCallback )] parsed_callbacks += [ c for c in callbacks if isinstance ( c , MetricCallback )] return parsed_callbacks def parse_benchmark ( self ): \"\"\"Extracts attributes from the benchmark and registers them to the algo for quick access.\"\"\" self . num_tasks = self . benchmark . num_tasks self . classes_per_task = self . benchmark . classes_per_task self . input_dimensions = self . benchmark . dimensions def update_episodic_memory ( self ) -> None : \"\"\"Updates the episodic memory. This funciton is called after fitting one task.\"\"\" logging . info ( \"Updating episodic memory for task {} \" . format ( self . task_counter )) self . episodic_memory_loader = self . benchmark . memory_dataloader ( self . task_counter ) self . episodic_memory_iter = iter ( self . episodic_memory_loader ) def sample_batch_from_memory ( self ): try : batch = next ( self . episodic_memory_iter ) except StopIteration : # makes the dataloader an infinite stream self . episodic_memory_iter = iter ( self . episodic_memory_loader ) batch = next ( self . episodic_memory_iter ) return batch def log ( self , item ): # logger: Logger if self . loggers is not None : for logger in self . loggers : logger . log ( item , step = self . step_counter , epoch = self . epoch_counter ) def log_figure ( self , figure , name ): if self . loggers is not None : for logger in self . loggers : logger . log_figure ( name = name , figure = figure ) def count_parameters ( self ): raise NotImplementedError def setup ( self ): for cb in self . callbacks : cb . connect ( self ) def teardown ( self ): pass def _configure_criterion ( self , task_id = None ): raise NotImplementedError def forward ( self , * args , ** kwargs ): \"\"\"Calls the forward function of the model.\"\"\" raise NotImplementedError def update_tqdm ( self , msg ): self . metric_callback_msg = msg # self.tqdm_dl.set_postfix(msg) def unpack_batch ( self , batch : Any ): \"\"\"Unpacks the batch and registers to the algorithm the current batch input, targets and task ids as `self.x`, `self.y` and `self.t`, respectively. It also registers the current batch size as `self.bs`\"\"\" raise NotImplementedError def optimizer_zero_grad ( self ): raise NotImplementedError def backpropagate_loss ( self ): raise NotImplementedError def optimizer_step ( self ): raise NotImplementedError def perform_gradient_clipping ( self ): raise NotImplementedError def training_step ( self , * args , ** kwargs ): \"\"\"The training step, i.e. training for each batch. Goes through the usual hoops of zeroing out the optimizer, forwarding the input, computing the loss, backpropagating and updating the weights. For each different steps, callabacks are offered for maximum versatility and ease of use. \"\"\" self . optimizer_zero_grad () y_hat = self . forward () self . loss = self . compute_loss ( y_hat , self . y , self . t ) self . on_before_backward () self . on_before_backward_callbacks () self . backpropagate_loss () self . on_after_backward () self . on_after_backward_callbacks () self . perform_gradient_clipping () self . on_before_optimizer_step () self . on_before_optimizer_step_callbacks () self . optimizer_step () self . on_after_optimizer_step () self . on_after_optimizer_step_callbacks () def valid_step ( self , * args , ** kwargs ): \"\"\"Performs the validation step.Callbacks are offered for each step of the process.\"\"\" raise NotImplementedError def test_step ( self , * args , ** kwargs ): \"\"\"Performs the testing step. Callbacks are offered for each step of the process.\"\"\" pass def training_epoch ( self , * args , ** kwargs ): \"\"\"Trains the model for a single epoch. Callbacks are offered for each method.\"\"\" self . increment ( \"epoch\" ) self . set_training_mode () self . current_dataloader = self . train_loader for self . batch_idx , batch in enumerate ( self . current_dataloader ): self . unpack_batch ( batch ) self . on_before_training_step () self . on_before_training_step_callbacks () self . increment ( \"step\" ) self . training_step () self . on_after_training_step () self . on_after_training_step_callbacks () def eval_epoch ( self , * args , ** kwargs ): \"\"\"Performs the evaluation of the model on the validation set. If no validation dataloader is provided, the method returns without any computation.\"\"\" if self . valid_loader is None : return self . set_evaluation_mode () self . current_dataloader = self . valid_loader for self . batch_idx , batch in enumerate ( self . current_dataloader ): self . unpack_batch ( batch ) self . on_before_val_step () self . on_before_val_step_callbacks () self . valid_step () self . on_after_val_step () self . on_after_val_step_callbacks () def test_epoch ( self , * args , ** kwargs ): pass def prepare_for_next_task ( self , task ): raise NotImplementedError def prepare_train_loader ( self , task ): return self . benchmark . train_dataloader ( task ) def train_algorithm_on_task ( self , task : int ): \"\"\"Fits a *single* task.\"\"\" self . train_loader = self . prepare_train_loader ( task ) self . prepare_for_next_task ( task ) assert isinstance ( self . _epochs , ( list , int , omegaconf . listconfig . ListConfig )) if not isinstance ( self . _epochs , int ): self . epochs = self . _epochs [ self . task_counter - 1 ] else : self . epochs = self . _epochs for self . current_task_epoch in range ( 1 , self . epochs + 1 ): self . _train_loop () self . _val_loop () def _train_loop ( self ): self . on_before_training_epoch () self . on_before_training_epoch_callbacks () self . training_epoch () self . on_after_training_epoch () self . on_after_training_epoch_callbacks () def _val_loop ( self ): # after each epoch, the model is validated on current and previous tasks. self . on_before_validating_algorithm_on_all_tasks () self . on_before_validating_algorithm_on_all_tasks_callbacks () self . validate_algorithm_on_all_tasks () self . on_after_validating_algorithm_on_all_tasks () self . on_after_validating_algorithm_on_all_tasks_callbacks () def validate_algorithm_on_all_tasks ( self ) -> Dict [ str , float ]: for task in range ( 1 , self . task_counter + 1 ): self . current_val_task = task self . valid_loader = self . benchmark . val_dataloader ( task ) self . on_before_val_epoch () self . on_before_val_epoch_callbacks () self . eval_epoch () self . on_after_val_epoch () self . on_after_val_epoch_callbacks () def _fit ( self ): \"\"\"Fits all tasks to the model, one after the other.\"\"\" for task in range ( 1 , self . num_tasks + 1 ): self . on_before_training_task () self . on_before_training_task_callbacks () self . increment ( \"task\" ) self . train_algorithm_on_task ( task ) self . on_after_training_task () self . on_after_training_task_callbacks () def _run_setup ( self ): self . on_before_setup () self . on_before_setup_callbacks () self . setup () self . on_after_setup () self . on_after_setup_callbacks () def _run_fit ( self ): self . on_before_fit () self . on_before_fit_callbacks () self . _fit () self . on_after_fit () self . on_after_fit_callbacks () def _run_teardown ( self ): self . on_before_teardown () self . on_before_teardown_callbacks () self . teardown () self . on_after_teardown () self . on_after_teardown_callbacks () def fit ( self , epochs ): self . _epochs = epochs self . _run_setup () self . _run_fit () self . _run_teardown () def compute_loss ( self , predictions , targets , task_ids , * args , ** kwargs ): raise NotImplementedError __init__ ( backbone , benchmark , optimizer , callbacks = [], loggers = None , lr_decay = None , grad_clip = None , reinit_optimizer = True ) Inits the BaseAlgorithm class. Handles all the engineering code. Base classes for algorithms in Pytorch and Jax inherit from this class. Parameters: Name Type Description Default backbone Union [ PytorchBaseBackbone , JaxBaseBackbone ] The backbone model, e.g., a CNN. required benchmark Benchmark The benchmark, e.g., SplitMNIST. required optimizer Union [ torch . optim . Optimizer , optax . GradientTransformation ] The optimizer used to update the backbone weights. required callbacks Iterable [ BaseCallback ] A list of callbacks. At least one instance of MetricCallback should be given. Defaults to []. [] loggers Optional [ Logger ] A list of logger, e.g. for Weights&Biases logging functionality. Defaults to None. None lr_decay Optional [ float ] A learning rate decay used for every new task. Defaults to None. None reinit_optimizer bool Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True. True Source code in sequel/algos/base_algo.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 def __init__ ( self , backbone : Union [ PytorchBaseBackbone , JaxBaseBackbone ], benchmark : Benchmark , optimizer : Union [ torch . optim . Optimizer , optax . GradientTransformation ], callbacks : Iterable [ BaseCallback ] = [], loggers : Optional [ Iterable [ Logger ]] = None , lr_decay : Optional [ float ] = None , grad_clip : Optional [ float ] = None , reinit_optimizer : bool = True , ) -> None : \"\"\"Inits the BaseAlgorithm class. Handles all the engineering code. Base classes for algorithms in Pytorch and Jax inherit from this class. Args: backbone (Union[PytorchBaseBackbone, JaxBaseBackbone]): The backbone model, e.g., a CNN. benchmark (Benchmark): The benchmark, e.g., SplitMNIST. optimizer (Union[torch.optim.Optimizer, optax.GradientTransformation]): The optimizer used to update the backbone weights. callbacks (Iterable[BaseCallback], optional): A list of callbacks. At least one instance of MetricCallback should be given. Defaults to []. loggers (Optional[Logger], optional): A list of logger, e.g. for Weights&Biases logging functionality. Defaults to None. lr_decay (Optional[float], optional): A learning rate decay used for every new task. Defaults to None. reinit_optimizer (bool): Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True. \"\"\" install_logging () self . benchmark = benchmark self . parse_benchmark () self . backbone = backbone self . callbacks = self . check_and_parse_callbacks ( callbacks ) self . loggers = loggers self . optimizer = optimizer self . lr_decay = lr_decay self . reinit_optimizer = reinit_optimizer self . grad_clip = grad_clip if self . grad_clip is not None : logging . info ( f \"Gradient clipping has been set to { self . grad_clip } .\" ) logging . info ( f \"The backbone model has { self . count_parameters () / 1e6 : .3f } m parameters\" ) check_and_parse_callbacks ( callbacks ) Checks that the callbacks is a list containing exaclty one MetricCallback. Parameters: Name Type Description Default callbacks Iterable [ BaseCallback ] list of callbacks required Returns: Type Description Iterable [ BaseCallback ] Iterable[BaseCallback]: the parsed list of callbacks. Source code in sequel/algos/base_algo.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def check_and_parse_callbacks ( self , callbacks : Iterable [ BaseCallback ]) -> Iterable [ BaseCallback ]: \"\"\"Checks that the callbacks is a list containing exaclty one MetricCallback. Args: callbacks (Iterable[BaseCallback]): list of callbacks Returns: Iterable[BaseCallback]: the parsed list of callbacks. \"\"\" from sequel.utils.callbacks.metrics.metric_callback import MetricCallback assert isinstance ( callbacks , list ), \"The callbacks should be given as a list.\" assert ( sum ([ isinstance ( c , MetricCallback ) for c in callbacks ]) == 1 ), \"Exactly one instance of MetricCallback should be given.\" # make sure that the MetricCallback is last. parsed_callbacks = [ c for c in callbacks if not isinstance ( c , MetricCallback )] parsed_callbacks += [ c for c in callbacks if isinstance ( c , MetricCallback )] return parsed_callbacks eval_epoch ( * args , ** kwargs ) Performs the evaluation of the model on the validation set. If no validation dataloader is provided, the method returns without any computation. Source code in sequel/algos/base_algo.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 def eval_epoch ( self , * args , ** kwargs ): \"\"\"Performs the evaluation of the model on the validation set. If no validation dataloader is provided, the method returns without any computation.\"\"\" if self . valid_loader is None : return self . set_evaluation_mode () self . current_dataloader = self . valid_loader for self . batch_idx , batch in enumerate ( self . current_dataloader ): self . unpack_batch ( batch ) self . on_before_val_step () self . on_before_val_step_callbacks () self . valid_step () self . on_after_val_step () self . on_after_val_step_callbacks () forward ( * args , ** kwargs ) Calls the forward function of the model. Source code in sequel/algos/base_algo.py 160 161 162 def forward ( self , * args , ** kwargs ): \"\"\"Calls the forward function of the model.\"\"\" raise NotImplementedError parse_benchmark () Extracts attributes from the benchmark and registers them to the algo for quick access. Source code in sequel/algos/base_algo.py 114 115 116 117 118 def parse_benchmark ( self ): \"\"\"Extracts attributes from the benchmark and registers them to the algo for quick access.\"\"\" self . num_tasks = self . benchmark . num_tasks self . classes_per_task = self . benchmark . classes_per_task self . input_dimensions = self . benchmark . dimensions test_step ( * args , ** kwargs ) Performs the testing step. Callbacks are offered for each step of the process. Source code in sequel/algos/base_algo.py 214 215 216 def test_step ( self , * args , ** kwargs ): \"\"\"Performs the testing step. Callbacks are offered for each step of the process.\"\"\" pass train_algorithm_on_task ( task ) Fits a single task. Source code in sequel/algos/base_algo.py 258 259 260 261 262 263 264 265 266 267 268 269 270 271 def train_algorithm_on_task ( self , task : int ): \"\"\"Fits a *single* task.\"\"\" self . train_loader = self . prepare_train_loader ( task ) self . prepare_for_next_task ( task ) assert isinstance ( self . _epochs , ( list , int , omegaconf . listconfig . ListConfig )) if not isinstance ( self . _epochs , int ): self . epochs = self . _epochs [ self . task_counter - 1 ] else : self . epochs = self . _epochs for self . current_task_epoch in range ( 1 , self . epochs + 1 ): self . _train_loop () self . _val_loop () training_epoch ( * args , ** kwargs ) Trains the model for a single epoch. Callbacks are offered for each method. Source code in sequel/algos/base_algo.py 218 219 220 221 222 223 224 225 226 227 228 229 230 def training_epoch ( self , * args , ** kwargs ): \"\"\"Trains the model for a single epoch. Callbacks are offered for each method.\"\"\" self . increment ( \"epoch\" ) self . set_training_mode () self . current_dataloader = self . train_loader for self . batch_idx , batch in enumerate ( self . current_dataloader ): self . unpack_batch ( batch ) self . on_before_training_step () self . on_before_training_step_callbacks () self . increment ( \"step\" ) self . training_step () self . on_after_training_step () self . on_after_training_step_callbacks () training_step ( * args , ** kwargs ) The training step, i.e. training for each batch. Goes through the usual hoops of zeroing out the optimizer, forwarding the input, computing the loss, backpropagating and updating the weights. For each different steps, callabacks are offered for maximum versatility and ease of use. Source code in sequel/algos/base_algo.py 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 def training_step ( self , * args , ** kwargs ): \"\"\"The training step, i.e. training for each batch. Goes through the usual hoops of zeroing out the optimizer, forwarding the input, computing the loss, backpropagating and updating the weights. For each different steps, callabacks are offered for maximum versatility and ease of use. \"\"\" self . optimizer_zero_grad () y_hat = self . forward () self . loss = self . compute_loss ( y_hat , self . y , self . t ) self . on_before_backward () self . on_before_backward_callbacks () self . backpropagate_loss () self . on_after_backward () self . on_after_backward_callbacks () self . perform_gradient_clipping () self . on_before_optimizer_step () self . on_before_optimizer_step_callbacks () self . optimizer_step () self . on_after_optimizer_step () self . on_after_optimizer_step_callbacks () unpack_batch ( batch ) Unpacks the batch and registers to the algorithm the current batch input, targets and task ids as self.x , self.y and self.t , respectively. It also registers the current batch size as self.bs Source code in sequel/algos/base_algo.py 168 169 170 171 def unpack_batch ( self , batch : Any ): \"\"\"Unpacks the batch and registers to the algorithm the current batch input, targets and task ids as `self.x`, `self.y` and `self.t`, respectively. It also registers the current batch size as `self.bs`\"\"\" raise NotImplementedError update_episodic_memory () Updates the episodic memory. This funciton is called after fitting one task. Source code in sequel/algos/base_algo.py 120 121 122 123 124 def update_episodic_memory ( self ) -> None : \"\"\"Updates the episodic memory. This funciton is called after fitting one task.\"\"\" logging . info ( \"Updating episodic memory for task {} \" . format ( self . task_counter )) self . episodic_memory_loader = self . benchmark . memory_dataloader ( self . task_counter ) self . episodic_memory_iter = iter ( self . episodic_memory_loader ) valid_step ( * args , ** kwargs ) Performs the validation step.Callbacks are offered for each step of the process. Source code in sequel/algos/base_algo.py 210 211 212 def valid_step ( self , * args , ** kwargs ): \"\"\"Performs the validation step.Callbacks are offered for each step of the process.\"\"\" raise NotImplementedError","title":"BaseAlgo"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm","text":"Bases: BaseStateManager , BaseCallbackHook , BaseCallback Base class for Trainer component. Handles all the engineering code. Connects the algorighm with callback and logging functionallities. The class also inherits from BaseCallback and the user can implement desired functionalities either as standalone callbacks or by overwriting the parent callback hooks of the algorithm. Attributes: Name Type Description metric_callback_msg Optional [ str ] A message set by the MetricCallback that informs about the progress of training/validation etc. Can be used by other callbacks, e.g., TqdmCallback, to display such information in the console. num_tasks int number of tasks. Set by parse_benchmark . classes_per_task int the number of classes per task. For the moment, all tasks should have the same number of classes. Set by parse_benchmark . episodic_memory_loader torch . utils . data . DataLoader The dataloader for the memory. Applies to methods that utilize memoreis, such as GEM. episodic_memory_iter Iterable [ torch . utils . data . DataLoader ] An iterator for episodic_memory_loader loss Union [ torch . Tensor , numpy . array ] The loss of the current batch. current_dataloader torch . utils . data . DataLoader The current training/validation/testing dataloader. x Union [ torch . Tensor , numpy . array ] The input tensors of the current batch. Set by unpack_batch . y Union [ torch . Tensor , numpy . array ] The targets of the current batch. Set by unpack_batch . t Union [ torch . Tensor , numpy . array ] The task ids of the current batch. Set by unpack_batch . bs int The size of the current batch. Set by unpack_batch . epochs int The epochs each task is trained for. Source code in sequel/algos/base_algo.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 class BaseAlgorithm ( BaseStateManager , BaseCallbackHook , BaseCallback ): \"\"\"Base class for Trainer component. Handles all the engineering code. Connects the algorighm with callback and logging functionallities. The class also inherits from BaseCallback and the user can implement desired functionalities either as standalone callbacks or by overwriting the parent callback hooks of the algorithm. Attributes: metric_callback_msg (Optional[str]): A message set by the MetricCallback that informs about the progress of training/validation etc. Can be used by other callbacks, e.g., TqdmCallback, to display such information in the console. num_tasks (int): number of tasks. Set by [`parse_benchmark`][sequel.algos.base_algo.BaseAlgorithm.parse_benchmark]. classes_per_task (int): the number of classes per task. For the moment, all tasks should have the same number of classes. Set by [`parse_benchmark`][sequel.algos.base_algo.BaseAlgorithm.parse_benchmark]. episodic_memory_loader (torch.utils.data.DataLoader): The dataloader for the memory. Applies to methods that utilize memoreis, such as GEM. episodic_memory_iter (Iterable[torch.utils.data.DataLoader]): An iterator for `episodic_memory_loader` loss (Union[torch.Tensor, numpy.array]): The loss of the current batch. current_dataloader (torch.utils.data.DataLoader): The current training/validation/testing dataloader. x (Union[torch.Tensor, numpy.array]): The input tensors of the current batch. Set by [`unpack_batch`][sequel.algos.base_algo.BaseAlgorithm.unpack_batch]. y (Union[torch.Tensor, numpy.array]): The targets of the current batch. Set by [`unpack_batch`][sequel.algos.base_algo.BaseAlgorithm.unpack_batch]. t (Union[torch.Tensor, numpy.array]): The task ids of the current batch. Set by [`unpack_batch`][sequel.algos.base_algo.BaseAlgorithm.unpack_batch]. bs (int): The size of the current batch. Set by [`unpack_batch`][sequel.algos.base_algo.BaseAlgorithm.unpack_batch]. epochs (int): The epochs each task is trained for. \"\"\" metric_callback_msg = None episodic_memory_loader = None episodic_memory_iter = None def __init__ ( self , backbone : Union [ PytorchBaseBackbone , JaxBaseBackbone ], benchmark : Benchmark , optimizer : Union [ torch . optim . Optimizer , optax . GradientTransformation ], callbacks : Iterable [ BaseCallback ] = [], loggers : Optional [ Iterable [ Logger ]] = None , lr_decay : Optional [ float ] = None , grad_clip : Optional [ float ] = None , reinit_optimizer : bool = True , ) -> None : \"\"\"Inits the BaseAlgorithm class. Handles all the engineering code. Base classes for algorithms in Pytorch and Jax inherit from this class. Args: backbone (Union[PytorchBaseBackbone, JaxBaseBackbone]): The backbone model, e.g., a CNN. benchmark (Benchmark): The benchmark, e.g., SplitMNIST. optimizer (Union[torch.optim.Optimizer, optax.GradientTransformation]): The optimizer used to update the backbone weights. callbacks (Iterable[BaseCallback], optional): A list of callbacks. At least one instance of MetricCallback should be given. Defaults to []. loggers (Optional[Logger], optional): A list of logger, e.g. for Weights&Biases logging functionality. Defaults to None. lr_decay (Optional[float], optional): A learning rate decay used for every new task. Defaults to None. reinit_optimizer (bool): Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True. \"\"\" install_logging () self . benchmark = benchmark self . parse_benchmark () self . backbone = backbone self . callbacks = self . check_and_parse_callbacks ( callbacks ) self . loggers = loggers self . optimizer = optimizer self . lr_decay = lr_decay self . reinit_optimizer = reinit_optimizer self . grad_clip = grad_clip if self . grad_clip is not None : logging . info ( f \"Gradient clipping has been set to { self . grad_clip } .\" ) logging . info ( f \"The backbone model has { self . count_parameters () / 1e6 : .3f } m parameters\" ) def check_and_parse_callbacks ( self , callbacks : Iterable [ BaseCallback ]) -> Iterable [ BaseCallback ]: \"\"\"Checks that the callbacks is a list containing exaclty one MetricCallback. Args: callbacks (Iterable[BaseCallback]): list of callbacks Returns: Iterable[BaseCallback]: the parsed list of callbacks. \"\"\" from sequel.utils.callbacks.metrics.metric_callback import MetricCallback assert isinstance ( callbacks , list ), \"The callbacks should be given as a list.\" assert ( sum ([ isinstance ( c , MetricCallback ) for c in callbacks ]) == 1 ), \"Exactly one instance of MetricCallback should be given.\" # make sure that the MetricCallback is last. parsed_callbacks = [ c for c in callbacks if not isinstance ( c , MetricCallback )] parsed_callbacks += [ c for c in callbacks if isinstance ( c , MetricCallback )] return parsed_callbacks def parse_benchmark ( self ): \"\"\"Extracts attributes from the benchmark and registers them to the algo for quick access.\"\"\" self . num_tasks = self . benchmark . num_tasks self . classes_per_task = self . benchmark . classes_per_task self . input_dimensions = self . benchmark . dimensions def update_episodic_memory ( self ) -> None : \"\"\"Updates the episodic memory. This funciton is called after fitting one task.\"\"\" logging . info ( \"Updating episodic memory for task {} \" . format ( self . task_counter )) self . episodic_memory_loader = self . benchmark . memory_dataloader ( self . task_counter ) self . episodic_memory_iter = iter ( self . episodic_memory_loader ) def sample_batch_from_memory ( self ): try : batch = next ( self . episodic_memory_iter ) except StopIteration : # makes the dataloader an infinite stream self . episodic_memory_iter = iter ( self . episodic_memory_loader ) batch = next ( self . episodic_memory_iter ) return batch def log ( self , item ): # logger: Logger if self . loggers is not None : for logger in self . loggers : logger . log ( item , step = self . step_counter , epoch = self . epoch_counter ) def log_figure ( self , figure , name ): if self . loggers is not None : for logger in self . loggers : logger . log_figure ( name = name , figure = figure ) def count_parameters ( self ): raise NotImplementedError def setup ( self ): for cb in self . callbacks : cb . connect ( self ) def teardown ( self ): pass def _configure_criterion ( self , task_id = None ): raise NotImplementedError def forward ( self , * args , ** kwargs ): \"\"\"Calls the forward function of the model.\"\"\" raise NotImplementedError def update_tqdm ( self , msg ): self . metric_callback_msg = msg # self.tqdm_dl.set_postfix(msg) def unpack_batch ( self , batch : Any ): \"\"\"Unpacks the batch and registers to the algorithm the current batch input, targets and task ids as `self.x`, `self.y` and `self.t`, respectively. It also registers the current batch size as `self.bs`\"\"\" raise NotImplementedError def optimizer_zero_grad ( self ): raise NotImplementedError def backpropagate_loss ( self ): raise NotImplementedError def optimizer_step ( self ): raise NotImplementedError def perform_gradient_clipping ( self ): raise NotImplementedError def training_step ( self , * args , ** kwargs ): \"\"\"The training step, i.e. training for each batch. Goes through the usual hoops of zeroing out the optimizer, forwarding the input, computing the loss, backpropagating and updating the weights. For each different steps, callabacks are offered for maximum versatility and ease of use. \"\"\" self . optimizer_zero_grad () y_hat = self . forward () self . loss = self . compute_loss ( y_hat , self . y , self . t ) self . on_before_backward () self . on_before_backward_callbacks () self . backpropagate_loss () self . on_after_backward () self . on_after_backward_callbacks () self . perform_gradient_clipping () self . on_before_optimizer_step () self . on_before_optimizer_step_callbacks () self . optimizer_step () self . on_after_optimizer_step () self . on_after_optimizer_step_callbacks () def valid_step ( self , * args , ** kwargs ): \"\"\"Performs the validation step.Callbacks are offered for each step of the process.\"\"\" raise NotImplementedError def test_step ( self , * args , ** kwargs ): \"\"\"Performs the testing step. Callbacks are offered for each step of the process.\"\"\" pass def training_epoch ( self , * args , ** kwargs ): \"\"\"Trains the model for a single epoch. Callbacks are offered for each method.\"\"\" self . increment ( \"epoch\" ) self . set_training_mode () self . current_dataloader = self . train_loader for self . batch_idx , batch in enumerate ( self . current_dataloader ): self . unpack_batch ( batch ) self . on_before_training_step () self . on_before_training_step_callbacks () self . increment ( \"step\" ) self . training_step () self . on_after_training_step () self . on_after_training_step_callbacks () def eval_epoch ( self , * args , ** kwargs ): \"\"\"Performs the evaluation of the model on the validation set. If no validation dataloader is provided, the method returns without any computation.\"\"\" if self . valid_loader is None : return self . set_evaluation_mode () self . current_dataloader = self . valid_loader for self . batch_idx , batch in enumerate ( self . current_dataloader ): self . unpack_batch ( batch ) self . on_before_val_step () self . on_before_val_step_callbacks () self . valid_step () self . on_after_val_step () self . on_after_val_step_callbacks () def test_epoch ( self , * args , ** kwargs ): pass def prepare_for_next_task ( self , task ): raise NotImplementedError def prepare_train_loader ( self , task ): return self . benchmark . train_dataloader ( task ) def train_algorithm_on_task ( self , task : int ): \"\"\"Fits a *single* task.\"\"\" self . train_loader = self . prepare_train_loader ( task ) self . prepare_for_next_task ( task ) assert isinstance ( self . _epochs , ( list , int , omegaconf . listconfig . ListConfig )) if not isinstance ( self . _epochs , int ): self . epochs = self . _epochs [ self . task_counter - 1 ] else : self . epochs = self . _epochs for self . current_task_epoch in range ( 1 , self . epochs + 1 ): self . _train_loop () self . _val_loop () def _train_loop ( self ): self . on_before_training_epoch () self . on_before_training_epoch_callbacks () self . training_epoch () self . on_after_training_epoch () self . on_after_training_epoch_callbacks () def _val_loop ( self ): # after each epoch, the model is validated on current and previous tasks. self . on_before_validating_algorithm_on_all_tasks () self . on_before_validating_algorithm_on_all_tasks_callbacks () self . validate_algorithm_on_all_tasks () self . on_after_validating_algorithm_on_all_tasks () self . on_after_validating_algorithm_on_all_tasks_callbacks () def validate_algorithm_on_all_tasks ( self ) -> Dict [ str , float ]: for task in range ( 1 , self . task_counter + 1 ): self . current_val_task = task self . valid_loader = self . benchmark . val_dataloader ( task ) self . on_before_val_epoch () self . on_before_val_epoch_callbacks () self . eval_epoch () self . on_after_val_epoch () self . on_after_val_epoch_callbacks () def _fit ( self ): \"\"\"Fits all tasks to the model, one after the other.\"\"\" for task in range ( 1 , self . num_tasks + 1 ): self . on_before_training_task () self . on_before_training_task_callbacks () self . increment ( \"task\" ) self . train_algorithm_on_task ( task ) self . on_after_training_task () self . on_after_training_task_callbacks () def _run_setup ( self ): self . on_before_setup () self . on_before_setup_callbacks () self . setup () self . on_after_setup () self . on_after_setup_callbacks () def _run_fit ( self ): self . on_before_fit () self . on_before_fit_callbacks () self . _fit () self . on_after_fit () self . on_after_fit_callbacks () def _run_teardown ( self ): self . on_before_teardown () self . on_before_teardown_callbacks () self . teardown () self . on_after_teardown () self . on_after_teardown_callbacks () def fit ( self , epochs ): self . _epochs = epochs self . _run_setup () self . _run_fit () self . _run_teardown () def compute_loss ( self , predictions , targets , task_ids , * args , ** kwargs ): raise NotImplementedError","title":"BaseAlgorithm"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.__init__","text":"Inits the BaseAlgorithm class. Handles all the engineering code. Base classes for algorithms in Pytorch and Jax inherit from this class. Parameters: Name Type Description Default backbone Union [ PytorchBaseBackbone , JaxBaseBackbone ] The backbone model, e.g., a CNN. required benchmark Benchmark The benchmark, e.g., SplitMNIST. required optimizer Union [ torch . optim . Optimizer , optax . GradientTransformation ] The optimizer used to update the backbone weights. required callbacks Iterable [ BaseCallback ] A list of callbacks. At least one instance of MetricCallback should be given. Defaults to []. [] loggers Optional [ Logger ] A list of logger, e.g. for Weights&Biases logging functionality. Defaults to None. None lr_decay Optional [ float ] A learning rate decay used for every new task. Defaults to None. None reinit_optimizer bool Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True. True Source code in sequel/algos/base_algo.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 def __init__ ( self , backbone : Union [ PytorchBaseBackbone , JaxBaseBackbone ], benchmark : Benchmark , optimizer : Union [ torch . optim . Optimizer , optax . GradientTransformation ], callbacks : Iterable [ BaseCallback ] = [], loggers : Optional [ Iterable [ Logger ]] = None , lr_decay : Optional [ float ] = None , grad_clip : Optional [ float ] = None , reinit_optimizer : bool = True , ) -> None : \"\"\"Inits the BaseAlgorithm class. Handles all the engineering code. Base classes for algorithms in Pytorch and Jax inherit from this class. Args: backbone (Union[PytorchBaseBackbone, JaxBaseBackbone]): The backbone model, e.g., a CNN. benchmark (Benchmark): The benchmark, e.g., SplitMNIST. optimizer (Union[torch.optim.Optimizer, optax.GradientTransformation]): The optimizer used to update the backbone weights. callbacks (Iterable[BaseCallback], optional): A list of callbacks. At least one instance of MetricCallback should be given. Defaults to []. loggers (Optional[Logger], optional): A list of logger, e.g. for Weights&Biases logging functionality. Defaults to None. lr_decay (Optional[float], optional): A learning rate decay used for every new task. Defaults to None. reinit_optimizer (bool): Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True. \"\"\" install_logging () self . benchmark = benchmark self . parse_benchmark () self . backbone = backbone self . callbacks = self . check_and_parse_callbacks ( callbacks ) self . loggers = loggers self . optimizer = optimizer self . lr_decay = lr_decay self . reinit_optimizer = reinit_optimizer self . grad_clip = grad_clip if self . grad_clip is not None : logging . info ( f \"Gradient clipping has been set to { self . grad_clip } .\" ) logging . info ( f \"The backbone model has { self . count_parameters () / 1e6 : .3f } m parameters\" )","title":"__init__()"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.check_and_parse_callbacks","text":"Checks that the callbacks is a list containing exaclty one MetricCallback. Parameters: Name Type Description Default callbacks Iterable [ BaseCallback ] list of callbacks required Returns: Type Description Iterable [ BaseCallback ] Iterable[BaseCallback]: the parsed list of callbacks. Source code in sequel/algos/base_algo.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def check_and_parse_callbacks ( self , callbacks : Iterable [ BaseCallback ]) -> Iterable [ BaseCallback ]: \"\"\"Checks that the callbacks is a list containing exaclty one MetricCallback. Args: callbacks (Iterable[BaseCallback]): list of callbacks Returns: Iterable[BaseCallback]: the parsed list of callbacks. \"\"\" from sequel.utils.callbacks.metrics.metric_callback import MetricCallback assert isinstance ( callbacks , list ), \"The callbacks should be given as a list.\" assert ( sum ([ isinstance ( c , MetricCallback ) for c in callbacks ]) == 1 ), \"Exactly one instance of MetricCallback should be given.\" # make sure that the MetricCallback is last. parsed_callbacks = [ c for c in callbacks if not isinstance ( c , MetricCallback )] parsed_callbacks += [ c for c in callbacks if isinstance ( c , MetricCallback )] return parsed_callbacks","title":"check_and_parse_callbacks()"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.eval_epoch","text":"Performs the evaluation of the model on the validation set. If no validation dataloader is provided, the method returns without any computation. Source code in sequel/algos/base_algo.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 def eval_epoch ( self , * args , ** kwargs ): \"\"\"Performs the evaluation of the model on the validation set. If no validation dataloader is provided, the method returns without any computation.\"\"\" if self . valid_loader is None : return self . set_evaluation_mode () self . current_dataloader = self . valid_loader for self . batch_idx , batch in enumerate ( self . current_dataloader ): self . unpack_batch ( batch ) self . on_before_val_step () self . on_before_val_step_callbacks () self . valid_step () self . on_after_val_step () self . on_after_val_step_callbacks ()","title":"eval_epoch()"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.forward","text":"Calls the forward function of the model. Source code in sequel/algos/base_algo.py 160 161 162 def forward ( self , * args , ** kwargs ): \"\"\"Calls the forward function of the model.\"\"\" raise NotImplementedError","title":"forward()"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.parse_benchmark","text":"Extracts attributes from the benchmark and registers them to the algo for quick access. Source code in sequel/algos/base_algo.py 114 115 116 117 118 def parse_benchmark ( self ): \"\"\"Extracts attributes from the benchmark and registers them to the algo for quick access.\"\"\" self . num_tasks = self . benchmark . num_tasks self . classes_per_task = self . benchmark . classes_per_task self . input_dimensions = self . benchmark . dimensions","title":"parse_benchmark()"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.test_step","text":"Performs the testing step. Callbacks are offered for each step of the process. Source code in sequel/algos/base_algo.py 214 215 216 def test_step ( self , * args , ** kwargs ): \"\"\"Performs the testing step. Callbacks are offered for each step of the process.\"\"\" pass","title":"test_step()"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.train_algorithm_on_task","text":"Fits a single task. Source code in sequel/algos/base_algo.py 258 259 260 261 262 263 264 265 266 267 268 269 270 271 def train_algorithm_on_task ( self , task : int ): \"\"\"Fits a *single* task.\"\"\" self . train_loader = self . prepare_train_loader ( task ) self . prepare_for_next_task ( task ) assert isinstance ( self . _epochs , ( list , int , omegaconf . listconfig . ListConfig )) if not isinstance ( self . _epochs , int ): self . epochs = self . _epochs [ self . task_counter - 1 ] else : self . epochs = self . _epochs for self . current_task_epoch in range ( 1 , self . epochs + 1 ): self . _train_loop () self . _val_loop ()","title":"train_algorithm_on_task()"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.training_epoch","text":"Trains the model for a single epoch. Callbacks are offered for each method. Source code in sequel/algos/base_algo.py 218 219 220 221 222 223 224 225 226 227 228 229 230 def training_epoch ( self , * args , ** kwargs ): \"\"\"Trains the model for a single epoch. Callbacks are offered for each method.\"\"\" self . increment ( \"epoch\" ) self . set_training_mode () self . current_dataloader = self . train_loader for self . batch_idx , batch in enumerate ( self . current_dataloader ): self . unpack_batch ( batch ) self . on_before_training_step () self . on_before_training_step_callbacks () self . increment ( \"step\" ) self . training_step () self . on_after_training_step () self . on_after_training_step_callbacks ()","title":"training_epoch()"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.training_step","text":"The training step, i.e. training for each batch. Goes through the usual hoops of zeroing out the optimizer, forwarding the input, computing the loss, backpropagating and updating the weights. For each different steps, callabacks are offered for maximum versatility and ease of use. Source code in sequel/algos/base_algo.py 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 def training_step ( self , * args , ** kwargs ): \"\"\"The training step, i.e. training for each batch. Goes through the usual hoops of zeroing out the optimizer, forwarding the input, computing the loss, backpropagating and updating the weights. For each different steps, callabacks are offered for maximum versatility and ease of use. \"\"\" self . optimizer_zero_grad () y_hat = self . forward () self . loss = self . compute_loss ( y_hat , self . y , self . t ) self . on_before_backward () self . on_before_backward_callbacks () self . backpropagate_loss () self . on_after_backward () self . on_after_backward_callbacks () self . perform_gradient_clipping () self . on_before_optimizer_step () self . on_before_optimizer_step_callbacks () self . optimizer_step () self . on_after_optimizer_step () self . on_after_optimizer_step_callbacks ()","title":"training_step()"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.unpack_batch","text":"Unpacks the batch and registers to the algorithm the current batch input, targets and task ids as self.x , self.y and self.t , respectively. It also registers the current batch size as self.bs Source code in sequel/algos/base_algo.py 168 169 170 171 def unpack_batch ( self , batch : Any ): \"\"\"Unpacks the batch and registers to the algorithm the current batch input, targets and task ids as `self.x`, `self.y` and `self.t`, respectively. It also registers the current batch size as `self.bs`\"\"\" raise NotImplementedError","title":"unpack_batch()"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.update_episodic_memory","text":"Updates the episodic memory. This funciton is called after fitting one task. Source code in sequel/algos/base_algo.py 120 121 122 123 124 def update_episodic_memory ( self ) -> None : \"\"\"Updates the episodic memory. This funciton is called after fitting one task.\"\"\" logging . info ( \"Updating episodic memory for task {} \" . format ( self . task_counter )) self . episodic_memory_loader = self . benchmark . memory_dataloader ( self . task_counter ) self . episodic_memory_iter = iter ( self . episodic_memory_loader )","title":"update_episodic_memory()"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.valid_step","text":"Performs the validation step.Callbacks are offered for each step of the process. Source code in sequel/algos/base_algo.py 210 211 212 def valid_step ( self , * args , ** kwargs ): \"\"\"Performs the validation step.Callbacks are offered for each step of the process.\"\"\" raise NotImplementedError","title":"valid_step()"},{"location":"algos/jax/agem/","text":"AGEM Bases: JaxBaseAlgorithm A-GEM: Averaged-Gradient Episodic Memory. Maintains a memory of samples from past tasks. The gradients for the current batch are projected to the convex hull of the task gradients produced by the the aforementioned memory. Inherits from BaseAlgorithm. The equivalent PyTorch implementation is A-GEM in Pytorch . References [1] Chaudhry, A., Ranzato, M., Rohrbach, M. & Elhoseiny, M. Efficient Lifelong Learning with A-GEM. in 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. Source code in sequel/algos/jax/agem.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 class AGEM ( JaxBaseAlgorithm ): \"\"\"A-GEM: Averaged-Gradient Episodic Memory. Maintains a memory of samples from past tasks. The gradients for the current batch are projected to the convex hull of the task gradients produced by the the aforementioned memory. Inherits from BaseAlgorithm. The equivalent PyTorch implementation is [`A-GEM in Pytorch`][sequel.algos.pytorch.agem.AGEM]. References: [1] Chaudhry, A., Ranzato, M., Rohrbach, M. & Elhoseiny, M. Efficient Lifelong Learning with A-GEM. in 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. \"\"\" def __init__ ( self , per_task_memory_samples : int , memory_batch_size : int , memory_group_by : Literal [ \"task\" , \"class\" ], * args , ** kwargs , ): \"\"\"Inits the A-GEM algorithm class. Args: per_task_memory_samples (int): number of exemplars per experience in the memory. memory_batch_size (int): the batch size of the memory samples used to modify the gradient update. memory_group_by (Literal[\"task\", \"class\"]): Determines the selection process of samples for the memory. \"\"\" super () . __init__ ( * args , ** kwargs ) self . memory = MemoryMechanism ( per_task_memory_samples = per_task_memory_samples , groupby = memory_group_by ) self . per_task_memory_samples = per_task_memory_samples self . memory_batch_size = memory_batch_size def __repr__ ( self ) -> str : return ( f \"AGEM(memory_batch_size= { self . memory_batch_size } , per_task_memory_samples= { self . per_task_memory_samples } )\" ) def on_after_training_task ( self , * args , ** kwargs ): self . memory . update_memory ( self ) self . update_episodic_memory () logging . info ( \"The episodic memory now stores {} samples\" . format ( len ( self . episodic_memory_loader . dataset ))) def update_episodic_memory ( self ): logging . info ( \"Updating episodic memory for task {} \" . format ( self . task_counter )) self . episodic_memory_loader = self . benchmark . memory_dataloader ( self . task_counter , self . memory_batch_size , return_infinite_stream = True , ) self . episodic_memory_iter = iter ( self . episodic_memory_loader ) def sample_batch_from_memory ( self ): try : return next ( self . episodic_memory_iter ) except StopIteration : # makes the dataloader an infinite stream # The exception is only reached if the argument `return_infinite_stream` is set to False in # [`memory_dataloader`][sequel.benchmarks.base_benchmark.return_infinite_stream] set in # [`update_episodic_memory`][sequel.algos.jax.agem.update_episodic_memory]. self . episodic_memory_iter = iter ( self . episodic_memory_loader ) return next ( self . episodic_memory_iter ) def training_step ( self ): if self . task_counter == 1 : super () . training_step () else : self . batch_outputs = self . agem_training_step ( self . state , self . x , self . y , self . t , self . mem_x , self . mem_y , self . mem_t , self . step_counter ) self . register_batch_outputs ( self . batch_outputs ) def on_before_training_step ( self , * args , ** kwargs ): if self . task_counter > 1 : batch = self . sample_batch_from_memory () x , y , t = self . unpack_batch_functional ( batch ) self . mem_x , self . mem_y , self . mem_t = x , y , t @partial ( jax . jit , static_argnums = ( 0 ,)) def agem_training_step ( self , state : TrainState , x , y , t , mem_x , mem_y , mem_t , step ): \"\"\"The A-GEM training step that uses the memory samples to modify the gradient. Note: this implementation is suboptimal since it computes mem_norm and performs the tree_map operation even if not needed (case of dotg nonnegative). However, it has been implemented in this way in order to jit in a single function the gradient updates. \"\"\" grad_fn = jax . value_and_grad ( self . cross_entropy , has_aux = True , allow_int = True ) ( loss , logits ), old_grads = grad_fn ( state . params , x , y , t , self . is_training , step = step ) # 1000000 is added so that steps are different. This applie for the rng of some modules, e.g. dropout _ , mem_grads = grad_fn ( state . params , mem_x , mem_y , mem_t , self . is_training , step = step + 1000000 ) dotg = jnp . minimum ( dot_product ( old_grads , mem_grads ), 0 ) mem_norm = dot_product ( mem_grads , mem_grads ) alpha = dotg / mem_norm grads = jax . tree_map ( lambda o , m : o - m * alpha , old_grads , mem_grads ) state = state . apply_gradients ( grads = grads ) return dict ( state = state , logits = logits , loss = loss , grads = grads ) __init__ ( per_task_memory_samples , memory_batch_size , memory_group_by , * args , ** kwargs ) Inits the A-GEM algorithm class. Parameters: Name Type Description Default per_task_memory_samples int number of exemplars per experience in the memory. required memory_batch_size int the batch size of the memory samples used to modify the gradient update. required memory_group_by Literal ['task', 'class'] Determines the selection process of samples for the memory. required Source code in sequel/algos/jax/agem.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 def __init__ ( self , per_task_memory_samples : int , memory_batch_size : int , memory_group_by : Literal [ \"task\" , \"class\" ], * args , ** kwargs , ): \"\"\"Inits the A-GEM algorithm class. Args: per_task_memory_samples (int): number of exemplars per experience in the memory. memory_batch_size (int): the batch size of the memory samples used to modify the gradient update. memory_group_by (Literal[\"task\", \"class\"]): Determines the selection process of samples for the memory. \"\"\" super () . __init__ ( * args , ** kwargs ) self . memory = MemoryMechanism ( per_task_memory_samples = per_task_memory_samples , groupby = memory_group_by ) self . per_task_memory_samples = per_task_memory_samples self . memory_batch_size = memory_batch_size agem_training_step ( state , x , y , t , mem_x , mem_y , mem_t , step ) The A-GEM training step that uses the memory samples to modify the gradient. Note this implementation is suboptimal since it computes mem_norm and performs the tree_map operation even if not needed (case of dotg nonnegative). However, it has been implemented in this way in order to jit in a single function the gradient updates. Source code in sequel/algos/jax/agem.py 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 @partial ( jax . jit , static_argnums = ( 0 ,)) def agem_training_step ( self , state : TrainState , x , y , t , mem_x , mem_y , mem_t , step ): \"\"\"The A-GEM training step that uses the memory samples to modify the gradient. Note: this implementation is suboptimal since it computes mem_norm and performs the tree_map operation even if not needed (case of dotg nonnegative). However, it has been implemented in this way in order to jit in a single function the gradient updates. \"\"\" grad_fn = jax . value_and_grad ( self . cross_entropy , has_aux = True , allow_int = True ) ( loss , logits ), old_grads = grad_fn ( state . params , x , y , t , self . is_training , step = step ) # 1000000 is added so that steps are different. This applie for the rng of some modules, e.g. dropout _ , mem_grads = grad_fn ( state . params , mem_x , mem_y , mem_t , self . is_training , step = step + 1000000 ) dotg = jnp . minimum ( dot_product ( old_grads , mem_grads ), 0 ) mem_norm = dot_product ( mem_grads , mem_grads ) alpha = dotg / mem_norm grads = jax . tree_map ( lambda o , m : o - m * alpha , old_grads , mem_grads ) state = state . apply_gradients ( grads = grads ) return dict ( state = state , logits = logits , loss = loss , grads = grads )","title":"AGEM"},{"location":"algos/jax/agem/#sequel.algos.jax.agem.AGEM","text":"Bases: JaxBaseAlgorithm A-GEM: Averaged-Gradient Episodic Memory. Maintains a memory of samples from past tasks. The gradients for the current batch are projected to the convex hull of the task gradients produced by the the aforementioned memory. Inherits from BaseAlgorithm. The equivalent PyTorch implementation is A-GEM in Pytorch . References [1] Chaudhry, A., Ranzato, M., Rohrbach, M. & Elhoseiny, M. Efficient Lifelong Learning with A-GEM. in 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. Source code in sequel/algos/jax/agem.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 class AGEM ( JaxBaseAlgorithm ): \"\"\"A-GEM: Averaged-Gradient Episodic Memory. Maintains a memory of samples from past tasks. The gradients for the current batch are projected to the convex hull of the task gradients produced by the the aforementioned memory. Inherits from BaseAlgorithm. The equivalent PyTorch implementation is [`A-GEM in Pytorch`][sequel.algos.pytorch.agem.AGEM]. References: [1] Chaudhry, A., Ranzato, M., Rohrbach, M. & Elhoseiny, M. Efficient Lifelong Learning with A-GEM. in 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. \"\"\" def __init__ ( self , per_task_memory_samples : int , memory_batch_size : int , memory_group_by : Literal [ \"task\" , \"class\" ], * args , ** kwargs , ): \"\"\"Inits the A-GEM algorithm class. Args: per_task_memory_samples (int): number of exemplars per experience in the memory. memory_batch_size (int): the batch size of the memory samples used to modify the gradient update. memory_group_by (Literal[\"task\", \"class\"]): Determines the selection process of samples for the memory. \"\"\" super () . __init__ ( * args , ** kwargs ) self . memory = MemoryMechanism ( per_task_memory_samples = per_task_memory_samples , groupby = memory_group_by ) self . per_task_memory_samples = per_task_memory_samples self . memory_batch_size = memory_batch_size def __repr__ ( self ) -> str : return ( f \"AGEM(memory_batch_size= { self . memory_batch_size } , per_task_memory_samples= { self . per_task_memory_samples } )\" ) def on_after_training_task ( self , * args , ** kwargs ): self . memory . update_memory ( self ) self . update_episodic_memory () logging . info ( \"The episodic memory now stores {} samples\" . format ( len ( self . episodic_memory_loader . dataset ))) def update_episodic_memory ( self ): logging . info ( \"Updating episodic memory for task {} \" . format ( self . task_counter )) self . episodic_memory_loader = self . benchmark . memory_dataloader ( self . task_counter , self . memory_batch_size , return_infinite_stream = True , ) self . episodic_memory_iter = iter ( self . episodic_memory_loader ) def sample_batch_from_memory ( self ): try : return next ( self . episodic_memory_iter ) except StopIteration : # makes the dataloader an infinite stream # The exception is only reached if the argument `return_infinite_stream` is set to False in # [`memory_dataloader`][sequel.benchmarks.base_benchmark.return_infinite_stream] set in # [`update_episodic_memory`][sequel.algos.jax.agem.update_episodic_memory]. self . episodic_memory_iter = iter ( self . episodic_memory_loader ) return next ( self . episodic_memory_iter ) def training_step ( self ): if self . task_counter == 1 : super () . training_step () else : self . batch_outputs = self . agem_training_step ( self . state , self . x , self . y , self . t , self . mem_x , self . mem_y , self . mem_t , self . step_counter ) self . register_batch_outputs ( self . batch_outputs ) def on_before_training_step ( self , * args , ** kwargs ): if self . task_counter > 1 : batch = self . sample_batch_from_memory () x , y , t = self . unpack_batch_functional ( batch ) self . mem_x , self . mem_y , self . mem_t = x , y , t @partial ( jax . jit , static_argnums = ( 0 ,)) def agem_training_step ( self , state : TrainState , x , y , t , mem_x , mem_y , mem_t , step ): \"\"\"The A-GEM training step that uses the memory samples to modify the gradient. Note: this implementation is suboptimal since it computes mem_norm and performs the tree_map operation even if not needed (case of dotg nonnegative). However, it has been implemented in this way in order to jit in a single function the gradient updates. \"\"\" grad_fn = jax . value_and_grad ( self . cross_entropy , has_aux = True , allow_int = True ) ( loss , logits ), old_grads = grad_fn ( state . params , x , y , t , self . is_training , step = step ) # 1000000 is added so that steps are different. This applie for the rng of some modules, e.g. dropout _ , mem_grads = grad_fn ( state . params , mem_x , mem_y , mem_t , self . is_training , step = step + 1000000 ) dotg = jnp . minimum ( dot_product ( old_grads , mem_grads ), 0 ) mem_norm = dot_product ( mem_grads , mem_grads ) alpha = dotg / mem_norm grads = jax . tree_map ( lambda o , m : o - m * alpha , old_grads , mem_grads ) state = state . apply_gradients ( grads = grads ) return dict ( state = state , logits = logits , loss = loss , grads = grads )","title":"AGEM"},{"location":"algos/jax/agem/#sequel.algos.jax.agem.AGEM.__init__","text":"Inits the A-GEM algorithm class. Parameters: Name Type Description Default per_task_memory_samples int number of exemplars per experience in the memory. required memory_batch_size int the batch size of the memory samples used to modify the gradient update. required memory_group_by Literal ['task', 'class'] Determines the selection process of samples for the memory. required Source code in sequel/algos/jax/agem.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 def __init__ ( self , per_task_memory_samples : int , memory_batch_size : int , memory_group_by : Literal [ \"task\" , \"class\" ], * args , ** kwargs , ): \"\"\"Inits the A-GEM algorithm class. Args: per_task_memory_samples (int): number of exemplars per experience in the memory. memory_batch_size (int): the batch size of the memory samples used to modify the gradient update. memory_group_by (Literal[\"task\", \"class\"]): Determines the selection process of samples for the memory. \"\"\" super () . __init__ ( * args , ** kwargs ) self . memory = MemoryMechanism ( per_task_memory_samples = per_task_memory_samples , groupby = memory_group_by ) self . per_task_memory_samples = per_task_memory_samples self . memory_batch_size = memory_batch_size","title":"__init__()"},{"location":"algos/jax/agem/#sequel.algos.jax.agem.AGEM.agem_training_step","text":"The A-GEM training step that uses the memory samples to modify the gradient. Note this implementation is suboptimal since it computes mem_norm and performs the tree_map operation even if not needed (case of dotg nonnegative). However, it has been implemented in this way in order to jit in a single function the gradient updates. Source code in sequel/algos/jax/agem.py 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 @partial ( jax . jit , static_argnums = ( 0 ,)) def agem_training_step ( self , state : TrainState , x , y , t , mem_x , mem_y , mem_t , step ): \"\"\"The A-GEM training step that uses the memory samples to modify the gradient. Note: this implementation is suboptimal since it computes mem_norm and performs the tree_map operation even if not needed (case of dotg nonnegative). However, it has been implemented in this way in order to jit in a single function the gradient updates. \"\"\" grad_fn = jax . value_and_grad ( self . cross_entropy , has_aux = True , allow_int = True ) ( loss , logits ), old_grads = grad_fn ( state . params , x , y , t , self . is_training , step = step ) # 1000000 is added so that steps are different. This applie for the rng of some modules, e.g. dropout _ , mem_grads = grad_fn ( state . params , mem_x , mem_y , mem_t , self . is_training , step = step + 1000000 ) dotg = jnp . minimum ( dot_product ( old_grads , mem_grads ), 0 ) mem_norm = dot_product ( mem_grads , mem_grads ) alpha = dotg / mem_norm grads = jax . tree_map ( lambda o , m : o - m * alpha , old_grads , mem_grads ) state = state . apply_gradients ( grads = grads ) return dict ( state = state , logits = logits , loss = loss , grads = grads )","title":"agem_training_step()"},{"location":"algos/jax/base_algo/","text":"JaxBaseAlgorithm Bases: BaseAlgorithm Base class for algorithms implemented in JAX. Source code in sequel/algos/jax/jax_base_algo.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 class JaxBaseAlgorithm ( BaseAlgorithm ): \"\"\"Base class for algorithms implemented in JAX.\"\"\" def __init__ ( self , backbone : JaxBaseBackbone , benchmark : Benchmark , optimizer : optax . GradientTransformation , callbacks : Iterable [ BaseCallback ] = [], loggers : Optional [ Iterable [ Logger ]] = None , lr_decay : Optional [ float ] = None , grad_clip : Optional [ float ] = None , reinit_optimizer : bool = True , seed = 0 , ) -> None : \"\"\"Inits JaxBaseAlgorithm class. Args: backbone (JaxBaseBackbone): The backbone model, e.g., a CNN. benchmark (Benchmark): The benchmark, e.g., SplitMNIST. optimizer (optax.GradientTransformation): The optimizer used to update the backbone weights. callbacks (Iterable[BaseCallback], optional): A list of callbacks. At least one instance of MetricCallback should be given. Defaults to []. loggers (Optional[Logger], optional): A list of logger, e.g. for Weights&Biases logging functionality. Defaults to None. lr_decay (Optional[float], optional): A learning rate decay used for every new task. Defaults to None. grad_clip (Optional[float], optional): The gradient clipping norm. Defaults to None. reinit_optimizer (bool): Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True. seed (int, optional): The seed used by JAX. Sets the corresponding `PRNGKey`. Defaults to 0. Note: 1. the `_configure_optimizers` method will be moved to a dedicated Callback. \"\"\" assert isinstance ( backbone , BaseBackbone ) super () . __init__ ( backbone = backbone , benchmark = benchmark , optimizer = optimizer , callbacks = callbacks , loggers = loggers , lr_decay = lr_decay , grad_clip = grad_clip , reinit_optimizer = reinit_optimizer , ) print ( \">\" * 100 ) print ( self . benchmark . num_classes ) print ( \">\" * 100 ) self . seed = seed rng = jax . random . PRNGKey ( seed ) self . rng , init_rng = jax . random . split ( rng ) self . state : TrainState = self . create_train_state ( self . backbone , init_rng , task = None ) self . apply_fn = self . state . apply_fn self . original_optimizer = copy . deepcopy ( self . optimizer ) def create_train_state ( self , model : nn . Module , rng : PRNGKey , task = None ) -> TrainState : \"\"\"Creates initial `TrainState`.\"\"\" dims = self . benchmark . dimensions dimensions = [ 1 ] + dims [ 1 :] + [ dims [ 0 ]] params = model . init ( rng , x = jnp . ones ( dimensions ), task_ids = None , training = False ) tx = self . optimizer rng , self . dropout_key = jax . random . split ( rng ) del rng return TrainState . create ( apply_fn = model . apply , params = params , tx = tx ) def prepare_for_next_task ( self , task : int ): if self . reinit_optimizer : logging . info ( \"Reinitializing optimizer for next task\" ) params = self . state . params apply_fn = self . state . apply_fn tx : optax . GradientTransformation = copy . deepcopy ( self . original_optimizer ) if self . lr_decay is not None and task > 1 : assert isinstance ( self . lr_decay , float ) assert self . lr_decay > 0 and self . lr_decay <= 1 , \"lr decay should be in the interval (0,1]\" new_lr = self . state . opt_state . hyperparams [ \"learning_rate\" ] * self . lr_decay logging . info ( f \"Decaying the learning rate by a factor of { self . lr_decay } to the next lr= { new_lr } \" ) else : new_lr = self . state . opt_state . hyperparams [ \"learning_rate\" ] self . state = TrainState . create ( apply_fn = apply_fn , params = params , tx = tx ) print ( self . state . opt_state . hyperparams ) self . state . opt_state . hyperparams [ \"learning_rate\" ] = new_lr print ( self . state . opt_state . hyperparams ) def count_parameters ( self ): dims = self . benchmark . dimensions dimensions = [ 1 ] + dims [ 1 :] + [ dims [ 0 ]] print ( dimensions ) rng = jax . random . PRNGKey ( 0 ) params = self . backbone . init ( rng , jnp . ones ( dimensions ), task_ids = None , training = False ) return sum ( x . size for x in jax . tree_util . tree_leaves ( params )) def _configure_criterion ( self , task_id = None ): logging . debug ( \"_configure_criterion should change?\" ) def unpack_batch ( self , batch ): self . x , self . y , self . t = self . unpack_batch_functional ( batch ) self . bs = len ( self . x ) def unpack_batch_functional ( self , batch ): x , y , t = batch if x . dim () > 2 : # in case of image datasets x = x . permute ( 0 , 2 , 3 , 1 ) return np . array ( x ), np . array ( y ), np . array ( t ) def perform_gradient_clipping ( self ): warnings . warn ( \"Gradient Clipping has not been implemented for JAX.\" ) pass @partial ( jax . jit , static_argnums = ( 0 , 4 )) def forward ( self , params , x , t , training , step ): dropout_train_key = jax . random . fold_in ( key = self . dropout_key , data = step ) logits = self . apply_fn ( params , x = x , task_ids = t , training = training , rngs = { \"dropout\" : dropout_train_key }, # This applies to ResNet; BathcNorm are not updated for the moment. mutable = False , ) return logits @partial ( jax . jit , static_argnums = ( 0 , 5 )) def cross_entropy ( self , params , x , y , t , training , step = None ): logits = self . forward ( params , x , t , training , step = step ) loss = cross_entropy_loss ( logits = logits , labels = y , num_classes = self . benchmark . num_classes ) return loss , logits @partial ( jax . jit , static_argnums = ( 0 ,)) def base_training_step ( self , state : TrainState , x , y , t , step ): \"\"\"Train for a single step.\"\"\" grad_fn = jax . value_and_grad ( self . cross_entropy , has_aux = True , allow_int = True ) ( loss , logits ), grads = grad_fn ( state . params , x = x , y = y , t = t , training = True , step = step ) state = state . apply_gradients ( grads = grads ) return dict ( state = state , logits = logits , loss = loss , grads = grads ) def register_batch_outputs ( self , batch_outputs ): self . state = batch_outputs [ \"state\" ] self . loss = batch_outputs [ \"loss\" ] self . y_hat = batch_outputs [ \"logits\" ] self . grads = batch_outputs [ \"grads\" ] def training_step ( self ): self . batch_outputs = self . base_training_step ( self . state , self . x , self . y , self . t , step = self . step_counter ) self . register_batch_outputs ( self . batch_outputs ) @partial ( jax . jit , static_argnums = ( 0 ,)) def base_eval_step ( self , state : TrainState , x , t ): return state . apply_fn ( state . params , x , t , training = False ) def valid_step ( self ): self . y_hat = self . base_eval_step ( self . state , self . x , self . t ) __init__ ( backbone , benchmark , optimizer , callbacks = [], loggers = None , lr_decay = None , grad_clip = None , reinit_optimizer = True , seed = 0 ) Inits JaxBaseAlgorithm class. Parameters: Name Type Description Default backbone JaxBaseBackbone The backbone model, e.g., a CNN. required benchmark Benchmark The benchmark, e.g., SplitMNIST. required optimizer optax . GradientTransformation The optimizer used to update the backbone weights. required callbacks Iterable [ BaseCallback ] A list of callbacks. At least one instance of MetricCallback should be given. Defaults to []. [] loggers Optional [ Logger ] A list of logger, e.g. for Weights&Biases logging functionality. Defaults to None. None lr_decay Optional [ float ] A learning rate decay used for every new task. Defaults to None. None grad_clip Optional [ float ] The gradient clipping norm. Defaults to None. None reinit_optimizer bool Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True. True seed int The seed used by JAX. Sets the corresponding PRNGKey . Defaults to 0. 0 Note the _configure_optimizers method will be moved to a dedicated Callback. Source code in sequel/algos/jax/jax_base_algo.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 def __init__ ( self , backbone : JaxBaseBackbone , benchmark : Benchmark , optimizer : optax . GradientTransformation , callbacks : Iterable [ BaseCallback ] = [], loggers : Optional [ Iterable [ Logger ]] = None , lr_decay : Optional [ float ] = None , grad_clip : Optional [ float ] = None , reinit_optimizer : bool = True , seed = 0 , ) -> None : \"\"\"Inits JaxBaseAlgorithm class. Args: backbone (JaxBaseBackbone): The backbone model, e.g., a CNN. benchmark (Benchmark): The benchmark, e.g., SplitMNIST. optimizer (optax.GradientTransformation): The optimizer used to update the backbone weights. callbacks (Iterable[BaseCallback], optional): A list of callbacks. At least one instance of MetricCallback should be given. Defaults to []. loggers (Optional[Logger], optional): A list of logger, e.g. for Weights&Biases logging functionality. Defaults to None. lr_decay (Optional[float], optional): A learning rate decay used for every new task. Defaults to None. grad_clip (Optional[float], optional): The gradient clipping norm. Defaults to None. reinit_optimizer (bool): Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True. seed (int, optional): The seed used by JAX. Sets the corresponding `PRNGKey`. Defaults to 0. Note: 1. the `_configure_optimizers` method will be moved to a dedicated Callback. \"\"\" assert isinstance ( backbone , BaseBackbone ) super () . __init__ ( backbone = backbone , benchmark = benchmark , optimizer = optimizer , callbacks = callbacks , loggers = loggers , lr_decay = lr_decay , grad_clip = grad_clip , reinit_optimizer = reinit_optimizer , ) print ( \">\" * 100 ) print ( self . benchmark . num_classes ) print ( \">\" * 100 ) self . seed = seed rng = jax . random . PRNGKey ( seed ) self . rng , init_rng = jax . random . split ( rng ) self . state : TrainState = self . create_train_state ( self . backbone , init_rng , task = None ) self . apply_fn = self . state . apply_fn self . original_optimizer = copy . deepcopy ( self . optimizer ) base_training_step ( state , x , y , t , step ) Train for a single step. Source code in sequel/algos/jax/jax_base_algo.py 162 163 164 165 166 167 168 @partial ( jax . jit , static_argnums = ( 0 ,)) def base_training_step ( self , state : TrainState , x , y , t , step ): \"\"\"Train for a single step.\"\"\" grad_fn = jax . value_and_grad ( self . cross_entropy , has_aux = True , allow_int = True ) ( loss , logits ), grads = grad_fn ( state . params , x = x , y = y , t = t , training = True , step = step ) state = state . apply_gradients ( grads = grads ) return dict ( state = state , logits = logits , loss = loss , grads = grads ) create_train_state ( model , rng , task = None ) Creates initial TrainState . Source code in sequel/algos/jax/jax_base_algo.py 86 87 88 89 90 91 92 93 94 95 96 def create_train_state ( self , model : nn . Module , rng : PRNGKey , task = None ) -> TrainState : \"\"\"Creates initial `TrainState`.\"\"\" dims = self . benchmark . dimensions dimensions = [ 1 ] + dims [ 1 :] + [ dims [ 0 ]] params = model . init ( rng , x = jnp . ones ( dimensions ), task_ids = None , training = False ) tx = self . optimizer rng , self . dropout_key = jax . random . split ( rng ) del rng return TrainState . create ( apply_fn = model . apply , params = params , tx = tx ) JaxRegularizationBaseAlgorithm Bases: JaxBaseAlgorithm JaxRegularizationBaseAlgorithm inherits from JaxBaseAlgorithm and implements a few utility functions that are used by all regularization-based algorithms such as calculating the regularization loss and computing the per-parameter importance. Source code in sequel/algos/jax/jax_base_algo.py 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 class JaxRegularizationBaseAlgorithm ( JaxBaseAlgorithm ): \"\"\"JaxRegularizationBaseAlgorithm inherits from `JaxBaseAlgorithm` and implements a few utility functions that are used by all regularization-based algorithms such as calculating the regularization loss and computing the per-parameter importance. \"\"\" def __init__ ( self , regularization_coefficient : float , * args , ** kwargs ) -> None : \"\"\"Base class for regularization-based algorithms implemented in JAX, such as EWC and SI Args: regularization_coefficient (float): the coefficient used to weigh the regularization loss. \"\"\" super () . __init__ ( * args , ** kwargs ) self . regularization_coefficient = regularization_coefficient self . old_params = None self . importance = None @partial ( jax . jit , static_argnums = ( 0 ,)) def calculate_regularization_loss ( self , params ): assert self . task_counter > 1 return tree_reduce ( lambda x , y : jnp . sum ( x ) + jnp . sum ( y ), tree_map ( lambda a , b , w : jnp . sum ( w * ( a - b ) ** 2.0 ), params , self . old_params , self . importance , ), ) @partial ( jax . jit , static_argnums = ( 0 ,)) def compute_overall_loss ( self , params , x , y , t , step ): ewc_loss = self . calculate_regularization_loss ( params ) loss , logits = self . cross_entropy ( params , x , y , t , training = True , step = step ) loss += self . regularization_coefficient * ewc_loss return loss , logits @partial ( jax . jit , static_argnums = ( 0 ,)) def regularization_training_step ( self , state : TrainState , x , y , t , step ): grad_fn = jax . value_and_grad ( self . compute_overall_loss , has_aux = True , allow_int = True ) ( loss , logits ), grads = grad_fn ( state . params , x , y , t , step = step ) state = state . apply_gradients ( grads = grads ) return dict ( state = state , logits = logits , loss = loss , grads = grads ) def training_step ( self , * args , ** kwargs ): if self . task_counter == 1 : return super () . training_step () else : self . batch_outputs = self . regularization_training_step ( self . state , self . x , self . y , self . t , step = self . step_counter ) self . register_batch_outputs ( self . batch_outputs ) __init__ ( regularization_coefficient , * args , ** kwargs ) Base class for regularization-based algorithms implemented in JAX, such as EWC and SI Parameters: Name Type Description Default regularization_coefficient float the coefficient used to weigh the regularization loss. required Source code in sequel/algos/jax/jax_base_algo.py 198 199 200 201 202 203 204 205 206 207 def __init__ ( self , regularization_coefficient : float , * args , ** kwargs ) -> None : \"\"\"Base class for regularization-based algorithms implemented in JAX, such as EWC and SI Args: regularization_coefficient (float): the coefficient used to weigh the regularization loss. \"\"\" super () . __init__ ( * args , ** kwargs ) self . regularization_coefficient = regularization_coefficient self . old_params = None self . importance = None","title":"JaxBaseAlgo"},{"location":"algos/jax/base_algo/#sequel.algos.jax.jax_base_algo.JaxBaseAlgorithm","text":"Bases: BaseAlgorithm Base class for algorithms implemented in JAX. Source code in sequel/algos/jax/jax_base_algo.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 class JaxBaseAlgorithm ( BaseAlgorithm ): \"\"\"Base class for algorithms implemented in JAX.\"\"\" def __init__ ( self , backbone : JaxBaseBackbone , benchmark : Benchmark , optimizer : optax . GradientTransformation , callbacks : Iterable [ BaseCallback ] = [], loggers : Optional [ Iterable [ Logger ]] = None , lr_decay : Optional [ float ] = None , grad_clip : Optional [ float ] = None , reinit_optimizer : bool = True , seed = 0 , ) -> None : \"\"\"Inits JaxBaseAlgorithm class. Args: backbone (JaxBaseBackbone): The backbone model, e.g., a CNN. benchmark (Benchmark): The benchmark, e.g., SplitMNIST. optimizer (optax.GradientTransformation): The optimizer used to update the backbone weights. callbacks (Iterable[BaseCallback], optional): A list of callbacks. At least one instance of MetricCallback should be given. Defaults to []. loggers (Optional[Logger], optional): A list of logger, e.g. for Weights&Biases logging functionality. Defaults to None. lr_decay (Optional[float], optional): A learning rate decay used for every new task. Defaults to None. grad_clip (Optional[float], optional): The gradient clipping norm. Defaults to None. reinit_optimizer (bool): Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True. seed (int, optional): The seed used by JAX. Sets the corresponding `PRNGKey`. Defaults to 0. Note: 1. the `_configure_optimizers` method will be moved to a dedicated Callback. \"\"\" assert isinstance ( backbone , BaseBackbone ) super () . __init__ ( backbone = backbone , benchmark = benchmark , optimizer = optimizer , callbacks = callbacks , loggers = loggers , lr_decay = lr_decay , grad_clip = grad_clip , reinit_optimizer = reinit_optimizer , ) print ( \">\" * 100 ) print ( self . benchmark . num_classes ) print ( \">\" * 100 ) self . seed = seed rng = jax . random . PRNGKey ( seed ) self . rng , init_rng = jax . random . split ( rng ) self . state : TrainState = self . create_train_state ( self . backbone , init_rng , task = None ) self . apply_fn = self . state . apply_fn self . original_optimizer = copy . deepcopy ( self . optimizer ) def create_train_state ( self , model : nn . Module , rng : PRNGKey , task = None ) -> TrainState : \"\"\"Creates initial `TrainState`.\"\"\" dims = self . benchmark . dimensions dimensions = [ 1 ] + dims [ 1 :] + [ dims [ 0 ]] params = model . init ( rng , x = jnp . ones ( dimensions ), task_ids = None , training = False ) tx = self . optimizer rng , self . dropout_key = jax . random . split ( rng ) del rng return TrainState . create ( apply_fn = model . apply , params = params , tx = tx ) def prepare_for_next_task ( self , task : int ): if self . reinit_optimizer : logging . info ( \"Reinitializing optimizer for next task\" ) params = self . state . params apply_fn = self . state . apply_fn tx : optax . GradientTransformation = copy . deepcopy ( self . original_optimizer ) if self . lr_decay is not None and task > 1 : assert isinstance ( self . lr_decay , float ) assert self . lr_decay > 0 and self . lr_decay <= 1 , \"lr decay should be in the interval (0,1]\" new_lr = self . state . opt_state . hyperparams [ \"learning_rate\" ] * self . lr_decay logging . info ( f \"Decaying the learning rate by a factor of { self . lr_decay } to the next lr= { new_lr } \" ) else : new_lr = self . state . opt_state . hyperparams [ \"learning_rate\" ] self . state = TrainState . create ( apply_fn = apply_fn , params = params , tx = tx ) print ( self . state . opt_state . hyperparams ) self . state . opt_state . hyperparams [ \"learning_rate\" ] = new_lr print ( self . state . opt_state . hyperparams ) def count_parameters ( self ): dims = self . benchmark . dimensions dimensions = [ 1 ] + dims [ 1 :] + [ dims [ 0 ]] print ( dimensions ) rng = jax . random . PRNGKey ( 0 ) params = self . backbone . init ( rng , jnp . ones ( dimensions ), task_ids = None , training = False ) return sum ( x . size for x in jax . tree_util . tree_leaves ( params )) def _configure_criterion ( self , task_id = None ): logging . debug ( \"_configure_criterion should change?\" ) def unpack_batch ( self , batch ): self . x , self . y , self . t = self . unpack_batch_functional ( batch ) self . bs = len ( self . x ) def unpack_batch_functional ( self , batch ): x , y , t = batch if x . dim () > 2 : # in case of image datasets x = x . permute ( 0 , 2 , 3 , 1 ) return np . array ( x ), np . array ( y ), np . array ( t ) def perform_gradient_clipping ( self ): warnings . warn ( \"Gradient Clipping has not been implemented for JAX.\" ) pass @partial ( jax . jit , static_argnums = ( 0 , 4 )) def forward ( self , params , x , t , training , step ): dropout_train_key = jax . random . fold_in ( key = self . dropout_key , data = step ) logits = self . apply_fn ( params , x = x , task_ids = t , training = training , rngs = { \"dropout\" : dropout_train_key }, # This applies to ResNet; BathcNorm are not updated for the moment. mutable = False , ) return logits @partial ( jax . jit , static_argnums = ( 0 , 5 )) def cross_entropy ( self , params , x , y , t , training , step = None ): logits = self . forward ( params , x , t , training , step = step ) loss = cross_entropy_loss ( logits = logits , labels = y , num_classes = self . benchmark . num_classes ) return loss , logits @partial ( jax . jit , static_argnums = ( 0 ,)) def base_training_step ( self , state : TrainState , x , y , t , step ): \"\"\"Train for a single step.\"\"\" grad_fn = jax . value_and_grad ( self . cross_entropy , has_aux = True , allow_int = True ) ( loss , logits ), grads = grad_fn ( state . params , x = x , y = y , t = t , training = True , step = step ) state = state . apply_gradients ( grads = grads ) return dict ( state = state , logits = logits , loss = loss , grads = grads ) def register_batch_outputs ( self , batch_outputs ): self . state = batch_outputs [ \"state\" ] self . loss = batch_outputs [ \"loss\" ] self . y_hat = batch_outputs [ \"logits\" ] self . grads = batch_outputs [ \"grads\" ] def training_step ( self ): self . batch_outputs = self . base_training_step ( self . state , self . x , self . y , self . t , step = self . step_counter ) self . register_batch_outputs ( self . batch_outputs ) @partial ( jax . jit , static_argnums = ( 0 ,)) def base_eval_step ( self , state : TrainState , x , t ): return state . apply_fn ( state . params , x , t , training = False ) def valid_step ( self ): self . y_hat = self . base_eval_step ( self . state , self . x , self . t )","title":"JaxBaseAlgorithm"},{"location":"algos/jax/base_algo/#sequel.algos.jax.jax_base_algo.JaxBaseAlgorithm.__init__","text":"Inits JaxBaseAlgorithm class. Parameters: Name Type Description Default backbone JaxBaseBackbone The backbone model, e.g., a CNN. required benchmark Benchmark The benchmark, e.g., SplitMNIST. required optimizer optax . GradientTransformation The optimizer used to update the backbone weights. required callbacks Iterable [ BaseCallback ] A list of callbacks. At least one instance of MetricCallback should be given. Defaults to []. [] loggers Optional [ Logger ] A list of logger, e.g. for Weights&Biases logging functionality. Defaults to None. None lr_decay Optional [ float ] A learning rate decay used for every new task. Defaults to None. None grad_clip Optional [ float ] The gradient clipping norm. Defaults to None. None reinit_optimizer bool Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True. True seed int The seed used by JAX. Sets the corresponding PRNGKey . Defaults to 0. 0 Note the _configure_optimizers method will be moved to a dedicated Callback. Source code in sequel/algos/jax/jax_base_algo.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 def __init__ ( self , backbone : JaxBaseBackbone , benchmark : Benchmark , optimizer : optax . GradientTransformation , callbacks : Iterable [ BaseCallback ] = [], loggers : Optional [ Iterable [ Logger ]] = None , lr_decay : Optional [ float ] = None , grad_clip : Optional [ float ] = None , reinit_optimizer : bool = True , seed = 0 , ) -> None : \"\"\"Inits JaxBaseAlgorithm class. Args: backbone (JaxBaseBackbone): The backbone model, e.g., a CNN. benchmark (Benchmark): The benchmark, e.g., SplitMNIST. optimizer (optax.GradientTransformation): The optimizer used to update the backbone weights. callbacks (Iterable[BaseCallback], optional): A list of callbacks. At least one instance of MetricCallback should be given. Defaults to []. loggers (Optional[Logger], optional): A list of logger, e.g. for Weights&Biases logging functionality. Defaults to None. lr_decay (Optional[float], optional): A learning rate decay used for every new task. Defaults to None. grad_clip (Optional[float], optional): The gradient clipping norm. Defaults to None. reinit_optimizer (bool): Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True. seed (int, optional): The seed used by JAX. Sets the corresponding `PRNGKey`. Defaults to 0. Note: 1. the `_configure_optimizers` method will be moved to a dedicated Callback. \"\"\" assert isinstance ( backbone , BaseBackbone ) super () . __init__ ( backbone = backbone , benchmark = benchmark , optimizer = optimizer , callbacks = callbacks , loggers = loggers , lr_decay = lr_decay , grad_clip = grad_clip , reinit_optimizer = reinit_optimizer , ) print ( \">\" * 100 ) print ( self . benchmark . num_classes ) print ( \">\" * 100 ) self . seed = seed rng = jax . random . PRNGKey ( seed ) self . rng , init_rng = jax . random . split ( rng ) self . state : TrainState = self . create_train_state ( self . backbone , init_rng , task = None ) self . apply_fn = self . state . apply_fn self . original_optimizer = copy . deepcopy ( self . optimizer )","title":"__init__()"},{"location":"algos/jax/base_algo/#sequel.algos.jax.jax_base_algo.JaxBaseAlgorithm.base_training_step","text":"Train for a single step. Source code in sequel/algos/jax/jax_base_algo.py 162 163 164 165 166 167 168 @partial ( jax . jit , static_argnums = ( 0 ,)) def base_training_step ( self , state : TrainState , x , y , t , step ): \"\"\"Train for a single step.\"\"\" grad_fn = jax . value_and_grad ( self . cross_entropy , has_aux = True , allow_int = True ) ( loss , logits ), grads = grad_fn ( state . params , x = x , y = y , t = t , training = True , step = step ) state = state . apply_gradients ( grads = grads ) return dict ( state = state , logits = logits , loss = loss , grads = grads )","title":"base_training_step()"},{"location":"algos/jax/base_algo/#sequel.algos.jax.jax_base_algo.JaxBaseAlgorithm.create_train_state","text":"Creates initial TrainState . Source code in sequel/algos/jax/jax_base_algo.py 86 87 88 89 90 91 92 93 94 95 96 def create_train_state ( self , model : nn . Module , rng : PRNGKey , task = None ) -> TrainState : \"\"\"Creates initial `TrainState`.\"\"\" dims = self . benchmark . dimensions dimensions = [ 1 ] + dims [ 1 :] + [ dims [ 0 ]] params = model . init ( rng , x = jnp . ones ( dimensions ), task_ids = None , training = False ) tx = self . optimizer rng , self . dropout_key = jax . random . split ( rng ) del rng return TrainState . create ( apply_fn = model . apply , params = params , tx = tx )","title":"create_train_state()"},{"location":"algos/jax/base_algo/#sequel.algos.jax.jax_base_algo.JaxRegularizationBaseAlgorithm","text":"Bases: JaxBaseAlgorithm JaxRegularizationBaseAlgorithm inherits from JaxBaseAlgorithm and implements a few utility functions that are used by all regularization-based algorithms such as calculating the regularization loss and computing the per-parameter importance. Source code in sequel/algos/jax/jax_base_algo.py 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 class JaxRegularizationBaseAlgorithm ( JaxBaseAlgorithm ): \"\"\"JaxRegularizationBaseAlgorithm inherits from `JaxBaseAlgorithm` and implements a few utility functions that are used by all regularization-based algorithms such as calculating the regularization loss and computing the per-parameter importance. \"\"\" def __init__ ( self , regularization_coefficient : float , * args , ** kwargs ) -> None : \"\"\"Base class for regularization-based algorithms implemented in JAX, such as EWC and SI Args: regularization_coefficient (float): the coefficient used to weigh the regularization loss. \"\"\" super () . __init__ ( * args , ** kwargs ) self . regularization_coefficient = regularization_coefficient self . old_params = None self . importance = None @partial ( jax . jit , static_argnums = ( 0 ,)) def calculate_regularization_loss ( self , params ): assert self . task_counter > 1 return tree_reduce ( lambda x , y : jnp . sum ( x ) + jnp . sum ( y ), tree_map ( lambda a , b , w : jnp . sum ( w * ( a - b ) ** 2.0 ), params , self . old_params , self . importance , ), ) @partial ( jax . jit , static_argnums = ( 0 ,)) def compute_overall_loss ( self , params , x , y , t , step ): ewc_loss = self . calculate_regularization_loss ( params ) loss , logits = self . cross_entropy ( params , x , y , t , training = True , step = step ) loss += self . regularization_coefficient * ewc_loss return loss , logits @partial ( jax . jit , static_argnums = ( 0 ,)) def regularization_training_step ( self , state : TrainState , x , y , t , step ): grad_fn = jax . value_and_grad ( self . compute_overall_loss , has_aux = True , allow_int = True ) ( loss , logits ), grads = grad_fn ( state . params , x , y , t , step = step ) state = state . apply_gradients ( grads = grads ) return dict ( state = state , logits = logits , loss = loss , grads = grads ) def training_step ( self , * args , ** kwargs ): if self . task_counter == 1 : return super () . training_step () else : self . batch_outputs = self . regularization_training_step ( self . state , self . x , self . y , self . t , step = self . step_counter ) self . register_batch_outputs ( self . batch_outputs )","title":"JaxRegularizationBaseAlgorithm"},{"location":"algos/jax/base_algo/#sequel.algos.jax.jax_base_algo.JaxRegularizationBaseAlgorithm.__init__","text":"Base class for regularization-based algorithms implemented in JAX, such as EWC and SI Parameters: Name Type Description Default regularization_coefficient float the coefficient used to weigh the regularization loss. required Source code in sequel/algos/jax/jax_base_algo.py 198 199 200 201 202 203 204 205 206 207 def __init__ ( self , regularization_coefficient : float , * args , ** kwargs ) -> None : \"\"\"Base class for regularization-based algorithms implemented in JAX, such as EWC and SI Args: regularization_coefficient (float): the coefficient used to weigh the regularization loss. \"\"\" super () . __init__ ( * args , ** kwargs ) self . regularization_coefficient = regularization_coefficient self . old_params = None self . importance = None","title":"__init__()"},{"location":"algos/jax/der/","text":"DER Bases: JaxBaseAlgorithm Dark Experience Replay algorithm implemented in JAX. The equivalent PyTorch implementation is DER in Pytorch . References [1] Buzzega, P., Boschini, M., Porrello, A., Abati, D. & Calderara, S. Dark experience for general continual learning: a strong, simple baseline. in Advances in neural information processing systems 2020. Source code in sequel/algos/jax/der.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 class DER ( JaxBaseAlgorithm ): \"\"\"Dark Experience Replay algorithm implemented in JAX. The equivalent PyTorch implementation is [`DER in Pytorch`][sequel.algos.pytorch.der.DER]. References: [1] Buzzega, P., Boschini, M., Porrello, A., Abati, D. & Calderara, S. Dark experience for general continual learning: a strong, simple baseline. in Advances in neural information processing systems 2020. \"\"\" def __init__ ( self , memory_size : int , alpha : float , beta : Optional [ float ] = None , * args , ** kwargs ): \"\"\"Inits the DER class. Implements the Dark Experience Replay algorithm. Args: memory_size (int): The size of the memory. alpha (float): The regularization coefficient for the DER objective. beta (Optional[float], optional): The regulrization coefficent for the DER++ objective. If set to None or zero, the algorithm corresponds to DER. Defaults to None. \"\"\" super () . __init__ ( * args , ** kwargs ) self . buffer = Buffer ( memory_size = memory_size , return_logits = True ) self . memory_size = memory_size self . alpha = alpha # Beta is used for DER++ self . beta = beta def __repr__ ( self ) -> str : if self . beta is None : return f \"DER(memory_size= { self . memory_size } , alpha= { self . alpha } )\" else : return f \"DER++(memory_size= { self . memory_size } , alpha= { self . alpha } , beta= { self . beta } )\" @partial ( jax . jit , static_argnums = ( 0 ,)) def der_loss ( self , params , x , y , t ): # TODO: add task id support dropout_train_key = jax . random . fold_in ( key = self . dropout_key , data = self . state . step ) logits = self . apply_fn ( params , x = x , training = self . is_training , rngs = { \"dropout\" : dropout_train_key }) loss = cross_entropy_loss ( logits = logits , labels = y ) # DER LOSS dropout_key = jax . random . fold_in ( key = dropout_train_key , data = self . state . step ) mem_y_hat = self . apply_fn ( params , x = x , training = self . is_training , rngs = { \"dropout\" : dropout_key }) der_loss = jnp . mean (( self . mem_logits - mem_y_hat ) ** 2 ) loss += self . alpha * der_loss return loss , logits @partial ( jax . jit , static_argnums = ( 0 ,)) def derpp_loss ( self , params , x , y , t ): # TODO: add task id support dropout_key = jax . random . fold_in ( key = self . dropout_key , data = self . state . step ) logits = self . apply_fn ( params , x = x , t = t , training = self . is_training , rngs = { \"dropout\" : dropout_key }) loss = cross_entropy_loss ( logits = logits , labels = y ) # DER LOSS dropout_key = jax . random . fold_in ( key = dropout_key , data = self . state . step ) mem_y_hat = self . apply_fn ( params , x = self . mem_x , training = self . is_training , rngs = { \"dropout\" : dropout_key }) der_loss = jnp . mean (( self . mem_logits - mem_y_hat ) ** 2 ) # DER++ LOSS dropout_key = jax . random . fold_in ( key = dropout_key , data = self . state . step ) mem_y_hat2 = self . apply_fn ( params , x = x , training = self . is_training , rngs = { \"dropout\" : dropout_key }) derpp_loss = cross_entropy_loss ( logits = mem_y_hat2 , labels = self . mem_y2 ) loss += self . alpha * der_loss + self . beta * derpp_loss return loss , logits @partial ( jax . jit , static_argnums = ( 0 , 5 )) def custom_training_step ( self , state : TrainState , x , y , t , loss_fn ): \"\"\"Train for a single step.\"\"\" grad_fn = jax . value_and_grad ( loss_fn , has_aux = True , allow_int = True ) ( loss , logits ), grads = grad_fn ( state . params , x = x , y = y , t = t ) state = state . apply_gradients ( grads = grads ) return dict ( state = state , logits = logits , loss = loss , grads = grads ) def training_step ( self , * args , ** kwargs ): if self . task_counter == 1 : self . batch_outputs = self . base_training_step ( self . state , self . x , self . y , self . t ) else : x , y , t , logits = self . buffer . sample_from_buffer ( batch_size = self . benchmark . batch_size ) self . mem_x , self . mem_y , self . mem_t , self . mem_logits = x , y , t , logits if self . beta is None : self . batch_outputs = self . custom_training_step ( self . state , self . x , self . y , self . t , self . der_loss ) else : x , y , t , _ = self . buffer . sample_from_buffer ( batch_size = self . benchmark . batch_size ) self . mem_x2 , self . mem_y2 , self . mem_t2 = x , y , t self . batch_outputs = self . custom_training_step ( self . state , self . x , self . y , self . t , self . derpp_loss ) self . register_batch_outputs ( self . batch_outputs ) def on_after_training_step ( self , * args , ** kwargs ): self . buffer . add_data ( self . x , self . y , self . t , self . y_hat ) __init__ ( memory_size , alpha , beta = None , * args , ** kwargs ) Inits the DER class. Implements the Dark Experience Replay algorithm. Parameters: Name Type Description Default memory_size int The size of the memory. required alpha float The regularization coefficient for the DER objective. required beta Optional [ float ] The regulrization coefficent for the DER++ objective. If set to None or zero, the algorithm corresponds to DER. Defaults to None. None Source code in sequel/algos/jax/der.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , memory_size : int , alpha : float , beta : Optional [ float ] = None , * args , ** kwargs ): \"\"\"Inits the DER class. Implements the Dark Experience Replay algorithm. Args: memory_size (int): The size of the memory. alpha (float): The regularization coefficient for the DER objective. beta (Optional[float], optional): The regulrization coefficent for the DER++ objective. If set to None or zero, the algorithm corresponds to DER. Defaults to None. \"\"\" super () . __init__ ( * args , ** kwargs ) self . buffer = Buffer ( memory_size = memory_size , return_logits = True ) self . memory_size = memory_size self . alpha = alpha # Beta is used for DER++ self . beta = beta custom_training_step ( state , x , y , t , loss_fn ) Train for a single step. Source code in sequel/algos/jax/der.py 81 82 83 84 85 86 87 @partial ( jax . jit , static_argnums = ( 0 , 5 )) def custom_training_step ( self , state : TrainState , x , y , t , loss_fn ): \"\"\"Train for a single step.\"\"\" grad_fn = jax . value_and_grad ( loss_fn , has_aux = True , allow_int = True ) ( loss , logits ), grads = grad_fn ( state . params , x = x , y = y , t = t ) state = state . apply_gradients ( grads = grads ) return dict ( state = state , logits = logits , loss = loss , grads = grads )","title":"DER"},{"location":"algos/jax/der/#sequel.algos.jax.der.DER","text":"Bases: JaxBaseAlgorithm Dark Experience Replay algorithm implemented in JAX. The equivalent PyTorch implementation is DER in Pytorch . References [1] Buzzega, P., Boschini, M., Porrello, A., Abati, D. & Calderara, S. Dark experience for general continual learning: a strong, simple baseline. in Advances in neural information processing systems 2020. Source code in sequel/algos/jax/der.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 class DER ( JaxBaseAlgorithm ): \"\"\"Dark Experience Replay algorithm implemented in JAX. The equivalent PyTorch implementation is [`DER in Pytorch`][sequel.algos.pytorch.der.DER]. References: [1] Buzzega, P., Boschini, M., Porrello, A., Abati, D. & Calderara, S. Dark experience for general continual learning: a strong, simple baseline. in Advances in neural information processing systems 2020. \"\"\" def __init__ ( self , memory_size : int , alpha : float , beta : Optional [ float ] = None , * args , ** kwargs ): \"\"\"Inits the DER class. Implements the Dark Experience Replay algorithm. Args: memory_size (int): The size of the memory. alpha (float): The regularization coefficient for the DER objective. beta (Optional[float], optional): The regulrization coefficent for the DER++ objective. If set to None or zero, the algorithm corresponds to DER. Defaults to None. \"\"\" super () . __init__ ( * args , ** kwargs ) self . buffer = Buffer ( memory_size = memory_size , return_logits = True ) self . memory_size = memory_size self . alpha = alpha # Beta is used for DER++ self . beta = beta def __repr__ ( self ) -> str : if self . beta is None : return f \"DER(memory_size= { self . memory_size } , alpha= { self . alpha } )\" else : return f \"DER++(memory_size= { self . memory_size } , alpha= { self . alpha } , beta= { self . beta } )\" @partial ( jax . jit , static_argnums = ( 0 ,)) def der_loss ( self , params , x , y , t ): # TODO: add task id support dropout_train_key = jax . random . fold_in ( key = self . dropout_key , data = self . state . step ) logits = self . apply_fn ( params , x = x , training = self . is_training , rngs = { \"dropout\" : dropout_train_key }) loss = cross_entropy_loss ( logits = logits , labels = y ) # DER LOSS dropout_key = jax . random . fold_in ( key = dropout_train_key , data = self . state . step ) mem_y_hat = self . apply_fn ( params , x = x , training = self . is_training , rngs = { \"dropout\" : dropout_key }) der_loss = jnp . mean (( self . mem_logits - mem_y_hat ) ** 2 ) loss += self . alpha * der_loss return loss , logits @partial ( jax . jit , static_argnums = ( 0 ,)) def derpp_loss ( self , params , x , y , t ): # TODO: add task id support dropout_key = jax . random . fold_in ( key = self . dropout_key , data = self . state . step ) logits = self . apply_fn ( params , x = x , t = t , training = self . is_training , rngs = { \"dropout\" : dropout_key }) loss = cross_entropy_loss ( logits = logits , labels = y ) # DER LOSS dropout_key = jax . random . fold_in ( key = dropout_key , data = self . state . step ) mem_y_hat = self . apply_fn ( params , x = self . mem_x , training = self . is_training , rngs = { \"dropout\" : dropout_key }) der_loss = jnp . mean (( self . mem_logits - mem_y_hat ) ** 2 ) # DER++ LOSS dropout_key = jax . random . fold_in ( key = dropout_key , data = self . state . step ) mem_y_hat2 = self . apply_fn ( params , x = x , training = self . is_training , rngs = { \"dropout\" : dropout_key }) derpp_loss = cross_entropy_loss ( logits = mem_y_hat2 , labels = self . mem_y2 ) loss += self . alpha * der_loss + self . beta * derpp_loss return loss , logits @partial ( jax . jit , static_argnums = ( 0 , 5 )) def custom_training_step ( self , state : TrainState , x , y , t , loss_fn ): \"\"\"Train for a single step.\"\"\" grad_fn = jax . value_and_grad ( loss_fn , has_aux = True , allow_int = True ) ( loss , logits ), grads = grad_fn ( state . params , x = x , y = y , t = t ) state = state . apply_gradients ( grads = grads ) return dict ( state = state , logits = logits , loss = loss , grads = grads ) def training_step ( self , * args , ** kwargs ): if self . task_counter == 1 : self . batch_outputs = self . base_training_step ( self . state , self . x , self . y , self . t ) else : x , y , t , logits = self . buffer . sample_from_buffer ( batch_size = self . benchmark . batch_size ) self . mem_x , self . mem_y , self . mem_t , self . mem_logits = x , y , t , logits if self . beta is None : self . batch_outputs = self . custom_training_step ( self . state , self . x , self . y , self . t , self . der_loss ) else : x , y , t , _ = self . buffer . sample_from_buffer ( batch_size = self . benchmark . batch_size ) self . mem_x2 , self . mem_y2 , self . mem_t2 = x , y , t self . batch_outputs = self . custom_training_step ( self . state , self . x , self . y , self . t , self . derpp_loss ) self . register_batch_outputs ( self . batch_outputs ) def on_after_training_step ( self , * args , ** kwargs ): self . buffer . add_data ( self . x , self . y , self . t , self . y_hat )","title":"DER"},{"location":"algos/jax/der/#sequel.algos.jax.der.DER.__init__","text":"Inits the DER class. Implements the Dark Experience Replay algorithm. Parameters: Name Type Description Default memory_size int The size of the memory. required alpha float The regularization coefficient for the DER objective. required beta Optional [ float ] The regulrization coefficent for the DER++ objective. If set to None or zero, the algorithm corresponds to DER. Defaults to None. None Source code in sequel/algos/jax/der.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , memory_size : int , alpha : float , beta : Optional [ float ] = None , * args , ** kwargs ): \"\"\"Inits the DER class. Implements the Dark Experience Replay algorithm. Args: memory_size (int): The size of the memory. alpha (float): The regularization coefficient for the DER objective. beta (Optional[float], optional): The regulrization coefficent for the DER++ objective. If set to None or zero, the algorithm corresponds to DER. Defaults to None. \"\"\" super () . __init__ ( * args , ** kwargs ) self . buffer = Buffer ( memory_size = memory_size , return_logits = True ) self . memory_size = memory_size self . alpha = alpha # Beta is used for DER++ self . beta = beta","title":"__init__()"},{"location":"algos/jax/der/#sequel.algos.jax.der.DER.custom_training_step","text":"Train for a single step. Source code in sequel/algos/jax/der.py 81 82 83 84 85 86 87 @partial ( jax . jit , static_argnums = ( 0 , 5 )) def custom_training_step ( self , state : TrainState , x , y , t , loss_fn ): \"\"\"Train for a single step.\"\"\" grad_fn = jax . value_and_grad ( loss_fn , has_aux = True , allow_int = True ) ( loss , logits ), grads = grad_fn ( state . params , x = x , y = y , t = t ) state = state . apply_gradients ( grads = grads ) return dict ( state = state , logits = logits , loss = loss , grads = grads )","title":"custom_training_step()"},{"location":"algos/jax/er/","text":"","title":"ER"},{"location":"algos/jax/ewc/","text":"EWC Bases: JaxRegularizationBaseAlgorithm The Elastic Weight Consolidation algorithm. The equivalent PyTorch implementation is EWC in Pytorch . References [1] Kirkpatrick, J. et al. Overcoming catastrophic forgetting in neural networks. PNAS 114, 3521-3526 (2017). Source code in sequel/algos/jax/ewc.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 class EWC ( JaxRegularizationBaseAlgorithm ): \"\"\"The Elastic Weight Consolidation algorithm. The equivalent PyTorch implementation is [`EWC in Pytorch`][sequel.algos.pytorch.ewc.EWC]. References: [1] Kirkpatrick, J. et al. Overcoming catastrophic forgetting in neural networks. PNAS 114, 3521-3526 (2017). \"\"\" def __init__ ( self , ewc_lambda : float , * args , ** kwargs ) -> None : super () . __init__ ( regularization_coefficient = ewc_lambda , * args , ** kwargs ) def __repr__ ( self ) -> str : return f \"EWC(ewc_lambda= { self . regularization_coefficient } )\" @partial ( jax . jit , static_argnums = ( 0 ,)) def fisher_training_step ( self , state , x , y , t , step ): grad_fn = jax . value_and_grad ( self . cross_entropy , has_aux = True , allow_int = True ) ( loss , logits ), grads = grad_fn ( state . params , x , y , t , training = True , step = step ) return grads def on_after_training_task ( self , * args , ** kwargs ): self . train_loader = self . benchmark . train_dataloader ( self . task_counter ) # initialize fisher diagonals to zero fisher_diagonals = jax . tree_map ( lambda x : 0 * x , self . state . params ) num_samples = 0 for self . batch_idx , batch in enumerate ( self . train_loader ): self . unpack_batch ( batch ) num_samples += self . bs grads = self . fisher_training_step ( self . state , self . x , self . y , self . t , self . step_counter ) fisher_diagonals = jax . tree_map ( lambda a , b : a ** 2 + b , grads , fisher_diagonals ) self . importance = jax . tree_map ( lambda x : x / num_samples , fisher_diagonals ) self . old_params = copy . deepcopy ( self . state . params )","title":"EWC"},{"location":"algos/jax/ewc/#sequel.algos.jax.ewc.EWC","text":"Bases: JaxRegularizationBaseAlgorithm The Elastic Weight Consolidation algorithm. The equivalent PyTorch implementation is EWC in Pytorch . References [1] Kirkpatrick, J. et al. Overcoming catastrophic forgetting in neural networks. PNAS 114, 3521-3526 (2017). Source code in sequel/algos/jax/ewc.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 class EWC ( JaxRegularizationBaseAlgorithm ): \"\"\"The Elastic Weight Consolidation algorithm. The equivalent PyTorch implementation is [`EWC in Pytorch`][sequel.algos.pytorch.ewc.EWC]. References: [1] Kirkpatrick, J. et al. Overcoming catastrophic forgetting in neural networks. PNAS 114, 3521-3526 (2017). \"\"\" def __init__ ( self , ewc_lambda : float , * args , ** kwargs ) -> None : super () . __init__ ( regularization_coefficient = ewc_lambda , * args , ** kwargs ) def __repr__ ( self ) -> str : return f \"EWC(ewc_lambda= { self . regularization_coefficient } )\" @partial ( jax . jit , static_argnums = ( 0 ,)) def fisher_training_step ( self , state , x , y , t , step ): grad_fn = jax . value_and_grad ( self . cross_entropy , has_aux = True , allow_int = True ) ( loss , logits ), grads = grad_fn ( state . params , x , y , t , training = True , step = step ) return grads def on_after_training_task ( self , * args , ** kwargs ): self . train_loader = self . benchmark . train_dataloader ( self . task_counter ) # initialize fisher diagonals to zero fisher_diagonals = jax . tree_map ( lambda x : 0 * x , self . state . params ) num_samples = 0 for self . batch_idx , batch in enumerate ( self . train_loader ): self . unpack_batch ( batch ) num_samples += self . bs grads = self . fisher_training_step ( self . state , self . x , self . y , self . t , self . step_counter ) fisher_diagonals = jax . tree_map ( lambda a , b : a ** 2 + b , grads , fisher_diagonals ) self . importance = jax . tree_map ( lambda x : x / num_samples , fisher_diagonals ) self . old_params = copy . deepcopy ( self . state . params )","title":"EWC"},{"location":"algos/jax/icarl/","text":"","title":"iCaRL"},{"location":"algos/jax/joint/","text":"JointTraining Bases: JaxBaseAlgorithm The JoinTraining algorithm. It is a variant of MultiTask Learning, where the model is trained with increasingly more samples. Specifically, during the t-th task, the model sees samples from all the previous and the current task. Inherits from BaseAlgorithm. Only the prepare_train_loader method is overwritten. The equivalent PyTorch implementation is JointTraining in Pytorch . Source code in sequel/algos/jax/joint.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 class JointTraining ( JaxBaseAlgorithm ): \"\"\"The JoinTraining algorithm. It is a variant of MultiTask Learning, where the model is trained with increasingly more samples. Specifically, during the t-th task, the model sees samples from all the previous and the current task. Inherits from BaseAlgorithm. Only the `prepare_train_loader` method is overwritten. The equivalent PyTorch implementation is [`JointTraining in Pytorch`][sequel.algos.pytorch.joint.JointTraining]. \"\"\" def __init__ ( self , * args , ** kwargs ) -> None : super () . __init__ ( * args , ** kwargs ) def __repr__ ( self ) -> str : return f \"JointTraining()\" def prepare_train_loader ( self , task_id : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Prepares the train_loader for Joint Training. The dataloader consists of all samples up to task `task_id`. Args: task_id (int): The last task to be loaded. batch_size (Optional[int], optional): The dataloader batch size. Defaults to None. Returns: DataLoader: The JointTraining train dataloder. \"\"\" return self . benchmark . train_dataloader_joint ( task_id , batch_size = batch_size ) prepare_train_loader ( task_id , batch_size = None ) Prepares the train_loader for Joint Training. The dataloader consists of all samples up to task task_id . Parameters: Name Type Description Default task_id int The last task to be loaded. required batch_size Optional [ int ] The dataloader batch size. Defaults to None. None Returns: Name Type Description DataLoader DataLoader The JointTraining train dataloder. Source code in sequel/algos/jax/joint.py 24 25 26 27 28 29 30 31 32 33 34 def prepare_train_loader ( self , task_id : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Prepares the train_loader for Joint Training. The dataloader consists of all samples up to task `task_id`. Args: task_id (int): The last task to be loaded. batch_size (Optional[int], optional): The dataloader batch size. Defaults to None. Returns: DataLoader: The JointTraining train dataloder. \"\"\" return self . benchmark . train_dataloader_joint ( task_id , batch_size = batch_size )","title":"Joint"},{"location":"algos/jax/joint/#sequel.algos.jax.joint.JointTraining","text":"Bases: JaxBaseAlgorithm The JoinTraining algorithm. It is a variant of MultiTask Learning, where the model is trained with increasingly more samples. Specifically, during the t-th task, the model sees samples from all the previous and the current task. Inherits from BaseAlgorithm. Only the prepare_train_loader method is overwritten. The equivalent PyTorch implementation is JointTraining in Pytorch . Source code in sequel/algos/jax/joint.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 class JointTraining ( JaxBaseAlgorithm ): \"\"\"The JoinTraining algorithm. It is a variant of MultiTask Learning, where the model is trained with increasingly more samples. Specifically, during the t-th task, the model sees samples from all the previous and the current task. Inherits from BaseAlgorithm. Only the `prepare_train_loader` method is overwritten. The equivalent PyTorch implementation is [`JointTraining in Pytorch`][sequel.algos.pytorch.joint.JointTraining]. \"\"\" def __init__ ( self , * args , ** kwargs ) -> None : super () . __init__ ( * args , ** kwargs ) def __repr__ ( self ) -> str : return f \"JointTraining()\" def prepare_train_loader ( self , task_id : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Prepares the train_loader for Joint Training. The dataloader consists of all samples up to task `task_id`. Args: task_id (int): The last task to be loaded. batch_size (Optional[int], optional): The dataloader batch size. Defaults to None. Returns: DataLoader: The JointTraining train dataloder. \"\"\" return self . benchmark . train_dataloader_joint ( task_id , batch_size = batch_size )","title":"JointTraining"},{"location":"algos/jax/joint/#sequel.algos.jax.joint.JointTraining.prepare_train_loader","text":"Prepares the train_loader for Joint Training. The dataloader consists of all samples up to task task_id . Parameters: Name Type Description Default task_id int The last task to be loaded. required batch_size Optional [ int ] The dataloader batch size. Defaults to None. None Returns: Name Type Description DataLoader DataLoader The JointTraining train dataloder. Source code in sequel/algos/jax/joint.py 24 25 26 27 28 29 30 31 32 33 34 def prepare_train_loader ( self , task_id : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Prepares the train_loader for Joint Training. The dataloader consists of all samples up to task `task_id`. Args: task_id (int): The last task to be loaded. batch_size (Optional[int], optional): The dataloader batch size. Defaults to None. Returns: DataLoader: The JointTraining train dataloder. \"\"\" return self . benchmark . train_dataloader_joint ( task_id , batch_size = batch_size )","title":"prepare_train_loader()"},{"location":"algos/jax/lfl/","text":"LFL Bases: JaxBaseAlgorithm Less-Forgetting Learning implementation in JAX. The equivalent PyTorch implementation is LFL in Pytorch . References [1] Jung, H., Ju, J., Jung, M. & Kim, J. Less-forgetful learning for domain expansion in deep neural networks. Proceedings of the AAAI Conference on Artificial Intelligence 32, (2018). Source code in sequel/algos/jax/lfl.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 class LFL ( JaxBaseAlgorithm ): \"\"\"Less-Forgetting Learning implementation in JAX. The equivalent PyTorch implementation is [`LFL in Pytorch`][sequel.algos.pytorch.lfl.LFL]. References: [1] Jung, H., Ju, J., Jung, M. & Kim, J. Less-forgetful learning for domain expansion in deep neural networks. Proceedings of the AAAI Conference on Artificial Intelligence 32, (2018). \"\"\" def __init__ ( self , lfl_lambda : float , * args , ** kwargs ): \"\"\"Inits the LFL class. Args: lfl_lambda (float): the regularization coefficient. \"\"\" super () . __init__ ( * args , ** kwargs ) self . regularization_coefficient = lfl_lambda def __repr__ ( self ) -> str : return f \"LFL(regularization_coefficient= { self . regularization_coefficient } )\" def on_after_training_task ( self , * args , ** kwargs ): # freeze previous model # assert isinstance self . prev_params = copy . deepcopy ( self . state . params ) @partial ( jax . jit , static_argnums = ( 0 ,)) def lfl_loss ( self , params , x , y , t ): dropout_train_key = jax . random . fold_in ( key = self . dropout_key , data = self . state . step ) logits = self . apply_fn ( params , x = x , training = self . is_training , rngs = { \"dropout\" : dropout_train_key }) loss = cross_entropy_loss ( logits = logits , labels = y ) # disable dropout, etc for features. Equivalent to model.eval() in PyTorch features = self . apply_fn ( params , x , training = False , method = lambda module , x , training : module . encoder ( x , training ), ) old_features = self . apply_fn ( self . prev_params , x , training = False , method = lambda module , x , training : module . encoder ( x , training ), ) lfl_loss = jnp . mean (( old_features - features ) ** 2 ) loss += self . regularization_coefficient * lfl_loss return loss , logits @partial ( jax . jit , static_argnums = ( 0 ,)) def lfl_training_step ( self , state : TrainState , x , y , t ): \"\"\"Train for a single step.\"\"\" grad_fn = jax . value_and_grad ( self . lfl_loss , has_aux = True , allow_int = True ) ( loss , logits ), grads = grad_fn ( state . params , x = x , y = y , t = t ) state = state . apply_gradients ( grads = grads ) return dict ( state = state , logits = logits , loss = loss , grads = grads ) def training_step ( self ): if self . task_counter == 1 : self . batch_outputs = self . base_training_step ( self . state , self . x , self . y , self . t ) else : self . batch_outputs = self . lfl_training_step ( self . state , self . x , self . y , self . t ) self . register_batch_outputs ( self . batch_outputs ) __init__ ( lfl_lambda , * args , ** kwargs ) Inits the LFL class. Parameters: Name Type Description Default lfl_lambda float the regularization coefficient. required Source code in sequel/algos/jax/lfl.py 20 21 22 23 24 25 26 27 def __init__ ( self , lfl_lambda : float , * args , ** kwargs ): \"\"\"Inits the LFL class. Args: lfl_lambda (float): the regularization coefficient. \"\"\" super () . __init__ ( * args , ** kwargs ) self . regularization_coefficient = lfl_lambda lfl_training_step ( state , x , y , t ) Train for a single step. Source code in sequel/algos/jax/lfl.py 63 64 65 66 67 68 69 @partial ( jax . jit , static_argnums = ( 0 ,)) def lfl_training_step ( self , state : TrainState , x , y , t ): \"\"\"Train for a single step.\"\"\" grad_fn = jax . value_and_grad ( self . lfl_loss , has_aux = True , allow_int = True ) ( loss , logits ), grads = grad_fn ( state . params , x = x , y = y , t = t ) state = state . apply_gradients ( grads = grads ) return dict ( state = state , logits = logits , loss = loss , grads = grads )","title":"LFL"},{"location":"algos/jax/lfl/#sequel.algos.jax.lfl.LFL","text":"Bases: JaxBaseAlgorithm Less-Forgetting Learning implementation in JAX. The equivalent PyTorch implementation is LFL in Pytorch . References [1] Jung, H., Ju, J., Jung, M. & Kim, J. Less-forgetful learning for domain expansion in deep neural networks. Proceedings of the AAAI Conference on Artificial Intelligence 32, (2018). Source code in sequel/algos/jax/lfl.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 class LFL ( JaxBaseAlgorithm ): \"\"\"Less-Forgetting Learning implementation in JAX. The equivalent PyTorch implementation is [`LFL in Pytorch`][sequel.algos.pytorch.lfl.LFL]. References: [1] Jung, H., Ju, J., Jung, M. & Kim, J. Less-forgetful learning for domain expansion in deep neural networks. Proceedings of the AAAI Conference on Artificial Intelligence 32, (2018). \"\"\" def __init__ ( self , lfl_lambda : float , * args , ** kwargs ): \"\"\"Inits the LFL class. Args: lfl_lambda (float): the regularization coefficient. \"\"\" super () . __init__ ( * args , ** kwargs ) self . regularization_coefficient = lfl_lambda def __repr__ ( self ) -> str : return f \"LFL(regularization_coefficient= { self . regularization_coefficient } )\" def on_after_training_task ( self , * args , ** kwargs ): # freeze previous model # assert isinstance self . prev_params = copy . deepcopy ( self . state . params ) @partial ( jax . jit , static_argnums = ( 0 ,)) def lfl_loss ( self , params , x , y , t ): dropout_train_key = jax . random . fold_in ( key = self . dropout_key , data = self . state . step ) logits = self . apply_fn ( params , x = x , training = self . is_training , rngs = { \"dropout\" : dropout_train_key }) loss = cross_entropy_loss ( logits = logits , labels = y ) # disable dropout, etc for features. Equivalent to model.eval() in PyTorch features = self . apply_fn ( params , x , training = False , method = lambda module , x , training : module . encoder ( x , training ), ) old_features = self . apply_fn ( self . prev_params , x , training = False , method = lambda module , x , training : module . encoder ( x , training ), ) lfl_loss = jnp . mean (( old_features - features ) ** 2 ) loss += self . regularization_coefficient * lfl_loss return loss , logits @partial ( jax . jit , static_argnums = ( 0 ,)) def lfl_training_step ( self , state : TrainState , x , y , t ): \"\"\"Train for a single step.\"\"\" grad_fn = jax . value_and_grad ( self . lfl_loss , has_aux = True , allow_int = True ) ( loss , logits ), grads = grad_fn ( state . params , x = x , y = y , t = t ) state = state . apply_gradients ( grads = grads ) return dict ( state = state , logits = logits , loss = loss , grads = grads ) def training_step ( self ): if self . task_counter == 1 : self . batch_outputs = self . base_training_step ( self . state , self . x , self . y , self . t ) else : self . batch_outputs = self . lfl_training_step ( self . state , self . x , self . y , self . t ) self . register_batch_outputs ( self . batch_outputs )","title":"LFL"},{"location":"algos/jax/lfl/#sequel.algos.jax.lfl.LFL.__init__","text":"Inits the LFL class. Parameters: Name Type Description Default lfl_lambda float the regularization coefficient. required Source code in sequel/algos/jax/lfl.py 20 21 22 23 24 25 26 27 def __init__ ( self , lfl_lambda : float , * args , ** kwargs ): \"\"\"Inits the LFL class. Args: lfl_lambda (float): the regularization coefficient. \"\"\" super () . __init__ ( * args , ** kwargs ) self . regularization_coefficient = lfl_lambda","title":"__init__()"},{"location":"algos/jax/lfl/#sequel.algos.jax.lfl.LFL.lfl_training_step","text":"Train for a single step. Source code in sequel/algos/jax/lfl.py 63 64 65 66 67 68 69 @partial ( jax . jit , static_argnums = ( 0 ,)) def lfl_training_step ( self , state : TrainState , x , y , t ): \"\"\"Train for a single step.\"\"\" grad_fn = jax . value_and_grad ( self . lfl_loss , has_aux = True , allow_int = True ) ( loss , logits ), grads = grad_fn ( state . params , x = x , y = y , t = t ) state = state . apply_gradients ( grads = grads ) return dict ( state = state , logits = logits , loss = loss , grads = grads )","title":"lfl_training_step()"},{"location":"algos/jax/mas/","text":"MAS Bases: JaxRegularizationBaseAlgorithm Memory Aware Synapses. Algorithm Class. Inherits from BaseAlgorithm. The equivalent PyTorch implementation is MAS in Pytorch . References [1] Aljundi, R., Babiloni, F., Elhoseiny, M., Rohrbach, M. & Tuytelaars, T. Memory Aware Synapses: Learning What (not) to Forget. in Computer Vision - ECCV 2018. Source code in sequel/algos/jax/mas.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class MAS ( JaxRegularizationBaseAlgorithm ): \"\"\"Memory Aware Synapses. Algorithm Class. Inherits from BaseAlgorithm. The equivalent PyTorch implementation is [`MAS in Pytorch`][sequel.algos.pytorch.mas.MAS]. References: [1] Aljundi, R., Babiloni, F., Elhoseiny, M., Rohrbach, M. & Tuytelaars, T. Memory Aware Synapses: Learning What (not) to Forget. in Computer Vision - ECCV 2018. \"\"\" def __init__ ( self , mas_lambda : float = 1.0 , * args , ** kwargs ): super () . __init__ ( regularization_coefficient = mas_lambda , * args , ** kwargs ) self . w = jax . tree_map ( lambda x : 0 * x , self . state . params ) def __repr__ ( self ) -> str : return f \"MAS(mas_lambda= { self . regularization_coefficient } )\" def calculate_parameter_importance ( self ): if self . task_counter == 1 : importance = jax . tree_map ( lambda x : 0 * x , self . state . params ) else : importance = self . importance importance = jax . tree_map ( lambda i , w : i + w , importance , self . w ) self . w = jax . tree_map ( lambda x : 0 * x , self . state . params ) return importance def on_before_training_step ( self , * args , ** kwargs ): self . old_params = copy . deepcopy ( self . state . params ) def on_after_training_step ( self , * args , ** kwargs ): @jax . jit def secondary_loss ( params , x , t , training = True ): logits = self . apply_fn ( params , x , t , training = training ) loss = jnp . mean ( jnp . square ( logits )) return loss , logits grad_fn = jax . value_and_grad ( secondary_loss , has_aux = True , allow_int = True ) _ , grads = grad_fn ( self . state . params , self . x , self . t , self . is_training ) self . w = jax . tree_map ( lambda w , g : w + jnp . abs ( g ) / len ( self . y ), self . w , grads ) def on_after_training_task ( self , * args , ** kwargs ): self . old_params = copy . deepcopy ( self . state . params ) self . importance = self . calculate_parameter_importance ()","title":"MAS"},{"location":"algos/jax/mas/#sequel.algos.jax.mas.MAS","text":"Bases: JaxRegularizationBaseAlgorithm Memory Aware Synapses. Algorithm Class. Inherits from BaseAlgorithm. The equivalent PyTorch implementation is MAS in Pytorch . References [1] Aljundi, R., Babiloni, F., Elhoseiny, M., Rohrbach, M. & Tuytelaars, T. Memory Aware Synapses: Learning What (not) to Forget. in Computer Vision - ECCV 2018. Source code in sequel/algos/jax/mas.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class MAS ( JaxRegularizationBaseAlgorithm ): \"\"\"Memory Aware Synapses. Algorithm Class. Inherits from BaseAlgorithm. The equivalent PyTorch implementation is [`MAS in Pytorch`][sequel.algos.pytorch.mas.MAS]. References: [1] Aljundi, R., Babiloni, F., Elhoseiny, M., Rohrbach, M. & Tuytelaars, T. Memory Aware Synapses: Learning What (not) to Forget. in Computer Vision - ECCV 2018. \"\"\" def __init__ ( self , mas_lambda : float = 1.0 , * args , ** kwargs ): super () . __init__ ( regularization_coefficient = mas_lambda , * args , ** kwargs ) self . w = jax . tree_map ( lambda x : 0 * x , self . state . params ) def __repr__ ( self ) -> str : return f \"MAS(mas_lambda= { self . regularization_coefficient } )\" def calculate_parameter_importance ( self ): if self . task_counter == 1 : importance = jax . tree_map ( lambda x : 0 * x , self . state . params ) else : importance = self . importance importance = jax . tree_map ( lambda i , w : i + w , importance , self . w ) self . w = jax . tree_map ( lambda x : 0 * x , self . state . params ) return importance def on_before_training_step ( self , * args , ** kwargs ): self . old_params = copy . deepcopy ( self . state . params ) def on_after_training_step ( self , * args , ** kwargs ): @jax . jit def secondary_loss ( params , x , t , training = True ): logits = self . apply_fn ( params , x , t , training = training ) loss = jnp . mean ( jnp . square ( logits )) return loss , logits grad_fn = jax . value_and_grad ( secondary_loss , has_aux = True , allow_int = True ) _ , grads = grad_fn ( self . state . params , self . x , self . t , self . is_training ) self . w = jax . tree_map ( lambda w , g : w + jnp . abs ( g ) / len ( self . y ), self . w , grads ) def on_after_training_task ( self , * args , ** kwargs ): self . old_params = copy . deepcopy ( self . state . params ) self . importance = self . calculate_parameter_importance ()","title":"MAS"},{"location":"algos/jax/mcsgd/","text":"MCSGD Bases: JaxBaseAlgorithm MC-SGD: Mode Connectivity-Stochastic Gradient Descent. Inherits from BaseAlgorithm. The equivalent PyTorch implementation is MCSGD in Pytorch . References [1] Mirzadeh, S.-I., Farajtabar, M., G\u00f6r\u00fcr, D., Pascanu, R. & Ghasemzadeh, H. Linear Mode Connectivity in Multitask and Continual Learning. in 9th International Conference on Learning Representations, ICLR 2021. Source code in sequel/algos/jax/mcsgd.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 class MCSGD ( JaxBaseAlgorithm ): \"\"\"MC-SGD: Mode Connectivity-Stochastic Gradient Descent. Inherits from BaseAlgorithm. The equivalent PyTorch implementation is [`MCSGD in Pytorch`][sequel.algos.pytorch.mcsgd.MCSGD]. References: [1] Mirzadeh, S.-I., Farajtabar, M., G\u00f6r\u00fcr, D., Pascanu, R. & Ghasemzadeh, H. Linear Mode Connectivity in Multitask and Continual Learning. in 9th International Conference on Learning Representations, ICLR 2021. \"\"\" state : TrainState def __init__ ( self , per_task_memory_samples : int = 100 , memory_group_by : Literal [ \"task\" , \"class\" ] = \"task\" , lmc_policy = \"offline\" , lmc_interpolation = \"linear\" , lmc_lr = 0.05 , lmc_momentum = 0.8 , lmc_batch_size = 64 , lmc_init_position = 0.1 , lmc_line_samples = 10 , lmc_epochs = 1 , * args , ** kwargs , ): super () . __init__ ( * args , ** kwargs ) self . memory = MemoryMechanism ( per_task_memory_samples = per_task_memory_samples , groupby = memory_group_by ) self . w_bar_prev = None self . w_hat_curr = None # parse init arguments self . per_task_memory_samples = per_task_memory_samples self . lmc_policy = lmc_policy self . lmc_interpolation = lmc_interpolation self . lmc_lr = lmc_lr self . lmc_momentum = lmc_momentum self . lmc_batch_size = lmc_batch_size self . lmc_init_position = lmc_init_position self . lmc_line_samples = lmc_line_samples self . lmc_epochs = lmc_epochs def __repr__ ( self ) -> str : return ( \"MCSGD(\" + f \"per_task_memory_samples= { self . per_task_memory_samples } , \" + f \"policy= { self . lmc_policy } , \" + f \"interpolation= { self . lmc_interpolation } , \" + f \"lr= { self . lmc_lr } , \" + f \"momentum= { self . lmc_momentum } , \" + f \"batch_size= { self . lmc_batch_size } , \" + f \"init_position= { self . lmc_init_position } , \" + f \"line_samples= { self . lmc_line_samples } , \" + f \"epochs= { self . lmc_epochs } \" + \")\" ) def calculate_line_loss ( self , w_start , w_end , loader ): line_samples = np . arange ( 0.0 , 1.01 , 1.0 / float ( self . lmc_line_samples )) grads = tree_map ( lambda x : 0 * x , w_start ) for t in tqdm ( line_samples , desc = \"Line samples\" ): params = tree_map ( lambda a , b : a + ( b - a ) * t , w_start , w_end ) g = self . calculate_point_loss ( params , loader ) grads = tree_map ( lambda a , b : a + b , grads , g ) return grads @partial ( jax . jit , static_argnums = ( 0 ,)) def simple_training_step ( self , params , x , y , t , step ): grad_fn = jax . value_and_grad ( self . cross_entropy , has_aux = True , allow_int = True ) ( loss , logits ), grads = grad_fn ( params , x , y , t , self . is_training , step = step ) return grads def calculate_point_loss ( self , params , loader ): total_count = 0.0 grads = tree_map ( lambda x : 0 * x , params ) for batch in loader : self . unpack_batch ( batch ) g = self . simple_training_step ( params , self . x , self . y , self . t , self . step_counter ) grads = tree_map ( lambda a , b : a + b , grads , g ) total_count += self . bs return tree_map ( lambda a : a / total_count , grads ) def find_connected_minima ( self , task ): bs = self . lmc_batch_size loader_curr = self . benchmark . train_dataloader_subset ( task , batch_size = bs , subset_size = self . per_task_memory_samples ) loader_prev = self . benchmark . memory_dataloader ( task , batch_size = bs , return_infinite_stream = False ) params = tree_map ( lambda a , b : a + ( b - a ) * self . lmc_init_position , self . w_bar_prev , self . w_hat_curr ) tx = optax . sgd ( learning_rate = self . lmc_lr , momentum = self . lmc_momentum ) state = TrainState . create ( apply_fn = self . apply_fn , params = params , tx = tx ) grads_prev = self . calculate_line_loss ( self . w_bar_prev , state . params , loader_prev ) grads_curr = self . calculate_line_loss ( self . w_hat_curr , state . params , loader_curr ) grads = tree_map ( lambda a , b : a + b , grads_prev , grads_curr ) state = state . apply_gradients ( grads = grads ) return state def on_after_training_epoch ( self , * args , ** kwargs ): self . w_hat_curr = copy . deepcopy ( self . state . params ) self . old_state = copy . deepcopy ( self . state ) def validate_algorithm_on_all_tasks ( self ) -> Dict [ str , float ]: if self . task_counter == 1 : super () . validate_algorithm_on_all_tasks () def on_after_validating_algorithm_on_all_tasks_callbacks ( self ): if self . task_counter == 1 : return super () . on_after_validating_algorithm_on_all_tasks_callbacks () def on_after_training_task ( self , * args , ** kwargs ): self . memory . update_memory ( self ) if self . task_counter > 1 : # save the backbone obtained from the mode-connectivity updates # as the Multi-Task approximate solution self . w_bar_prev = self . find_connected_minima ( self . task_counter ) . params # perform the validation with the weights obtained after the mode-connectivity updates self . state = self . state . replace ( params = self . w_bar_prev ) super () . on_before_validating_algorithm_on_all_tasks_callbacks () super () . validate_algorithm_on_all_tasks () super () . on_after_validating_algorithm_on_all_tasks_callbacks () else : self . w_bar_prev = copy . deepcopy ( self . state . params ) # revert the weights of the backbone to the Continual Learning solution self . state = copy . deepcopy ( self . old_state )","title":"MC-SGD"},{"location":"algos/jax/mcsgd/#sequel.algos.jax.mcsgd.MCSGD","text":"Bases: JaxBaseAlgorithm MC-SGD: Mode Connectivity-Stochastic Gradient Descent. Inherits from BaseAlgorithm. The equivalent PyTorch implementation is MCSGD in Pytorch . References [1] Mirzadeh, S.-I., Farajtabar, M., G\u00f6r\u00fcr, D., Pascanu, R. & Ghasemzadeh, H. Linear Mode Connectivity in Multitask and Continual Learning. in 9th International Conference on Learning Representations, ICLR 2021. Source code in sequel/algos/jax/mcsgd.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 class MCSGD ( JaxBaseAlgorithm ): \"\"\"MC-SGD: Mode Connectivity-Stochastic Gradient Descent. Inherits from BaseAlgorithm. The equivalent PyTorch implementation is [`MCSGD in Pytorch`][sequel.algos.pytorch.mcsgd.MCSGD]. References: [1] Mirzadeh, S.-I., Farajtabar, M., G\u00f6r\u00fcr, D., Pascanu, R. & Ghasemzadeh, H. Linear Mode Connectivity in Multitask and Continual Learning. in 9th International Conference on Learning Representations, ICLR 2021. \"\"\" state : TrainState def __init__ ( self , per_task_memory_samples : int = 100 , memory_group_by : Literal [ \"task\" , \"class\" ] = \"task\" , lmc_policy = \"offline\" , lmc_interpolation = \"linear\" , lmc_lr = 0.05 , lmc_momentum = 0.8 , lmc_batch_size = 64 , lmc_init_position = 0.1 , lmc_line_samples = 10 , lmc_epochs = 1 , * args , ** kwargs , ): super () . __init__ ( * args , ** kwargs ) self . memory = MemoryMechanism ( per_task_memory_samples = per_task_memory_samples , groupby = memory_group_by ) self . w_bar_prev = None self . w_hat_curr = None # parse init arguments self . per_task_memory_samples = per_task_memory_samples self . lmc_policy = lmc_policy self . lmc_interpolation = lmc_interpolation self . lmc_lr = lmc_lr self . lmc_momentum = lmc_momentum self . lmc_batch_size = lmc_batch_size self . lmc_init_position = lmc_init_position self . lmc_line_samples = lmc_line_samples self . lmc_epochs = lmc_epochs def __repr__ ( self ) -> str : return ( \"MCSGD(\" + f \"per_task_memory_samples= { self . per_task_memory_samples } , \" + f \"policy= { self . lmc_policy } , \" + f \"interpolation= { self . lmc_interpolation } , \" + f \"lr= { self . lmc_lr } , \" + f \"momentum= { self . lmc_momentum } , \" + f \"batch_size= { self . lmc_batch_size } , \" + f \"init_position= { self . lmc_init_position } , \" + f \"line_samples= { self . lmc_line_samples } , \" + f \"epochs= { self . lmc_epochs } \" + \")\" ) def calculate_line_loss ( self , w_start , w_end , loader ): line_samples = np . arange ( 0.0 , 1.01 , 1.0 / float ( self . lmc_line_samples )) grads = tree_map ( lambda x : 0 * x , w_start ) for t in tqdm ( line_samples , desc = \"Line samples\" ): params = tree_map ( lambda a , b : a + ( b - a ) * t , w_start , w_end ) g = self . calculate_point_loss ( params , loader ) grads = tree_map ( lambda a , b : a + b , grads , g ) return grads @partial ( jax . jit , static_argnums = ( 0 ,)) def simple_training_step ( self , params , x , y , t , step ): grad_fn = jax . value_and_grad ( self . cross_entropy , has_aux = True , allow_int = True ) ( loss , logits ), grads = grad_fn ( params , x , y , t , self . is_training , step = step ) return grads def calculate_point_loss ( self , params , loader ): total_count = 0.0 grads = tree_map ( lambda x : 0 * x , params ) for batch in loader : self . unpack_batch ( batch ) g = self . simple_training_step ( params , self . x , self . y , self . t , self . step_counter ) grads = tree_map ( lambda a , b : a + b , grads , g ) total_count += self . bs return tree_map ( lambda a : a / total_count , grads ) def find_connected_minima ( self , task ): bs = self . lmc_batch_size loader_curr = self . benchmark . train_dataloader_subset ( task , batch_size = bs , subset_size = self . per_task_memory_samples ) loader_prev = self . benchmark . memory_dataloader ( task , batch_size = bs , return_infinite_stream = False ) params = tree_map ( lambda a , b : a + ( b - a ) * self . lmc_init_position , self . w_bar_prev , self . w_hat_curr ) tx = optax . sgd ( learning_rate = self . lmc_lr , momentum = self . lmc_momentum ) state = TrainState . create ( apply_fn = self . apply_fn , params = params , tx = tx ) grads_prev = self . calculate_line_loss ( self . w_bar_prev , state . params , loader_prev ) grads_curr = self . calculate_line_loss ( self . w_hat_curr , state . params , loader_curr ) grads = tree_map ( lambda a , b : a + b , grads_prev , grads_curr ) state = state . apply_gradients ( grads = grads ) return state def on_after_training_epoch ( self , * args , ** kwargs ): self . w_hat_curr = copy . deepcopy ( self . state . params ) self . old_state = copy . deepcopy ( self . state ) def validate_algorithm_on_all_tasks ( self ) -> Dict [ str , float ]: if self . task_counter == 1 : super () . validate_algorithm_on_all_tasks () def on_after_validating_algorithm_on_all_tasks_callbacks ( self ): if self . task_counter == 1 : return super () . on_after_validating_algorithm_on_all_tasks_callbacks () def on_after_training_task ( self , * args , ** kwargs ): self . memory . update_memory ( self ) if self . task_counter > 1 : # save the backbone obtained from the mode-connectivity updates # as the Multi-Task approximate solution self . w_bar_prev = self . find_connected_minima ( self . task_counter ) . params # perform the validation with the weights obtained after the mode-connectivity updates self . state = self . state . replace ( params = self . w_bar_prev ) super () . on_before_validating_algorithm_on_all_tasks_callbacks () super () . validate_algorithm_on_all_tasks () super () . on_after_validating_algorithm_on_all_tasks_callbacks () else : self . w_bar_prev = copy . deepcopy ( self . state . params ) # revert the weights of the backbone to the Continual Learning solution self . state = copy . deepcopy ( self . old_state )","title":"MCSGD"},{"location":"algos/jax/si/","text":"SI Bases: JaxRegularizationBaseAlgorithm Synaptic Intelligence Algorithm. The equivalent PyTorch implementation is SI in Pytorch . References [1] Zenke, F., Poole, B. & Ganguli, S. Continual Learning Through Synaptic Intelligence. in Proceedings of the 34th International Conference on Machine Learning, ICML 2017. Source code in sequel/algos/jax/si.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 class SI ( JaxRegularizationBaseAlgorithm ): \"\"\"Synaptic Intelligence Algorithm. The equivalent PyTorch implementation is [`SI in Pytorch`][sequel.algos.pytorch.si.SI]. References: [1] Zenke, F., Poole, B. & Ganguli, S. Continual Learning Through Synaptic Intelligence. in Proceedings of the 34th International Conference on Machine Learning, ICML 2017. \"\"\" def __init__ ( self , si_lambda : float = 1.0 , xi : float = 0.1 , * args , ** kwargs ): super () . __init__ ( regularization_coefficient = si_lambda , * args , ** kwargs ) self . xi = xi self . w = jax . tree_map ( lambda a : 0 * a , self . state . params ) def __repr__ ( self ) -> str : return f \"SI(si_lambda= { self . regularization_coefficient } , xi= { self . xi } )\" def calculate_parameter_importance ( self ): if self . task_counter == 1 : importance = jax . tree_map ( lambda x : 0 * x , self . state . params ) else : importance = self . importance delta = jax . tree_map ( lambda w_cur , w_old : w_cur - w_old , self . state . params , self . old_params ) importance = jax . tree_map ( lambda i , w , dt : i + w / ( dt ** 2 + self . xi ), importance , self . w , delta ) self . w = jax . tree_map ( lambda x : 0 * x , self . state . params ) return importance def on_before_training_step ( self , * args , ** kwargs ): self . prev_params = copy . deepcopy ( self . state . params ) # @partial(jax.jit, static_argnums=(0,)) def on_after_training_step ( self , * args , ** kwargs ): grads = self . batch_outputs [ \"grads\" ] delta = jax . tree_map ( lambda w_cur , w_old : w_cur - w_old , self . state . params , self . prev_params ) self . w = jax . tree_map ( lambda w , g , d : w - g * d , self . w , grads , delta ) def on_after_training_task ( self , * args , ** kwargs ): self . old_params = copy . deepcopy ( self . state . params ) self . importance = self . calculate_parameter_importance ()","title":"SI"},{"location":"algos/jax/si/#sequel.algos.jax.si.SI","text":"Bases: JaxRegularizationBaseAlgorithm Synaptic Intelligence Algorithm. The equivalent PyTorch implementation is SI in Pytorch . References [1] Zenke, F., Poole, B. & Ganguli, S. Continual Learning Through Synaptic Intelligence. in Proceedings of the 34th International Conference on Machine Learning, ICML 2017. Source code in sequel/algos/jax/si.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 class SI ( JaxRegularizationBaseAlgorithm ): \"\"\"Synaptic Intelligence Algorithm. The equivalent PyTorch implementation is [`SI in Pytorch`][sequel.algos.pytorch.si.SI]. References: [1] Zenke, F., Poole, B. & Ganguli, S. Continual Learning Through Synaptic Intelligence. in Proceedings of the 34th International Conference on Machine Learning, ICML 2017. \"\"\" def __init__ ( self , si_lambda : float = 1.0 , xi : float = 0.1 , * args , ** kwargs ): super () . __init__ ( regularization_coefficient = si_lambda , * args , ** kwargs ) self . xi = xi self . w = jax . tree_map ( lambda a : 0 * a , self . state . params ) def __repr__ ( self ) -> str : return f \"SI(si_lambda= { self . regularization_coefficient } , xi= { self . xi } )\" def calculate_parameter_importance ( self ): if self . task_counter == 1 : importance = jax . tree_map ( lambda x : 0 * x , self . state . params ) else : importance = self . importance delta = jax . tree_map ( lambda w_cur , w_old : w_cur - w_old , self . state . params , self . old_params ) importance = jax . tree_map ( lambda i , w , dt : i + w / ( dt ** 2 + self . xi ), importance , self . w , delta ) self . w = jax . tree_map ( lambda x : 0 * x , self . state . params ) return importance def on_before_training_step ( self , * args , ** kwargs ): self . prev_params = copy . deepcopy ( self . state . params ) # @partial(jax.jit, static_argnums=(0,)) def on_after_training_step ( self , * args , ** kwargs ): grads = self . batch_outputs [ \"grads\" ] delta = jax . tree_map ( lambda w_cur , w_old : w_cur - w_old , self . state . params , self . prev_params ) self . w = jax . tree_map ( lambda w , g , d : w - g * d , self . w , grads , delta ) def on_after_training_task ( self , * args , ** kwargs ): self . old_params = copy . deepcopy ( self . state . params ) self . importance = self . calculate_parameter_importance ()","title":"SI"},{"location":"algos/pytorch/agem/","text":"AGEM Bases: PytorchBaseAlgorithm A-GEM: Averaged-Gradient Episodic Memory. Maintains a memory of samples from past tasks. The gradients for the current batch are projected to the convex hull of the task gradients produced by the the aforementioned memory. Inherits from BaseAlgorithm. The equivalent JAX implementation is A-GEM in JAX . References [1] Chaudhry, A., Ranzato, M., Rohrbach, M. & Elhoseiny, M. Efficient Lifelong Learning with A-GEM. in 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. Source code in sequel/algos/pytorch/agem.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 class AGEM ( PytorchBaseAlgorithm ): \"\"\"A-GEM: Averaged-Gradient Episodic Memory. Maintains a memory of samples from past tasks. The gradients for the current batch are projected to the convex hull of the task gradients produced by the the aforementioned memory. Inherits from BaseAlgorithm. The equivalent JAX implementation is [`A-GEM in JAX`][sequel.algos.jax.agem.AGEM]. References: [1] Chaudhry, A., Ranzato, M., Rohrbach, M. & Elhoseiny, M. Efficient Lifelong Learning with A-GEM. in 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. \"\"\" def __init__ ( self , per_task_memory_samples : int , memory_batch_size : int , memory_group_by : Literal [ \"task\" , \"class\" ], * args , ** kwargs , ): \"\"\"Inits the AGEM algorithm class. Args: per_task_memory_samples (int): number of exemplars per experience in the memory. \"\"\" super () . __init__ ( * args , ** kwargs ) self . memory = MemoryMechanism ( per_task_memory_samples = per_task_memory_samples , groupby = memory_group_by ) self . per_task_memory_samples = per_task_memory_samples self . memory_batch_size = memory_batch_size def __repr__ ( self ) -> str : return ( f \"AGEM(memory_batch_size= { self . memory_batch_size } , per_task_memory_samples= { self . per_task_memory_samples } )\" ) def on_after_training_task ( self , * args , ** kwargs ): self . memory . update_memory ( self ) self . update_episodic_memory () logging . info ( \"The episodic memory now stores {} samples\" . format ( len ( self . episodic_memory_loader . dataset ))) def update_episodic_memory ( self ): logging . info ( \"Updating episodic memory for task {} \" . format ( self . task_counter )) self . episodic_memory_loader = self . benchmark . memory_dataloader ( self . task_counter , self . memory_batch_size ) self . episodic_memory_iter = iter ( self . episodic_memory_loader ) def sample_batch_from_memory ( self ): try : return next ( self . episodic_memory_iter ) except StopIteration : # makes the dataloader an infinite stream self . episodic_memory_iter = iter ( self . episodic_memory_loader ) return next ( self . episodic_memory_iter ) def on_before_optimizer_step ( self , * args , ** kwargs ): if self . task_counter == 1 : return # save gradients from current task and flush optimizer gradients old_grads = get_grads ( self . backbone ) . detach () . clone () self . optimizer_zero_grad () # sample from memory and compute corresponding gradients. x , y , t = self . sample_batch_from_memory () x , y = x . to ( self . device ), y . to ( self . device ) y_hat = self . backbone ( x , t ) loss = self . compute_loss ( y_hat , y , t ) loss . backward () # gradients from memory mem_grads = get_grads ( self . backbone ) . detach () . clone () assert old_grads . shape == mem_grads . shape , \"Different model parameters in AGEM projection\" dotg = torch . dot ( old_grads , mem_grads ) if dotg < 0 : # if current task and memory gradients have negative angle (negative cosine similarity), # perform the A-GEM projection. alpha2 = dotg / torch . dot ( mem_grads , mem_grads ) new_grads = old_grads - mem_grads * alpha2 self . backbone = set_grads ( self . backbone , new_grads ) else : self . backbone = set_grads ( self . backbone , old_grads ) return super () . on_before_optimizer_step ( * args , ** kwargs ) __init__ ( per_task_memory_samples , memory_batch_size , memory_group_by , * args , ** kwargs ) Inits the AGEM algorithm class. Parameters: Name Type Description Default per_task_memory_samples int number of exemplars per experience in the memory. required Source code in sequel/algos/pytorch/agem.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , per_task_memory_samples : int , memory_batch_size : int , memory_group_by : Literal [ \"task\" , \"class\" ], * args , ** kwargs , ): \"\"\"Inits the AGEM algorithm class. Args: per_task_memory_samples (int): number of exemplars per experience in the memory. \"\"\" super () . __init__ ( * args , ** kwargs ) self . memory = MemoryMechanism ( per_task_memory_samples = per_task_memory_samples , groupby = memory_group_by ) self . per_task_memory_samples = per_task_memory_samples self . memory_batch_size = memory_batch_size","title":"AGEM"},{"location":"algos/pytorch/agem/#sequel.algos.pytorch.agem.AGEM","text":"Bases: PytorchBaseAlgorithm A-GEM: Averaged-Gradient Episodic Memory. Maintains a memory of samples from past tasks. The gradients for the current batch are projected to the convex hull of the task gradients produced by the the aforementioned memory. Inherits from BaseAlgorithm. The equivalent JAX implementation is A-GEM in JAX . References [1] Chaudhry, A., Ranzato, M., Rohrbach, M. & Elhoseiny, M. Efficient Lifelong Learning with A-GEM. in 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. Source code in sequel/algos/pytorch/agem.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 class AGEM ( PytorchBaseAlgorithm ): \"\"\"A-GEM: Averaged-Gradient Episodic Memory. Maintains a memory of samples from past tasks. The gradients for the current batch are projected to the convex hull of the task gradients produced by the the aforementioned memory. Inherits from BaseAlgorithm. The equivalent JAX implementation is [`A-GEM in JAX`][sequel.algos.jax.agem.AGEM]. References: [1] Chaudhry, A., Ranzato, M., Rohrbach, M. & Elhoseiny, M. Efficient Lifelong Learning with A-GEM. in 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. \"\"\" def __init__ ( self , per_task_memory_samples : int , memory_batch_size : int , memory_group_by : Literal [ \"task\" , \"class\" ], * args , ** kwargs , ): \"\"\"Inits the AGEM algorithm class. Args: per_task_memory_samples (int): number of exemplars per experience in the memory. \"\"\" super () . __init__ ( * args , ** kwargs ) self . memory = MemoryMechanism ( per_task_memory_samples = per_task_memory_samples , groupby = memory_group_by ) self . per_task_memory_samples = per_task_memory_samples self . memory_batch_size = memory_batch_size def __repr__ ( self ) -> str : return ( f \"AGEM(memory_batch_size= { self . memory_batch_size } , per_task_memory_samples= { self . per_task_memory_samples } )\" ) def on_after_training_task ( self , * args , ** kwargs ): self . memory . update_memory ( self ) self . update_episodic_memory () logging . info ( \"The episodic memory now stores {} samples\" . format ( len ( self . episodic_memory_loader . dataset ))) def update_episodic_memory ( self ): logging . info ( \"Updating episodic memory for task {} \" . format ( self . task_counter )) self . episodic_memory_loader = self . benchmark . memory_dataloader ( self . task_counter , self . memory_batch_size ) self . episodic_memory_iter = iter ( self . episodic_memory_loader ) def sample_batch_from_memory ( self ): try : return next ( self . episodic_memory_iter ) except StopIteration : # makes the dataloader an infinite stream self . episodic_memory_iter = iter ( self . episodic_memory_loader ) return next ( self . episodic_memory_iter ) def on_before_optimizer_step ( self , * args , ** kwargs ): if self . task_counter == 1 : return # save gradients from current task and flush optimizer gradients old_grads = get_grads ( self . backbone ) . detach () . clone () self . optimizer_zero_grad () # sample from memory and compute corresponding gradients. x , y , t = self . sample_batch_from_memory () x , y = x . to ( self . device ), y . to ( self . device ) y_hat = self . backbone ( x , t ) loss = self . compute_loss ( y_hat , y , t ) loss . backward () # gradients from memory mem_grads = get_grads ( self . backbone ) . detach () . clone () assert old_grads . shape == mem_grads . shape , \"Different model parameters in AGEM projection\" dotg = torch . dot ( old_grads , mem_grads ) if dotg < 0 : # if current task and memory gradients have negative angle (negative cosine similarity), # perform the A-GEM projection. alpha2 = dotg / torch . dot ( mem_grads , mem_grads ) new_grads = old_grads - mem_grads * alpha2 self . backbone = set_grads ( self . backbone , new_grads ) else : self . backbone = set_grads ( self . backbone , old_grads ) return super () . on_before_optimizer_step ( * args , ** kwargs )","title":"AGEM"},{"location":"algos/pytorch/agem/#sequel.algos.pytorch.agem.AGEM.__init__","text":"Inits the AGEM algorithm class. Parameters: Name Type Description Default per_task_memory_samples int number of exemplars per experience in the memory. required Source code in sequel/algos/pytorch/agem.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , per_task_memory_samples : int , memory_batch_size : int , memory_group_by : Literal [ \"task\" , \"class\" ], * args , ** kwargs , ): \"\"\"Inits the AGEM algorithm class. Args: per_task_memory_samples (int): number of exemplars per experience in the memory. \"\"\" super () . __init__ ( * args , ** kwargs ) self . memory = MemoryMechanism ( per_task_memory_samples = per_task_memory_samples , groupby = memory_group_by ) self . per_task_memory_samples = per_task_memory_samples self . memory_batch_size = memory_batch_size","title":"__init__()"},{"location":"algos/pytorch/base_algo/","text":"PytorchBaseAlgorithm Bases: BaseAlgorithm Source code in sequel/algos/pytorch/pytorch_base_algo.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 class PytorchBaseAlgorithm ( BaseAlgorithm ): optimizer : torch . optim . Optimizer backbone : torch . nn . Module def __init__ ( self , backbone : PytorchBaseBackbone , benchmark : Benchmark , optimizer : torch . optim . Optimizer , callbacks : Iterable [ BaseCallback ] = [], loggers : Optional [ Iterable [ Logger ]] = None , lr_decay : Optional [ float ] = None , grad_clip : Optional [ float ] = None , reinit_optimizer : bool = True , device = \"cuda:0\" , min_lr = 0.00005 , ) -> None : \"\"\"Inits the PytorchBaseAlgorithm class. Args: backbone (PytorchBaseBackbone): The backbone model, e.g., a CNN. benchmark (Benchmark): The benchmark, e.g., SplitMNIST. optimizer (torch.optim.Optimizer): The optimizer used to update the backbone weights. callbacks (Iterable[BaseCallback], optional): A list of callbacks. At least one instance of MetricCallback should be given. Defaults to []. loggers (Optional[Logger], optional): A list of logger, e.g. for Weights&Biases logging functionality. Defaults to None. lr_decay (Optional[float], optional): A learning rate decay used for every new task. Defaults to None. grad_clip (Optional[float], optional): The gradient clipping norm. Defaults to None. reinit_optimizer (bool): Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True. device (str, optional): _description_. Defaults to \"cuda:0\". min_lr (float, optional): _description_. Defaults to 0.00005. Note: 1. the `_configure_optimizers` method will be moved to a dedicated Callback. \"\"\" self . device = device if not isinstance ( backbone , BaseBackbone ): backbone = BackboneWrapper ( backbone ) super () . __init__ ( backbone = backbone , benchmark = benchmark , optimizer = optimizer , callbacks = callbacks , loggers = loggers , lr_decay = lr_decay , grad_clip = grad_clip , reinit_optimizer = reinit_optimizer , ) self . backbone = self . backbone . to ( self . device ) self . min_lr = min_lr def count_parameters ( self ): device = next ( self . backbone . parameters ()) . device self . backbone ( torch . ones ( self . input_dimensions ) . unsqueeze ( 0 ) . to ( device ), torch . ones (( 1 ))) return sum ([ p . numel () for p in self . backbone . parameters () if p . requires_grad ]) def _configure_optimizers ( self , task ): if self . task_counter == 1 or self . reinit_optimizer : assert len ( self . optimizer . param_groups ) == 1 lr = self . optimizer . param_groups [ 0 ][ \"lr\" ] self . optimizer . state = defaultdict ( dict ) self . optimizer . param_groups [ 0 ][ \"params\" ] = list ( self . backbone . parameters ()) if self . lr_decay is not None and task > 1 : assert isinstance ( self . lr_decay , float ) assert self . lr_decay > 0 and self . lr_decay <= 1 , \"lr decay should be in the interval (0,1]\" new_lr = max ( lr * self . lr_decay , self . min_lr ) self . optimizer . param_groups [ 0 ][ \"lr\" ] = new_lr logging . info ( f \"Decaying the learning rate by a factor of { self . lr_decay } \" ) logging . info ( self . optimizer ) def _configure_criterion ( self , task_id = None ): return torch . nn . CrossEntropyLoss () def forward ( self , * args , ** kwargs ): \"\"\"Calls the forward function of the model.\"\"\" outs = self . backbone ( self . x , self . t ) self . y_hat = outs return outs def unpack_batch ( self , batch ): device = self . device x , y , t = batch self . x , self . y , self . t = x . to ( device ), y . to ( device ), t . to ( device ) self . bs = len ( x ) def optimizer_zero_grad ( self ): self . optimizer . zero_grad () def backpropagate_loss ( self ): self . loss . backward () def optimizer_step ( self ): self . optimizer . step () def perform_gradient_clipping ( self ): if self . grad_clip is not None : assert self . grad_clip > 0 torch . nn . utils . clip_grad_norm_ ( self . backbone . parameters (), self . grad_clip ) def valid_step ( self , * args , ** kwargs ): \"\"\"Performs the validation step. Callbacks are offered for each step of the process.\"\"\" with torch . no_grad (): y_hat = self . forward () self . loss = self . compute_loss ( y_hat , self . y , self . t ) def test_step ( self , * args , ** kwargs ): \"\"\"Performs the testing step. Callbacks are offered for each step of the process.\"\"\" pass def prepare_for_next_task ( self , task ): self . _configure_optimizers ( task ) def set_training_mode ( self ): self . backbone . train () super () . set_training_mode () def set_evaluation_mode ( self ): self . backbone . eval () super () . set_evaluation_mode () def fit ( self , epochs ): self . backbone = self . backbone . to ( self . device ) return super () . fit ( epochs = epochs ) def compute_loss ( self , predictions , targets , task_ids = None , * args , ** kwargs ) -> torch . Tensor : return F . cross_entropy ( predictions , targets ) __init__ ( backbone , benchmark , optimizer , callbacks = [], loggers = None , lr_decay = None , grad_clip = None , reinit_optimizer = True , device = 'cuda:0' , min_lr = 5e-05 ) Inits the PytorchBaseAlgorithm class. Parameters: Name Type Description Default backbone PytorchBaseBackbone The backbone model, e.g., a CNN. required benchmark Benchmark The benchmark, e.g., SplitMNIST. required optimizer torch . optim . Optimizer The optimizer used to update the backbone weights. required callbacks Iterable [ BaseCallback ] A list of callbacks. At least one instance of MetricCallback should be given. Defaults to []. [] loggers Optional [ Logger ] A list of logger, e.g. for Weights&Biases logging functionality. Defaults to None. None lr_decay Optional [ float ] A learning rate decay used for every new task. Defaults to None. None grad_clip Optional [ float ] The gradient clipping norm. Defaults to None. None reinit_optimizer bool Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True. True device str description . Defaults to \"cuda:0\". 'cuda:0' min_lr float description . Defaults to 0.00005. 5e-05 Note the _configure_optimizers method will be moved to a dedicated Callback. Source code in sequel/algos/pytorch/pytorch_base_algo.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def __init__ ( self , backbone : PytorchBaseBackbone , benchmark : Benchmark , optimizer : torch . optim . Optimizer , callbacks : Iterable [ BaseCallback ] = [], loggers : Optional [ Iterable [ Logger ]] = None , lr_decay : Optional [ float ] = None , grad_clip : Optional [ float ] = None , reinit_optimizer : bool = True , device = \"cuda:0\" , min_lr = 0.00005 , ) -> None : \"\"\"Inits the PytorchBaseAlgorithm class. Args: backbone (PytorchBaseBackbone): The backbone model, e.g., a CNN. benchmark (Benchmark): The benchmark, e.g., SplitMNIST. optimizer (torch.optim.Optimizer): The optimizer used to update the backbone weights. callbacks (Iterable[BaseCallback], optional): A list of callbacks. At least one instance of MetricCallback should be given. Defaults to []. loggers (Optional[Logger], optional): A list of logger, e.g. for Weights&Biases logging functionality. Defaults to None. lr_decay (Optional[float], optional): A learning rate decay used for every new task. Defaults to None. grad_clip (Optional[float], optional): The gradient clipping norm. Defaults to None. reinit_optimizer (bool): Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True. device (str, optional): _description_. Defaults to \"cuda:0\". min_lr (float, optional): _description_. Defaults to 0.00005. Note: 1. the `_configure_optimizers` method will be moved to a dedicated Callback. \"\"\" self . device = device if not isinstance ( backbone , BaseBackbone ): backbone = BackboneWrapper ( backbone ) super () . __init__ ( backbone = backbone , benchmark = benchmark , optimizer = optimizer , callbacks = callbacks , loggers = loggers , lr_decay = lr_decay , grad_clip = grad_clip , reinit_optimizer = reinit_optimizer , ) self . backbone = self . backbone . to ( self . device ) self . min_lr = min_lr forward ( * args , ** kwargs ) Calls the forward function of the model. Source code in sequel/algos/pytorch/pytorch_base_algo.py 94 95 96 97 98 def forward ( self , * args , ** kwargs ): \"\"\"Calls the forward function of the model.\"\"\" outs = self . backbone ( self . x , self . t ) self . y_hat = outs return outs test_step ( * args , ** kwargs ) Performs the testing step. Callbacks are offered for each step of the process. Source code in sequel/algos/pytorch/pytorch_base_algo.py 126 127 128 def test_step ( self , * args , ** kwargs ): \"\"\"Performs the testing step. Callbacks are offered for each step of the process.\"\"\" pass valid_step ( * args , ** kwargs ) Performs the validation step. Callbacks are offered for each step of the process. Source code in sequel/algos/pytorch/pytorch_base_algo.py 120 121 122 123 124 def valid_step ( self , * args , ** kwargs ): \"\"\"Performs the validation step. Callbacks are offered for each step of the process.\"\"\" with torch . no_grad (): y_hat = self . forward () self . loss = self . compute_loss ( y_hat , self . y , self . t ) PytorchRegularizationBaseAlgorithm Bases: PytorchBaseAlgorithm Source code in sequel/algos/pytorch/pytorch_base_algo.py 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 class PytorchRegularizationBaseAlgorithm ( PytorchBaseAlgorithm ): def __init__ ( self , regularization_coefficient , * args , ** kwargs ) -> None : super () . __init__ ( * args , ** kwargs ) self . regularization_coefficient = regularization_coefficient self . w = {} for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) # register old parameters and importance weight self . backbone . register_buffer ( f \" { name } _old\" , torch . zeros_like ( param )) self . backbone . register_buffer ( f \" { name } _importance\" , torch . zeros_like ( param )) def calculate_regularization_loss ( self ): \"\"\"Calculates the regularization loss: $$ \\\\mathcal{L}_{\\\\textrm{reg}} = \\\\sum\\\\limits_{i} \\\\Omega_i(\\\\theta_i-\\\\theta_{i, \\\\textrm{old}})^2 $$ where $\\\\Omega_i$ is the importance of parameter $i$, $\\\\theta_i$ and $\\\\theta_{i, \\\\textrm{old}}$ are the current and previous task's parameters. The parameter importances $\\\\Omega_i$ are calculated by the method `calculate_parameter_importance`. \"\"\" assert self . task_counter > 1 # shouldn't be called for the first task # because we have not calculate_parameter_importanced anything yet losses = [] for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) old_param = getattr ( self . backbone , f \" { name } _old\" ) importance = getattr ( self . backbone , f \" { name } _importance\" ) losses . append (( importance * ( param - old_param ) ** 2 ) . sum ()) return sum ( losses ) def compute_loss ( self , predictions : Tensor , targets : Tensor , task_ids : Tensor , * args , ** kwargs ) -> Tensor : \"\"\"Computes the loss. For tasks excluding the initial one, the loss also includes the regularization term. Args: predictions (Tensor): Model predictions. targets (Tensor): Targets of the current batch. task_ids (Tensor): Task ids of the current batch. Returns: Tensor: the overall loss. \"\"\" loss = super () . compute_loss ( predictions , targets , task_ids , * args , ** kwargs ) if self . task_counter > 1 : reg_loss = self . calculate_regularization_loss () loss += self . regularization_coefficient * ( reg_loss / 2 ) return loss def calculate_parameter_importance ( self ) -> Dict [ str , Tensor ]: r \"\"\"Calculcates the per-parameter importance. Should return a dictionary with keys in the format \"{name}_importance\" where name corresponds the `torch.nn.Parameter` the importance is attached to. Raises: NotImplementedError: Should be implemented according to each algorithm. \"\"\" raise NotImplementedError def on_after_training_task ( self , * args , ** kwargs ): importances = self . calculate_parameter_importance () for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) setattr ( self . backbone , f \" { name } _importance\" , importances [ name ] . clone ()) setattr ( self . backbone , f \" { name } _old\" , param . data . clone ()) return super () . on_after_training_task ( * args , ** kwargs ) calculate_parameter_importance () Calculcates the per-parameter importance. Should return a dictionary with keys in the format \"{name}_importance\" where name corresponds the torch.nn.Parameter the importance is attached to. Raises: Type Description NotImplementedError Should be implemented according to each algorithm. Source code in sequel/algos/pytorch/pytorch_base_algo.py 206 207 208 209 210 211 212 213 def calculate_parameter_importance ( self ) -> Dict [ str , Tensor ]: r \"\"\"Calculcates the per-parameter importance. Should return a dictionary with keys in the format \"{name}_importance\" where name corresponds the `torch.nn.Parameter` the importance is attached to. Raises: NotImplementedError: Should be implemented according to each algorithm. \"\"\" raise NotImplementedError calculate_regularization_loss () Calculates the regularization loss: \\mathcal{L}_{\\textrm{reg}} = \\sum\\limits_{i} \\Omega_i(\\theta_i-\\theta_{i, \\textrm{old}})^2 \\mathcal{L}_{\\textrm{reg}} = \\sum\\limits_{i} \\Omega_i(\\theta_i-\\theta_{i, \\textrm{old}})^2 where \\Omega_i \\Omega_i is the importance of parameter i i , \\theta_i \\theta_i and \\theta_{i, \\textrm{old}} \\theta_{i, \\textrm{old}} are the current and previous task's parameters. The parameter importances \\Omega_i \\Omega_i are calculated by the method calculate_parameter_importance . Source code in sequel/algos/pytorch/pytorch_base_algo.py 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 def calculate_regularization_loss ( self ): \"\"\"Calculates the regularization loss: $$ \\\\mathcal{L}_{\\\\textrm{reg}} = \\\\sum\\\\limits_{i} \\\\Omega_i(\\\\theta_i-\\\\theta_{i, \\\\textrm{old}})^2 $$ where $\\\\Omega_i$ is the importance of parameter $i$, $\\\\theta_i$ and $\\\\theta_{i, \\\\textrm{old}}$ are the current and previous task's parameters. The parameter importances $\\\\Omega_i$ are calculated by the method `calculate_parameter_importance`. \"\"\" assert self . task_counter > 1 # shouldn't be called for the first task # because we have not calculate_parameter_importanced anything yet losses = [] for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) old_param = getattr ( self . backbone , f \" { name } _old\" ) importance = getattr ( self . backbone , f \" { name } _importance\" ) losses . append (( importance * ( param - old_param ) ** 2 ) . sum ()) return sum ( losses ) compute_loss ( predictions , targets , task_ids , * args , ** kwargs ) Computes the loss. For tasks excluding the initial one, the loss also includes the regularization term. Parameters: Name Type Description Default predictions Tensor Model predictions. required targets Tensor Targets of the current batch. required task_ids Tensor Task ids of the current batch. required Returns: Name Type Description Tensor Tensor the overall loss. Source code in sequel/algos/pytorch/pytorch_base_algo.py 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 def compute_loss ( self , predictions : Tensor , targets : Tensor , task_ids : Tensor , * args , ** kwargs ) -> Tensor : \"\"\"Computes the loss. For tasks excluding the initial one, the loss also includes the regularization term. Args: predictions (Tensor): Model predictions. targets (Tensor): Targets of the current batch. task_ids (Tensor): Task ids of the current batch. Returns: Tensor: the overall loss. \"\"\" loss = super () . compute_loss ( predictions , targets , task_ids , * args , ** kwargs ) if self . task_counter > 1 : reg_loss = self . calculate_regularization_loss () loss += self . regularization_coefficient * ( reg_loss / 2 ) return loss","title":"PyTorchBaseAlgo"},{"location":"algos/pytorch/base_algo/#sequel.algos.pytorch.pytorch_base_algo.PytorchBaseAlgorithm","text":"Bases: BaseAlgorithm Source code in sequel/algos/pytorch/pytorch_base_algo.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 class PytorchBaseAlgorithm ( BaseAlgorithm ): optimizer : torch . optim . Optimizer backbone : torch . nn . Module def __init__ ( self , backbone : PytorchBaseBackbone , benchmark : Benchmark , optimizer : torch . optim . Optimizer , callbacks : Iterable [ BaseCallback ] = [], loggers : Optional [ Iterable [ Logger ]] = None , lr_decay : Optional [ float ] = None , grad_clip : Optional [ float ] = None , reinit_optimizer : bool = True , device = \"cuda:0\" , min_lr = 0.00005 , ) -> None : \"\"\"Inits the PytorchBaseAlgorithm class. Args: backbone (PytorchBaseBackbone): The backbone model, e.g., a CNN. benchmark (Benchmark): The benchmark, e.g., SplitMNIST. optimizer (torch.optim.Optimizer): The optimizer used to update the backbone weights. callbacks (Iterable[BaseCallback], optional): A list of callbacks. At least one instance of MetricCallback should be given. Defaults to []. loggers (Optional[Logger], optional): A list of logger, e.g. for Weights&Biases logging functionality. Defaults to None. lr_decay (Optional[float], optional): A learning rate decay used for every new task. Defaults to None. grad_clip (Optional[float], optional): The gradient clipping norm. Defaults to None. reinit_optimizer (bool): Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True. device (str, optional): _description_. Defaults to \"cuda:0\". min_lr (float, optional): _description_. Defaults to 0.00005. Note: 1. the `_configure_optimizers` method will be moved to a dedicated Callback. \"\"\" self . device = device if not isinstance ( backbone , BaseBackbone ): backbone = BackboneWrapper ( backbone ) super () . __init__ ( backbone = backbone , benchmark = benchmark , optimizer = optimizer , callbacks = callbacks , loggers = loggers , lr_decay = lr_decay , grad_clip = grad_clip , reinit_optimizer = reinit_optimizer , ) self . backbone = self . backbone . to ( self . device ) self . min_lr = min_lr def count_parameters ( self ): device = next ( self . backbone . parameters ()) . device self . backbone ( torch . ones ( self . input_dimensions ) . unsqueeze ( 0 ) . to ( device ), torch . ones (( 1 ))) return sum ([ p . numel () for p in self . backbone . parameters () if p . requires_grad ]) def _configure_optimizers ( self , task ): if self . task_counter == 1 or self . reinit_optimizer : assert len ( self . optimizer . param_groups ) == 1 lr = self . optimizer . param_groups [ 0 ][ \"lr\" ] self . optimizer . state = defaultdict ( dict ) self . optimizer . param_groups [ 0 ][ \"params\" ] = list ( self . backbone . parameters ()) if self . lr_decay is not None and task > 1 : assert isinstance ( self . lr_decay , float ) assert self . lr_decay > 0 and self . lr_decay <= 1 , \"lr decay should be in the interval (0,1]\" new_lr = max ( lr * self . lr_decay , self . min_lr ) self . optimizer . param_groups [ 0 ][ \"lr\" ] = new_lr logging . info ( f \"Decaying the learning rate by a factor of { self . lr_decay } \" ) logging . info ( self . optimizer ) def _configure_criterion ( self , task_id = None ): return torch . nn . CrossEntropyLoss () def forward ( self , * args , ** kwargs ): \"\"\"Calls the forward function of the model.\"\"\" outs = self . backbone ( self . x , self . t ) self . y_hat = outs return outs def unpack_batch ( self , batch ): device = self . device x , y , t = batch self . x , self . y , self . t = x . to ( device ), y . to ( device ), t . to ( device ) self . bs = len ( x ) def optimizer_zero_grad ( self ): self . optimizer . zero_grad () def backpropagate_loss ( self ): self . loss . backward () def optimizer_step ( self ): self . optimizer . step () def perform_gradient_clipping ( self ): if self . grad_clip is not None : assert self . grad_clip > 0 torch . nn . utils . clip_grad_norm_ ( self . backbone . parameters (), self . grad_clip ) def valid_step ( self , * args , ** kwargs ): \"\"\"Performs the validation step. Callbacks are offered for each step of the process.\"\"\" with torch . no_grad (): y_hat = self . forward () self . loss = self . compute_loss ( y_hat , self . y , self . t ) def test_step ( self , * args , ** kwargs ): \"\"\"Performs the testing step. Callbacks are offered for each step of the process.\"\"\" pass def prepare_for_next_task ( self , task ): self . _configure_optimizers ( task ) def set_training_mode ( self ): self . backbone . train () super () . set_training_mode () def set_evaluation_mode ( self ): self . backbone . eval () super () . set_evaluation_mode () def fit ( self , epochs ): self . backbone = self . backbone . to ( self . device ) return super () . fit ( epochs = epochs ) def compute_loss ( self , predictions , targets , task_ids = None , * args , ** kwargs ) -> torch . Tensor : return F . cross_entropy ( predictions , targets )","title":"PytorchBaseAlgorithm"},{"location":"algos/pytorch/base_algo/#sequel.algos.pytorch.pytorch_base_algo.PytorchBaseAlgorithm.__init__","text":"Inits the PytorchBaseAlgorithm class. Parameters: Name Type Description Default backbone PytorchBaseBackbone The backbone model, e.g., a CNN. required benchmark Benchmark The benchmark, e.g., SplitMNIST. required optimizer torch . optim . Optimizer The optimizer used to update the backbone weights. required callbacks Iterable [ BaseCallback ] A list of callbacks. At least one instance of MetricCallback should be given. Defaults to []. [] loggers Optional [ Logger ] A list of logger, e.g. for Weights&Biases logging functionality. Defaults to None. None lr_decay Optional [ float ] A learning rate decay used for every new task. Defaults to None. None grad_clip Optional [ float ] The gradient clipping norm. Defaults to None. None reinit_optimizer bool Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True. True device str description . Defaults to \"cuda:0\". 'cuda:0' min_lr float description . Defaults to 0.00005. 5e-05 Note the _configure_optimizers method will be moved to a dedicated Callback. Source code in sequel/algos/pytorch/pytorch_base_algo.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def __init__ ( self , backbone : PytorchBaseBackbone , benchmark : Benchmark , optimizer : torch . optim . Optimizer , callbacks : Iterable [ BaseCallback ] = [], loggers : Optional [ Iterable [ Logger ]] = None , lr_decay : Optional [ float ] = None , grad_clip : Optional [ float ] = None , reinit_optimizer : bool = True , device = \"cuda:0\" , min_lr = 0.00005 , ) -> None : \"\"\"Inits the PytorchBaseAlgorithm class. Args: backbone (PytorchBaseBackbone): The backbone model, e.g., a CNN. benchmark (Benchmark): The benchmark, e.g., SplitMNIST. optimizer (torch.optim.Optimizer): The optimizer used to update the backbone weights. callbacks (Iterable[BaseCallback], optional): A list of callbacks. At least one instance of MetricCallback should be given. Defaults to []. loggers (Optional[Logger], optional): A list of logger, e.g. for Weights&Biases logging functionality. Defaults to None. lr_decay (Optional[float], optional): A learning rate decay used for every new task. Defaults to None. grad_clip (Optional[float], optional): The gradient clipping norm. Defaults to None. reinit_optimizer (bool): Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True. device (str, optional): _description_. Defaults to \"cuda:0\". min_lr (float, optional): _description_. Defaults to 0.00005. Note: 1. the `_configure_optimizers` method will be moved to a dedicated Callback. \"\"\" self . device = device if not isinstance ( backbone , BaseBackbone ): backbone = BackboneWrapper ( backbone ) super () . __init__ ( backbone = backbone , benchmark = benchmark , optimizer = optimizer , callbacks = callbacks , loggers = loggers , lr_decay = lr_decay , grad_clip = grad_clip , reinit_optimizer = reinit_optimizer , ) self . backbone = self . backbone . to ( self . device ) self . min_lr = min_lr","title":"__init__()"},{"location":"algos/pytorch/base_algo/#sequel.algos.pytorch.pytorch_base_algo.PytorchBaseAlgorithm.forward","text":"Calls the forward function of the model. Source code in sequel/algos/pytorch/pytorch_base_algo.py 94 95 96 97 98 def forward ( self , * args , ** kwargs ): \"\"\"Calls the forward function of the model.\"\"\" outs = self . backbone ( self . x , self . t ) self . y_hat = outs return outs","title":"forward()"},{"location":"algos/pytorch/base_algo/#sequel.algos.pytorch.pytorch_base_algo.PytorchBaseAlgorithm.test_step","text":"Performs the testing step. Callbacks are offered for each step of the process. Source code in sequel/algos/pytorch/pytorch_base_algo.py 126 127 128 def test_step ( self , * args , ** kwargs ): \"\"\"Performs the testing step. Callbacks are offered for each step of the process.\"\"\" pass","title":"test_step()"},{"location":"algos/pytorch/base_algo/#sequel.algos.pytorch.pytorch_base_algo.PytorchBaseAlgorithm.valid_step","text":"Performs the validation step. Callbacks are offered for each step of the process. Source code in sequel/algos/pytorch/pytorch_base_algo.py 120 121 122 123 124 def valid_step ( self , * args , ** kwargs ): \"\"\"Performs the validation step. Callbacks are offered for each step of the process.\"\"\" with torch . no_grad (): y_hat = self . forward () self . loss = self . compute_loss ( y_hat , self . y , self . t )","title":"valid_step()"},{"location":"algos/pytorch/base_algo/#sequel.algos.pytorch.pytorch_base_algo.PytorchRegularizationBaseAlgorithm","text":"Bases: PytorchBaseAlgorithm Source code in sequel/algos/pytorch/pytorch_base_algo.py 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 class PytorchRegularizationBaseAlgorithm ( PytorchBaseAlgorithm ): def __init__ ( self , regularization_coefficient , * args , ** kwargs ) -> None : super () . __init__ ( * args , ** kwargs ) self . regularization_coefficient = regularization_coefficient self . w = {} for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) # register old parameters and importance weight self . backbone . register_buffer ( f \" { name } _old\" , torch . zeros_like ( param )) self . backbone . register_buffer ( f \" { name } _importance\" , torch . zeros_like ( param )) def calculate_regularization_loss ( self ): \"\"\"Calculates the regularization loss: $$ \\\\mathcal{L}_{\\\\textrm{reg}} = \\\\sum\\\\limits_{i} \\\\Omega_i(\\\\theta_i-\\\\theta_{i, \\\\textrm{old}})^2 $$ where $\\\\Omega_i$ is the importance of parameter $i$, $\\\\theta_i$ and $\\\\theta_{i, \\\\textrm{old}}$ are the current and previous task's parameters. The parameter importances $\\\\Omega_i$ are calculated by the method `calculate_parameter_importance`. \"\"\" assert self . task_counter > 1 # shouldn't be called for the first task # because we have not calculate_parameter_importanced anything yet losses = [] for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) old_param = getattr ( self . backbone , f \" { name } _old\" ) importance = getattr ( self . backbone , f \" { name } _importance\" ) losses . append (( importance * ( param - old_param ) ** 2 ) . sum ()) return sum ( losses ) def compute_loss ( self , predictions : Tensor , targets : Tensor , task_ids : Tensor , * args , ** kwargs ) -> Tensor : \"\"\"Computes the loss. For tasks excluding the initial one, the loss also includes the regularization term. Args: predictions (Tensor): Model predictions. targets (Tensor): Targets of the current batch. task_ids (Tensor): Task ids of the current batch. Returns: Tensor: the overall loss. \"\"\" loss = super () . compute_loss ( predictions , targets , task_ids , * args , ** kwargs ) if self . task_counter > 1 : reg_loss = self . calculate_regularization_loss () loss += self . regularization_coefficient * ( reg_loss / 2 ) return loss def calculate_parameter_importance ( self ) -> Dict [ str , Tensor ]: r \"\"\"Calculcates the per-parameter importance. Should return a dictionary with keys in the format \"{name}_importance\" where name corresponds the `torch.nn.Parameter` the importance is attached to. Raises: NotImplementedError: Should be implemented according to each algorithm. \"\"\" raise NotImplementedError def on_after_training_task ( self , * args , ** kwargs ): importances = self . calculate_parameter_importance () for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) setattr ( self . backbone , f \" { name } _importance\" , importances [ name ] . clone ()) setattr ( self . backbone , f \" { name } _old\" , param . data . clone ()) return super () . on_after_training_task ( * args , ** kwargs )","title":"PytorchRegularizationBaseAlgorithm"},{"location":"algos/pytorch/base_algo/#sequel.algos.pytorch.pytorch_base_algo.PytorchRegularizationBaseAlgorithm.calculate_parameter_importance","text":"Calculcates the per-parameter importance. Should return a dictionary with keys in the format \"{name}_importance\" where name corresponds the torch.nn.Parameter the importance is attached to. Raises: Type Description NotImplementedError Should be implemented according to each algorithm. Source code in sequel/algos/pytorch/pytorch_base_algo.py 206 207 208 209 210 211 212 213 def calculate_parameter_importance ( self ) -> Dict [ str , Tensor ]: r \"\"\"Calculcates the per-parameter importance. Should return a dictionary with keys in the format \"{name}_importance\" where name corresponds the `torch.nn.Parameter` the importance is attached to. Raises: NotImplementedError: Should be implemented according to each algorithm. \"\"\" raise NotImplementedError","title":"calculate_parameter_importance()"},{"location":"algos/pytorch/base_algo/#sequel.algos.pytorch.pytorch_base_algo.PytorchRegularizationBaseAlgorithm.calculate_regularization_loss","text":"Calculates the regularization loss: \\mathcal{L}_{\\textrm{reg}} = \\sum\\limits_{i} \\Omega_i(\\theta_i-\\theta_{i, \\textrm{old}})^2 \\mathcal{L}_{\\textrm{reg}} = \\sum\\limits_{i} \\Omega_i(\\theta_i-\\theta_{i, \\textrm{old}})^2 where \\Omega_i \\Omega_i is the importance of parameter i i , \\theta_i \\theta_i and \\theta_{i, \\textrm{old}} \\theta_{i, \\textrm{old}} are the current and previous task's parameters. The parameter importances \\Omega_i \\Omega_i are calculated by the method calculate_parameter_importance . Source code in sequel/algos/pytorch/pytorch_base_algo.py 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 def calculate_regularization_loss ( self ): \"\"\"Calculates the regularization loss: $$ \\\\mathcal{L}_{\\\\textrm{reg}} = \\\\sum\\\\limits_{i} \\\\Omega_i(\\\\theta_i-\\\\theta_{i, \\\\textrm{old}})^2 $$ where $\\\\Omega_i$ is the importance of parameter $i$, $\\\\theta_i$ and $\\\\theta_{i, \\\\textrm{old}}$ are the current and previous task's parameters. The parameter importances $\\\\Omega_i$ are calculated by the method `calculate_parameter_importance`. \"\"\" assert self . task_counter > 1 # shouldn't be called for the first task # because we have not calculate_parameter_importanced anything yet losses = [] for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) old_param = getattr ( self . backbone , f \" { name } _old\" ) importance = getattr ( self . backbone , f \" { name } _importance\" ) losses . append (( importance * ( param - old_param ) ** 2 ) . sum ()) return sum ( losses )","title":"calculate_regularization_loss()"},{"location":"algos/pytorch/base_algo/#sequel.algos.pytorch.pytorch_base_algo.PytorchRegularizationBaseAlgorithm.compute_loss","text":"Computes the loss. For tasks excluding the initial one, the loss also includes the regularization term. Parameters: Name Type Description Default predictions Tensor Model predictions. required targets Tensor Targets of the current batch. required task_ids Tensor Task ids of the current batch. required Returns: Name Type Description Tensor Tensor the overall loss. Source code in sequel/algos/pytorch/pytorch_base_algo.py 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 def compute_loss ( self , predictions : Tensor , targets : Tensor , task_ids : Tensor , * args , ** kwargs ) -> Tensor : \"\"\"Computes the loss. For tasks excluding the initial one, the loss also includes the regularization term. Args: predictions (Tensor): Model predictions. targets (Tensor): Targets of the current batch. task_ids (Tensor): Task ids of the current batch. Returns: Tensor: the overall loss. \"\"\" loss = super () . compute_loss ( predictions , targets , task_ids , * args , ** kwargs ) if self . task_counter > 1 : reg_loss = self . calculate_regularization_loss () loss += self . regularization_coefficient * ( reg_loss / 2 ) return loss","title":"compute_loss()"},{"location":"algos/pytorch/der/","text":"DER Bases: PytorchBaseAlgorithm Dark Experience Replay algorithm implemented in PyTorch. The equivalent JAX implementation is DER in JAX . References [1] Buzzega, P., Boschini, M., Porrello, A., Abati, D. & Calderara, S. Dark experience for general continual learning: a strong, simple baseline. in Advances in neural information processing systems 2020. Source code in sequel/algos/pytorch/der.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 class DER ( PytorchBaseAlgorithm ): \"\"\"Dark Experience Replay algorithm implemented in PyTorch. The equivalent JAX implementation is [`DER in JAX`][sequel.algos.jax.der.DER]. References: [1] Buzzega, P., Boschini, M., Porrello, A., Abati, D. & Calderara, S. Dark experience for general continual learning: a strong, simple baseline. in Advances in neural information processing systems 2020. \"\"\" def __init__ ( self , memory_size : int , alpha : float , beta : Optional [ float ] = None , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . buffer = Buffer ( memory_size = memory_size , return_logits = True ) self . memory_size = memory_size self . alpha = alpha # Beta is used for DER++ self . beta = beta def on_before_backward ( self , * args , ** kwargs ): if len ( self . buffer ) > 0 : # if self.task_counter > 1: x , y , t , logits = self . buffer . sample_from_buffer ( batch_size = self . benchmark . batch_size ) self . mem_x , self . mem_y , self . mem_t , self . mem_logits = x , y , t , logits self . mem_y_hat = self . backbone ( self . mem_x , self . mem_t ) loss = F . mse_loss ( self . mem_y_hat , self . mem_logits ) self . loss += self . alpha * loss if self . beta is not None : x , y , t , _ = self . buffer . sample_from_buffer ( batch_size = self . benchmark . batch_size ) self . mem_x2 , self . mem_y2 , self . mem_t2 = x . to ( self . device ), y . to ( self . device ), t . to ( self . device ) self . mem_y_hat2 = self . backbone ( self . mem_x2 , self . mem_t2 ) self . loss += self . beta * self . compute_loss ( self . mem_y_hat2 , self . mem_y2 , self . mem_t2 ) def on_before_optimizer_step ( self , * args , ** kwargs ): if self . task_counter > 1 : return super () . on_before_optimizer_step ( * args , ** kwargs ) def on_after_training_step ( self , * args , ** kwargs ): self . buffer . add_data ( self . x , self . y , self . t , self . y_hat . data ) def __repr__ ( self ) -> str : if self . beta is None : return f \"DER(memory_size= { self . memory_size } , alpha= { self . alpha } )\" else : return f \"DER++(memory_size= { self . memory_size } , alpha= { self . alpha } , beta= { self . beta } )\"","title":"DER"},{"location":"algos/pytorch/der/#sequel.algos.pytorch.der.DER","text":"Bases: PytorchBaseAlgorithm Dark Experience Replay algorithm implemented in PyTorch. The equivalent JAX implementation is DER in JAX . References [1] Buzzega, P., Boschini, M., Porrello, A., Abati, D. & Calderara, S. Dark experience for general continual learning: a strong, simple baseline. in Advances in neural information processing systems 2020. Source code in sequel/algos/pytorch/der.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 class DER ( PytorchBaseAlgorithm ): \"\"\"Dark Experience Replay algorithm implemented in PyTorch. The equivalent JAX implementation is [`DER in JAX`][sequel.algos.jax.der.DER]. References: [1] Buzzega, P., Boschini, M., Porrello, A., Abati, D. & Calderara, S. Dark experience for general continual learning: a strong, simple baseline. in Advances in neural information processing systems 2020. \"\"\" def __init__ ( self , memory_size : int , alpha : float , beta : Optional [ float ] = None , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . buffer = Buffer ( memory_size = memory_size , return_logits = True ) self . memory_size = memory_size self . alpha = alpha # Beta is used for DER++ self . beta = beta def on_before_backward ( self , * args , ** kwargs ): if len ( self . buffer ) > 0 : # if self.task_counter > 1: x , y , t , logits = self . buffer . sample_from_buffer ( batch_size = self . benchmark . batch_size ) self . mem_x , self . mem_y , self . mem_t , self . mem_logits = x , y , t , logits self . mem_y_hat = self . backbone ( self . mem_x , self . mem_t ) loss = F . mse_loss ( self . mem_y_hat , self . mem_logits ) self . loss += self . alpha * loss if self . beta is not None : x , y , t , _ = self . buffer . sample_from_buffer ( batch_size = self . benchmark . batch_size ) self . mem_x2 , self . mem_y2 , self . mem_t2 = x . to ( self . device ), y . to ( self . device ), t . to ( self . device ) self . mem_y_hat2 = self . backbone ( self . mem_x2 , self . mem_t2 ) self . loss += self . beta * self . compute_loss ( self . mem_y_hat2 , self . mem_y2 , self . mem_t2 ) def on_before_optimizer_step ( self , * args , ** kwargs ): if self . task_counter > 1 : return super () . on_before_optimizer_step ( * args , ** kwargs ) def on_after_training_step ( self , * args , ** kwargs ): self . buffer . add_data ( self . x , self . y , self . t , self . y_hat . data ) def __repr__ ( self ) -> str : if self . beta is None : return f \"DER(memory_size= { self . memory_size } , alpha= { self . alpha } )\" else : return f \"DER++(memory_size= { self . memory_size } , alpha= { self . alpha } , beta= { self . beta } )\"","title":"DER"},{"location":"algos/pytorch/er/","text":"","title":"ER"},{"location":"algos/pytorch/ewc/","text":"EWC Bases: PytorchRegularizationBaseAlgorithm Elastic Weight Consolidation Algorithm Class. Inherits from BaseAlgorithm. The equivalent JAX implementation is EWC in JAX . References [1] Kirkpatrick, J. et al. Overcoming catastrophic forgetting in neural networks. PNAS 114, 3521-3526 (2017). Source code in sequel/algos/pytorch/ewc.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 class EWC ( PytorchRegularizationBaseAlgorithm ): \"\"\"Elastic Weight Consolidation Algorithm Class. Inherits from BaseAlgorithm. The equivalent JAX implementation is [`EWC in JAX`][sequel.algos.jax.ewc.EWC]. References: [1] Kirkpatrick, J. et al. Overcoming catastrophic forgetting in neural networks. PNAS 114, 3521-3526 (2017). \"\"\" def __init__ ( self , ewc_lambda : float = 1.0 , * args , ** kwargs ): \"\"\"Inits the Elastic Weight Consolidation algorithm. Args: ewc_lambda (float): The lambda coefficient of EWC algorithm. \"\"\" super () . __init__ ( regularization_coefficient = ewc_lambda , * args , ** kwargs ) def __repr__ ( self ) -> str : return f \"EWC(ewc_lambda= { self . regularization_coefficient } )\" def calculate_parameter_importance ( self ): train_loader = self . benchmark . train_dataloader ( self . task_counter ) self . backbone = self . backbone . to ( self . device ) importances = {} for ii , batch in enumerate ( train_loader ): self . unpack_batch ( batch ) outs = self . backbone ( self . x , self . t ) loss = super () . compute_loss ( outs , self . y , self . t ) loss . backward () for ( name , p ) in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) if p . grad is not None : if getattr ( importances , name , None ) is None : importances [ name ] = p . grad . data . clone () . pow ( 2 ) / len ( train_loader ) else : importances [ name ] += p . grad . data . clone () . pow ( 2 ) / len ( train_loader ) return importances __init__ ( ewc_lambda = 1.0 , * args , ** kwargs ) Inits the Elastic Weight Consolidation algorithm. Parameters: Name Type Description Default ewc_lambda float The lambda coefficient of EWC algorithm. 1.0 Source code in sequel/algos/pytorch/ewc.py 13 14 15 16 17 18 19 def __init__ ( self , ewc_lambda : float = 1.0 , * args , ** kwargs ): \"\"\"Inits the Elastic Weight Consolidation algorithm. Args: ewc_lambda (float): The lambda coefficient of EWC algorithm. \"\"\" super () . __init__ ( regularization_coefficient = ewc_lambda , * args , ** kwargs )","title":"EWC"},{"location":"algos/pytorch/ewc/#sequel.algos.pytorch.ewc.EWC","text":"Bases: PytorchRegularizationBaseAlgorithm Elastic Weight Consolidation Algorithm Class. Inherits from BaseAlgorithm. The equivalent JAX implementation is EWC in JAX . References [1] Kirkpatrick, J. et al. Overcoming catastrophic forgetting in neural networks. PNAS 114, 3521-3526 (2017). Source code in sequel/algos/pytorch/ewc.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 class EWC ( PytorchRegularizationBaseAlgorithm ): \"\"\"Elastic Weight Consolidation Algorithm Class. Inherits from BaseAlgorithm. The equivalent JAX implementation is [`EWC in JAX`][sequel.algos.jax.ewc.EWC]. References: [1] Kirkpatrick, J. et al. Overcoming catastrophic forgetting in neural networks. PNAS 114, 3521-3526 (2017). \"\"\" def __init__ ( self , ewc_lambda : float = 1.0 , * args , ** kwargs ): \"\"\"Inits the Elastic Weight Consolidation algorithm. Args: ewc_lambda (float): The lambda coefficient of EWC algorithm. \"\"\" super () . __init__ ( regularization_coefficient = ewc_lambda , * args , ** kwargs ) def __repr__ ( self ) -> str : return f \"EWC(ewc_lambda= { self . regularization_coefficient } )\" def calculate_parameter_importance ( self ): train_loader = self . benchmark . train_dataloader ( self . task_counter ) self . backbone = self . backbone . to ( self . device ) importances = {} for ii , batch in enumerate ( train_loader ): self . unpack_batch ( batch ) outs = self . backbone ( self . x , self . t ) loss = super () . compute_loss ( outs , self . y , self . t ) loss . backward () for ( name , p ) in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) if p . grad is not None : if getattr ( importances , name , None ) is None : importances [ name ] = p . grad . data . clone () . pow ( 2 ) / len ( train_loader ) else : importances [ name ] += p . grad . data . clone () . pow ( 2 ) / len ( train_loader ) return importances","title":"EWC"},{"location":"algos/pytorch/ewc/#sequel.algos.pytorch.ewc.EWC.__init__","text":"Inits the Elastic Weight Consolidation algorithm. Parameters: Name Type Description Default ewc_lambda float The lambda coefficient of EWC algorithm. 1.0 Source code in sequel/algos/pytorch/ewc.py 13 14 15 16 17 18 19 def __init__ ( self , ewc_lambda : float = 1.0 , * args , ** kwargs ): \"\"\"Inits the Elastic Weight Consolidation algorithm. Args: ewc_lambda (float): The lambda coefficient of EWC algorithm. \"\"\" super () . __init__ ( regularization_coefficient = ewc_lambda , * args , ** kwargs )","title":"__init__()"},{"location":"algos/pytorch/icarl/","text":"FeatureExtractor Bases: nn . Module Wrapper that returns a flattened version of the output of specific PyTorch model. It is used to retrieve the feature representations (e.g. for iCaRL algorithm). Source code in sequel/algos/pytorch/icarl.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class FeatureExtractor ( nn . Module ): \"\"\"Wrapper that returns a flattened version of the output of specific PyTorch model. It is used to retrieve the feature representations (e.g. for iCaRL algorithm). \"\"\" def __init__ ( self , model : nn . Module ) -> None : super () . __init__ () self . model = model self . model . eval () def forward ( self , x : Tensor , * agrs , ** kwargs ) -> Tensor : bs = x . size ( 0 ) x = self . model ( x ) return x . view ( bs , - 1 ) Icarl Bases: PytorchBaseAlgorithm iCaRL: Incremental Classifier and Representation Learning algorithm. Inherits from BaseAlgorithm. Source code in sequel/algos/pytorch/icarl.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 class Icarl ( PytorchBaseAlgorithm ): \"\"\"iCaRL: Incremental Classifier and Representation Learning algorithm. Inherits from BaseAlgorithm.\"\"\" def __init__ ( self , memory_size : int , * args , ** kwargs ): \"\"\"Inits the iCaRL algorithm. Args: memory_size (int): The overall memory size used by the algorithm. \"\"\" super () . __init__ ( * args , ** kwargs ) self . memory_size = memory_size @classmethod def from_config ( cls , config , callbacks , loggers , * args , ** kwargs ): memory_size = config . algo . memory_size return cls ( memory_size = memory_size , config = config , callbacks = callbacks , loggers = loggers , * args , ** kwargs , ) def prepare_train_loader ( self , task_id : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Prepares the train_loader. After the initical task, the train dataloader is augmented with the memory samples. Args: task_id (int): The id of the task to be loaded. batch_size (Optional[int], optional): The batch size for the dataloader. If set to None, the default batch size (for the current experiment) is used. Defaults to None. Returns: DataLoader: The train dataloader for the current epoch. \"\"\" if task_id == 1 : return super () . prepare_train_loader ( task_id , batch_size ) else : return self . benchmark . train_dataloader_with_memory ( task_id , batch_size = batch_size , verbose = True ) def on_after_training_task ( self , * args , ** kwargs ): \"\"\"Handles memory specifics for the iCaRL algorithm, such as memory resizing and selecting new memory indices using the Herding algorithm. Raises: ValueError: The current task must not have memory yet, since this methods sets it. \"\"\" k = self . memory_size // self . task_counter for task in range ( 1 , self . task_counter ): old_indices = self . benchmark . get_memory_indices ( task ) new_indices = self . resize_memory ( old_indices , k ) self . benchmark . set_memory_indices ( task , new_indices ) # compute current task indices. The excess of exemplars goes to the last task for simplicity. num_indices = k + self . memory_size % self . task_counter indices = self . compute_new_indices ( num_indices = num_indices ) if self . task_counter in self . benchmark . memory_indices . keys (): raise ValueError ( \"Overwriting memory...Is something wrong?\" ) self . benchmark . set_memory_indices ( self . task_counter , indices ) @torch . no_grad () def compute_new_indices ( self , num_indices : int ) -> List [ int ]: \"\"\"Selects the indices for the current task, using the herding algorithm. Args: num_indices (int): The number of indices to be selected. Returns: List[int]: The selected indices. \"\"\" dataloader = super () . prepare_data_loader ( self . task_counter ) self . backbone . eval () model = FeatureExtractor ( self . backbone . encoder ) model . eval () features = torch . cat ([ model ( batch [ 0 ] . to ( self . device )) for batch in dataloader ]) indices = self . select_indices_with_herding ( features , num_indices ) return indices def select_indices_with_herding ( self , features : torch . Tensor , num_indices : int ) -> List [ int ]: \"\"\"Implements the herding algorithm. The most representative `num_indices` samples are selected based on their L2 distance to the feature mean. Args: features (torch.Tensor): The features of all samples. num_indices (int): The number of samples to be selected. Raises: ValueError: The features must be given in a 2D tensor. Returns: List[int]: The indices of the selected samples. \"\"\" if features . dim () != 2 : raise ValueError ( \"The features must be a Tensor of two dimensions, where the first dimension \\ corresponds to the number of samples.\" ) selected_indices = [] center = features . mean ( dim = 0 ) current_center = center * 0 for i in range ( num_indices ): # Compute distances with real center candidate_centers = current_center * i / ( i + 1 ) + features / ( i + 1 ) distances = pow ( candidate_centers - center , 2 ) . sum ( dim = 1 ) distances [ selected_indices ] = torch . inf # Select best candidate new_index = distances . argmin () . tolist () selected_indices . append ( new_index ) current_center = candidate_centers [ new_index ] return selected_indices @staticmethod def resize_memory ( indices : List [ int ], k : int ) -> list [ int ]: \"\"\"Resizes memory by selecting the first `k` indices. Args: indices (List[int]): The current memory indices. k (int): the new size of the memory. Raises: ValueError: The new memory size `k` cannot be larger than the previous one. Returns: list[int]: the new memory indices. \"\"\" if k > len ( indices ): raise ValueError ( \"The new memory cannot be larger than the current.\" ) return indices [: k ] __init__ ( memory_size , * args , ** kwargs ) Inits the iCaRL algorithm. Parameters: Name Type Description Default memory_size int The overall memory size used by the algorithm. required Source code in sequel/algos/pytorch/icarl.py 30 31 32 33 34 35 36 37 def __init__ ( self , memory_size : int , * args , ** kwargs ): \"\"\"Inits the iCaRL algorithm. Args: memory_size (int): The overall memory size used by the algorithm. \"\"\" super () . __init__ ( * args , ** kwargs ) self . memory_size = memory_size compute_new_indices ( num_indices ) Selects the indices for the current task, using the herding algorithm. Parameters: Name Type Description Default num_indices int The number of indices to be selected. required Returns: Type Description List [ int ] List[int]: The selected indices. Source code in sequel/algos/pytorch/icarl.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 @torch . no_grad () def compute_new_indices ( self , num_indices : int ) -> List [ int ]: \"\"\"Selects the indices for the current task, using the herding algorithm. Args: num_indices (int): The number of indices to be selected. Returns: List[int]: The selected indices. \"\"\" dataloader = super () . prepare_data_loader ( self . task_counter ) self . backbone . eval () model = FeatureExtractor ( self . backbone . encoder ) model . eval () features = torch . cat ([ model ( batch [ 0 ] . to ( self . device )) for batch in dataloader ]) indices = self . select_indices_with_herding ( features , num_indices ) return indices on_after_training_task ( * args , ** kwargs ) Handles memory specifics for the iCaRL algorithm, such as memory resizing and selecting new memory indices using the Herding algorithm. Raises: Type Description ValueError The current task must not have memory yet, since this methods sets it. Source code in sequel/algos/pytorch/icarl.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def on_after_training_task ( self , * args , ** kwargs ): \"\"\"Handles memory specifics for the iCaRL algorithm, such as memory resizing and selecting new memory indices using the Herding algorithm. Raises: ValueError: The current task must not have memory yet, since this methods sets it. \"\"\" k = self . memory_size // self . task_counter for task in range ( 1 , self . task_counter ): old_indices = self . benchmark . get_memory_indices ( task ) new_indices = self . resize_memory ( old_indices , k ) self . benchmark . set_memory_indices ( task , new_indices ) # compute current task indices. The excess of exemplars goes to the last task for simplicity. num_indices = k + self . memory_size % self . task_counter indices = self . compute_new_indices ( num_indices = num_indices ) if self . task_counter in self . benchmark . memory_indices . keys (): raise ValueError ( \"Overwriting memory...Is something wrong?\" ) self . benchmark . set_memory_indices ( self . task_counter , indices ) prepare_train_loader ( task_id , batch_size = None ) Prepares the train_loader. After the initical task, the train dataloader is augmented with the memory samples. Parameters: Name Type Description Default task_id int The id of the task to be loaded. required batch_size Optional [ int ] The batch size for the dataloader. If set to None, the default batch size (for the current experiment) is used. Defaults to None. None Returns: Name Type Description DataLoader DataLoader The train dataloader for the current epoch. Source code in sequel/algos/pytorch/icarl.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def prepare_train_loader ( self , task_id : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Prepares the train_loader. After the initical task, the train dataloader is augmented with the memory samples. Args: task_id (int): The id of the task to be loaded. batch_size (Optional[int], optional): The batch size for the dataloader. If set to None, the default batch size (for the current experiment) is used. Defaults to None. Returns: DataLoader: The train dataloader for the current epoch. \"\"\" if task_id == 1 : return super () . prepare_train_loader ( task_id , batch_size ) else : return self . benchmark . train_dataloader_with_memory ( task_id , batch_size = batch_size , verbose = True ) resize_memory ( indices , k ) staticmethod Resizes memory by selecting the first k indices. Parameters: Name Type Description Default indices List [ int ] The current memory indices. required k int the new size of the memory. required Raises: Type Description ValueError The new memory size k cannot be larger than the previous one. Returns: Type Description list [ int ] list[int]: the new memory indices. Source code in sequel/algos/pytorch/icarl.py 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 @staticmethod def resize_memory ( indices : List [ int ], k : int ) -> list [ int ]: \"\"\"Resizes memory by selecting the first `k` indices. Args: indices (List[int]): The current memory indices. k (int): the new size of the memory. Raises: ValueError: The new memory size `k` cannot be larger than the previous one. Returns: list[int]: the new memory indices. \"\"\" if k > len ( indices ): raise ValueError ( \"The new memory cannot be larger than the current.\" ) return indices [: k ] select_indices_with_herding ( features , num_indices ) Implements the herding algorithm. The most representative num_indices samples are selected based on their L2 distance to the feature mean. Parameters: Name Type Description Default features torch . Tensor The features of all samples. required num_indices int The number of samples to be selected. required Raises: Type Description ValueError The features must be given in a 2D tensor. Returns: Type Description List [ int ] List[int]: The indices of the selected samples. Source code in sequel/algos/pytorch/icarl.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def select_indices_with_herding ( self , features : torch . Tensor , num_indices : int ) -> List [ int ]: \"\"\"Implements the herding algorithm. The most representative `num_indices` samples are selected based on their L2 distance to the feature mean. Args: features (torch.Tensor): The features of all samples. num_indices (int): The number of samples to be selected. Raises: ValueError: The features must be given in a 2D tensor. Returns: List[int]: The indices of the selected samples. \"\"\" if features . dim () != 2 : raise ValueError ( \"The features must be a Tensor of two dimensions, where the first dimension \\ corresponds to the number of samples.\" ) selected_indices = [] center = features . mean ( dim = 0 ) current_center = center * 0 for i in range ( num_indices ): # Compute distances with real center candidate_centers = current_center * i / ( i + 1 ) + features / ( i + 1 ) distances = pow ( candidate_centers - center , 2 ) . sum ( dim = 1 ) distances [ selected_indices ] = torch . inf # Select best candidate new_index = distances . argmin () . tolist () selected_indices . append ( new_index ) current_center = candidate_centers [ new_index ] return selected_indices","title":"iCaRL"},{"location":"algos/pytorch/icarl/#sequel.algos.pytorch.icarl.FeatureExtractor","text":"Bases: nn . Module Wrapper that returns a flattened version of the output of specific PyTorch model. It is used to retrieve the feature representations (e.g. for iCaRL algorithm). Source code in sequel/algos/pytorch/icarl.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class FeatureExtractor ( nn . Module ): \"\"\"Wrapper that returns a flattened version of the output of specific PyTorch model. It is used to retrieve the feature representations (e.g. for iCaRL algorithm). \"\"\" def __init__ ( self , model : nn . Module ) -> None : super () . __init__ () self . model = model self . model . eval () def forward ( self , x : Tensor , * agrs , ** kwargs ) -> Tensor : bs = x . size ( 0 ) x = self . model ( x ) return x . view ( bs , - 1 )","title":"FeatureExtractor"},{"location":"algos/pytorch/icarl/#sequel.algos.pytorch.icarl.Icarl","text":"Bases: PytorchBaseAlgorithm iCaRL: Incremental Classifier and Representation Learning algorithm. Inherits from BaseAlgorithm. Source code in sequel/algos/pytorch/icarl.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 class Icarl ( PytorchBaseAlgorithm ): \"\"\"iCaRL: Incremental Classifier and Representation Learning algorithm. Inherits from BaseAlgorithm.\"\"\" def __init__ ( self , memory_size : int , * args , ** kwargs ): \"\"\"Inits the iCaRL algorithm. Args: memory_size (int): The overall memory size used by the algorithm. \"\"\" super () . __init__ ( * args , ** kwargs ) self . memory_size = memory_size @classmethod def from_config ( cls , config , callbacks , loggers , * args , ** kwargs ): memory_size = config . algo . memory_size return cls ( memory_size = memory_size , config = config , callbacks = callbacks , loggers = loggers , * args , ** kwargs , ) def prepare_train_loader ( self , task_id : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Prepares the train_loader. After the initical task, the train dataloader is augmented with the memory samples. Args: task_id (int): The id of the task to be loaded. batch_size (Optional[int], optional): The batch size for the dataloader. If set to None, the default batch size (for the current experiment) is used. Defaults to None. Returns: DataLoader: The train dataloader for the current epoch. \"\"\" if task_id == 1 : return super () . prepare_train_loader ( task_id , batch_size ) else : return self . benchmark . train_dataloader_with_memory ( task_id , batch_size = batch_size , verbose = True ) def on_after_training_task ( self , * args , ** kwargs ): \"\"\"Handles memory specifics for the iCaRL algorithm, such as memory resizing and selecting new memory indices using the Herding algorithm. Raises: ValueError: The current task must not have memory yet, since this methods sets it. \"\"\" k = self . memory_size // self . task_counter for task in range ( 1 , self . task_counter ): old_indices = self . benchmark . get_memory_indices ( task ) new_indices = self . resize_memory ( old_indices , k ) self . benchmark . set_memory_indices ( task , new_indices ) # compute current task indices. The excess of exemplars goes to the last task for simplicity. num_indices = k + self . memory_size % self . task_counter indices = self . compute_new_indices ( num_indices = num_indices ) if self . task_counter in self . benchmark . memory_indices . keys (): raise ValueError ( \"Overwriting memory...Is something wrong?\" ) self . benchmark . set_memory_indices ( self . task_counter , indices ) @torch . no_grad () def compute_new_indices ( self , num_indices : int ) -> List [ int ]: \"\"\"Selects the indices for the current task, using the herding algorithm. Args: num_indices (int): The number of indices to be selected. Returns: List[int]: The selected indices. \"\"\" dataloader = super () . prepare_data_loader ( self . task_counter ) self . backbone . eval () model = FeatureExtractor ( self . backbone . encoder ) model . eval () features = torch . cat ([ model ( batch [ 0 ] . to ( self . device )) for batch in dataloader ]) indices = self . select_indices_with_herding ( features , num_indices ) return indices def select_indices_with_herding ( self , features : torch . Tensor , num_indices : int ) -> List [ int ]: \"\"\"Implements the herding algorithm. The most representative `num_indices` samples are selected based on their L2 distance to the feature mean. Args: features (torch.Tensor): The features of all samples. num_indices (int): The number of samples to be selected. Raises: ValueError: The features must be given in a 2D tensor. Returns: List[int]: The indices of the selected samples. \"\"\" if features . dim () != 2 : raise ValueError ( \"The features must be a Tensor of two dimensions, where the first dimension \\ corresponds to the number of samples.\" ) selected_indices = [] center = features . mean ( dim = 0 ) current_center = center * 0 for i in range ( num_indices ): # Compute distances with real center candidate_centers = current_center * i / ( i + 1 ) + features / ( i + 1 ) distances = pow ( candidate_centers - center , 2 ) . sum ( dim = 1 ) distances [ selected_indices ] = torch . inf # Select best candidate new_index = distances . argmin () . tolist () selected_indices . append ( new_index ) current_center = candidate_centers [ new_index ] return selected_indices @staticmethod def resize_memory ( indices : List [ int ], k : int ) -> list [ int ]: \"\"\"Resizes memory by selecting the first `k` indices. Args: indices (List[int]): The current memory indices. k (int): the new size of the memory. Raises: ValueError: The new memory size `k` cannot be larger than the previous one. Returns: list[int]: the new memory indices. \"\"\" if k > len ( indices ): raise ValueError ( \"The new memory cannot be larger than the current.\" ) return indices [: k ]","title":"Icarl"},{"location":"algos/pytorch/icarl/#sequel.algos.pytorch.icarl.Icarl.__init__","text":"Inits the iCaRL algorithm. Parameters: Name Type Description Default memory_size int The overall memory size used by the algorithm. required Source code in sequel/algos/pytorch/icarl.py 30 31 32 33 34 35 36 37 def __init__ ( self , memory_size : int , * args , ** kwargs ): \"\"\"Inits the iCaRL algorithm. Args: memory_size (int): The overall memory size used by the algorithm. \"\"\" super () . __init__ ( * args , ** kwargs ) self . memory_size = memory_size","title":"__init__()"},{"location":"algos/pytorch/icarl/#sequel.algos.pytorch.icarl.Icarl.compute_new_indices","text":"Selects the indices for the current task, using the herding algorithm. Parameters: Name Type Description Default num_indices int The number of indices to be selected. required Returns: Type Description List [ int ] List[int]: The selected indices. Source code in sequel/algos/pytorch/icarl.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 @torch . no_grad () def compute_new_indices ( self , num_indices : int ) -> List [ int ]: \"\"\"Selects the indices for the current task, using the herding algorithm. Args: num_indices (int): The number of indices to be selected. Returns: List[int]: The selected indices. \"\"\" dataloader = super () . prepare_data_loader ( self . task_counter ) self . backbone . eval () model = FeatureExtractor ( self . backbone . encoder ) model . eval () features = torch . cat ([ model ( batch [ 0 ] . to ( self . device )) for batch in dataloader ]) indices = self . select_indices_with_herding ( features , num_indices ) return indices","title":"compute_new_indices()"},{"location":"algos/pytorch/icarl/#sequel.algos.pytorch.icarl.Icarl.on_after_training_task","text":"Handles memory specifics for the iCaRL algorithm, such as memory resizing and selecting new memory indices using the Herding algorithm. Raises: Type Description ValueError The current task must not have memory yet, since this methods sets it. Source code in sequel/algos/pytorch/icarl.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def on_after_training_task ( self , * args , ** kwargs ): \"\"\"Handles memory specifics for the iCaRL algorithm, such as memory resizing and selecting new memory indices using the Herding algorithm. Raises: ValueError: The current task must not have memory yet, since this methods sets it. \"\"\" k = self . memory_size // self . task_counter for task in range ( 1 , self . task_counter ): old_indices = self . benchmark . get_memory_indices ( task ) new_indices = self . resize_memory ( old_indices , k ) self . benchmark . set_memory_indices ( task , new_indices ) # compute current task indices. The excess of exemplars goes to the last task for simplicity. num_indices = k + self . memory_size % self . task_counter indices = self . compute_new_indices ( num_indices = num_indices ) if self . task_counter in self . benchmark . memory_indices . keys (): raise ValueError ( \"Overwriting memory...Is something wrong?\" ) self . benchmark . set_memory_indices ( self . task_counter , indices )","title":"on_after_training_task()"},{"location":"algos/pytorch/icarl/#sequel.algos.pytorch.icarl.Icarl.prepare_train_loader","text":"Prepares the train_loader. After the initical task, the train dataloader is augmented with the memory samples. Parameters: Name Type Description Default task_id int The id of the task to be loaded. required batch_size Optional [ int ] The batch size for the dataloader. If set to None, the default batch size (for the current experiment) is used. Defaults to None. None Returns: Name Type Description DataLoader DataLoader The train dataloader for the current epoch. Source code in sequel/algos/pytorch/icarl.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def prepare_train_loader ( self , task_id : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Prepares the train_loader. After the initical task, the train dataloader is augmented with the memory samples. Args: task_id (int): The id of the task to be loaded. batch_size (Optional[int], optional): The batch size for the dataloader. If set to None, the default batch size (for the current experiment) is used. Defaults to None. Returns: DataLoader: The train dataloader for the current epoch. \"\"\" if task_id == 1 : return super () . prepare_train_loader ( task_id , batch_size ) else : return self . benchmark . train_dataloader_with_memory ( task_id , batch_size = batch_size , verbose = True )","title":"prepare_train_loader()"},{"location":"algos/pytorch/icarl/#sequel.algos.pytorch.icarl.Icarl.resize_memory","text":"Resizes memory by selecting the first k indices. Parameters: Name Type Description Default indices List [ int ] The current memory indices. required k int the new size of the memory. required Raises: Type Description ValueError The new memory size k cannot be larger than the previous one. Returns: Type Description list [ int ] list[int]: the new memory indices. Source code in sequel/algos/pytorch/icarl.py 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 @staticmethod def resize_memory ( indices : List [ int ], k : int ) -> list [ int ]: \"\"\"Resizes memory by selecting the first `k` indices. Args: indices (List[int]): The current memory indices. k (int): the new size of the memory. Raises: ValueError: The new memory size `k` cannot be larger than the previous one. Returns: list[int]: the new memory indices. \"\"\" if k > len ( indices ): raise ValueError ( \"The new memory cannot be larger than the current.\" ) return indices [: k ]","title":"resize_memory()"},{"location":"algos/pytorch/icarl/#sequel.algos.pytorch.icarl.Icarl.select_indices_with_herding","text":"Implements the herding algorithm. The most representative num_indices samples are selected based on their L2 distance to the feature mean. Parameters: Name Type Description Default features torch . Tensor The features of all samples. required num_indices int The number of samples to be selected. required Raises: Type Description ValueError The features must be given in a 2D tensor. Returns: Type Description List [ int ] List[int]: The indices of the selected samples. Source code in sequel/algos/pytorch/icarl.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def select_indices_with_herding ( self , features : torch . Tensor , num_indices : int ) -> List [ int ]: \"\"\"Implements the herding algorithm. The most representative `num_indices` samples are selected based on their L2 distance to the feature mean. Args: features (torch.Tensor): The features of all samples. num_indices (int): The number of samples to be selected. Raises: ValueError: The features must be given in a 2D tensor. Returns: List[int]: The indices of the selected samples. \"\"\" if features . dim () != 2 : raise ValueError ( \"The features must be a Tensor of two dimensions, where the first dimension \\ corresponds to the number of samples.\" ) selected_indices = [] center = features . mean ( dim = 0 ) current_center = center * 0 for i in range ( num_indices ): # Compute distances with real center candidate_centers = current_center * i / ( i + 1 ) + features / ( i + 1 ) distances = pow ( candidate_centers - center , 2 ) . sum ( dim = 1 ) distances [ selected_indices ] = torch . inf # Select best candidate new_index = distances . argmin () . tolist () selected_indices . append ( new_index ) current_center = candidate_centers [ new_index ] return selected_indices","title":"select_indices_with_herding()"},{"location":"algos/pytorch/joint/","text":"JointTraining Bases: PytorchBaseAlgorithm The JoinTraining algorithm. It is a variant of MultiTask Learning, where the model is trained with increasingly more samples. Specifically, during the t-th task, the model sees samples from all the previous and the current task. Inherits from BaseAlgorithm. Only the prepare_train_loader method is overwritten. The equivalent JAX implementation is JointTraining in JAX . Source code in sequel/algos/pytorch/joint.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 class JointTraining ( PytorchBaseAlgorithm ): \"\"\"The JoinTraining algorithm. It is a variant of MultiTask Learning, where the model is trained with increasingly more samples. Specifically, during the t-th task, the model sees samples from all the previous and the current task. Inherits from BaseAlgorithm. Only the `prepare_train_loader` method is overwritten. The equivalent JAX implementation is [`JointTraining in JAX`][sequel.algos.jax.joint.JointTraining]. \"\"\" def __init__ ( self , * args , ** kwargs ) -> None : super () . __init__ ( * args , ** kwargs ) def __repr__ ( self ) -> str : return f \"JointTraining()\" def prepare_train_loader ( self , task_id : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Prepares the train_loader for Joint Training. The dataloader consists of all samples up to task `task_id`. Args: task_id (int): The last task to be loaded. batch_size (Optional[int], optional): The dataloader batch size. Defaults to None. Returns: DataLoader: The JointTraining train dataloder. \"\"\" return self . benchmark . train_dataloader_joint ( task_id , batch_size = batch_size ) prepare_train_loader ( task_id , batch_size = None ) Prepares the train_loader for Joint Training. The dataloader consists of all samples up to task task_id . Parameters: Name Type Description Default task_id int The last task to be loaded. required batch_size Optional [ int ] The dataloader batch size. Defaults to None. None Returns: Name Type Description DataLoader DataLoader The JointTraining train dataloder. Source code in sequel/algos/pytorch/joint.py 25 26 27 28 29 30 31 32 33 34 35 def prepare_train_loader ( self , task_id : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Prepares the train_loader for Joint Training. The dataloader consists of all samples up to task `task_id`. Args: task_id (int): The last task to be loaded. batch_size (Optional[int], optional): The dataloader batch size. Defaults to None. Returns: DataLoader: The JointTraining train dataloder. \"\"\" return self . benchmark . train_dataloader_joint ( task_id , batch_size = batch_size )","title":"Joint"},{"location":"algos/pytorch/joint/#sequel.algos.pytorch.joint.JointTraining","text":"Bases: PytorchBaseAlgorithm The JoinTraining algorithm. It is a variant of MultiTask Learning, where the model is trained with increasingly more samples. Specifically, during the t-th task, the model sees samples from all the previous and the current task. Inherits from BaseAlgorithm. Only the prepare_train_loader method is overwritten. The equivalent JAX implementation is JointTraining in JAX . Source code in sequel/algos/pytorch/joint.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 class JointTraining ( PytorchBaseAlgorithm ): \"\"\"The JoinTraining algorithm. It is a variant of MultiTask Learning, where the model is trained with increasingly more samples. Specifically, during the t-th task, the model sees samples from all the previous and the current task. Inherits from BaseAlgorithm. Only the `prepare_train_loader` method is overwritten. The equivalent JAX implementation is [`JointTraining in JAX`][sequel.algos.jax.joint.JointTraining]. \"\"\" def __init__ ( self , * args , ** kwargs ) -> None : super () . __init__ ( * args , ** kwargs ) def __repr__ ( self ) -> str : return f \"JointTraining()\" def prepare_train_loader ( self , task_id : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Prepares the train_loader for Joint Training. The dataloader consists of all samples up to task `task_id`. Args: task_id (int): The last task to be loaded. batch_size (Optional[int], optional): The dataloader batch size. Defaults to None. Returns: DataLoader: The JointTraining train dataloder. \"\"\" return self . benchmark . train_dataloader_joint ( task_id , batch_size = batch_size )","title":"JointTraining"},{"location":"algos/pytorch/joint/#sequel.algos.pytorch.joint.JointTraining.prepare_train_loader","text":"Prepares the train_loader for Joint Training. The dataloader consists of all samples up to task task_id . Parameters: Name Type Description Default task_id int The last task to be loaded. required batch_size Optional [ int ] The dataloader batch size. Defaults to None. None Returns: Name Type Description DataLoader DataLoader The JointTraining train dataloder. Source code in sequel/algos/pytorch/joint.py 25 26 27 28 29 30 31 32 33 34 35 def prepare_train_loader ( self , task_id : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Prepares the train_loader for Joint Training. The dataloader consists of all samples up to task `task_id`. Args: task_id (int): The last task to be loaded. batch_size (Optional[int], optional): The dataloader batch size. Defaults to None. Returns: DataLoader: The JointTraining train dataloder. \"\"\" return self . benchmark . train_dataloader_joint ( task_id , batch_size = batch_size )","title":"prepare_train_loader()"},{"location":"algos/pytorch/kcl/","text":"Amortized Bases: nn . Module Source code in sequel/algos/pytorch/kcl.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 class Amortized ( nn . Module ): def __init__ ( self , input_units : int , d_theta : int , output_units : int ): \"\"\"Inits the inference block used by the Kernel Continual Learning algorithm. Args: input_units (int): dimensionality of the input. d_theta (int): dimensionality of the intermediate hidden layers. output_units (int): dimensionality of the output. \"\"\" super ( Amortized , self ) . __init__ () self . output_units = output_units self . weight_mean = InferenceBlock ( input_units , d_theta , output_units ) self . weight_log_variance = InferenceBlock ( input_units , d_theta , output_units ) def forward ( self , x : torch . Tensor ) -> torch . Tensor : weight_mean = self . weight_mean ( x ) weight_log_variance = self . weight_log_variance ( x ) return weight_mean , weight_log_variance __init__ ( input_units , d_theta , output_units ) Inits the inference block used by the Kernel Continual Learning algorithm. Parameters: Name Type Description Default input_units int dimensionality of the input. required d_theta int dimensionality of the intermediate hidden layers. required output_units int dimensionality of the output. required Source code in sequel/algos/pytorch/kcl.py 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , input_units : int , d_theta : int , output_units : int ): \"\"\"Inits the inference block used by the Kernel Continual Learning algorithm. Args: input_units (int): dimensionality of the input. d_theta (int): dimensionality of the intermediate hidden layers. output_units (int): dimensionality of the output. \"\"\" super ( Amortized , self ) . __init__ () self . output_units = output_units self . weight_mean = InferenceBlock ( input_units , d_theta , output_units ) self . weight_log_variance = InferenceBlock ( input_units , d_theta , output_units ) InferenceBlock Bases: nn . Module Source code in sequel/algos/pytorch/kcl.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 class InferenceBlock ( nn . Module ): def __init__ ( self , input_units : int , d_theta : int , output_units : int ): \"\"\"Inits the inference block used by the Kernel Continual Learning algorithm. Args: input_units (int): dimensionality of the input. d_theta (int): dimensionality of the intermediate hidden layers. output_units (int): dimensionality of the output. \"\"\" super ( InferenceBlock , self ) . __init__ () self . module = nn . Sequential ( nn . Linear ( input_units , d_theta , bias = True ), nn . ELU ( inplace = True ), nn . Linear ( d_theta , d_theta , bias = True ), nn . ELU ( inplace = True ), nn . Linear ( d_theta , output_units , bias = True ), ) def forward ( self , x : torch . Tensor ) -> torch . Tensor : return self . module ( x ) __init__ ( input_units , d_theta , output_units ) Inits the inference block used by the Kernel Continual Learning algorithm. Parameters: Name Type Description Default input_units int dimensionality of the input. required d_theta int dimensionality of the intermediate hidden layers. required output_units int dimensionality of the output. required Source code in sequel/algos/pytorch/kcl.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def __init__ ( self , input_units : int , d_theta : int , output_units : int ): \"\"\"Inits the inference block used by the Kernel Continual Learning algorithm. Args: input_units (int): dimensionality of the input. d_theta (int): dimensionality of the intermediate hidden layers. output_units (int): dimensionality of the output. \"\"\" super ( InferenceBlock , self ) . __init__ () self . module = nn . Sequential ( nn . Linear ( input_units , d_theta , bias = True ), nn . ELU ( inplace = True ), nn . Linear ( d_theta , d_theta , bias = True ), nn . ELU ( inplace = True ), nn . Linear ( d_theta , output_units , bias = True ), ) KCL Bases: PytorchBaseAlgorithm Kernel Continual Learning algorithm. The code is adapted from https://github.com/mmderakhshani/KCL/blob/main/stable_sgd/main.py KCL is not yet implemented in JAX. References [1] Derakhshani, M. M., Zhen, X., Shao, L. & Snoek, C. Kernel Continual Learning. in Proceedings of the 38th International Conference on Machine Learning, ICML 2021. Source code in sequel/algos/pytorch/kcl.py 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 class KCL ( PytorchBaseAlgorithm ): \"\"\"Kernel Continual Learning algorithm. The code is adapted from https://github.com/mmderakhshani/KCL/blob/main/stable_sgd/main.py KCL is not yet implemented in JAX. References: [1] Derakhshani, M. M., Zhen, X., Shao, L. & Snoek, C. Kernel Continual Learning. in Proceedings of the 38th International Conference on Machine Learning, ICML 2021. \"\"\" def __init__ ( self , lmd : float , core_size : int , d_rn_f : int , kernel_type : Literal [ \"rbf\" , \"rff\" , \"linear\" , \"poly\" ], tau : float , * args , ** kwargs , ): super () . __init__ ( * args , ** kwargs ) self . __check_valid__ () self . core_size = core_size self . kernel_type = kernel_type self . tau = tau self . coresets = {} device = next ( self . backbone . parameters ()) . device embedding = self . backbone . encoder ( torch . ones ( self . input_dimensions ) . unsqueeze ( 0 ) . to ( device )) self . backbone = KernelBackboneWrapper ( self . backbone , hiddens = embedding . numel (), lmd = lmd , num_tasks = self . num_tasks , d_rn_f = d_rn_f ) . to ( device ) def __check_valid__ ( self ): if getattr ( self . backbone , \"encoder\" , None ) is None : raise AttributeError ( \"The backbone must have an encoder subnetwork to be compatible with the implementation of Kernel \" \"Continual Learning. The encoder consists of the entire original backbone except from the last Linear \" \"layer, i.e., the classifier.\" ) def count_parameters ( self ) -> int : if not isinstance ( self . backbone , KernelBackboneWrapper ): return super () . count_parameters () return sum ([ p . numel () for p in self . backbone . parameters () if p . requires_grad ]) def prepare_train_loader ( self , task : int ) -> DataLoader : \"\"\"Splits the training dataset of the given `task` to training and coreset.\"\"\" dataset = self . benchmark . get_train_dataset ( task ) dataset , coreset = random_split ( dataset , lengths = [ len ( dataset ) - self . core_size , self . core_size ]) self . coresets [ task ] = coreset self . register_coreset ( coreset ) return DataLoader ( dataset , self . benchmark . batch_size , shuffle = True , ** self . benchmark . dl_kwargs ) def register_coreset ( self , coreset ): num_classes = self . benchmark . num_classes x = [ sample [ 0 ] for sample in coreset ] y = [ sample [ 1 ] for sample in coreset ] self . coreset_input = torch . stack ( x ) . to ( self . device ) self . coreset_target = F . one_hot ( torch . tensor ( y ), num_classes = num_classes ) . to ( self . device ) . float () def forward ( self ): \"\"\"Performs the forward for the Kernel Continual Learning backbone.\"\"\" self . y_hat = self . backbone . forward ( self . x , self . t , self . coreset_input , self . coreset_target ) return self . y_hat def kl_div ( self , m : torch . Tensor , log_v : torch . Tensor , m0 : torch . Tensor , log_v0 : torch . Tensor ) -> torch . Tensor : \"\"\"Computes the Kullback-Leibler divergence assuming two normal distributions parameterized by the arguments.\"\"\" v = log_v . exp () v0 = log_v0 . exp () dout , din = m . shape const_term = - 0.5 * dout * din log_std_diff = 0.5 * torch . sum ( torch . log ( v0 ) - torch . log ( v )) mu_diff_term = 0.5 * torch . sum (( v + ( m0 - m ) ** 2 ) / v0 ) kl = const_term + log_std_diff + mu_diff_term return kl def training_step ( self , * args , ** kwargs ): self . optimizer_zero_grad () self . y_hat = self . forward () self . loss = F . cross_entropy ( self . y_hat , self . y ) if self . kernel_type == \"rff\" : r_mu , r_log_var = self . backbone . r_mu , self . backbone . r_log_var p_mu , p_log_var = self . backbone . p_mu , self . backbone . p_log_var self . loss += self . tau * self . kl_div ( r_mu , r_log_var , p_mu , p_log_var ) self . loss . backward () self . optimizer . step () def on_before_val_epoch ( self , * args , ** kwargs ): logging . info ( f \"Setting the coreset for validating task { self . current_val_task } .\" ) self . register_coreset ( self . coresets [ self . current_val_task ]) return super () . on_before_val_epoch ( * args , ** kwargs ) forward () Performs the forward for the Kernel Continual Learning backbone. Source code in sequel/algos/pytorch/kcl.py 237 238 239 240 def forward ( self ): \"\"\"Performs the forward for the Kernel Continual Learning backbone.\"\"\" self . y_hat = self . backbone . forward ( self . x , self . t , self . coreset_input , self . coreset_target ) return self . y_hat kl_div ( m , log_v , m0 , log_v0 ) Computes the Kullback-Leibler divergence assuming two normal distributions parameterized by the arguments. Source code in sequel/algos/pytorch/kcl.py 242 243 244 245 246 247 248 249 250 251 252 253 def kl_div ( self , m : torch . Tensor , log_v : torch . Tensor , m0 : torch . Tensor , log_v0 : torch . Tensor ) -> torch . Tensor : \"\"\"Computes the Kullback-Leibler divergence assuming two normal distributions parameterized by the arguments.\"\"\" v = log_v . exp () v0 = log_v0 . exp () dout , din = m . shape const_term = - 0.5 * dout * din log_std_diff = 0.5 * torch . sum ( torch . log ( v0 ) - torch . log ( v )) mu_diff_term = 0.5 * torch . sum (( v + ( m0 - m ) ** 2 ) / v0 ) kl = const_term + log_std_diff + mu_diff_term return kl prepare_train_loader ( task ) Splits the training dataset of the given task to training and coreset. Source code in sequel/algos/pytorch/kcl.py 222 223 224 225 226 227 228 def prepare_train_loader ( self , task : int ) -> DataLoader : \"\"\"Splits the training dataset of the given `task` to training and coreset.\"\"\" dataset = self . benchmark . get_train_dataset ( task ) dataset , coreset = random_split ( dataset , lengths = [ len ( dataset ) - self . core_size , self . core_size ]) self . coresets [ task ] = coreset self . register_coreset ( coreset ) return DataLoader ( dataset , self . benchmark . batch_size , shuffle = True , ** self . benchmark . dl_kwargs ) KernelBackboneWrapper Bases: BaseBackbone Source code in sequel/algos/pytorch/kcl.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 class KernelBackboneWrapper ( BaseBackbone ): def __init__ ( self , model : BaseBackbone , hiddens : int , lmd : float , num_tasks : int , d_rn_f : int , kernel_type : Literal [ \"rbf\" , \"rff\" , \"linear\" , \"poly\" ] = \"rff\" , ): \"\"\"Model Wrapper for Kernel Continual Learning. Extracts the encoder of the original backbone and performs the k ernel computations outlined in [1]. Notes: The `hiddens` argument can be removed and instead inferred. Args: model (BaseBackbone): the original backbone. The model must have an encoder component. hiddens (int): the dimensionality of the hidden dimensions for the kernel-specific modules. lmd (float): The initial value for the lmd Parameter. num_tasks (int): the number of tasks to be solved. d_rn_f (int): dimensionality of the Random Fourier Features (RFFs). Applicable only if `kernel_type` is 'rff'. kernel_type (str, optional): _description_. Defaults to \"rbf\". \"\"\" multihead , classes_per_task , masking_value = model . multihead , model . classes_per_task , model . masking_value super () . __init__ ( multihead = multihead , classes_per_task = classes_per_task , masking_value = masking_value ) self . encoder = model . encoder self . d_rn_f = d_rn_f self . post = Amortized ( hiddens , hiddens , hiddens ) self . prior = Amortized ( hiddens , hiddens , hiddens ) device = next ( model . parameters ()) . device self . lmd = nn . Parameter ( torch . tensor ([ lmd for _ in range ( num_tasks )])) . to ( device ) self . gma = nn . Parameter ( torch . tensor ([ 1.0 for _ in range ( num_tasks )])) . to ( device ) self . bta = nn . Parameter ( torch . tensor ([ 0.0 for _ in range ( num_tasks )])) . to ( device ) self . kernel_type = kernel_type self . bias = 2 * math . pi * torch . rand ( d_rn_f , 1 ) . to ( device ) def inner_forward ( self , x : torch . Tensor , post : bool = False ) -> Tuple [ torch . Tensor , torch . Tensor , torch . Tensor ]: out = self . encoder ( x ) out_features = self . normalize ( out ) out_mean = torch . mean ( out_features , dim = 0 , keepdim = True ) if post : mu , logvar = self . post ( out_mean ) else : mu , logvar = self . prior ( out_mean ) return out_features , mu , logvar def kernel ( self , x : torch . Tensor , y : torch . Tensor ) -> torch . Tensor : if self . kernel_type == \"rbf\" : support_kernel = torch . exp ( - 0.25 * torch . norm ( x . unsqueeze ( 1 ) - y , dim = 2 , p = 1 )) elif self . kernel_type == \"linear\" : support_kernel = x @ y . T elif self . kernel_type == \"poly\" : support_kernel = ( torch . matmul ( x , y . T ) + 1 ) . pow ( 3 ) elif self . kernel_type == \"rff\" : support_kernel = x . T @ y else : raise Exception ( f \"Unknown kenrel. Only support RBF, RFF, POLY, LIN.\" ) return support_kernel @staticmethod def sample ( mu : torch . Tensor , logvar : torch . Tensor , L : int , device ) -> torch . Tensor : shape = ( L ,) + mu . size () eps = torch . randn ( shape ) . to ( device ) return mu . unsqueeze ( 0 ) + eps * logvar . exp () . sqrt () . unsqueeze ( 0 ) def rand_features ( self , bases : torch . Tensor , features : torch . Tensor ) -> torch . Tensor : return math . sqrt ( 2 / self . bias . shape [ 0 ]) * torch . cos ( torch . matmul ( bases , features ) + self . bias ) def compute_kernels ( self , features_train : torch . Tensor , features_coreset : torch . Tensor ) -> Tuple [ torch . Tensor , torch . Tensor ]: device = features_coreset . device if self . kernel_type == \"rff\" : # project to random features rs = self . sample ( self . r_mu , self . r_log_var , self . d_rn_f , device ) . squeeze () features_coreset = self . rand_features ( rs , torch . transpose ( features_coreset , 1 , 0 )) features_train = self . rand_features ( rs , torch . transpose ( features_train , 1 , 0 )) support_kernel = self . kernel ( features_coreset , features_coreset ) cross_kernel = self . kernel ( features_coreset , features_train ) return support_kernel , cross_kernel def forward ( self , x : torch . Tensor , task_ids : torch . Tensor , coreset_input : torch . Tensor , coreset_target : torch . Tensor ) -> torch . Tensor : current_task = torch . unique ( task_ids ) assert len ( current_task ) == 1 features_train , self . p_mu , self . p_log_var = self . inner_forward ( x , post = False ) features_coreset , self . r_mu , self . r_log_var = self . inner_forward ( coreset_input , post = True ) support_kernel , cross_kernel = self . compute_kernels ( features_train , features_coreset ) alpha = torch . matmul ( torch . inverse ( support_kernel + ( torch . abs ( self . lmd [ current_task - 1 ]) + 0.01 ) * torch . eye ( support_kernel . shape [ 0 ]) . to ( x . device ) ), coreset_target , ) out = self . gma [ current_task - 1 ] * torch . matmul ( cross_kernel . T , alpha ) + self . bta [ current_task - 1 ] if self . multihead : out = self . select_output_head ( out , task_ids ) return out def normalize ( self , x : torch . Tensor ) -> torch . Tensor : max_val = x . max () min_val = x . min () return ( x - min_val ) / ( max_val - min_val ) __init__ ( model , hiddens , lmd , num_tasks , d_rn_f , kernel_type = 'rff' ) Model Wrapper for Kernel Continual Learning. Extracts the encoder of the original backbone and performs the k ernel computations outlined in [1]. Notes The hiddens argument can be removed and instead inferred. Parameters: Name Type Description Default model BaseBackbone the original backbone. The model must have an encoder component. required hiddens int the dimensionality of the hidden dimensions for the kernel-specific modules. required lmd float The initial value for the lmd Parameter. required num_tasks int the number of tasks to be solved. required d_rn_f int dimensionality of the Random Fourier Features (RFFs). Applicable only if kernel_type is 'rff'. required kernel_type str description . Defaults to \"rbf\". 'rff' Source code in sequel/algos/pytorch/kcl.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def __init__ ( self , model : BaseBackbone , hiddens : int , lmd : float , num_tasks : int , d_rn_f : int , kernel_type : Literal [ \"rbf\" , \"rff\" , \"linear\" , \"poly\" ] = \"rff\" , ): \"\"\"Model Wrapper for Kernel Continual Learning. Extracts the encoder of the original backbone and performs the k ernel computations outlined in [1]. Notes: The `hiddens` argument can be removed and instead inferred. Args: model (BaseBackbone): the original backbone. The model must have an encoder component. hiddens (int): the dimensionality of the hidden dimensions for the kernel-specific modules. lmd (float): The initial value for the lmd Parameter. num_tasks (int): the number of tasks to be solved. d_rn_f (int): dimensionality of the Random Fourier Features (RFFs). Applicable only if `kernel_type` is 'rff'. kernel_type (str, optional): _description_. Defaults to \"rbf\". \"\"\" multihead , classes_per_task , masking_value = model . multihead , model . classes_per_task , model . masking_value super () . __init__ ( multihead = multihead , classes_per_task = classes_per_task , masking_value = masking_value ) self . encoder = model . encoder self . d_rn_f = d_rn_f self . post = Amortized ( hiddens , hiddens , hiddens ) self . prior = Amortized ( hiddens , hiddens , hiddens ) device = next ( model . parameters ()) . device self . lmd = nn . Parameter ( torch . tensor ([ lmd for _ in range ( num_tasks )])) . to ( device ) self . gma = nn . Parameter ( torch . tensor ([ 1.0 for _ in range ( num_tasks )])) . to ( device ) self . bta = nn . Parameter ( torch . tensor ([ 0.0 for _ in range ( num_tasks )])) . to ( device ) self . kernel_type = kernel_type self . bias = 2 * math . pi * torch . rand ( d_rn_f , 1 ) . to ( device )","title":"KCL"},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.Amortized","text":"Bases: nn . Module Source code in sequel/algos/pytorch/kcl.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 class Amortized ( nn . Module ): def __init__ ( self , input_units : int , d_theta : int , output_units : int ): \"\"\"Inits the inference block used by the Kernel Continual Learning algorithm. Args: input_units (int): dimensionality of the input. d_theta (int): dimensionality of the intermediate hidden layers. output_units (int): dimensionality of the output. \"\"\" super ( Amortized , self ) . __init__ () self . output_units = output_units self . weight_mean = InferenceBlock ( input_units , d_theta , output_units ) self . weight_log_variance = InferenceBlock ( input_units , d_theta , output_units ) def forward ( self , x : torch . Tensor ) -> torch . Tensor : weight_mean = self . weight_mean ( x ) weight_log_variance = self . weight_log_variance ( x ) return weight_mean , weight_log_variance","title":"Amortized"},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.Amortized.__init__","text":"Inits the inference block used by the Kernel Continual Learning algorithm. Parameters: Name Type Description Default input_units int dimensionality of the input. required d_theta int dimensionality of the intermediate hidden layers. required output_units int dimensionality of the output. required Source code in sequel/algos/pytorch/kcl.py 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , input_units : int , d_theta : int , output_units : int ): \"\"\"Inits the inference block used by the Kernel Continual Learning algorithm. Args: input_units (int): dimensionality of the input. d_theta (int): dimensionality of the intermediate hidden layers. output_units (int): dimensionality of the output. \"\"\" super ( Amortized , self ) . __init__ () self . output_units = output_units self . weight_mean = InferenceBlock ( input_units , d_theta , output_units ) self . weight_log_variance = InferenceBlock ( input_units , d_theta , output_units )","title":"__init__()"},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.InferenceBlock","text":"Bases: nn . Module Source code in sequel/algos/pytorch/kcl.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 class InferenceBlock ( nn . Module ): def __init__ ( self , input_units : int , d_theta : int , output_units : int ): \"\"\"Inits the inference block used by the Kernel Continual Learning algorithm. Args: input_units (int): dimensionality of the input. d_theta (int): dimensionality of the intermediate hidden layers. output_units (int): dimensionality of the output. \"\"\" super ( InferenceBlock , self ) . __init__ () self . module = nn . Sequential ( nn . Linear ( input_units , d_theta , bias = True ), nn . ELU ( inplace = True ), nn . Linear ( d_theta , d_theta , bias = True ), nn . ELU ( inplace = True ), nn . Linear ( d_theta , output_units , bias = True ), ) def forward ( self , x : torch . Tensor ) -> torch . Tensor : return self . module ( x )","title":"InferenceBlock"},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.InferenceBlock.__init__","text":"Inits the inference block used by the Kernel Continual Learning algorithm. Parameters: Name Type Description Default input_units int dimensionality of the input. required d_theta int dimensionality of the intermediate hidden layers. required output_units int dimensionality of the output. required Source code in sequel/algos/pytorch/kcl.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def __init__ ( self , input_units : int , d_theta : int , output_units : int ): \"\"\"Inits the inference block used by the Kernel Continual Learning algorithm. Args: input_units (int): dimensionality of the input. d_theta (int): dimensionality of the intermediate hidden layers. output_units (int): dimensionality of the output. \"\"\" super ( InferenceBlock , self ) . __init__ () self . module = nn . Sequential ( nn . Linear ( input_units , d_theta , bias = True ), nn . ELU ( inplace = True ), nn . Linear ( d_theta , d_theta , bias = True ), nn . ELU ( inplace = True ), nn . Linear ( d_theta , output_units , bias = True ), )","title":"__init__()"},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.KCL","text":"Bases: PytorchBaseAlgorithm Kernel Continual Learning algorithm. The code is adapted from https://github.com/mmderakhshani/KCL/blob/main/stable_sgd/main.py KCL is not yet implemented in JAX. References [1] Derakhshani, M. M., Zhen, X., Shao, L. & Snoek, C. Kernel Continual Learning. in Proceedings of the 38th International Conference on Machine Learning, ICML 2021. Source code in sequel/algos/pytorch/kcl.py 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 class KCL ( PytorchBaseAlgorithm ): \"\"\"Kernel Continual Learning algorithm. The code is adapted from https://github.com/mmderakhshani/KCL/blob/main/stable_sgd/main.py KCL is not yet implemented in JAX. References: [1] Derakhshani, M. M., Zhen, X., Shao, L. & Snoek, C. Kernel Continual Learning. in Proceedings of the 38th International Conference on Machine Learning, ICML 2021. \"\"\" def __init__ ( self , lmd : float , core_size : int , d_rn_f : int , kernel_type : Literal [ \"rbf\" , \"rff\" , \"linear\" , \"poly\" ], tau : float , * args , ** kwargs , ): super () . __init__ ( * args , ** kwargs ) self . __check_valid__ () self . core_size = core_size self . kernel_type = kernel_type self . tau = tau self . coresets = {} device = next ( self . backbone . parameters ()) . device embedding = self . backbone . encoder ( torch . ones ( self . input_dimensions ) . unsqueeze ( 0 ) . to ( device )) self . backbone = KernelBackboneWrapper ( self . backbone , hiddens = embedding . numel (), lmd = lmd , num_tasks = self . num_tasks , d_rn_f = d_rn_f ) . to ( device ) def __check_valid__ ( self ): if getattr ( self . backbone , \"encoder\" , None ) is None : raise AttributeError ( \"The backbone must have an encoder subnetwork to be compatible with the implementation of Kernel \" \"Continual Learning. The encoder consists of the entire original backbone except from the last Linear \" \"layer, i.e., the classifier.\" ) def count_parameters ( self ) -> int : if not isinstance ( self . backbone , KernelBackboneWrapper ): return super () . count_parameters () return sum ([ p . numel () for p in self . backbone . parameters () if p . requires_grad ]) def prepare_train_loader ( self , task : int ) -> DataLoader : \"\"\"Splits the training dataset of the given `task` to training and coreset.\"\"\" dataset = self . benchmark . get_train_dataset ( task ) dataset , coreset = random_split ( dataset , lengths = [ len ( dataset ) - self . core_size , self . core_size ]) self . coresets [ task ] = coreset self . register_coreset ( coreset ) return DataLoader ( dataset , self . benchmark . batch_size , shuffle = True , ** self . benchmark . dl_kwargs ) def register_coreset ( self , coreset ): num_classes = self . benchmark . num_classes x = [ sample [ 0 ] for sample in coreset ] y = [ sample [ 1 ] for sample in coreset ] self . coreset_input = torch . stack ( x ) . to ( self . device ) self . coreset_target = F . one_hot ( torch . tensor ( y ), num_classes = num_classes ) . to ( self . device ) . float () def forward ( self ): \"\"\"Performs the forward for the Kernel Continual Learning backbone.\"\"\" self . y_hat = self . backbone . forward ( self . x , self . t , self . coreset_input , self . coreset_target ) return self . y_hat def kl_div ( self , m : torch . Tensor , log_v : torch . Tensor , m0 : torch . Tensor , log_v0 : torch . Tensor ) -> torch . Tensor : \"\"\"Computes the Kullback-Leibler divergence assuming two normal distributions parameterized by the arguments.\"\"\" v = log_v . exp () v0 = log_v0 . exp () dout , din = m . shape const_term = - 0.5 * dout * din log_std_diff = 0.5 * torch . sum ( torch . log ( v0 ) - torch . log ( v )) mu_diff_term = 0.5 * torch . sum (( v + ( m0 - m ) ** 2 ) / v0 ) kl = const_term + log_std_diff + mu_diff_term return kl def training_step ( self , * args , ** kwargs ): self . optimizer_zero_grad () self . y_hat = self . forward () self . loss = F . cross_entropy ( self . y_hat , self . y ) if self . kernel_type == \"rff\" : r_mu , r_log_var = self . backbone . r_mu , self . backbone . r_log_var p_mu , p_log_var = self . backbone . p_mu , self . backbone . p_log_var self . loss += self . tau * self . kl_div ( r_mu , r_log_var , p_mu , p_log_var ) self . loss . backward () self . optimizer . step () def on_before_val_epoch ( self , * args , ** kwargs ): logging . info ( f \"Setting the coreset for validating task { self . current_val_task } .\" ) self . register_coreset ( self . coresets [ self . current_val_task ]) return super () . on_before_val_epoch ( * args , ** kwargs )","title":"KCL"},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.KCL.forward","text":"Performs the forward for the Kernel Continual Learning backbone. Source code in sequel/algos/pytorch/kcl.py 237 238 239 240 def forward ( self ): \"\"\"Performs the forward for the Kernel Continual Learning backbone.\"\"\" self . y_hat = self . backbone . forward ( self . x , self . t , self . coreset_input , self . coreset_target ) return self . y_hat","title":"forward()"},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.KCL.kl_div","text":"Computes the Kullback-Leibler divergence assuming two normal distributions parameterized by the arguments. Source code in sequel/algos/pytorch/kcl.py 242 243 244 245 246 247 248 249 250 251 252 253 def kl_div ( self , m : torch . Tensor , log_v : torch . Tensor , m0 : torch . Tensor , log_v0 : torch . Tensor ) -> torch . Tensor : \"\"\"Computes the Kullback-Leibler divergence assuming two normal distributions parameterized by the arguments.\"\"\" v = log_v . exp () v0 = log_v0 . exp () dout , din = m . shape const_term = - 0.5 * dout * din log_std_diff = 0.5 * torch . sum ( torch . log ( v0 ) - torch . log ( v )) mu_diff_term = 0.5 * torch . sum (( v + ( m0 - m ) ** 2 ) / v0 ) kl = const_term + log_std_diff + mu_diff_term return kl","title":"kl_div()"},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.KCL.prepare_train_loader","text":"Splits the training dataset of the given task to training and coreset. Source code in sequel/algos/pytorch/kcl.py 222 223 224 225 226 227 228 def prepare_train_loader ( self , task : int ) -> DataLoader : \"\"\"Splits the training dataset of the given `task` to training and coreset.\"\"\" dataset = self . benchmark . get_train_dataset ( task ) dataset , coreset = random_split ( dataset , lengths = [ len ( dataset ) - self . core_size , self . core_size ]) self . coresets [ task ] = coreset self . register_coreset ( coreset ) return DataLoader ( dataset , self . benchmark . batch_size , shuffle = True , ** self . benchmark . dl_kwargs )","title":"prepare_train_loader()"},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.KernelBackboneWrapper","text":"Bases: BaseBackbone Source code in sequel/algos/pytorch/kcl.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 class KernelBackboneWrapper ( BaseBackbone ): def __init__ ( self , model : BaseBackbone , hiddens : int , lmd : float , num_tasks : int , d_rn_f : int , kernel_type : Literal [ \"rbf\" , \"rff\" , \"linear\" , \"poly\" ] = \"rff\" , ): \"\"\"Model Wrapper for Kernel Continual Learning. Extracts the encoder of the original backbone and performs the k ernel computations outlined in [1]. Notes: The `hiddens` argument can be removed and instead inferred. Args: model (BaseBackbone): the original backbone. The model must have an encoder component. hiddens (int): the dimensionality of the hidden dimensions for the kernel-specific modules. lmd (float): The initial value for the lmd Parameter. num_tasks (int): the number of tasks to be solved. d_rn_f (int): dimensionality of the Random Fourier Features (RFFs). Applicable only if `kernel_type` is 'rff'. kernel_type (str, optional): _description_. Defaults to \"rbf\". \"\"\" multihead , classes_per_task , masking_value = model . multihead , model . classes_per_task , model . masking_value super () . __init__ ( multihead = multihead , classes_per_task = classes_per_task , masking_value = masking_value ) self . encoder = model . encoder self . d_rn_f = d_rn_f self . post = Amortized ( hiddens , hiddens , hiddens ) self . prior = Amortized ( hiddens , hiddens , hiddens ) device = next ( model . parameters ()) . device self . lmd = nn . Parameter ( torch . tensor ([ lmd for _ in range ( num_tasks )])) . to ( device ) self . gma = nn . Parameter ( torch . tensor ([ 1.0 for _ in range ( num_tasks )])) . to ( device ) self . bta = nn . Parameter ( torch . tensor ([ 0.0 for _ in range ( num_tasks )])) . to ( device ) self . kernel_type = kernel_type self . bias = 2 * math . pi * torch . rand ( d_rn_f , 1 ) . to ( device ) def inner_forward ( self , x : torch . Tensor , post : bool = False ) -> Tuple [ torch . Tensor , torch . Tensor , torch . Tensor ]: out = self . encoder ( x ) out_features = self . normalize ( out ) out_mean = torch . mean ( out_features , dim = 0 , keepdim = True ) if post : mu , logvar = self . post ( out_mean ) else : mu , logvar = self . prior ( out_mean ) return out_features , mu , logvar def kernel ( self , x : torch . Tensor , y : torch . Tensor ) -> torch . Tensor : if self . kernel_type == \"rbf\" : support_kernel = torch . exp ( - 0.25 * torch . norm ( x . unsqueeze ( 1 ) - y , dim = 2 , p = 1 )) elif self . kernel_type == \"linear\" : support_kernel = x @ y . T elif self . kernel_type == \"poly\" : support_kernel = ( torch . matmul ( x , y . T ) + 1 ) . pow ( 3 ) elif self . kernel_type == \"rff\" : support_kernel = x . T @ y else : raise Exception ( f \"Unknown kenrel. Only support RBF, RFF, POLY, LIN.\" ) return support_kernel @staticmethod def sample ( mu : torch . Tensor , logvar : torch . Tensor , L : int , device ) -> torch . Tensor : shape = ( L ,) + mu . size () eps = torch . randn ( shape ) . to ( device ) return mu . unsqueeze ( 0 ) + eps * logvar . exp () . sqrt () . unsqueeze ( 0 ) def rand_features ( self , bases : torch . Tensor , features : torch . Tensor ) -> torch . Tensor : return math . sqrt ( 2 / self . bias . shape [ 0 ]) * torch . cos ( torch . matmul ( bases , features ) + self . bias ) def compute_kernels ( self , features_train : torch . Tensor , features_coreset : torch . Tensor ) -> Tuple [ torch . Tensor , torch . Tensor ]: device = features_coreset . device if self . kernel_type == \"rff\" : # project to random features rs = self . sample ( self . r_mu , self . r_log_var , self . d_rn_f , device ) . squeeze () features_coreset = self . rand_features ( rs , torch . transpose ( features_coreset , 1 , 0 )) features_train = self . rand_features ( rs , torch . transpose ( features_train , 1 , 0 )) support_kernel = self . kernel ( features_coreset , features_coreset ) cross_kernel = self . kernel ( features_coreset , features_train ) return support_kernel , cross_kernel def forward ( self , x : torch . Tensor , task_ids : torch . Tensor , coreset_input : torch . Tensor , coreset_target : torch . Tensor ) -> torch . Tensor : current_task = torch . unique ( task_ids ) assert len ( current_task ) == 1 features_train , self . p_mu , self . p_log_var = self . inner_forward ( x , post = False ) features_coreset , self . r_mu , self . r_log_var = self . inner_forward ( coreset_input , post = True ) support_kernel , cross_kernel = self . compute_kernels ( features_train , features_coreset ) alpha = torch . matmul ( torch . inverse ( support_kernel + ( torch . abs ( self . lmd [ current_task - 1 ]) + 0.01 ) * torch . eye ( support_kernel . shape [ 0 ]) . to ( x . device ) ), coreset_target , ) out = self . gma [ current_task - 1 ] * torch . matmul ( cross_kernel . T , alpha ) + self . bta [ current_task - 1 ] if self . multihead : out = self . select_output_head ( out , task_ids ) return out def normalize ( self , x : torch . Tensor ) -> torch . Tensor : max_val = x . max () min_val = x . min () return ( x - min_val ) / ( max_val - min_val )","title":"KernelBackboneWrapper"},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.KernelBackboneWrapper.__init__","text":"Model Wrapper for Kernel Continual Learning. Extracts the encoder of the original backbone and performs the k ernel computations outlined in [1]. Notes The hiddens argument can be removed and instead inferred. Parameters: Name Type Description Default model BaseBackbone the original backbone. The model must have an encoder component. required hiddens int the dimensionality of the hidden dimensions for the kernel-specific modules. required lmd float The initial value for the lmd Parameter. required num_tasks int the number of tasks to be solved. required d_rn_f int dimensionality of the Random Fourier Features (RFFs). Applicable only if kernel_type is 'rff'. required kernel_type str description . Defaults to \"rbf\". 'rff' Source code in sequel/algos/pytorch/kcl.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def __init__ ( self , model : BaseBackbone , hiddens : int , lmd : float , num_tasks : int , d_rn_f : int , kernel_type : Literal [ \"rbf\" , \"rff\" , \"linear\" , \"poly\" ] = \"rff\" , ): \"\"\"Model Wrapper for Kernel Continual Learning. Extracts the encoder of the original backbone and performs the k ernel computations outlined in [1]. Notes: The `hiddens` argument can be removed and instead inferred. Args: model (BaseBackbone): the original backbone. The model must have an encoder component. hiddens (int): the dimensionality of the hidden dimensions for the kernel-specific modules. lmd (float): The initial value for the lmd Parameter. num_tasks (int): the number of tasks to be solved. d_rn_f (int): dimensionality of the Random Fourier Features (RFFs). Applicable only if `kernel_type` is 'rff'. kernel_type (str, optional): _description_. Defaults to \"rbf\". \"\"\" multihead , classes_per_task , masking_value = model . multihead , model . classes_per_task , model . masking_value super () . __init__ ( multihead = multihead , classes_per_task = classes_per_task , masking_value = masking_value ) self . encoder = model . encoder self . d_rn_f = d_rn_f self . post = Amortized ( hiddens , hiddens , hiddens ) self . prior = Amortized ( hiddens , hiddens , hiddens ) device = next ( model . parameters ()) . device self . lmd = nn . Parameter ( torch . tensor ([ lmd for _ in range ( num_tasks )])) . to ( device ) self . gma = nn . Parameter ( torch . tensor ([ 1.0 for _ in range ( num_tasks )])) . to ( device ) self . bta = nn . Parameter ( torch . tensor ([ 0.0 for _ in range ( num_tasks )])) . to ( device ) self . kernel_type = kernel_type self . bias = 2 * math . pi * torch . rand ( d_rn_f , 1 ) . to ( device )","title":"__init__()"},{"location":"algos/pytorch/lamaml/","text":"LaMAML Bases: PytorchBaseAlgorithm Look-Ahead Model Agnostic Meta Learning implementation in PyTorch. LaMAML is not yet implemented in JAX. References [1] Gupta, G., Yadav, K. & Paull, L. Look-ahead meta learning for continual learning. in Advances in neural information processing systems 202. Source code in sequel/algos/pytorch/lamaml.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 class LaMAML ( PytorchBaseAlgorithm ): \"\"\"Look-Ahead Model Agnostic Meta Learning implementation in PyTorch. LaMAML is not yet implemented in JAX. References: [1] Gupta, G., Yadav, K. & Paull, L. Look-ahead meta learning for continual learning. in Advances in neural information processing systems 202. \"\"\" backbone_func : FunctionalModule params : List [ torch . nn . Parameter ] def __init__ ( self , mem_size : int , glances : int = 5 , n_inner_updates : int = 5 , second_order : bool = False , grad_clip_norm : float = 2.0 , learn_lr : bool = True , lr_alpha : float = 0.3 , sync_update : bool = False , initial_alpha_value : float = 0.15 , lr_weights : float = 0.1 , * args , ** kwargs ): \"\"\"Inits the LaMAML algorithm class. Args: mem_size (int): The size of the memory. glances (int, optional): The number of gradient steps performed on the current batch. Defaults to 5. n_inner_updates (int, optional): The number of updates performed for the inner step of the Meta Learning process. The batch is split into `n_inner_updates` sub-batches. Defaults to 5. second_order (bool, optional): Boolean denoting whether the computational graph is kept for second-order derivative calculations. Defaults to False. grad_clip_norm (float, optional): The max norm of the gradients. Defaults to 2.0. learn_lr (bool, optional): Boolean denoting whether the per-parameter learning rate is learned or not. Defaults to True. lr_alpha (float, optional): The learning rate for the parameters corresponding to the learnt learning rate for the weights. Defaults to 0.3. sync_update (bool, optional): _description_. Defaults to False. initial_alpha_value (float, optional): The initial value for the per-parameter learning rate. Defaults to 0.15. lr_weights (float, optional): The learning rate for the weights. Applies onl if `sync_update` is set to True. Defaults to 0.1. \"\"\" super () . __init__ ( * args , ** kwargs ) self . glances = glances self . n_inner_updates = n_inner_updates self . second_order = second_order self . grad_clip_norm = grad_clip_norm self . learn_lr = learn_lr self . lr_alpha = lr_alpha self . sync_update = sync_update self . initial_alpha_value = initial_alpha_value self . mem_size = mem_size self . lr_weights = lr_weights self . buffer = Buffer ( memory_size = mem_size ) self . backbone_func , self . params = make_functional ( self . backbone ) alpha_params = [ nn . Parameter ( initial_alpha_value * torch . ones_like ( p )) for p in self . params ] self . alpha_lr = nn . ParameterList ( alpha_params ) . to ( self . device ) self . opt_lr = torch . optim . SGD ( self . alpha_lr . parameters (), lr = lr_alpha ) if self . sync_update : self . opt_wt = torch . optim . SGD ( self . params , lr = self . lr_weights ) warnings . warn ( \"The LaMAML implementation disposes of the optimizer provided in the class arguments. The newly-defined\" \" optimizer concerns the parameters responsible for the learning rate of the underlying backbone parameters.\" ) warnings . warn ( \"The argument `n_inner_updates` is not used at the moment. It is automatically set to the number of \" \"samples in a batch. Hence, the inner update is performed with only one sample.\" ) warnings . warn ( \"LaMAML does not currently support benchmarks with task ids, such as SPlitCIFAR100.\" ) def forward ( self ) -> torch . Tensor : self . y_hat = self . backbone_func ( self . params , self . x ) return self . y_hat def meta_loss ( self , fast_weights , x , y , t ) -> Tuple [ torch . Tensor , torch . Tensor ]: logits = self . backbone_func ( fast_weights , x ) loss_q = self . compute_loss ( logits . squeeze ( 1 ), y ) return loss_q , logits def inner_update ( self , fast_weights , x , y , t ) -> List [ torch . nn . Parameter ]: if fast_weights is None : fast_weights = self . params logits = self . backbone_func ( fast_weights , x ) loss = self . compute_loss ( logits . squeeze (), y ) # NOTE if we want higher order grads to be allowed, change create_graph=False to True graph_required = self . second_order grads = torch . autograd . grad ( loss , fast_weights , create_graph = graph_required , retain_graph = graph_required ) grads = [ torch . clamp ( g , min =- self . grad_clip_norm , max = self . grad_clip_norm ) for g in grads ] fast_weights = list ( map ( lambda p , g , a : p - g * F . relu ( a ), fast_weights , grads , self . alpha_lr )) return fast_weights def observe ( self , x : torch . Tensor , y : torch . Tensor , t : torch . Tensor ) -> float : # self.backbone.train() self . orig_x , self . orig_y , self . orig_t = x , y , t for self . glance_idx in range ( self . glances ): perm = torch . randperm ( x . size ( 0 )) x = x [ perm ] y = y [ perm ] self . opt_lr . zero_grad () fast_weights = None meta_losses = [] self . x , self . y , self . t = self . buffer . augment_batch_with_memory ( x , y , t ) # `n_inner_updates` is set to the batch size implicitly. for batch_x , batch_y , batch_t in zip ( x , y , t ): fast_weights = self . inner_update ( fast_weights , batch_x , batch_y , batch_t ) if self . current_task_epoch == 1 : self . buffer . add_data ( batch_x , batch_y , batch_t ) meta_loss , self . y_hat = self . meta_loss ( fast_weights , self . x , self . y , self . t ) meta_losses . append ( meta_loss ) # Taking the meta gradient step (will update the learning rates) self . opt_lr . zero_grad () meta_loss : torch . Tensor = sum ( meta_losses ) / len ( meta_losses ) meta_loss . backward () torch . nn . utils . clip_grad_norm_ ( self . params , self . grad_clip_norm ) torch . nn . utils . clip_grad_norm_ ( self . alpha_lr . parameters (), self . grad_clip_norm ) if self . learn_lr : self . opt_lr . step () if self . sync_update : self . opt_wt . step () self . opt_wt . zero_grad () self . alpha_lr . zero_grad () else : for i , p in enumerate ( self . params ): p . data = p . data - p . grad * F . relu ( self . alpha_lr [ i ]) for p in self . params : p . grad . zero_ () self . alpha_lr . zero_grad () self . loss = meta_loss return meta_loss . item () def training_step ( self , * args , ** kwargs ): self . observe ( self . x , self . y , self . t ) def _configure_optimizers ( self , task ): pass __init__ ( mem_size , glances = 5 , n_inner_updates = 5 , second_order = False , grad_clip_norm = 2.0 , learn_lr = True , lr_alpha = 0.3 , sync_update = False , initial_alpha_value = 0.15 , lr_weights = 0.1 , * args , ** kwargs ) Inits the LaMAML algorithm class. Parameters: Name Type Description Default mem_size int The size of the memory. required glances int The number of gradient steps performed on the current batch. Defaults to 5. 5 n_inner_updates int The number of updates performed for the inner step of the Meta Learning process. The batch is split into n_inner_updates sub-batches. Defaults to 5. 5 second_order bool Boolean denoting whether the computational graph is kept for second-order derivative calculations. Defaults to False. False grad_clip_norm float The max norm of the gradients. Defaults to 2.0. 2.0 learn_lr bool Boolean denoting whether the per-parameter learning rate is learned or not. Defaults to True. True lr_alpha float The learning rate for the parameters corresponding to the learnt learning rate for the weights. Defaults to 0.3. 0.3 sync_update bool description . Defaults to False. False initial_alpha_value float The initial value for the per-parameter learning rate. Defaults to 0.15. 0.15 lr_weights float The learning rate for the weights. Applies onl if sync_update is set to True. Defaults to 0.1. 0.1 Source code in sequel/algos/pytorch/lamaml.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 def __init__ ( self , mem_size : int , glances : int = 5 , n_inner_updates : int = 5 , second_order : bool = False , grad_clip_norm : float = 2.0 , learn_lr : bool = True , lr_alpha : float = 0.3 , sync_update : bool = False , initial_alpha_value : float = 0.15 , lr_weights : float = 0.1 , * args , ** kwargs ): \"\"\"Inits the LaMAML algorithm class. Args: mem_size (int): The size of the memory. glances (int, optional): The number of gradient steps performed on the current batch. Defaults to 5. n_inner_updates (int, optional): The number of updates performed for the inner step of the Meta Learning process. The batch is split into `n_inner_updates` sub-batches. Defaults to 5. second_order (bool, optional): Boolean denoting whether the computational graph is kept for second-order derivative calculations. Defaults to False. grad_clip_norm (float, optional): The max norm of the gradients. Defaults to 2.0. learn_lr (bool, optional): Boolean denoting whether the per-parameter learning rate is learned or not. Defaults to True. lr_alpha (float, optional): The learning rate for the parameters corresponding to the learnt learning rate for the weights. Defaults to 0.3. sync_update (bool, optional): _description_. Defaults to False. initial_alpha_value (float, optional): The initial value for the per-parameter learning rate. Defaults to 0.15. lr_weights (float, optional): The learning rate for the weights. Applies onl if `sync_update` is set to True. Defaults to 0.1. \"\"\" super () . __init__ ( * args , ** kwargs ) self . glances = glances self . n_inner_updates = n_inner_updates self . second_order = second_order self . grad_clip_norm = grad_clip_norm self . learn_lr = learn_lr self . lr_alpha = lr_alpha self . sync_update = sync_update self . initial_alpha_value = initial_alpha_value self . mem_size = mem_size self . lr_weights = lr_weights self . buffer = Buffer ( memory_size = mem_size ) self . backbone_func , self . params = make_functional ( self . backbone ) alpha_params = [ nn . Parameter ( initial_alpha_value * torch . ones_like ( p )) for p in self . params ] self . alpha_lr = nn . ParameterList ( alpha_params ) . to ( self . device ) self . opt_lr = torch . optim . SGD ( self . alpha_lr . parameters (), lr = lr_alpha ) if self . sync_update : self . opt_wt = torch . optim . SGD ( self . params , lr = self . lr_weights ) warnings . warn ( \"The LaMAML implementation disposes of the optimizer provided in the class arguments. The newly-defined\" \" optimizer concerns the parameters responsible for the learning rate of the underlying backbone parameters.\" ) warnings . warn ( \"The argument `n_inner_updates` is not used at the moment. It is automatically set to the number of \" \"samples in a batch. Hence, the inner update is performed with only one sample.\" ) warnings . warn ( \"LaMAML does not currently support benchmarks with task ids, such as SPlitCIFAR100.\" )","title":"LaMAML"},{"location":"algos/pytorch/lamaml/#sequel.algos.pytorch.lamaml.LaMAML","text":"Bases: PytorchBaseAlgorithm Look-Ahead Model Agnostic Meta Learning implementation in PyTorch. LaMAML is not yet implemented in JAX. References [1] Gupta, G., Yadav, K. & Paull, L. Look-ahead meta learning for continual learning. in Advances in neural information processing systems 202. Source code in sequel/algos/pytorch/lamaml.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 class LaMAML ( PytorchBaseAlgorithm ): \"\"\"Look-Ahead Model Agnostic Meta Learning implementation in PyTorch. LaMAML is not yet implemented in JAX. References: [1] Gupta, G., Yadav, K. & Paull, L. Look-ahead meta learning for continual learning. in Advances in neural information processing systems 202. \"\"\" backbone_func : FunctionalModule params : List [ torch . nn . Parameter ] def __init__ ( self , mem_size : int , glances : int = 5 , n_inner_updates : int = 5 , second_order : bool = False , grad_clip_norm : float = 2.0 , learn_lr : bool = True , lr_alpha : float = 0.3 , sync_update : bool = False , initial_alpha_value : float = 0.15 , lr_weights : float = 0.1 , * args , ** kwargs ): \"\"\"Inits the LaMAML algorithm class. Args: mem_size (int): The size of the memory. glances (int, optional): The number of gradient steps performed on the current batch. Defaults to 5. n_inner_updates (int, optional): The number of updates performed for the inner step of the Meta Learning process. The batch is split into `n_inner_updates` sub-batches. Defaults to 5. second_order (bool, optional): Boolean denoting whether the computational graph is kept for second-order derivative calculations. Defaults to False. grad_clip_norm (float, optional): The max norm of the gradients. Defaults to 2.0. learn_lr (bool, optional): Boolean denoting whether the per-parameter learning rate is learned or not. Defaults to True. lr_alpha (float, optional): The learning rate for the parameters corresponding to the learnt learning rate for the weights. Defaults to 0.3. sync_update (bool, optional): _description_. Defaults to False. initial_alpha_value (float, optional): The initial value for the per-parameter learning rate. Defaults to 0.15. lr_weights (float, optional): The learning rate for the weights. Applies onl if `sync_update` is set to True. Defaults to 0.1. \"\"\" super () . __init__ ( * args , ** kwargs ) self . glances = glances self . n_inner_updates = n_inner_updates self . second_order = second_order self . grad_clip_norm = grad_clip_norm self . learn_lr = learn_lr self . lr_alpha = lr_alpha self . sync_update = sync_update self . initial_alpha_value = initial_alpha_value self . mem_size = mem_size self . lr_weights = lr_weights self . buffer = Buffer ( memory_size = mem_size ) self . backbone_func , self . params = make_functional ( self . backbone ) alpha_params = [ nn . Parameter ( initial_alpha_value * torch . ones_like ( p )) for p in self . params ] self . alpha_lr = nn . ParameterList ( alpha_params ) . to ( self . device ) self . opt_lr = torch . optim . SGD ( self . alpha_lr . parameters (), lr = lr_alpha ) if self . sync_update : self . opt_wt = torch . optim . SGD ( self . params , lr = self . lr_weights ) warnings . warn ( \"The LaMAML implementation disposes of the optimizer provided in the class arguments. The newly-defined\" \" optimizer concerns the parameters responsible for the learning rate of the underlying backbone parameters.\" ) warnings . warn ( \"The argument `n_inner_updates` is not used at the moment. It is automatically set to the number of \" \"samples in a batch. Hence, the inner update is performed with only one sample.\" ) warnings . warn ( \"LaMAML does not currently support benchmarks with task ids, such as SPlitCIFAR100.\" ) def forward ( self ) -> torch . Tensor : self . y_hat = self . backbone_func ( self . params , self . x ) return self . y_hat def meta_loss ( self , fast_weights , x , y , t ) -> Tuple [ torch . Tensor , torch . Tensor ]: logits = self . backbone_func ( fast_weights , x ) loss_q = self . compute_loss ( logits . squeeze ( 1 ), y ) return loss_q , logits def inner_update ( self , fast_weights , x , y , t ) -> List [ torch . nn . Parameter ]: if fast_weights is None : fast_weights = self . params logits = self . backbone_func ( fast_weights , x ) loss = self . compute_loss ( logits . squeeze (), y ) # NOTE if we want higher order grads to be allowed, change create_graph=False to True graph_required = self . second_order grads = torch . autograd . grad ( loss , fast_weights , create_graph = graph_required , retain_graph = graph_required ) grads = [ torch . clamp ( g , min =- self . grad_clip_norm , max = self . grad_clip_norm ) for g in grads ] fast_weights = list ( map ( lambda p , g , a : p - g * F . relu ( a ), fast_weights , grads , self . alpha_lr )) return fast_weights def observe ( self , x : torch . Tensor , y : torch . Tensor , t : torch . Tensor ) -> float : # self.backbone.train() self . orig_x , self . orig_y , self . orig_t = x , y , t for self . glance_idx in range ( self . glances ): perm = torch . randperm ( x . size ( 0 )) x = x [ perm ] y = y [ perm ] self . opt_lr . zero_grad () fast_weights = None meta_losses = [] self . x , self . y , self . t = self . buffer . augment_batch_with_memory ( x , y , t ) # `n_inner_updates` is set to the batch size implicitly. for batch_x , batch_y , batch_t in zip ( x , y , t ): fast_weights = self . inner_update ( fast_weights , batch_x , batch_y , batch_t ) if self . current_task_epoch == 1 : self . buffer . add_data ( batch_x , batch_y , batch_t ) meta_loss , self . y_hat = self . meta_loss ( fast_weights , self . x , self . y , self . t ) meta_losses . append ( meta_loss ) # Taking the meta gradient step (will update the learning rates) self . opt_lr . zero_grad () meta_loss : torch . Tensor = sum ( meta_losses ) / len ( meta_losses ) meta_loss . backward () torch . nn . utils . clip_grad_norm_ ( self . params , self . grad_clip_norm ) torch . nn . utils . clip_grad_norm_ ( self . alpha_lr . parameters (), self . grad_clip_norm ) if self . learn_lr : self . opt_lr . step () if self . sync_update : self . opt_wt . step () self . opt_wt . zero_grad () self . alpha_lr . zero_grad () else : for i , p in enumerate ( self . params ): p . data = p . data - p . grad * F . relu ( self . alpha_lr [ i ]) for p in self . params : p . grad . zero_ () self . alpha_lr . zero_grad () self . loss = meta_loss return meta_loss . item () def training_step ( self , * args , ** kwargs ): self . observe ( self . x , self . y , self . t ) def _configure_optimizers ( self , task ): pass","title":"LaMAML"},{"location":"algos/pytorch/lamaml/#sequel.algos.pytorch.lamaml.LaMAML.__init__","text":"Inits the LaMAML algorithm class. Parameters: Name Type Description Default mem_size int The size of the memory. required glances int The number of gradient steps performed on the current batch. Defaults to 5. 5 n_inner_updates int The number of updates performed for the inner step of the Meta Learning process. The batch is split into n_inner_updates sub-batches. Defaults to 5. 5 second_order bool Boolean denoting whether the computational graph is kept for second-order derivative calculations. Defaults to False. False grad_clip_norm float The max norm of the gradients. Defaults to 2.0. 2.0 learn_lr bool Boolean denoting whether the per-parameter learning rate is learned or not. Defaults to True. True lr_alpha float The learning rate for the parameters corresponding to the learnt learning rate for the weights. Defaults to 0.3. 0.3 sync_update bool description . Defaults to False. False initial_alpha_value float The initial value for the per-parameter learning rate. Defaults to 0.15. 0.15 lr_weights float The learning rate for the weights. Applies onl if sync_update is set to True. Defaults to 0.1. 0.1 Source code in sequel/algos/pytorch/lamaml.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 def __init__ ( self , mem_size : int , glances : int = 5 , n_inner_updates : int = 5 , second_order : bool = False , grad_clip_norm : float = 2.0 , learn_lr : bool = True , lr_alpha : float = 0.3 , sync_update : bool = False , initial_alpha_value : float = 0.15 , lr_weights : float = 0.1 , * args , ** kwargs ): \"\"\"Inits the LaMAML algorithm class. Args: mem_size (int): The size of the memory. glances (int, optional): The number of gradient steps performed on the current batch. Defaults to 5. n_inner_updates (int, optional): The number of updates performed for the inner step of the Meta Learning process. The batch is split into `n_inner_updates` sub-batches. Defaults to 5. second_order (bool, optional): Boolean denoting whether the computational graph is kept for second-order derivative calculations. Defaults to False. grad_clip_norm (float, optional): The max norm of the gradients. Defaults to 2.0. learn_lr (bool, optional): Boolean denoting whether the per-parameter learning rate is learned or not. Defaults to True. lr_alpha (float, optional): The learning rate for the parameters corresponding to the learnt learning rate for the weights. Defaults to 0.3. sync_update (bool, optional): _description_. Defaults to False. initial_alpha_value (float, optional): The initial value for the per-parameter learning rate. Defaults to 0.15. lr_weights (float, optional): The learning rate for the weights. Applies onl if `sync_update` is set to True. Defaults to 0.1. \"\"\" super () . __init__ ( * args , ** kwargs ) self . glances = glances self . n_inner_updates = n_inner_updates self . second_order = second_order self . grad_clip_norm = grad_clip_norm self . learn_lr = learn_lr self . lr_alpha = lr_alpha self . sync_update = sync_update self . initial_alpha_value = initial_alpha_value self . mem_size = mem_size self . lr_weights = lr_weights self . buffer = Buffer ( memory_size = mem_size ) self . backbone_func , self . params = make_functional ( self . backbone ) alpha_params = [ nn . Parameter ( initial_alpha_value * torch . ones_like ( p )) for p in self . params ] self . alpha_lr = nn . ParameterList ( alpha_params ) . to ( self . device ) self . opt_lr = torch . optim . SGD ( self . alpha_lr . parameters (), lr = lr_alpha ) if self . sync_update : self . opt_wt = torch . optim . SGD ( self . params , lr = self . lr_weights ) warnings . warn ( \"The LaMAML implementation disposes of the optimizer provided in the class arguments. The newly-defined\" \" optimizer concerns the parameters responsible for the learning rate of the underlying backbone parameters.\" ) warnings . warn ( \"The argument `n_inner_updates` is not used at the moment. It is automatically set to the number of \" \"samples in a batch. Hence, the inner update is performed with only one sample.\" ) warnings . warn ( \"LaMAML does not currently support benchmarks with task ids, such as SPlitCIFAR100.\" )","title":"__init__()"},{"location":"algos/pytorch/lfl/","text":"LFL Bases: PytorchBaseAlgorithm Less-Forgetting Learning implementation in PyTorch. The equivalent JAX implementation is LFL in JAX . References [1] Jung, H., Ju, J., Jung, M. & Kim, J. Less-forgetful learning for domain expansion in deep neural networks. Proceedings of the AAAI Conference on Artificial Intelligence 32, (2018). Source code in sequel/algos/pytorch/lfl.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 class LFL ( PytorchBaseAlgorithm ): \"\"\"Less-Forgetting Learning implementation in PyTorch. The equivalent JAX implementation is [`LFL in JAX`][sequel.algos.jax.lfl.LFL]. References: [1] Jung, H., Ju, J., Jung, M. & Kim, J. Less-forgetful learning for domain expansion in deep neural networks. Proceedings of the AAAI Conference on Artificial Intelligence 32, (2018). \"\"\" def __init__ ( self , lfl_lambda : float , * args , ** kwargs ): \"\"\"Inits the LFL class. Args: lfl_lambda (float): the regularization coefficient. \"\"\" super () . __init__ ( * args , ** kwargs ) self . regularization_coefficient = lfl_lambda def __repr__ ( self ) -> str : return f \"LFL(regularization_coefficient= { self . regularization_coefficient } )\" def on_after_training_task ( self , * args , ** kwargs ): # freeze previous model # assert isinstance self . prev_backbone = copy . deepcopy ( self . backbone ) self . prev_backbone . eval () for p in self . prev_backbone . parameters (): p . requires_grad = False def on_before_backward ( self , * args , ** kwargs ): if self . task_counter > 1 : self . prev_backbone . eval () self . backbone . eval () features = self . backbone . encoder ( self . x ) prev_features = self . prev_backbone . encoder ( self . x ) self . loss += self . regularization_coefficient * F . mse_loss ( features , prev_features ) __init__ ( lfl_lambda , * args , ** kwargs ) Inits the LFL class. Parameters: Name Type Description Default lfl_lambda float the regularization coefficient. required Source code in sequel/algos/pytorch/lfl.py 17 18 19 20 21 22 23 24 def __init__ ( self , lfl_lambda : float , * args , ** kwargs ): \"\"\"Inits the LFL class. Args: lfl_lambda (float): the regularization coefficient. \"\"\" super () . __init__ ( * args , ** kwargs ) self . regularization_coefficient = lfl_lambda","title":"LFL"},{"location":"algos/pytorch/lfl/#sequel.algos.pytorch.lfl.LFL","text":"Bases: PytorchBaseAlgorithm Less-Forgetting Learning implementation in PyTorch. The equivalent JAX implementation is LFL in JAX . References [1] Jung, H., Ju, J., Jung, M. & Kim, J. Less-forgetful learning for domain expansion in deep neural networks. Proceedings of the AAAI Conference on Artificial Intelligence 32, (2018). Source code in sequel/algos/pytorch/lfl.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 class LFL ( PytorchBaseAlgorithm ): \"\"\"Less-Forgetting Learning implementation in PyTorch. The equivalent JAX implementation is [`LFL in JAX`][sequel.algos.jax.lfl.LFL]. References: [1] Jung, H., Ju, J., Jung, M. & Kim, J. Less-forgetful learning for domain expansion in deep neural networks. Proceedings of the AAAI Conference on Artificial Intelligence 32, (2018). \"\"\" def __init__ ( self , lfl_lambda : float , * args , ** kwargs ): \"\"\"Inits the LFL class. Args: lfl_lambda (float): the regularization coefficient. \"\"\" super () . __init__ ( * args , ** kwargs ) self . regularization_coefficient = lfl_lambda def __repr__ ( self ) -> str : return f \"LFL(regularization_coefficient= { self . regularization_coefficient } )\" def on_after_training_task ( self , * args , ** kwargs ): # freeze previous model # assert isinstance self . prev_backbone = copy . deepcopy ( self . backbone ) self . prev_backbone . eval () for p in self . prev_backbone . parameters (): p . requires_grad = False def on_before_backward ( self , * args , ** kwargs ): if self . task_counter > 1 : self . prev_backbone . eval () self . backbone . eval () features = self . backbone . encoder ( self . x ) prev_features = self . prev_backbone . encoder ( self . x ) self . loss += self . regularization_coefficient * F . mse_loss ( features , prev_features )","title":"LFL"},{"location":"algos/pytorch/lfl/#sequel.algos.pytorch.lfl.LFL.__init__","text":"Inits the LFL class. Parameters: Name Type Description Default lfl_lambda float the regularization coefficient. required Source code in sequel/algos/pytorch/lfl.py 17 18 19 20 21 22 23 24 def __init__ ( self , lfl_lambda : float , * args , ** kwargs ): \"\"\"Inits the LFL class. Args: lfl_lambda (float): the regularization coefficient. \"\"\" super () . __init__ ( * args , ** kwargs ) self . regularization_coefficient = lfl_lambda","title":"__init__()"},{"location":"algos/pytorch/mas/","text":"MAS Bases: PytorchRegularizationBaseAlgorithm Memory Aware Synapses. Algorithm Class. Inherits from BaseAlgorithm. The equivalent JAX implementation is MAS in JAX . References [1] Aljundi, R., Babiloni, F., Elhoseiny, M., Rohrbach, M. & Tuytelaars, T. Memory Aware Synapses: Learning What (not) to Forget. in Computer Vision - ECCV 2018. Source code in sequel/algos/pytorch/mas.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 class MAS ( PytorchRegularizationBaseAlgorithm ): \"\"\"Memory Aware Synapses. Algorithm Class. Inherits from BaseAlgorithm. The equivalent JAX implementation is [`MAS in JAX`][sequel.algos.jax.mas.MAS]. References: [1] Aljundi, R., Babiloni, F., Elhoseiny, M., Rohrbach, M. & Tuytelaars, T. Memory Aware Synapses: Learning What (not) to Forget. in Computer Vision - ECCV 2018. \"\"\" def __init__ ( self , mas_lambda : float = 1.0 , * args , ** kwargs ): \"\"\"Inits the Memory Aware Synapses algorithm. Args: mas_lambda (float): The c coefficient of the algorithm. \"\"\" super () . __init__ ( regularization_coefficient = mas_lambda , * args , ** kwargs ) torch . autograd . set_detect_anomaly ( True ) for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) self . backbone . register_buffer ( f \" { name } _w\" , torch . zeros_like ( param )) def __repr__ ( self ) -> str : return f \"MAS(mas_lambda= { self . regularization_coefficient } )\" def on_after_training_step ( self , * args , ** kwargs ): # perform the forward pass once again with the new parameters. self . forward () self . optimizer_zero_grad () f_loss : torch . Tensor = self . y_hat . pow_ ( 2 ) . mean () f_loss . backward () for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) w = getattr ( self . backbone , f \" { name } _w\" ) if param . grad is not None : setattr ( self . backbone , f \" { name } _w\" , w + param . grad . abs () / len ( self . train_loader )) return super () . on_after_training_step ( * args , ** kwargs ) def calculate_parameter_importance ( self ): importances = {} for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) importances [ name ] = getattr ( self . backbone , f \" { name } _w\" ) return importances __init__ ( mas_lambda = 1.0 , * args , ** kwargs ) Inits the Memory Aware Synapses algorithm. Parameters: Name Type Description Default mas_lambda float The c coefficient of the algorithm. 1.0 Source code in sequel/algos/pytorch/mas.py 15 16 17 18 19 20 21 22 23 24 25 26 def __init__ ( self , mas_lambda : float = 1.0 , * args , ** kwargs ): \"\"\"Inits the Memory Aware Synapses algorithm. Args: mas_lambda (float): The c coefficient of the algorithm. \"\"\" super () . __init__ ( regularization_coefficient = mas_lambda , * args , ** kwargs ) torch . autograd . set_detect_anomaly ( True ) for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) self . backbone . register_buffer ( f \" { name } _w\" , torch . zeros_like ( param ))","title":"MAS"},{"location":"algos/pytorch/mas/#sequel.algos.pytorch.mas.MAS","text":"Bases: PytorchRegularizationBaseAlgorithm Memory Aware Synapses. Algorithm Class. Inherits from BaseAlgorithm. The equivalent JAX implementation is MAS in JAX . References [1] Aljundi, R., Babiloni, F., Elhoseiny, M., Rohrbach, M. & Tuytelaars, T. Memory Aware Synapses: Learning What (not) to Forget. in Computer Vision - ECCV 2018. Source code in sequel/algos/pytorch/mas.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 class MAS ( PytorchRegularizationBaseAlgorithm ): \"\"\"Memory Aware Synapses. Algorithm Class. Inherits from BaseAlgorithm. The equivalent JAX implementation is [`MAS in JAX`][sequel.algos.jax.mas.MAS]. References: [1] Aljundi, R., Babiloni, F., Elhoseiny, M., Rohrbach, M. & Tuytelaars, T. Memory Aware Synapses: Learning What (not) to Forget. in Computer Vision - ECCV 2018. \"\"\" def __init__ ( self , mas_lambda : float = 1.0 , * args , ** kwargs ): \"\"\"Inits the Memory Aware Synapses algorithm. Args: mas_lambda (float): The c coefficient of the algorithm. \"\"\" super () . __init__ ( regularization_coefficient = mas_lambda , * args , ** kwargs ) torch . autograd . set_detect_anomaly ( True ) for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) self . backbone . register_buffer ( f \" { name } _w\" , torch . zeros_like ( param )) def __repr__ ( self ) -> str : return f \"MAS(mas_lambda= { self . regularization_coefficient } )\" def on_after_training_step ( self , * args , ** kwargs ): # perform the forward pass once again with the new parameters. self . forward () self . optimizer_zero_grad () f_loss : torch . Tensor = self . y_hat . pow_ ( 2 ) . mean () f_loss . backward () for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) w = getattr ( self . backbone , f \" { name } _w\" ) if param . grad is not None : setattr ( self . backbone , f \" { name } _w\" , w + param . grad . abs () / len ( self . train_loader )) return super () . on_after_training_step ( * args , ** kwargs ) def calculate_parameter_importance ( self ): importances = {} for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) importances [ name ] = getattr ( self . backbone , f \" { name } _w\" ) return importances","title":"MAS"},{"location":"algos/pytorch/mas/#sequel.algos.pytorch.mas.MAS.__init__","text":"Inits the Memory Aware Synapses algorithm. Parameters: Name Type Description Default mas_lambda float The c coefficient of the algorithm. 1.0 Source code in sequel/algos/pytorch/mas.py 15 16 17 18 19 20 21 22 23 24 25 26 def __init__ ( self , mas_lambda : float = 1.0 , * args , ** kwargs ): \"\"\"Inits the Memory Aware Synapses algorithm. Args: mas_lambda (float): The c coefficient of the algorithm. \"\"\" super () . __init__ ( regularization_coefficient = mas_lambda , * args , ** kwargs ) torch . autograd . set_detect_anomaly ( True ) for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) self . backbone . register_buffer ( f \" { name } _w\" , torch . zeros_like ( param ))","title":"__init__()"},{"location":"algos/pytorch/mcsgd/","text":"MCSGD Bases: PytorchBaseAlgorithm MC-SGD: Mode Connectivity-Stochastic Gradient Descent. Inherits from BaseAlgorithm. The equivalent JAX implementation is MCSGD in JAX . References [1] Mirzadeh, S.-I., Farajtabar, M., G\u00f6r\u00fcr, D., Pascanu, R. & Ghasemzadeh, H. Linear Mode Connectivity in Multitask and Continual Learning. in 9th International Conference on Learning Representations, ICLR 2021. Source code in sequel/algos/pytorch/mcsgd.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 class MCSGD ( PytorchBaseAlgorithm ): \"\"\"MC-SGD: Mode Connectivity-Stochastic Gradient Descent. Inherits from BaseAlgorithm. The equivalent JAX implementation is [`MCSGD in JAX`][sequel.algos.jax.mcsgd.MCSGD]. References: [1] Mirzadeh, S.-I., Farajtabar, M., G\u00f6r\u00fcr, D., Pascanu, R. & Ghasemzadeh, H. Linear Mode Connectivity in Multitask and Continual Learning. in 9th International Conference on Learning Representations, ICLR 2021. \"\"\" def __init__ ( self , per_task_memory_samples : int = 100 , memory_group_by : Literal [ \"task\" , \"class\" ] = \"task\" , lmc_policy = \"offline\" , lmc_interpolation = \"linear\" , lmc_lr = 0.05 , lmc_momentum = 0.8 , lmc_batch_size = 64 , lmc_init_position = 0.1 , lmc_line_samples = 10 , lmc_epochs = 1 , * args , ** kwargs , ): super () . __init__ ( * args , ** kwargs ) self . memory = MemoryMechanism ( per_task_memory_samples = per_task_memory_samples , groupby = memory_group_by ) self . w_bar_prev = None self . w_hat_curr = None # parse init arguments self . per_task_memory_samples = per_task_memory_samples self . lmc_policy = lmc_policy self . lmc_interpolation = lmc_interpolation self . lmc_lr = lmc_lr self . lmc_momentum = lmc_momentum self . lmc_batch_size = lmc_batch_size self . lmc_init_position = lmc_init_position self . lmc_line_samples = lmc_line_samples self . lmc_epochs = lmc_epochs def __repr__ ( self ) -> str : return ( \"MCSGD(\" + f \"per_task_memory_samples= { self . per_task_memory_samples } , \" + f \"policy= { self . lmc_policy } , \" + f \"interpolation= { self . lmc_interpolation } , \" + f \"lr= { self . lmc_lr } , \" + f \"momentum= { self . lmc_momentum } , \" + f \"batch_size= { self . lmc_batch_size } , \" + f \"init_position= { self . lmc_init_position } , \" + f \"line_samples= { self . lmc_line_samples } , \" + f \"epochs= { self . lmc_epochs } \" + \")\" ) def calculate_line_loss ( self , w_start , w_end , loader ): line_samples = np . arange ( 0.0 , 1.01 , 1.0 / float ( self . lmc_line_samples )) grads = 0 for t in tqdm ( line_samples , desc = \"Line samples\" ): w_mid = w_start + ( w_end - w_start ) * t m = set_weights ( self . backbone , w_mid ) self . calculate_point_loss ( m , loader ) . backward () grads += torch . cat ([ p . grad . view ( - 1 ) for _ , p in m . named_parameters ()]) return grads def calculate_point_loss ( self , model , loader ): criterion = self . _configure_criterion () model . eval () total_loss , total_count = 0.0 , 0.0 for batch in loader : self . unpack_batch ( batch ) self . y_hat = model ( self . x , self . t ) total_loss += criterion ( self . y_hat , self . y ) total_count += self . bs return total_loss / total_count def find_connected_minima ( self , task ): bs = self . lmc_batch_size loader_curr = self . benchmark . train_dataloader_subset ( task , batch_size = bs , subset_size = self . per_task_memory_samples ) loader_prev = self . benchmark . memory_dataloader ( task , batch_size = bs , return_infinite_stream = False ) mc_model = set_weights ( self . backbone , self . w_bar_prev + ( self . w_hat_curr - self . w_bar_prev ) * self . lmc_init_position ) optimizer = torch . optim . SGD ( mc_model . parameters (), lr = self . lmc_lr , momentum = self . lmc_momentum ) mc_model . train () optimizer . zero_grad () grads_prev = self . calculate_line_loss ( self . w_bar_prev , get_weights ( mc_model ), loader_prev ) grads_curr = self . calculate_line_loss ( self . w_hat_curr , get_weights ( mc_model ), loader_curr ) mc_model = set_grads ( mc_model , ( grads_prev + grads_curr )) optimizer . step () return mc_model def on_after_training_epoch ( self , * args , ** kwargs ): # save the weights of the current Continual Learning solution self . w_hat_curr = get_weights ( self . backbone ) def validate_algorithm_on_all_tasks ( self ) -> Dict [ str , float ]: if self . task_counter == 1 : super () . validate_algorithm_on_all_tasks () def on_after_validating_algorithm_on_all_tasks_callbacks ( self ): if self . task_counter == 1 : return super () . on_after_validating_algorithm_on_all_tasks_callbacks () def on_after_training_task ( self , * args , ** kwargs ): \"\"\"After training for a task similarly to the na\u00efve algorithm, MCSGD performs another round of epochs corresponding to the linear connectivity updates of the algorithm. Note that the validation is performed with the weights obtained at the end of these updates. \"\"\" # update the memory to include samples from the current task self . memory . update_memory ( self ) if self . task_counter > 1 : self . backbone = self . find_connected_minima ( self . task_counter ) # perform the validation with the weights obtained after the mode-connectivity updates super () . on_before_validating_algorithm_on_all_tasks_callbacks () super () . validate_algorithm_on_all_tasks () super () . on_after_validating_algorithm_on_all_tasks_callbacks () # save the backbone obtained from the mode-connectivity updates # as the Multi-Task approximate solution self . w_bar_prev = get_weights ( self . backbone ) # revert the weights of the backbone to the Continual Learning solution self . backbone = set_weights ( self . backbone , self . w_hat_curr ) on_after_training_task ( * args , ** kwargs ) After training for a task similarly to the na\u00efve algorithm, MCSGD performs another round of epochs corresponding to the linear connectivity updates of the algorithm. Note that the validation is performed with the weights obtained at the end of these updates. Source code in sequel/algos/pytorch/mcsgd.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def on_after_training_task ( self , * args , ** kwargs ): \"\"\"After training for a task similarly to the na\u00efve algorithm, MCSGD performs another round of epochs corresponding to the linear connectivity updates of the algorithm. Note that the validation is performed with the weights obtained at the end of these updates. \"\"\" # update the memory to include samples from the current task self . memory . update_memory ( self ) if self . task_counter > 1 : self . backbone = self . find_connected_minima ( self . task_counter ) # perform the validation with the weights obtained after the mode-connectivity updates super () . on_before_validating_algorithm_on_all_tasks_callbacks () super () . validate_algorithm_on_all_tasks () super () . on_after_validating_algorithm_on_all_tasks_callbacks () # save the backbone obtained from the mode-connectivity updates # as the Multi-Task approximate solution self . w_bar_prev = get_weights ( self . backbone ) # revert the weights of the backbone to the Continual Learning solution self . backbone = set_weights ( self . backbone , self . w_hat_curr )","title":"MC-SGD"},{"location":"algos/pytorch/mcsgd/#sequel.algos.pytorch.mcsgd.MCSGD","text":"Bases: PytorchBaseAlgorithm MC-SGD: Mode Connectivity-Stochastic Gradient Descent. Inherits from BaseAlgorithm. The equivalent JAX implementation is MCSGD in JAX . References [1] Mirzadeh, S.-I., Farajtabar, M., G\u00f6r\u00fcr, D., Pascanu, R. & Ghasemzadeh, H. Linear Mode Connectivity in Multitask and Continual Learning. in 9th International Conference on Learning Representations, ICLR 2021. Source code in sequel/algos/pytorch/mcsgd.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 class MCSGD ( PytorchBaseAlgorithm ): \"\"\"MC-SGD: Mode Connectivity-Stochastic Gradient Descent. Inherits from BaseAlgorithm. The equivalent JAX implementation is [`MCSGD in JAX`][sequel.algos.jax.mcsgd.MCSGD]. References: [1] Mirzadeh, S.-I., Farajtabar, M., G\u00f6r\u00fcr, D., Pascanu, R. & Ghasemzadeh, H. Linear Mode Connectivity in Multitask and Continual Learning. in 9th International Conference on Learning Representations, ICLR 2021. \"\"\" def __init__ ( self , per_task_memory_samples : int = 100 , memory_group_by : Literal [ \"task\" , \"class\" ] = \"task\" , lmc_policy = \"offline\" , lmc_interpolation = \"linear\" , lmc_lr = 0.05 , lmc_momentum = 0.8 , lmc_batch_size = 64 , lmc_init_position = 0.1 , lmc_line_samples = 10 , lmc_epochs = 1 , * args , ** kwargs , ): super () . __init__ ( * args , ** kwargs ) self . memory = MemoryMechanism ( per_task_memory_samples = per_task_memory_samples , groupby = memory_group_by ) self . w_bar_prev = None self . w_hat_curr = None # parse init arguments self . per_task_memory_samples = per_task_memory_samples self . lmc_policy = lmc_policy self . lmc_interpolation = lmc_interpolation self . lmc_lr = lmc_lr self . lmc_momentum = lmc_momentum self . lmc_batch_size = lmc_batch_size self . lmc_init_position = lmc_init_position self . lmc_line_samples = lmc_line_samples self . lmc_epochs = lmc_epochs def __repr__ ( self ) -> str : return ( \"MCSGD(\" + f \"per_task_memory_samples= { self . per_task_memory_samples } , \" + f \"policy= { self . lmc_policy } , \" + f \"interpolation= { self . lmc_interpolation } , \" + f \"lr= { self . lmc_lr } , \" + f \"momentum= { self . lmc_momentum } , \" + f \"batch_size= { self . lmc_batch_size } , \" + f \"init_position= { self . lmc_init_position } , \" + f \"line_samples= { self . lmc_line_samples } , \" + f \"epochs= { self . lmc_epochs } \" + \")\" ) def calculate_line_loss ( self , w_start , w_end , loader ): line_samples = np . arange ( 0.0 , 1.01 , 1.0 / float ( self . lmc_line_samples )) grads = 0 for t in tqdm ( line_samples , desc = \"Line samples\" ): w_mid = w_start + ( w_end - w_start ) * t m = set_weights ( self . backbone , w_mid ) self . calculate_point_loss ( m , loader ) . backward () grads += torch . cat ([ p . grad . view ( - 1 ) for _ , p in m . named_parameters ()]) return grads def calculate_point_loss ( self , model , loader ): criterion = self . _configure_criterion () model . eval () total_loss , total_count = 0.0 , 0.0 for batch in loader : self . unpack_batch ( batch ) self . y_hat = model ( self . x , self . t ) total_loss += criterion ( self . y_hat , self . y ) total_count += self . bs return total_loss / total_count def find_connected_minima ( self , task ): bs = self . lmc_batch_size loader_curr = self . benchmark . train_dataloader_subset ( task , batch_size = bs , subset_size = self . per_task_memory_samples ) loader_prev = self . benchmark . memory_dataloader ( task , batch_size = bs , return_infinite_stream = False ) mc_model = set_weights ( self . backbone , self . w_bar_prev + ( self . w_hat_curr - self . w_bar_prev ) * self . lmc_init_position ) optimizer = torch . optim . SGD ( mc_model . parameters (), lr = self . lmc_lr , momentum = self . lmc_momentum ) mc_model . train () optimizer . zero_grad () grads_prev = self . calculate_line_loss ( self . w_bar_prev , get_weights ( mc_model ), loader_prev ) grads_curr = self . calculate_line_loss ( self . w_hat_curr , get_weights ( mc_model ), loader_curr ) mc_model = set_grads ( mc_model , ( grads_prev + grads_curr )) optimizer . step () return mc_model def on_after_training_epoch ( self , * args , ** kwargs ): # save the weights of the current Continual Learning solution self . w_hat_curr = get_weights ( self . backbone ) def validate_algorithm_on_all_tasks ( self ) -> Dict [ str , float ]: if self . task_counter == 1 : super () . validate_algorithm_on_all_tasks () def on_after_validating_algorithm_on_all_tasks_callbacks ( self ): if self . task_counter == 1 : return super () . on_after_validating_algorithm_on_all_tasks_callbacks () def on_after_training_task ( self , * args , ** kwargs ): \"\"\"After training for a task similarly to the na\u00efve algorithm, MCSGD performs another round of epochs corresponding to the linear connectivity updates of the algorithm. Note that the validation is performed with the weights obtained at the end of these updates. \"\"\" # update the memory to include samples from the current task self . memory . update_memory ( self ) if self . task_counter > 1 : self . backbone = self . find_connected_minima ( self . task_counter ) # perform the validation with the weights obtained after the mode-connectivity updates super () . on_before_validating_algorithm_on_all_tasks_callbacks () super () . validate_algorithm_on_all_tasks () super () . on_after_validating_algorithm_on_all_tasks_callbacks () # save the backbone obtained from the mode-connectivity updates # as the Multi-Task approximate solution self . w_bar_prev = get_weights ( self . backbone ) # revert the weights of the backbone to the Continual Learning solution self . backbone = set_weights ( self . backbone , self . w_hat_curr )","title":"MCSGD"},{"location":"algos/pytorch/mcsgd/#sequel.algos.pytorch.mcsgd.MCSGD.on_after_training_task","text":"After training for a task similarly to the na\u00efve algorithm, MCSGD performs another round of epochs corresponding to the linear connectivity updates of the algorithm. Note that the validation is performed with the weights obtained at the end of these updates. Source code in sequel/algos/pytorch/mcsgd.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def on_after_training_task ( self , * args , ** kwargs ): \"\"\"After training for a task similarly to the na\u00efve algorithm, MCSGD performs another round of epochs corresponding to the linear connectivity updates of the algorithm. Note that the validation is performed with the weights obtained at the end of these updates. \"\"\" # update the memory to include samples from the current task self . memory . update_memory ( self ) if self . task_counter > 1 : self . backbone = self . find_connected_minima ( self . task_counter ) # perform the validation with the weights obtained after the mode-connectivity updates super () . on_before_validating_algorithm_on_all_tasks_callbacks () super () . validate_algorithm_on_all_tasks () super () . on_after_validating_algorithm_on_all_tasks_callbacks () # save the backbone obtained from the mode-connectivity updates # as the Multi-Task approximate solution self . w_bar_prev = get_weights ( self . backbone ) # revert the weights of the backbone to the Continual Learning solution self . backbone = set_weights ( self . backbone , self . w_hat_curr )","title":"on_after_training_task()"},{"location":"algos/pytorch/si/","text":"SI Bases: PytorchRegularizationBaseAlgorithm Synaptic Intelligence Algorithm Class. Inherits from PytorchBaseAlgorithm. The equivalent JAX implementation is SI in JAX . References [1] Zenke, F., Poole, B. & Ganguli, S. Continual Learning Through Synaptic Intelligence. in Proceedings of the 34th International Conference on Machine Learning, ICML 2017. Source code in sequel/algos/pytorch/si.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 class SI ( PytorchRegularizationBaseAlgorithm ): \"\"\"Synaptic Intelligence Algorithm Class. Inherits from PytorchBaseAlgorithm. The equivalent JAX implementation is [`SI in JAX`][sequel.algos.jax.si.SI]. References: [1] Zenke, F., Poole, B. & Ganguli, S. Continual Learning Through Synaptic Intelligence. in Proceedings of the 34th International Conference on Machine Learning, ICML 2017. \"\"\" def __init__ ( self , si_lambda : float = 1.0 , xi : float = 0.1 , * args , ** kwargs ): super () . __init__ ( regularization_coefficient = si_lambda , * args , ** kwargs ) # hyperparameters self . xi = xi for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) self . backbone . register_buffer ( f \" { name } _w\" , torch . zeros_like ( param )) def __repr__ ( self ) -> str : return f \"SI(si_lambda= { self . regularization_coefficient } , xi= { self . xi } )\" def on_before_training_step ( self , * args , ** kwargs ): for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) setattr ( self . backbone , f \" { name } _prev\" , param . data . clone ()) def on_after_training_step ( self , * args , ** kwargs ): for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) if param . grad is not None : delta = param . clone () . detach () - getattr ( self . backbone , f \" { name } _prev\" ) w = getattr ( self . backbone , f \" { name } _w\" ) setattr ( self . backbone , f \" { name } _w\" , w - w * delta ) def calculate_parameter_importance ( self ): logging . info ( \"Updating importance parameters for Synaptic Intelligence\" ) importances = {} for ( name , p ) in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) old_importance = getattr ( self . backbone , f \" { name } _importance\" ) omega : Tensor = getattr ( self . backbone , f \" { name } _w\" ) delta : Tensor = p . detach () - getattr ( self . backbone , f \" { name } _old\" ) # see Eq. 5 from paper. importances [ name ] = old_importance + omega / ( delta . pow ( 2 ) + self . xi ) # reset (small) omega for next task setattr ( self . backbone , f \" { name } _w\" , omega . clone () . zero_ ()) return importances","title":"SI"},{"location":"algos/pytorch/si/#sequel.algos.pytorch.si.SI","text":"Bases: PytorchRegularizationBaseAlgorithm Synaptic Intelligence Algorithm Class. Inherits from PytorchBaseAlgorithm. The equivalent JAX implementation is SI in JAX . References [1] Zenke, F., Poole, B. & Ganguli, S. Continual Learning Through Synaptic Intelligence. in Proceedings of the 34th International Conference on Machine Learning, ICML 2017. Source code in sequel/algos/pytorch/si.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 class SI ( PytorchRegularizationBaseAlgorithm ): \"\"\"Synaptic Intelligence Algorithm Class. Inherits from PytorchBaseAlgorithm. The equivalent JAX implementation is [`SI in JAX`][sequel.algos.jax.si.SI]. References: [1] Zenke, F., Poole, B. & Ganguli, S. Continual Learning Through Synaptic Intelligence. in Proceedings of the 34th International Conference on Machine Learning, ICML 2017. \"\"\" def __init__ ( self , si_lambda : float = 1.0 , xi : float = 0.1 , * args , ** kwargs ): super () . __init__ ( regularization_coefficient = si_lambda , * args , ** kwargs ) # hyperparameters self . xi = xi for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) self . backbone . register_buffer ( f \" { name } _w\" , torch . zeros_like ( param )) def __repr__ ( self ) -> str : return f \"SI(si_lambda= { self . regularization_coefficient } , xi= { self . xi } )\" def on_before_training_step ( self , * args , ** kwargs ): for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) setattr ( self . backbone , f \" { name } _prev\" , param . data . clone ()) def on_after_training_step ( self , * args , ** kwargs ): for name , param in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) if param . grad is not None : delta = param . clone () . detach () - getattr ( self . backbone , f \" { name } _prev\" ) w = getattr ( self . backbone , f \" { name } _w\" ) setattr ( self . backbone , f \" { name } _w\" , w - w * delta ) def calculate_parameter_importance ( self ): logging . info ( \"Updating importance parameters for Synaptic Intelligence\" ) importances = {} for ( name , p ) in self . backbone . named_parameters (): name = name . replace ( \".\" , \"_\" ) old_importance = getattr ( self . backbone , f \" { name } _importance\" ) omega : Tensor = getattr ( self . backbone , f \" { name } _w\" ) delta : Tensor = p . detach () - getattr ( self . backbone , f \" { name } _old\" ) # see Eq. 5 from paper. importances [ name ] = old_importance + omega / ( delta . pow ( 2 ) + self . xi ) # reset (small) omega for next task setattr ( self . backbone , f \" { name } _w\" , omega . clone () . zero_ ()) return importances","title":"SI"},{"location":"algos/utils/callback_hooks/","text":"BaseCallbackHook Bases: abc . ABC Source code in sequel/algos/utils/callback_hooks.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 class BaseCallbackHook ( abc . ABC ): callbacks : List [ BaseCallback ] = [] def on_before_setup_callbacks ( self ): \"\"\"Callbacks before the setup.\"\"\" for cb in self . callbacks : cb . on_before_setup ( self ) def on_after_setup_callbacks ( self ): \"\"\"Callbacks after the setup.\"\"\" for cb in self . callbacks : cb . on_after_setup ( self ) def on_before_teardown_callbacks ( self ): \"\"\"Callbacks before the teardown.\"\"\" for cb in self . callbacks : cb . on_before_teardown ( self ) def on_after_teardown_callbacks ( self ): \"\"\"Callbacks after the teardown.\"\"\" for cb in self . callbacks : cb . on_after_teardown ( self ) def on_before_fit_callbacks ( self ): \"\"\"Callbacks before fitting the data.\"\"\" for cb in self . callbacks : cb . on_before_fit ( self ) def on_after_fit_callbacks ( self ): \"\"\"Callbacks after fitting the data.\"\"\" for cb in self . callbacks : cb . on_after_fit ( self ) def on_before_training_task_callbacks ( self ): \"\"\"Callbacks before training a single task.\"\"\" for cb in self . callbacks : cb . on_before_training_task ( self ) def on_after_training_task_callbacks ( self ): \"\"\"Callbacks after training a single task.\"\"\" for cb in self . callbacks : cb . on_after_training_task ( self ) def on_before_training_epoch_callbacks ( self ): \"\"\"Callbacks before training one epoch.\"\"\" for cb in self . callbacks : cb . on_before_training_epoch ( self ) def on_after_training_epoch_callbacks ( self ): \"\"\"Callbacks after training one epoch.\"\"\" for cb in self . callbacks : cb . on_after_training_epoch ( self ) def on_before_val_epoch_callbacks ( self ): \"\"\"Callbacks before validating one epoch.\"\"\" for cb in self . callbacks : cb . on_before_val_epoch ( self ) def on_after_val_epoch_callbacks ( self ): \"\"\"Callbacks after validating one epoch.\"\"\" for cb in self . callbacks : cb . on_after_val_epoch ( self ) def on_before_val_step_callbacks ( self ): \"\"\"Callbacks before the val step (single batch step).\"\"\" for cb in self . callbacks : cb . on_before_val_step ( self ) def on_after_val_step_callbacks ( self ): \"\"\"Callbacks after the val step.\"\"\" for cb in self . callbacks : cb . on_after_val_step ( self ) def on_before_training_step_callbacks ( self ): \"\"\"Callbacks before the training step (single batch step).\"\"\" for cb in self . callbacks : cb . on_before_training_step ( self ) def on_after_training_step_callbacks ( self ): \"\"\"Callbacks after the training step.\"\"\" for cb in self . callbacks : cb . on_after_training_step ( self ) def on_before_backward_callbacks ( self ): \"\"\"Callbacks before backpropagation.\"\"\" for cb in self . callbacks : cb . on_before_backward ( self ) def on_after_backward_callbacks ( self ): \"\"\"Callbacks after backpropagation.\"\"\" for cb in self . callbacks : cb . on_after_backward ( self ) def on_before_optimizer_step_callbacks ( self ): \"\"\"Callbacks before optimizer step.\"\"\" for cb in self . callbacks : cb . on_before_optimizer_step ( self ) def on_after_optimizer_step_callbacks ( self ): \"\"\"Callbacks after optimizer step.\"\"\" for cb in self . callbacks : cb . on_after_optimizer_step ( self ) def on_before_validating_algorithm_on_all_tasks_callbacks ( self ): for cb in self . callbacks : cb . on_before_validating_algorithm_on_all_tasks ( self ) def on_after_validating_algorithm_on_all_tasks_callbacks ( self ): for cb in self . callbacks : cb . on_after_validating_algorithm_on_all_tasks ( self ) on_after_backward_callbacks () Callbacks after backpropagation. Source code in sequel/algos/utils/callback_hooks.py 95 96 97 98 def on_after_backward_callbacks ( self ): \"\"\"Callbacks after backpropagation.\"\"\" for cb in self . callbacks : cb . on_after_backward ( self ) on_after_fit_callbacks () Callbacks after fitting the data. Source code in sequel/algos/utils/callback_hooks.py 35 36 37 38 def on_after_fit_callbacks ( self ): \"\"\"Callbacks after fitting the data.\"\"\" for cb in self . callbacks : cb . on_after_fit ( self ) on_after_optimizer_step_callbacks () Callbacks after optimizer step. Source code in sequel/algos/utils/callback_hooks.py 105 106 107 108 def on_after_optimizer_step_callbacks ( self ): \"\"\"Callbacks after optimizer step.\"\"\" for cb in self . callbacks : cb . on_after_optimizer_step ( self ) on_after_setup_callbacks () Callbacks after the setup. Source code in sequel/algos/utils/callback_hooks.py 15 16 17 18 def on_after_setup_callbacks ( self ): \"\"\"Callbacks after the setup.\"\"\" for cb in self . callbacks : cb . on_after_setup ( self ) on_after_teardown_callbacks () Callbacks after the teardown. Source code in sequel/algos/utils/callback_hooks.py 25 26 27 28 def on_after_teardown_callbacks ( self ): \"\"\"Callbacks after the teardown.\"\"\" for cb in self . callbacks : cb . on_after_teardown ( self ) on_after_training_epoch_callbacks () Callbacks after training one epoch. Source code in sequel/algos/utils/callback_hooks.py 55 56 57 58 def on_after_training_epoch_callbacks ( self ): \"\"\"Callbacks after training one epoch.\"\"\" for cb in self . callbacks : cb . on_after_training_epoch ( self ) on_after_training_step_callbacks () Callbacks after the training step. Source code in sequel/algos/utils/callback_hooks.py 85 86 87 88 def on_after_training_step_callbacks ( self ): \"\"\"Callbacks after the training step.\"\"\" for cb in self . callbacks : cb . on_after_training_step ( self ) on_after_training_task_callbacks () Callbacks after training a single task. Source code in sequel/algos/utils/callback_hooks.py 45 46 47 48 def on_after_training_task_callbacks ( self ): \"\"\"Callbacks after training a single task.\"\"\" for cb in self . callbacks : cb . on_after_training_task ( self ) on_after_val_epoch_callbacks () Callbacks after validating one epoch. Source code in sequel/algos/utils/callback_hooks.py 65 66 67 68 def on_after_val_epoch_callbacks ( self ): \"\"\"Callbacks after validating one epoch.\"\"\" for cb in self . callbacks : cb . on_after_val_epoch ( self ) on_after_val_step_callbacks () Callbacks after the val step. Source code in sequel/algos/utils/callback_hooks.py 75 76 77 78 def on_after_val_step_callbacks ( self ): \"\"\"Callbacks after the val step.\"\"\" for cb in self . callbacks : cb . on_after_val_step ( self ) on_before_backward_callbacks () Callbacks before backpropagation. Source code in sequel/algos/utils/callback_hooks.py 90 91 92 93 def on_before_backward_callbacks ( self ): \"\"\"Callbacks before backpropagation.\"\"\" for cb in self . callbacks : cb . on_before_backward ( self ) on_before_fit_callbacks () Callbacks before fitting the data. Source code in sequel/algos/utils/callback_hooks.py 30 31 32 33 def on_before_fit_callbacks ( self ): \"\"\"Callbacks before fitting the data.\"\"\" for cb in self . callbacks : cb . on_before_fit ( self ) on_before_optimizer_step_callbacks () Callbacks before optimizer step. Source code in sequel/algos/utils/callback_hooks.py 100 101 102 103 def on_before_optimizer_step_callbacks ( self ): \"\"\"Callbacks before optimizer step.\"\"\" for cb in self . callbacks : cb . on_before_optimizer_step ( self ) on_before_setup_callbacks () Callbacks before the setup. Source code in sequel/algos/utils/callback_hooks.py 10 11 12 13 def on_before_setup_callbacks ( self ): \"\"\"Callbacks before the setup.\"\"\" for cb in self . callbacks : cb . on_before_setup ( self ) on_before_teardown_callbacks () Callbacks before the teardown. Source code in sequel/algos/utils/callback_hooks.py 20 21 22 23 def on_before_teardown_callbacks ( self ): \"\"\"Callbacks before the teardown.\"\"\" for cb in self . callbacks : cb . on_before_teardown ( self ) on_before_training_epoch_callbacks () Callbacks before training one epoch. Source code in sequel/algos/utils/callback_hooks.py 50 51 52 53 def on_before_training_epoch_callbacks ( self ): \"\"\"Callbacks before training one epoch.\"\"\" for cb in self . callbacks : cb . on_before_training_epoch ( self ) on_before_training_step_callbacks () Callbacks before the training step (single batch step). Source code in sequel/algos/utils/callback_hooks.py 80 81 82 83 def on_before_training_step_callbacks ( self ): \"\"\"Callbacks before the training step (single batch step).\"\"\" for cb in self . callbacks : cb . on_before_training_step ( self ) on_before_training_task_callbacks () Callbacks before training a single task. Source code in sequel/algos/utils/callback_hooks.py 40 41 42 43 def on_before_training_task_callbacks ( self ): \"\"\"Callbacks before training a single task.\"\"\" for cb in self . callbacks : cb . on_before_training_task ( self ) on_before_val_epoch_callbacks () Callbacks before validating one epoch. Source code in sequel/algos/utils/callback_hooks.py 60 61 62 63 def on_before_val_epoch_callbacks ( self ): \"\"\"Callbacks before validating one epoch.\"\"\" for cb in self . callbacks : cb . on_before_val_epoch ( self ) on_before_val_step_callbacks () Callbacks before the val step (single batch step). Source code in sequel/algos/utils/callback_hooks.py 70 71 72 73 def on_before_val_step_callbacks ( self ): \"\"\"Callbacks before the val step (single batch step).\"\"\" for cb in self . callbacks : cb . on_before_val_step ( self )","title":"callback_hooks"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook","text":"Bases: abc . ABC Source code in sequel/algos/utils/callback_hooks.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 class BaseCallbackHook ( abc . ABC ): callbacks : List [ BaseCallback ] = [] def on_before_setup_callbacks ( self ): \"\"\"Callbacks before the setup.\"\"\" for cb in self . callbacks : cb . on_before_setup ( self ) def on_after_setup_callbacks ( self ): \"\"\"Callbacks after the setup.\"\"\" for cb in self . callbacks : cb . on_after_setup ( self ) def on_before_teardown_callbacks ( self ): \"\"\"Callbacks before the teardown.\"\"\" for cb in self . callbacks : cb . on_before_teardown ( self ) def on_after_teardown_callbacks ( self ): \"\"\"Callbacks after the teardown.\"\"\" for cb in self . callbacks : cb . on_after_teardown ( self ) def on_before_fit_callbacks ( self ): \"\"\"Callbacks before fitting the data.\"\"\" for cb in self . callbacks : cb . on_before_fit ( self ) def on_after_fit_callbacks ( self ): \"\"\"Callbacks after fitting the data.\"\"\" for cb in self . callbacks : cb . on_after_fit ( self ) def on_before_training_task_callbacks ( self ): \"\"\"Callbacks before training a single task.\"\"\" for cb in self . callbacks : cb . on_before_training_task ( self ) def on_after_training_task_callbacks ( self ): \"\"\"Callbacks after training a single task.\"\"\" for cb in self . callbacks : cb . on_after_training_task ( self ) def on_before_training_epoch_callbacks ( self ): \"\"\"Callbacks before training one epoch.\"\"\" for cb in self . callbacks : cb . on_before_training_epoch ( self ) def on_after_training_epoch_callbacks ( self ): \"\"\"Callbacks after training one epoch.\"\"\" for cb in self . callbacks : cb . on_after_training_epoch ( self ) def on_before_val_epoch_callbacks ( self ): \"\"\"Callbacks before validating one epoch.\"\"\" for cb in self . callbacks : cb . on_before_val_epoch ( self ) def on_after_val_epoch_callbacks ( self ): \"\"\"Callbacks after validating one epoch.\"\"\" for cb in self . callbacks : cb . on_after_val_epoch ( self ) def on_before_val_step_callbacks ( self ): \"\"\"Callbacks before the val step (single batch step).\"\"\" for cb in self . callbacks : cb . on_before_val_step ( self ) def on_after_val_step_callbacks ( self ): \"\"\"Callbacks after the val step.\"\"\" for cb in self . callbacks : cb . on_after_val_step ( self ) def on_before_training_step_callbacks ( self ): \"\"\"Callbacks before the training step (single batch step).\"\"\" for cb in self . callbacks : cb . on_before_training_step ( self ) def on_after_training_step_callbacks ( self ): \"\"\"Callbacks after the training step.\"\"\" for cb in self . callbacks : cb . on_after_training_step ( self ) def on_before_backward_callbacks ( self ): \"\"\"Callbacks before backpropagation.\"\"\" for cb in self . callbacks : cb . on_before_backward ( self ) def on_after_backward_callbacks ( self ): \"\"\"Callbacks after backpropagation.\"\"\" for cb in self . callbacks : cb . on_after_backward ( self ) def on_before_optimizer_step_callbacks ( self ): \"\"\"Callbacks before optimizer step.\"\"\" for cb in self . callbacks : cb . on_before_optimizer_step ( self ) def on_after_optimizer_step_callbacks ( self ): \"\"\"Callbacks after optimizer step.\"\"\" for cb in self . callbacks : cb . on_after_optimizer_step ( self ) def on_before_validating_algorithm_on_all_tasks_callbacks ( self ): for cb in self . callbacks : cb . on_before_validating_algorithm_on_all_tasks ( self ) def on_after_validating_algorithm_on_all_tasks_callbacks ( self ): for cb in self . callbacks : cb . on_after_validating_algorithm_on_all_tasks ( self )","title":"BaseCallbackHook"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_backward_callbacks","text":"Callbacks after backpropagation. Source code in sequel/algos/utils/callback_hooks.py 95 96 97 98 def on_after_backward_callbacks ( self ): \"\"\"Callbacks after backpropagation.\"\"\" for cb in self . callbacks : cb . on_after_backward ( self )","title":"on_after_backward_callbacks()"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_fit_callbacks","text":"Callbacks after fitting the data. Source code in sequel/algos/utils/callback_hooks.py 35 36 37 38 def on_after_fit_callbacks ( self ): \"\"\"Callbacks after fitting the data.\"\"\" for cb in self . callbacks : cb . on_after_fit ( self )","title":"on_after_fit_callbacks()"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_optimizer_step_callbacks","text":"Callbacks after optimizer step. Source code in sequel/algos/utils/callback_hooks.py 105 106 107 108 def on_after_optimizer_step_callbacks ( self ): \"\"\"Callbacks after optimizer step.\"\"\" for cb in self . callbacks : cb . on_after_optimizer_step ( self )","title":"on_after_optimizer_step_callbacks()"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_setup_callbacks","text":"Callbacks after the setup. Source code in sequel/algos/utils/callback_hooks.py 15 16 17 18 def on_after_setup_callbacks ( self ): \"\"\"Callbacks after the setup.\"\"\" for cb in self . callbacks : cb . on_after_setup ( self )","title":"on_after_setup_callbacks()"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_teardown_callbacks","text":"Callbacks after the teardown. Source code in sequel/algos/utils/callback_hooks.py 25 26 27 28 def on_after_teardown_callbacks ( self ): \"\"\"Callbacks after the teardown.\"\"\" for cb in self . callbacks : cb . on_after_teardown ( self )","title":"on_after_teardown_callbacks()"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_training_epoch_callbacks","text":"Callbacks after training one epoch. Source code in sequel/algos/utils/callback_hooks.py 55 56 57 58 def on_after_training_epoch_callbacks ( self ): \"\"\"Callbacks after training one epoch.\"\"\" for cb in self . callbacks : cb . on_after_training_epoch ( self )","title":"on_after_training_epoch_callbacks()"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_training_step_callbacks","text":"Callbacks after the training step. Source code in sequel/algos/utils/callback_hooks.py 85 86 87 88 def on_after_training_step_callbacks ( self ): \"\"\"Callbacks after the training step.\"\"\" for cb in self . callbacks : cb . on_after_training_step ( self )","title":"on_after_training_step_callbacks()"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_training_task_callbacks","text":"Callbacks after training a single task. Source code in sequel/algos/utils/callback_hooks.py 45 46 47 48 def on_after_training_task_callbacks ( self ): \"\"\"Callbacks after training a single task.\"\"\" for cb in self . callbacks : cb . on_after_training_task ( self )","title":"on_after_training_task_callbacks()"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_val_epoch_callbacks","text":"Callbacks after validating one epoch. Source code in sequel/algos/utils/callback_hooks.py 65 66 67 68 def on_after_val_epoch_callbacks ( self ): \"\"\"Callbacks after validating one epoch.\"\"\" for cb in self . callbacks : cb . on_after_val_epoch ( self )","title":"on_after_val_epoch_callbacks()"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_val_step_callbacks","text":"Callbacks after the val step. Source code in sequel/algos/utils/callback_hooks.py 75 76 77 78 def on_after_val_step_callbacks ( self ): \"\"\"Callbacks after the val step.\"\"\" for cb in self . callbacks : cb . on_after_val_step ( self )","title":"on_after_val_step_callbacks()"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_backward_callbacks","text":"Callbacks before backpropagation. Source code in sequel/algos/utils/callback_hooks.py 90 91 92 93 def on_before_backward_callbacks ( self ): \"\"\"Callbacks before backpropagation.\"\"\" for cb in self . callbacks : cb . on_before_backward ( self )","title":"on_before_backward_callbacks()"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_fit_callbacks","text":"Callbacks before fitting the data. Source code in sequel/algos/utils/callback_hooks.py 30 31 32 33 def on_before_fit_callbacks ( self ): \"\"\"Callbacks before fitting the data.\"\"\" for cb in self . callbacks : cb . on_before_fit ( self )","title":"on_before_fit_callbacks()"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_optimizer_step_callbacks","text":"Callbacks before optimizer step. Source code in sequel/algos/utils/callback_hooks.py 100 101 102 103 def on_before_optimizer_step_callbacks ( self ): \"\"\"Callbacks before optimizer step.\"\"\" for cb in self . callbacks : cb . on_before_optimizer_step ( self )","title":"on_before_optimizer_step_callbacks()"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_setup_callbacks","text":"Callbacks before the setup. Source code in sequel/algos/utils/callback_hooks.py 10 11 12 13 def on_before_setup_callbacks ( self ): \"\"\"Callbacks before the setup.\"\"\" for cb in self . callbacks : cb . on_before_setup ( self )","title":"on_before_setup_callbacks()"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_teardown_callbacks","text":"Callbacks before the teardown. Source code in sequel/algos/utils/callback_hooks.py 20 21 22 23 def on_before_teardown_callbacks ( self ): \"\"\"Callbacks before the teardown.\"\"\" for cb in self . callbacks : cb . on_before_teardown ( self )","title":"on_before_teardown_callbacks()"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_training_epoch_callbacks","text":"Callbacks before training one epoch. Source code in sequel/algos/utils/callback_hooks.py 50 51 52 53 def on_before_training_epoch_callbacks ( self ): \"\"\"Callbacks before training one epoch.\"\"\" for cb in self . callbacks : cb . on_before_training_epoch ( self )","title":"on_before_training_epoch_callbacks()"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_training_step_callbacks","text":"Callbacks before the training step (single batch step). Source code in sequel/algos/utils/callback_hooks.py 80 81 82 83 def on_before_training_step_callbacks ( self ): \"\"\"Callbacks before the training step (single batch step).\"\"\" for cb in self . callbacks : cb . on_before_training_step ( self )","title":"on_before_training_step_callbacks()"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_training_task_callbacks","text":"Callbacks before training a single task. Source code in sequel/algos/utils/callback_hooks.py 40 41 42 43 def on_before_training_task_callbacks ( self ): \"\"\"Callbacks before training a single task.\"\"\" for cb in self . callbacks : cb . on_before_training_task ( self )","title":"on_before_training_task_callbacks()"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_val_epoch_callbacks","text":"Callbacks before validating one epoch. Source code in sequel/algos/utils/callback_hooks.py 60 61 62 63 def on_before_val_epoch_callbacks ( self ): \"\"\"Callbacks before validating one epoch.\"\"\" for cb in self . callbacks : cb . on_before_val_epoch ( self )","title":"on_before_val_epoch_callbacks()"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_val_step_callbacks","text":"Callbacks before the val step (single batch step). Source code in sequel/algos/utils/callback_hooks.py 70 71 72 73 def on_before_val_step_callbacks ( self ): \"\"\"Callbacks before the val step (single batch step).\"\"\" for cb in self . callbacks : cb . on_before_val_step ( self )","title":"on_before_val_step_callbacks()"},{"location":"algos/utils/state_manager/","text":"","title":"state_manager"},{"location":"backbones/jax/base/","text":"BaseBackbone Bases: nn . Module Inits the BaseBackbone class. This class defines the Jax base class for neural networks. All models should inherit from this class. Inherits from flax.nn.Module and the BaseCallback class that endows callbacks for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc. Attributes: Name Type Description multihead bool Set to True if the backbone is multi-headed. Defaults to False. classes_per_task Optional [ int ] The number of classes per task. Defaults to None. masking_value float The value that replaces the logits. Only used if multihead is set to True. Defaults to -10e10. Note Currently, the BaseBackbone only considers tasks with equal number of classes. Source code in sequel/backbones/jax/base_backbone.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 class BaseBackbone ( nn . Module ): \"\"\"Inits the BaseBackbone class. This class defines the Jax base class for neural networks. All models should inherit from this class. Inherits from flax.nn.Module and the BaseCallback class that endows callbacks for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc. Attributes: multihead (bool, optional): Set to True if the backbone is multi-headed. Defaults to False. classes_per_task (Optional[int], optional): The number of classes per task. Defaults to None. masking_value (float, optional): The value that replaces the logits. Only used if multihead is set to True. Defaults to -10e10. Note: Currently, the BaseBackbone only considers tasks with equal number of classes. \"\"\" masking_value = - 10e10 classes_per_task : int multihead : bool @nn . compact def __call__ ( self , x : jnp . ndarray , task_ids : jnp . ndarray , training : bool = True ) -> jnp . ndarray : raise NotImplementedError def select_output_head ( self , x , task_ids ): assert self . multihead assert isinstance ( x , jnp . ndarray ) mask = jnp . ones_like ( x ) z = jnp . zeros (( 1 , self . classes_per_task )) for i , task_id in enumerate ( task_ids ): task_id = task_id - 1 mask = dynamic_update_slice ( mask , z , ( i , task_id * self . classes_per_task )) x = jnp . where ( mask , other_fun (), x ) return x","title":"Base"},{"location":"backbones/jax/base/#sequel.backbones.jax.base_backbone.BaseBackbone","text":"Bases: nn . Module Inits the BaseBackbone class. This class defines the Jax base class for neural networks. All models should inherit from this class. Inherits from flax.nn.Module and the BaseCallback class that endows callbacks for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc. Attributes: Name Type Description multihead bool Set to True if the backbone is multi-headed. Defaults to False. classes_per_task Optional [ int ] The number of classes per task. Defaults to None. masking_value float The value that replaces the logits. Only used if multihead is set to True. Defaults to -10e10. Note Currently, the BaseBackbone only considers tasks with equal number of classes. Source code in sequel/backbones/jax/base_backbone.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 class BaseBackbone ( nn . Module ): \"\"\"Inits the BaseBackbone class. This class defines the Jax base class for neural networks. All models should inherit from this class. Inherits from flax.nn.Module and the BaseCallback class that endows callbacks for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc. Attributes: multihead (bool, optional): Set to True if the backbone is multi-headed. Defaults to False. classes_per_task (Optional[int], optional): The number of classes per task. Defaults to None. masking_value (float, optional): The value that replaces the logits. Only used if multihead is set to True. Defaults to -10e10. Note: Currently, the BaseBackbone only considers tasks with equal number of classes. \"\"\" masking_value = - 10e10 classes_per_task : int multihead : bool @nn . compact def __call__ ( self , x : jnp . ndarray , task_ids : jnp . ndarray , training : bool = True ) -> jnp . ndarray : raise NotImplementedError def select_output_head ( self , x , task_ids ): assert self . multihead assert isinstance ( x , jnp . ndarray ) mask = jnp . ones_like ( x ) z = jnp . zeros (( 1 , self . classes_per_task )) for i , task_id in enumerate ( task_ids ): task_id = task_id - 1 mask = dynamic_update_slice ( mask , z , ( i , task_id * self . classes_per_task )) x = jnp . where ( mask , other_fun (), x ) return x","title":"BaseBackbone"},{"location":"backbones/jax/cnn/","text":"","title":"CNN"},{"location":"backbones/jax/mlp/","text":"","title":"MLP"},{"location":"backbones/pytorch/base/","text":"BaseBackbone Bases: nn . Module The PyTorch base class for neural networks. Inherits from torch.nn.Module and the BaseCallback class that endows callbacks for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc. Source code in sequel/backbones/pytorch/base_backbone.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 class BaseBackbone ( nn . Module ): \"\"\"The PyTorch base class for neural networks. Inherits from torch.nn.Module and the BaseCallback class that endows callbacks for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc. \"\"\" def __init__ ( self , multihead : bool = False , classes_per_task : Optional [ int ] = None , masking_value : float = - 10e10 ): \"\"\"Inits the BaseBackbone class. This class defines the PyTorch base class for neural networks. All models should inherit from this class. Inherits from torch.nn.Module and the BaseCallback class that endows callbacks for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc. Args: multihead (bool, optional): Set to True if the backbone is multi-headed. Defaults to False. classes_per_task (Optional[int], optional): The number of classes per task. Defaults to None. masking_value (float, optional): The value that replaces the logits. Only used if multihead is set to True. Defaults to -10e10. Note: Currently, the BaseBackbone only considers tasks with equal number of classes. \"\"\" super () . __init__ () self . multihead = multihead logging . info ( f \"multihead is set to { self . multihead } \" ) if self . multihead : assert classes_per_task is not None self . classes_per_task = classes_per_task self . masking_value = masking_value def select_output_head ( self , x : torch . Tensor , task_ids : torch . Tensor ) -> torch . Tensor : \"\"\"Utility function in case `multihead=True` that replaces the original logits by a low value so that almost zero probability is given to the corresponding classes. Args: x (torch.Tensor): The original logits. task_ids (torch.Tensor): The task id for each sample in the batch. Returns: torch.Tensor: the manipulated logits. \"\"\" assert self . multihead assert isinstance ( x , torch . Tensor ) for i , task_id in enumerate ( task_ids ): task_id = task_id - 1 if isinstance ( task_id , torch . Tensor ): task_id = task_id . cpu () . int () . item () start = task_id * self . classes_per_task end = ( task_id + 1 ) * self . classes_per_task x [ i , : start ] . data . fill_ ( self . masking_value ) x [ i , end :] . data . fill_ ( self . masking_value ) return x def forward ( self , x : torch . Tensor , task_ids : torch . Tensor ) -> torch . Tensor : \"\"\"Implements the forward function of the backbone. Models must ovveride this method. Example: # perform the forward. x = ... # select the correct output head. if self.multihead: return self.select_output_head(x, task_ids) Args: x (torch.Tensor): The batch inputs. task_ids (torch.Tensor): The batch task ids. Returns: torch.Tensor: The batch predicitons. \"\"\" raise NotImplementedError __init__ ( multihead = False , classes_per_task = None , masking_value =- 100000000000.0 ) Inits the BaseBackbone class. This class defines the PyTorch base class for neural networks. All models should inherit from this class. Inherits from torch.nn.Module and the BaseCallback class that endows callbacks for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc. Parameters: Name Type Description Default multihead bool Set to True if the backbone is multi-headed. Defaults to False. False classes_per_task Optional [ int ] The number of classes per task. Defaults to None. None masking_value float The value that replaces the logits. Only used if multihead is set to True. Defaults to -10e10. -100000000000.0 Note Currently, the BaseBackbone only considers tasks with equal number of classes. Source code in sequel/backbones/pytorch/base_backbone.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 def __init__ ( self , multihead : bool = False , classes_per_task : Optional [ int ] = None , masking_value : float = - 10e10 ): \"\"\"Inits the BaseBackbone class. This class defines the PyTorch base class for neural networks. All models should inherit from this class. Inherits from torch.nn.Module and the BaseCallback class that endows callbacks for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc. Args: multihead (bool, optional): Set to True if the backbone is multi-headed. Defaults to False. classes_per_task (Optional[int], optional): The number of classes per task. Defaults to None. masking_value (float, optional): The value that replaces the logits. Only used if multihead is set to True. Defaults to -10e10. Note: Currently, the BaseBackbone only considers tasks with equal number of classes. \"\"\" super () . __init__ () self . multihead = multihead logging . info ( f \"multihead is set to { self . multihead } \" ) if self . multihead : assert classes_per_task is not None self . classes_per_task = classes_per_task self . masking_value = masking_value forward ( x , task_ids ) Implements the forward function of the backbone. Models must ovveride this method. Example perform the forward. x = ... select the correct output head. if self.multihead: return self.select_output_head(x, task_ids) Parameters: Name Type Description Default x torch . Tensor The batch inputs. required task_ids torch . Tensor The batch task ids. required Returns: Type Description torch . Tensor torch.Tensor: The batch predicitons. Source code in sequel/backbones/pytorch/base_backbone.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 def forward ( self , x : torch . Tensor , task_ids : torch . Tensor ) -> torch . Tensor : \"\"\"Implements the forward function of the backbone. Models must ovveride this method. Example: # perform the forward. x = ... # select the correct output head. if self.multihead: return self.select_output_head(x, task_ids) Args: x (torch.Tensor): The batch inputs. task_ids (torch.Tensor): The batch task ids. Returns: torch.Tensor: The batch predicitons. \"\"\" raise NotImplementedError select_output_head ( x , task_ids ) Utility function in case multihead=True that replaces the original logits by a low value so that almost zero probability is given to the corresponding classes. Parameters: Name Type Description Default x torch . Tensor The original logits. required task_ids torch . Tensor The task id for each sample in the batch. required Returns: Type Description torch . Tensor torch.Tensor: the manipulated logits. Source code in sequel/backbones/pytorch/base_backbone.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 def select_output_head ( self , x : torch . Tensor , task_ids : torch . Tensor ) -> torch . Tensor : \"\"\"Utility function in case `multihead=True` that replaces the original logits by a low value so that almost zero probability is given to the corresponding classes. Args: x (torch.Tensor): The original logits. task_ids (torch.Tensor): The task id for each sample in the batch. Returns: torch.Tensor: the manipulated logits. \"\"\" assert self . multihead assert isinstance ( x , torch . Tensor ) for i , task_id in enumerate ( task_ids ): task_id = task_id - 1 if isinstance ( task_id , torch . Tensor ): task_id = task_id . cpu () . int () . item () start = task_id * self . classes_per_task end = ( task_id + 1 ) * self . classes_per_task x [ i , : start ] . data . fill_ ( self . masking_value ) x [ i , end :] . data . fill_ ( self . masking_value ) return x","title":"Base"},{"location":"backbones/pytorch/base/#sequel.backbones.pytorch.base_backbone.BaseBackbone","text":"Bases: nn . Module The PyTorch base class for neural networks. Inherits from torch.nn.Module and the BaseCallback class that endows callbacks for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc. Source code in sequel/backbones/pytorch/base_backbone.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 class BaseBackbone ( nn . Module ): \"\"\"The PyTorch base class for neural networks. Inherits from torch.nn.Module and the BaseCallback class that endows callbacks for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc. \"\"\" def __init__ ( self , multihead : bool = False , classes_per_task : Optional [ int ] = None , masking_value : float = - 10e10 ): \"\"\"Inits the BaseBackbone class. This class defines the PyTorch base class for neural networks. All models should inherit from this class. Inherits from torch.nn.Module and the BaseCallback class that endows callbacks for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc. Args: multihead (bool, optional): Set to True if the backbone is multi-headed. Defaults to False. classes_per_task (Optional[int], optional): The number of classes per task. Defaults to None. masking_value (float, optional): The value that replaces the logits. Only used if multihead is set to True. Defaults to -10e10. Note: Currently, the BaseBackbone only considers tasks with equal number of classes. \"\"\" super () . __init__ () self . multihead = multihead logging . info ( f \"multihead is set to { self . multihead } \" ) if self . multihead : assert classes_per_task is not None self . classes_per_task = classes_per_task self . masking_value = masking_value def select_output_head ( self , x : torch . Tensor , task_ids : torch . Tensor ) -> torch . Tensor : \"\"\"Utility function in case `multihead=True` that replaces the original logits by a low value so that almost zero probability is given to the corresponding classes. Args: x (torch.Tensor): The original logits. task_ids (torch.Tensor): The task id for each sample in the batch. Returns: torch.Tensor: the manipulated logits. \"\"\" assert self . multihead assert isinstance ( x , torch . Tensor ) for i , task_id in enumerate ( task_ids ): task_id = task_id - 1 if isinstance ( task_id , torch . Tensor ): task_id = task_id . cpu () . int () . item () start = task_id * self . classes_per_task end = ( task_id + 1 ) * self . classes_per_task x [ i , : start ] . data . fill_ ( self . masking_value ) x [ i , end :] . data . fill_ ( self . masking_value ) return x def forward ( self , x : torch . Tensor , task_ids : torch . Tensor ) -> torch . Tensor : \"\"\"Implements the forward function of the backbone. Models must ovveride this method. Example: # perform the forward. x = ... # select the correct output head. if self.multihead: return self.select_output_head(x, task_ids) Args: x (torch.Tensor): The batch inputs. task_ids (torch.Tensor): The batch task ids. Returns: torch.Tensor: The batch predicitons. \"\"\" raise NotImplementedError","title":"BaseBackbone"},{"location":"backbones/pytorch/base/#sequel.backbones.pytorch.base_backbone.BaseBackbone.__init__","text":"Inits the BaseBackbone class. This class defines the PyTorch base class for neural networks. All models should inherit from this class. Inherits from torch.nn.Module and the BaseCallback class that endows callbacks for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc. Parameters: Name Type Description Default multihead bool Set to True if the backbone is multi-headed. Defaults to False. False classes_per_task Optional [ int ] The number of classes per task. Defaults to None. None masking_value float The value that replaces the logits. Only used if multihead is set to True. Defaults to -10e10. -100000000000.0 Note Currently, the BaseBackbone only considers tasks with equal number of classes. Source code in sequel/backbones/pytorch/base_backbone.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 def __init__ ( self , multihead : bool = False , classes_per_task : Optional [ int ] = None , masking_value : float = - 10e10 ): \"\"\"Inits the BaseBackbone class. This class defines the PyTorch base class for neural networks. All models should inherit from this class. Inherits from torch.nn.Module and the BaseCallback class that endows callbacks for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc. Args: multihead (bool, optional): Set to True if the backbone is multi-headed. Defaults to False. classes_per_task (Optional[int], optional): The number of classes per task. Defaults to None. masking_value (float, optional): The value that replaces the logits. Only used if multihead is set to True. Defaults to -10e10. Note: Currently, the BaseBackbone only considers tasks with equal number of classes. \"\"\" super () . __init__ () self . multihead = multihead logging . info ( f \"multihead is set to { self . multihead } \" ) if self . multihead : assert classes_per_task is not None self . classes_per_task = classes_per_task self . masking_value = masking_value","title":"__init__()"},{"location":"backbones/pytorch/base/#sequel.backbones.pytorch.base_backbone.BaseBackbone.forward","text":"Implements the forward function of the backbone. Models must ovveride this method. Example","title":"forward()"},{"location":"backbones/pytorch/base/#sequel.backbones.pytorch.base_backbone.BaseBackbone.forward--perform-the-forward","text":"x = ...","title":"perform the forward."},{"location":"backbones/pytorch/base/#sequel.backbones.pytorch.base_backbone.BaseBackbone.forward--select-the-correct-output-head","text":"if self.multihead: return self.select_output_head(x, task_ids) Parameters: Name Type Description Default x torch . Tensor The batch inputs. required task_ids torch . Tensor The batch task ids. required Returns: Type Description torch . Tensor torch.Tensor: The batch predicitons. Source code in sequel/backbones/pytorch/base_backbone.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 def forward ( self , x : torch . Tensor , task_ids : torch . Tensor ) -> torch . Tensor : \"\"\"Implements the forward function of the backbone. Models must ovveride this method. Example: # perform the forward. x = ... # select the correct output head. if self.multihead: return self.select_output_head(x, task_ids) Args: x (torch.Tensor): The batch inputs. task_ids (torch.Tensor): The batch task ids. Returns: torch.Tensor: The batch predicitons. \"\"\" raise NotImplementedError","title":"select the correct output head."},{"location":"backbones/pytorch/base/#sequel.backbones.pytorch.base_backbone.BaseBackbone.select_output_head","text":"Utility function in case multihead=True that replaces the original logits by a low value so that almost zero probability is given to the corresponding classes. Parameters: Name Type Description Default x torch . Tensor The original logits. required task_ids torch . Tensor The task id for each sample in the batch. required Returns: Type Description torch . Tensor torch.Tensor: the manipulated logits. Source code in sequel/backbones/pytorch/base_backbone.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 def select_output_head ( self , x : torch . Tensor , task_ids : torch . Tensor ) -> torch . Tensor : \"\"\"Utility function in case `multihead=True` that replaces the original logits by a low value so that almost zero probability is given to the corresponding classes. Args: x (torch.Tensor): The original logits. task_ids (torch.Tensor): The task id for each sample in the batch. Returns: torch.Tensor: the manipulated logits. \"\"\" assert self . multihead assert isinstance ( x , torch . Tensor ) for i , task_id in enumerate ( task_ids ): task_id = task_id - 1 if isinstance ( task_id , torch . Tensor ): task_id = task_id . cpu () . int () . item () start = task_id * self . classes_per_task end = ( task_id + 1 ) * self . classes_per_task x [ i , : start ] . data . fill_ ( self . masking_value ) x [ i , end :] . data . fill_ ( self . masking_value ) return x","title":"select_output_head()"},{"location":"backbones/pytorch/cnn/","text":"CNN Bases: BaseBackbone Source code in sequel/backbones/pytorch/cnn.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 class CNN ( BaseBackbone ): def __init__ ( self , channels : List [ int ], linear_layers : Optional [ Union [ List , int ]] = None , num_classes : int = 10 , multiplier : int = 1 , kernel_size : int = 3 , activation = \"relu\" , stride : int = 2 , use_maxpool : bool = False , ) -> None : \"\"\"Inits the CNN backbone. Args: channels (int): The number if in channels. linear_layers (Optional[Union[List, int]], optional): The linear layers' widths. These linear layers suceed the convolutional layers. If set to None, no linear layers are used except the output layer, whose width is defined by `num_classes`. Defaults to None. num_classes (int, optional): The number of output logits. Defaults to 10. multiplier (int, optional): Multiplies the number of channels for all layers, making the model wider. Defaults to 1. kernel_size (int, optional): The kernel size of the convolutions. Currenrly all convolutions have the share kernel size. Defaults to 3. activation (str, optional): The type of activation used. Defaults to \"relu\". stride (int, optional): The convolutional stride. Defaults to 2. use_maxpool (bool, optional): If set, the model uses maxpool layers. Defaults to False. Raises: ValueError: If stride is not equal to 1 or 2. ValueError: If maxpool and stride of 2 are used at the same time. ValueError: If `num_classes` is not a positive integer. \"\"\" super () . __init__ () if not ( stride == 1 or stride == 2 ): raise ValueError ( \"Only strides of 1 or 2 are supported.\" ) if int ( stride == 2 ) + int ( use_maxpool ) != 1 : raise ValueError ( \"You cannot use a stride of 2 and maxpool concurrently!\" ) if not isinstance ( num_classes , int ) and num_classes < 1 : raise ValueError ( \"The number of output classes must be positive integer.\" ) warnings . warn ( \"The CNN class does not include Batch Normalization.\" ) self . num_classes = num_classes self . multiplier = multiplier self . kernel_size = kernel_size self . activation = activation if linear_layers is not None : self . linear_layers = linear_layers if isinstance ( linear_layers , list ) else [ linear_layers ] else : self . linear_layers = [] # multiply number of channels self . channels = [ c * multiplier for c in channels ] # construct convolutional encoder layers layers = [] for i , c in enumerate ( self . channels ): layers . append ( nn . LazyConv2d ( c , kernel_size = kernel_size , stride = stride , padding = 1 )) layers . append ( ACTIVATION_MAP [ activation ]) if use_maxpool : layers . append ( nn . MaxPool2d ( kernel_size = 2 )) layers . append ( nn . Flatten ()) # construct fully-connected layers for feats in self . linear_layers : layers . append ( nn . LazyLinear ( feats )) layers . append ( ACTIVATION_MAP [ activation ]) self . encoder = nn . Sequential ( * layers ) self . classifier = nn . LazyLinear ( num_classes ) def forward ( self , x : torch . Tensor , task_ids : Optional [ torch . Tensor ] = None ) -> torch . Tensor : x = self . encoder ( x ) x = self . classifier ( x ) if self . multihead : x = self . select_output_head ( x , task_ids = task_ids ) return x @classmethod def from_config ( cls , config : omegaconf . ListConfig ): linear_layers = config . backbone . linear_layers channels = config . backbone . channels multiplier = getattr ( config . backbone , \"multiplier\" , 1 ) kernel_size = getattr ( config . backbone , \"kernel_size\" , 3 ) activation = getattr ( config . backbone , \"activation\" , \"relu\" ) stride = getattr ( config . backbone , \"stride\" , 2 ) use_maxpool = getattr ( config . backbone , \"use_maxpool\" , False ) return cls ( linear_layers = linear_layers , channels = channels , multiplier = multiplier , kernel_size = kernel_size , activation = activation , stride = stride , use_maxpool = use_maxpool , ) __init__ ( channels , linear_layers = None , num_classes = 10 , multiplier = 1 , kernel_size = 3 , activation = 'relu' , stride = 2 , use_maxpool = False ) Inits the CNN backbone. Parameters: Name Type Description Default channels int The number if in channels. required linear_layers Optional [ Union [ List , int ]] The linear layers' widths. These linear layers suceed the convolutional layers. If set to None, no linear layers are used except the output layer, whose width is defined by num_classes . Defaults to None. None num_classes int The number of output logits. Defaults to 10. 10 multiplier int Multiplies the number of channels for all layers, making the model wider. Defaults to 1. 1 kernel_size int The kernel size of the convolutions. Currenrly all convolutions have the share kernel size. Defaults to 3. 3 activation str The type of activation used. Defaults to \"relu\". 'relu' stride int The convolutional stride. Defaults to 2. 2 use_maxpool bool If set, the model uses maxpool layers. Defaults to False. False Raises: Type Description ValueError If stride is not equal to 1 or 2. ValueError If maxpool and stride of 2 are used at the same time. ValueError If num_classes is not a positive integer. Source code in sequel/backbones/pytorch/cnn.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def __init__ ( self , channels : List [ int ], linear_layers : Optional [ Union [ List , int ]] = None , num_classes : int = 10 , multiplier : int = 1 , kernel_size : int = 3 , activation = \"relu\" , stride : int = 2 , use_maxpool : bool = False , ) -> None : \"\"\"Inits the CNN backbone. Args: channels (int): The number if in channels. linear_layers (Optional[Union[List, int]], optional): The linear layers' widths. These linear layers suceed the convolutional layers. If set to None, no linear layers are used except the output layer, whose width is defined by `num_classes`. Defaults to None. num_classes (int, optional): The number of output logits. Defaults to 10. multiplier (int, optional): Multiplies the number of channels for all layers, making the model wider. Defaults to 1. kernel_size (int, optional): The kernel size of the convolutions. Currenrly all convolutions have the share kernel size. Defaults to 3. activation (str, optional): The type of activation used. Defaults to \"relu\". stride (int, optional): The convolutional stride. Defaults to 2. use_maxpool (bool, optional): If set, the model uses maxpool layers. Defaults to False. Raises: ValueError: If stride is not equal to 1 or 2. ValueError: If maxpool and stride of 2 are used at the same time. ValueError: If `num_classes` is not a positive integer. \"\"\" super () . __init__ () if not ( stride == 1 or stride == 2 ): raise ValueError ( \"Only strides of 1 or 2 are supported.\" ) if int ( stride == 2 ) + int ( use_maxpool ) != 1 : raise ValueError ( \"You cannot use a stride of 2 and maxpool concurrently!\" ) if not isinstance ( num_classes , int ) and num_classes < 1 : raise ValueError ( \"The number of output classes must be positive integer.\" ) warnings . warn ( \"The CNN class does not include Batch Normalization.\" ) self . num_classes = num_classes self . multiplier = multiplier self . kernel_size = kernel_size self . activation = activation if linear_layers is not None : self . linear_layers = linear_layers if isinstance ( linear_layers , list ) else [ linear_layers ] else : self . linear_layers = [] # multiply number of channels self . channels = [ c * multiplier for c in channels ] # construct convolutional encoder layers layers = [] for i , c in enumerate ( self . channels ): layers . append ( nn . LazyConv2d ( c , kernel_size = kernel_size , stride = stride , padding = 1 )) layers . append ( ACTIVATION_MAP [ activation ]) if use_maxpool : layers . append ( nn . MaxPool2d ( kernel_size = 2 )) layers . append ( nn . Flatten ()) # construct fully-connected layers for feats in self . linear_layers : layers . append ( nn . LazyLinear ( feats )) layers . append ( ACTIVATION_MAP [ activation ]) self . encoder = nn . Sequential ( * layers ) self . classifier = nn . LazyLinear ( num_classes ) get_model_output_features ( config , model ) Calculates the output dimension of a model. This method is used to infer he number of out features of an encoder, which serve as in_features of the decoders (task-specific layers). Parameters: Name Type Description Default config omegaconf . ListConfig The hydra config for the current experiment. required model torch . nn . Module The PyTorch model (the encoder of the Shared-Bottom architecture.) required Returns: Name Type Description int int The number of out_features of the model. Source code in sequel/backbones/pytorch/cnn.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 def get_model_output_features ( config : omegaconf . ListConfig , model : torch . nn . Module ) -> int : \"\"\"Calculates the output dimension of a model. This method is used to infer he number of out features of an encoder, which serve as `in_features` of the decoders (task-specific layers). Args: config (omegaconf.ListConfig): The hydra config for the current experiment. model (torch.nn.Module): The PyTorch model (the encoder of the Shared-Bottom architecture.) Returns: int: The number of out_features of the model. \"\"\" c = getattr ( config . benchmark , \"channels\" , 1 ) h , w = getattr ( config . benchmark , \"dimensions\" ) # generate a random sample. x = torch . rand ( 1 , c , h , w ) with torch . no_grad (): x = model ( x ) assert x . dim () == 2 return x . size ( 1 )","title":"CNN"},{"location":"backbones/pytorch/cnn/#sequel.backbones.pytorch.cnn.CNN","text":"Bases: BaseBackbone Source code in sequel/backbones/pytorch/cnn.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 class CNN ( BaseBackbone ): def __init__ ( self , channels : List [ int ], linear_layers : Optional [ Union [ List , int ]] = None , num_classes : int = 10 , multiplier : int = 1 , kernel_size : int = 3 , activation = \"relu\" , stride : int = 2 , use_maxpool : bool = False , ) -> None : \"\"\"Inits the CNN backbone. Args: channels (int): The number if in channels. linear_layers (Optional[Union[List, int]], optional): The linear layers' widths. These linear layers suceed the convolutional layers. If set to None, no linear layers are used except the output layer, whose width is defined by `num_classes`. Defaults to None. num_classes (int, optional): The number of output logits. Defaults to 10. multiplier (int, optional): Multiplies the number of channels for all layers, making the model wider. Defaults to 1. kernel_size (int, optional): The kernel size of the convolutions. Currenrly all convolutions have the share kernel size. Defaults to 3. activation (str, optional): The type of activation used. Defaults to \"relu\". stride (int, optional): The convolutional stride. Defaults to 2. use_maxpool (bool, optional): If set, the model uses maxpool layers. Defaults to False. Raises: ValueError: If stride is not equal to 1 or 2. ValueError: If maxpool and stride of 2 are used at the same time. ValueError: If `num_classes` is not a positive integer. \"\"\" super () . __init__ () if not ( stride == 1 or stride == 2 ): raise ValueError ( \"Only strides of 1 or 2 are supported.\" ) if int ( stride == 2 ) + int ( use_maxpool ) != 1 : raise ValueError ( \"You cannot use a stride of 2 and maxpool concurrently!\" ) if not isinstance ( num_classes , int ) and num_classes < 1 : raise ValueError ( \"The number of output classes must be positive integer.\" ) warnings . warn ( \"The CNN class does not include Batch Normalization.\" ) self . num_classes = num_classes self . multiplier = multiplier self . kernel_size = kernel_size self . activation = activation if linear_layers is not None : self . linear_layers = linear_layers if isinstance ( linear_layers , list ) else [ linear_layers ] else : self . linear_layers = [] # multiply number of channels self . channels = [ c * multiplier for c in channels ] # construct convolutional encoder layers layers = [] for i , c in enumerate ( self . channels ): layers . append ( nn . LazyConv2d ( c , kernel_size = kernel_size , stride = stride , padding = 1 )) layers . append ( ACTIVATION_MAP [ activation ]) if use_maxpool : layers . append ( nn . MaxPool2d ( kernel_size = 2 )) layers . append ( nn . Flatten ()) # construct fully-connected layers for feats in self . linear_layers : layers . append ( nn . LazyLinear ( feats )) layers . append ( ACTIVATION_MAP [ activation ]) self . encoder = nn . Sequential ( * layers ) self . classifier = nn . LazyLinear ( num_classes ) def forward ( self , x : torch . Tensor , task_ids : Optional [ torch . Tensor ] = None ) -> torch . Tensor : x = self . encoder ( x ) x = self . classifier ( x ) if self . multihead : x = self . select_output_head ( x , task_ids = task_ids ) return x @classmethod def from_config ( cls , config : omegaconf . ListConfig ): linear_layers = config . backbone . linear_layers channels = config . backbone . channels multiplier = getattr ( config . backbone , \"multiplier\" , 1 ) kernel_size = getattr ( config . backbone , \"kernel_size\" , 3 ) activation = getattr ( config . backbone , \"activation\" , \"relu\" ) stride = getattr ( config . backbone , \"stride\" , 2 ) use_maxpool = getattr ( config . backbone , \"use_maxpool\" , False ) return cls ( linear_layers = linear_layers , channels = channels , multiplier = multiplier , kernel_size = kernel_size , activation = activation , stride = stride , use_maxpool = use_maxpool , )","title":"CNN"},{"location":"backbones/pytorch/cnn/#sequel.backbones.pytorch.cnn.CNN.__init__","text":"Inits the CNN backbone. Parameters: Name Type Description Default channels int The number if in channels. required linear_layers Optional [ Union [ List , int ]] The linear layers' widths. These linear layers suceed the convolutional layers. If set to None, no linear layers are used except the output layer, whose width is defined by num_classes . Defaults to None. None num_classes int The number of output logits. Defaults to 10. 10 multiplier int Multiplies the number of channels for all layers, making the model wider. Defaults to 1. 1 kernel_size int The kernel size of the convolutions. Currenrly all convolutions have the share kernel size. Defaults to 3. 3 activation str The type of activation used. Defaults to \"relu\". 'relu' stride int The convolutional stride. Defaults to 2. 2 use_maxpool bool If set, the model uses maxpool layers. Defaults to False. False Raises: Type Description ValueError If stride is not equal to 1 or 2. ValueError If maxpool and stride of 2 are used at the same time. ValueError If num_classes is not a positive integer. Source code in sequel/backbones/pytorch/cnn.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def __init__ ( self , channels : List [ int ], linear_layers : Optional [ Union [ List , int ]] = None , num_classes : int = 10 , multiplier : int = 1 , kernel_size : int = 3 , activation = \"relu\" , stride : int = 2 , use_maxpool : bool = False , ) -> None : \"\"\"Inits the CNN backbone. Args: channels (int): The number if in channels. linear_layers (Optional[Union[List, int]], optional): The linear layers' widths. These linear layers suceed the convolutional layers. If set to None, no linear layers are used except the output layer, whose width is defined by `num_classes`. Defaults to None. num_classes (int, optional): The number of output logits. Defaults to 10. multiplier (int, optional): Multiplies the number of channels for all layers, making the model wider. Defaults to 1. kernel_size (int, optional): The kernel size of the convolutions. Currenrly all convolutions have the share kernel size. Defaults to 3. activation (str, optional): The type of activation used. Defaults to \"relu\". stride (int, optional): The convolutional stride. Defaults to 2. use_maxpool (bool, optional): If set, the model uses maxpool layers. Defaults to False. Raises: ValueError: If stride is not equal to 1 or 2. ValueError: If maxpool and stride of 2 are used at the same time. ValueError: If `num_classes` is not a positive integer. \"\"\" super () . __init__ () if not ( stride == 1 or stride == 2 ): raise ValueError ( \"Only strides of 1 or 2 are supported.\" ) if int ( stride == 2 ) + int ( use_maxpool ) != 1 : raise ValueError ( \"You cannot use a stride of 2 and maxpool concurrently!\" ) if not isinstance ( num_classes , int ) and num_classes < 1 : raise ValueError ( \"The number of output classes must be positive integer.\" ) warnings . warn ( \"The CNN class does not include Batch Normalization.\" ) self . num_classes = num_classes self . multiplier = multiplier self . kernel_size = kernel_size self . activation = activation if linear_layers is not None : self . linear_layers = linear_layers if isinstance ( linear_layers , list ) else [ linear_layers ] else : self . linear_layers = [] # multiply number of channels self . channels = [ c * multiplier for c in channels ] # construct convolutional encoder layers layers = [] for i , c in enumerate ( self . channels ): layers . append ( nn . LazyConv2d ( c , kernel_size = kernel_size , stride = stride , padding = 1 )) layers . append ( ACTIVATION_MAP [ activation ]) if use_maxpool : layers . append ( nn . MaxPool2d ( kernel_size = 2 )) layers . append ( nn . Flatten ()) # construct fully-connected layers for feats in self . linear_layers : layers . append ( nn . LazyLinear ( feats )) layers . append ( ACTIVATION_MAP [ activation ]) self . encoder = nn . Sequential ( * layers ) self . classifier = nn . LazyLinear ( num_classes )","title":"__init__()"},{"location":"backbones/pytorch/cnn/#sequel.backbones.pytorch.cnn.get_model_output_features","text":"Calculates the output dimension of a model. This method is used to infer he number of out features of an encoder, which serve as in_features of the decoders (task-specific layers). Parameters: Name Type Description Default config omegaconf . ListConfig The hydra config for the current experiment. required model torch . nn . Module The PyTorch model (the encoder of the Shared-Bottom architecture.) required Returns: Name Type Description int int The number of out_features of the model. Source code in sequel/backbones/pytorch/cnn.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 def get_model_output_features ( config : omegaconf . ListConfig , model : torch . nn . Module ) -> int : \"\"\"Calculates the output dimension of a model. This method is used to infer he number of out features of an encoder, which serve as `in_features` of the decoders (task-specific layers). Args: config (omegaconf.ListConfig): The hydra config for the current experiment. model (torch.nn.Module): The PyTorch model (the encoder of the Shared-Bottom architecture.) Returns: int: The number of out_features of the model. \"\"\" c = getattr ( config . benchmark , \"channels\" , 1 ) h , w = getattr ( config . benchmark , \"dimensions\" ) # generate a random sample. x = torch . rand ( 1 , c , h , w ) with torch . no_grad (): x = model ( x ) assert x . dim () == 2 return x . size ( 1 )","title":"get_model_output_features()"},{"location":"backbones/pytorch/mlp/","text":"MLP Bases: BaseBackbone Source code in sequel/backbones/pytorch/mlp.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 class MLP ( BaseBackbone ): def __init__ ( self , width : int , n_hidden_layers : int , dropout : Optional [ float ] = None , num_classes : int = 10 , * args , ** kwargs , ) -> None : \"\"\"A Multi-Layer Peceptron of `n_hidden_layers`, each of which has `width` neurons. This class is used as the encoder for the SharedBottom architecture. Args: n_hidden_layers (int): Number of hidden layers width (int): Width of (all) hidden layers dropout (Optional[float], optional): If set, the model includes a dropout layer after every Linear with probability equal to the set value. Defaults to None. \"\"\" super () . __init__ ( * args , ** kwargs ) self . widths = width self . num_classes = num_classes self . n_hidden_layers = n_hidden_layers layers = [ nn . Flatten ()] for w in range ( n_hidden_layers ): layers . append ( nn . LazyLinear ( width )) layers . append ( nn . ReLU ( inplace = True )) if dropout : layers . append ( nn . Dropout ( p = dropout )) self . encoder = nn . Sequential ( * layers ) self . classifier = nn . LazyLinear ( self . num_classes ) def forward ( self , x : torch . Tensor , task_ids : Optional [ torch . Tensor ] = None ) -> torch . Tensor : x = self . encoder ( x ) x = self . classifier ( x ) if self . multihead : x = self . select_output_head ( x , task_ids ) return x @classmethod def from_config ( cls , config : omegaconf . ListConfig ) -> BaseBackbone : n_hidden_layers = config . backbone . n_hidden_layers width = config . backbone . width dropout = getattr ( config . backbone , \"dropout\" , None ) num_classes = getattr ( config . backbone , \"num_classes\" , 10 ) return cls ( widths = n_hidden_layers , width = width , dropout = dropout , num_classes = num_classes , ) __init__ ( width , n_hidden_layers , dropout = None , num_classes = 10 , * args , ** kwargs ) A Multi-Layer Peceptron of n_hidden_layers , each of which has width neurons. This class is used as the encoder for the SharedBottom architecture. Parameters: Name Type Description Default n_hidden_layers int Number of hidden layers required width int Width of (all) hidden layers required dropout Optional [ float ] If set, the model includes a dropout layer after every Linear with probability equal to the set value. Defaults to None. None Source code in sequel/backbones/pytorch/mlp.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def __init__ ( self , width : int , n_hidden_layers : int , dropout : Optional [ float ] = None , num_classes : int = 10 , * args , ** kwargs , ) -> None : \"\"\"A Multi-Layer Peceptron of `n_hidden_layers`, each of which has `width` neurons. This class is used as the encoder for the SharedBottom architecture. Args: n_hidden_layers (int): Number of hidden layers width (int): Width of (all) hidden layers dropout (Optional[float], optional): If set, the model includes a dropout layer after every Linear with probability equal to the set value. Defaults to None. \"\"\" super () . __init__ ( * args , ** kwargs ) self . widths = width self . num_classes = num_classes self . n_hidden_layers = n_hidden_layers layers = [ nn . Flatten ()] for w in range ( n_hidden_layers ): layers . append ( nn . LazyLinear ( width )) layers . append ( nn . ReLU ( inplace = True )) if dropout : layers . append ( nn . Dropout ( p = dropout )) self . encoder = nn . Sequential ( * layers ) self . classifier = nn . LazyLinear ( self . num_classes )","title":"MLP"},{"location":"backbones/pytorch/mlp/#sequel.backbones.pytorch.mlp.MLP","text":"Bases: BaseBackbone Source code in sequel/backbones/pytorch/mlp.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 class MLP ( BaseBackbone ): def __init__ ( self , width : int , n_hidden_layers : int , dropout : Optional [ float ] = None , num_classes : int = 10 , * args , ** kwargs , ) -> None : \"\"\"A Multi-Layer Peceptron of `n_hidden_layers`, each of which has `width` neurons. This class is used as the encoder for the SharedBottom architecture. Args: n_hidden_layers (int): Number of hidden layers width (int): Width of (all) hidden layers dropout (Optional[float], optional): If set, the model includes a dropout layer after every Linear with probability equal to the set value. Defaults to None. \"\"\" super () . __init__ ( * args , ** kwargs ) self . widths = width self . num_classes = num_classes self . n_hidden_layers = n_hidden_layers layers = [ nn . Flatten ()] for w in range ( n_hidden_layers ): layers . append ( nn . LazyLinear ( width )) layers . append ( nn . ReLU ( inplace = True )) if dropout : layers . append ( nn . Dropout ( p = dropout )) self . encoder = nn . Sequential ( * layers ) self . classifier = nn . LazyLinear ( self . num_classes ) def forward ( self , x : torch . Tensor , task_ids : Optional [ torch . Tensor ] = None ) -> torch . Tensor : x = self . encoder ( x ) x = self . classifier ( x ) if self . multihead : x = self . select_output_head ( x , task_ids ) return x @classmethod def from_config ( cls , config : omegaconf . ListConfig ) -> BaseBackbone : n_hidden_layers = config . backbone . n_hidden_layers width = config . backbone . width dropout = getattr ( config . backbone , \"dropout\" , None ) num_classes = getattr ( config . backbone , \"num_classes\" , 10 ) return cls ( widths = n_hidden_layers , width = width , dropout = dropout , num_classes = num_classes , )","title":"MLP"},{"location":"backbones/pytorch/mlp/#sequel.backbones.pytorch.mlp.MLP.__init__","text":"A Multi-Layer Peceptron of n_hidden_layers , each of which has width neurons. This class is used as the encoder for the SharedBottom architecture. Parameters: Name Type Description Default n_hidden_layers int Number of hidden layers required width int Width of (all) hidden layers required dropout Optional [ float ] If set, the model includes a dropout layer after every Linear with probability equal to the set value. Defaults to None. None Source code in sequel/backbones/pytorch/mlp.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def __init__ ( self , width : int , n_hidden_layers : int , dropout : Optional [ float ] = None , num_classes : int = 10 , * args , ** kwargs , ) -> None : \"\"\"A Multi-Layer Peceptron of `n_hidden_layers`, each of which has `width` neurons. This class is used as the encoder for the SharedBottom architecture. Args: n_hidden_layers (int): Number of hidden layers width (int): Width of (all) hidden layers dropout (Optional[float], optional): If set, the model includes a dropout layer after every Linear with probability equal to the set value. Defaults to None. \"\"\" super () . __init__ ( * args , ** kwargs ) self . widths = width self . num_classes = num_classes self . n_hidden_layers = n_hidden_layers layers = [ nn . Flatten ()] for w in range ( n_hidden_layers ): layers . append ( nn . LazyLinear ( width )) layers . append ( nn . ReLU ( inplace = True )) if dropout : layers . append ( nn . Dropout ( p = dropout )) self . encoder = nn . Sequential ( * layers ) self . classifier = nn . LazyLinear ( self . num_classes )","title":"__init__()"},{"location":"backbones/pytorch/resnet/","text":"ResNet Bases: BaseBackbone ResNet18 backbone with the number of features as an arguments. For nf=20 , the ResNet has 1/3 of the features of the original. Code adapted from: 1. https://github.com/facebookresearch/GradientEpisodicMemory 2. https://worksheets.codalab.org/rest/bundles/0xaf60b5ed6a4a44c89d296aae9bc6a0f1/contents/blob/models.py Source code in sequel/backbones/pytorch/resnet.py 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 class ResNet ( BaseBackbone ): \"\"\"ResNet18 backbone with the number of features as an arguments. For `nf=20`, the ResNet has 1/3 of the features of the original. Code adapted from: 1. https://github.com/facebookresearch/GradientEpisodicMemory 2. https://worksheets.codalab.org/rest/bundles/0xaf60b5ed6a4a44c89d296aae9bc6a0f1/contents/blob/models.py \"\"\" def __init__ ( self , block , num_blocks , num_classes , nf = 20 , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . encoder = ResNetEncoder ( block , num_blocks , num_classes , nf ) self . classifier = nn . Linear ( nf * 8 * block . expansion , num_classes ) def forward ( self , inp : torch . Tensor , head_ids : Optional [ Iterable ] = None ): out = self . encoder ( inp ) out = self . classifier ( out ) if self . multihead : out = self . select_output_head ( out , head_ids ) return out","title":"ResNet"},{"location":"backbones/pytorch/resnet/#sequel.backbones.pytorch.resnet.ResNet","text":"Bases: BaseBackbone ResNet18 backbone with the number of features as an arguments. For nf=20 , the ResNet has 1/3 of the features of the original. Code adapted from: 1. https://github.com/facebookresearch/GradientEpisodicMemory 2. https://worksheets.codalab.org/rest/bundles/0xaf60b5ed6a4a44c89d296aae9bc6a0f1/contents/blob/models.py Source code in sequel/backbones/pytorch/resnet.py 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 class ResNet ( BaseBackbone ): \"\"\"ResNet18 backbone with the number of features as an arguments. For `nf=20`, the ResNet has 1/3 of the features of the original. Code adapted from: 1. https://github.com/facebookresearch/GradientEpisodicMemory 2. https://worksheets.codalab.org/rest/bundles/0xaf60b5ed6a4a44c89d296aae9bc6a0f1/contents/blob/models.py \"\"\" def __init__ ( self , block , num_blocks , num_classes , nf = 20 , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . encoder = ResNetEncoder ( block , num_blocks , num_classes , nf ) self . classifier = nn . Linear ( nf * 8 * block . expansion , num_classes ) def forward ( self , inp : torch . Tensor , head_ids : Optional [ Iterable ] = None ): out = self . encoder ( inp ) out = self . classifier ( out ) if self . multihead : out = self . select_output_head ( out , head_ids ) return out","title":"ResNet"},{"location":"benchmarks/base_benchmark/","text":"Benchmark Base class for Continual Learning datasets (called benchmarks). All benchmarks (e.g. PermutedMNIST, SplitCifar100 etc) inherit from this class. It implements basic dataset and memory handling, such as splitting the original dataset into task datasets (train+val), constructing dataloaders which include one or multiple task datasets, dataloaders only for memory samples, dataloaders for one or multiple task datasets augmented with memory samples and more! Source code in sequel/benchmarks/base_benchmark.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 class Benchmark : \"\"\"Base class for Continual Learning datasets (called benchmarks). All benchmarks (e.g. PermutedMNIST, SplitCifar100 etc) inherit from this class. It implements basic dataset and memory handling, such as splitting the original dataset into task datasets (train+val), constructing dataloaders which include one or multiple task datasets, dataloaders only for memory samples, dataloaders for one or multiple task datasets augmented with memory samples and more! \"\"\" @staticmethod def get_default_kwargs ( config : omegaconf . ListConfig ) -> dict : \"\"\"Utility function that covers the standard arguments for the construction of a benchmark. Used implicilty by benchmark selectors. Args: config (omegaconf.ListConfig): The user-specified experiment configuration. Returns: dict: a dictionary with argument key and value pairs for the construction of the benchmark. \"\"\" kwargs = {} kwargs [ \"num_tasks\" ] = config . num_tasks kwargs [ \"batch_size\" ] = config . batch_size kwargs [ \"eval_batch_size\" ] = getattr ( config , \"eval_batch_size\" , None ) kwargs [ \"num_workers\" ] = getattr ( config , \"num_workers\" , 2 ) kwargs [ \"pin_memory\" ] = getattr ( config , \"pin_memory\" , True ) kwargs [ \"subset\" ] = getattr ( config , \"subset\" , None ) return kwargs @property def dimensions ( self ) -> List [ int ]: raise NotImplementedError @property def num_classes ( self ) -> int : raise NotImplementedError def __init__ ( self , num_tasks : int , batch_size : int , eval_batch_size : int = None , num_workers : int = 0 , pin_memory : bool = True , subset : Optional [ int ] = None , ): \"\"\"Inits the base Benchmark class. Args: num_tasks (int): the number of tasks in the benchmark. batch_size (int, optional): The train dataloader batch size. Defaults to 256. eval_batch_size (int, optional): The validation dataloader batch size. If None, `eval_batch_size` is set to `batch_size`. Defaults to None. num_workers (int, optional): Dataloader number of workers. Defaults to 0. pin_memory (bool, optional): pin_memory argument for dataloaders. Defaults to True. \"\"\" self . num_tasks = num_tasks # dataloader arguments self . batch_size = batch_size self . eval_batch_size = eval_batch_size if eval_batch_size is not None else batch_size self . num_workers = num_workers self . pin_memory = pin_memory self . subset = subset self . dl_kwargs = dict ( pin_memory = pin_memory , num_workers = num_workers ) # set up self . trains , self . tests = self . prepare_datasets () self . memory_indices = {} if subset is not None : logging . info ( \"Setting up the subset indices.\" ) assert isinstance ( subset , int ) and subset > 0 self . subset_indices = {} for k , v in self . trains . items (): indices = list ( range ( len ( v ))) random . shuffle ( indices ) self . subset_indices [ k ] = indices [: subset ] def __check_valid_task__ ( self , task : int ): if task > self . num_tasks : raise ValueError ( f \"Asked to load task { task } but the benchmark has { self . num_tasks } tasks\" ) @classmethod def from_config ( cls , config : omegaconf . OmegaConf , * args , ** kwargs ): raise NotImplementedError def prepare_datasets ( self ) -> Tuple [ ContinualDataset , ContinualDataset ]: raise NotImplementedError def get_memory_indices ( self , task : int ) -> torch . Tensor : return self . memory_indices [ task ] def set_memory_indices ( self , task : int , indices : List [ int ]) -> None : self . memory_indices [ task ] = indices def get_train_dataset ( self , task : int ) -> ContinualDataset : return self . trains [ task ] def get_test_dataset ( self , task : int ) -> ContinualDataset : return self . tests [ task ] def get_memories ( self , task : int ) -> ContinualConcatDataset : \"\"\"Returns a `ContinualConcatDataset` containing all the memory samples for tasks up to `task`. Args: task (int): The current task. The final dataset consists of all memory samples up to the specified id. Returns: ContinualConcatDataset: The constructed concatenated dataset. \"\"\" self . __check_valid_task__ ( task ) memories = [ ContinualSubsetDataset ( self . get_train_dataset ( t ), self . memory_indices [ t ]) for t in range ( 1 , task + 1 ) ] return ContinualConcatDataset ( memories ) def train_dataloader ( self , task : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Constructs the train dataloader for the current task. Args: task (int): the current task id batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. Returns: DataLoader: the constructed DataLoader \"\"\" self . __check_valid_task__ ( task ) if batch_size is None : batch_size = self . batch_size dataset = self . get_train_dataset ( task ) if self . subset : indices = self . subset_indices [ task ] logging . info ( f \"Extracting subset [ { len ( indices ) } / { len ( dataset ) } samples] for train dataset of task { task } \" ) dataset = ContinualSubsetDataset ( dataset , indices ) return DataLoader ( dataset , batch_size , shuffle = True , ** self . dl_kwargs ) def val_dataloader ( self , task : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Constructs the val dataloader for the current task. Args: task (int): the current task id batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. Returns: DataLoader: the constructed DataLoader \"\"\" self . __check_valid_task__ ( task ) if batch_size is None : batch_size = self . eval_batch_size dataset = self . get_test_dataset ( task ) return DataLoader ( dataset , batch_size , ** self . dl_kwargs ) def train_dataloader_subset ( self , task : int , subset_size : Optional [ int ] = None , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Constructs a dataloader containing a random subset from the dataset indexed by id `task`. Args: task (int): the dataset task id. batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. Returns: DataLoader: the constructed dataloader. \"\"\" self . __check_valid_task__ ( task ) if batch_size is None : batch_size = self . batch_size if subset_size is None : assert self . subset is not None subset_size = self . subset train_dataset = self . get_train_dataset ( task ) indices = torch . randperm ( len ( train_dataset ))[: subset_size ] # sampler = RandomSampler(train_dataset, replacement=True, num_samples=subset_size) train_dataset = ContinualSubsetDataset ( train_dataset , indices = indices ) return DataLoader ( train_dataset , batch_size , ** self . dl_kwargs ) def train_dataloader_joint ( self , task : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Constructs the train dataloader for the current task. Args: task (int): the current task id batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. Returns: DataLoader: the constructed DataLoader \"\"\" self . __check_valid_task__ ( task ) if batch_size is None : batch_size = self . batch_size dataset = ContinualConcatDataset ([ self . get_train_dataset ( t ) for t in range ( 1 , task + 1 )]) return DataLoader ( dataset , batch_size , shuffle = True , ** self . dl_kwargs ) def memory_dataloader ( self , task : int , batch_size : Optional [ int ] = None , return_infinite_stream : bool = True ) -> DataLoader : self . __check_valid_task__ ( task ) dataset = self . get_memories ( task ) if batch_size is None : batch_size = self . batch_size if batch_size > len ( dataset ): batch_size = len ( dataset ) if return_infinite_stream : sampler = RandomSampler ( dataset , replacement = True , num_samples = 100 ** 100 ) return DataLoader ( dataset , batch_size , shuffle = False , sampler = sampler , ** self . dl_kwargs ) else : return DataLoader ( dataset , batch_size , shuffle = True , ** self . dl_kwargs ) def train_dataloader_with_memory ( self , task : int , batch_size : Optional [ int ] = None , verbose : bool = False ) -> DataLoader : \"\"\"Constructs a dataloader consisting of samples coming from the current task as well as the memory samples for all previous tasks. Args: task (int): the current task id batch_size (Optional[int], optional): The dataloader batch size. If set to None, the benchmark batch size is used. Defaults to None. verbose (bool, optional): boolean indicating if the method will print additional information to the console. Defaults to False. Returns: Dataloader: the constructed PyTorch dataloader. \"\"\" self . __check_valid_task__ ( task ) current_train_dataset = self . get_train_dataset ( task ) memory = self . get_memories ( task ) dataset = ContinualConcatDataset ([ current_train_dataset , memory ]) if verbose : logging . info ( \"Samples of train dataset: \\t {} \" . format ( len ( current_train_dataset ))) logging . info ( \"Samples of memory: \\t {} \" . format ( len ( memory ))) logging . info ( \"Samples of overall dataset: \\t {} \" . format ( len ( dataset ))) if batch_size is None : batch_size = self . batch_size return DataLoader ( dataset , batch_size , ** self . dl_kwargs ) __init__ ( num_tasks , batch_size , eval_batch_size = None , num_workers = 0 , pin_memory = True , subset = None ) Inits the base Benchmark class. Parameters: Name Type Description Default num_tasks int the number of tasks in the benchmark. required batch_size int The train dataloader batch size. Defaults to 256. required eval_batch_size int The validation dataloader batch size. If None, eval_batch_size is set to batch_size . Defaults to None. None num_workers int Dataloader number of workers. Defaults to 0. 0 pin_memory bool pin_memory argument for dataloaders. Defaults to True. True Source code in sequel/benchmarks/base_benchmark.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 def __init__ ( self , num_tasks : int , batch_size : int , eval_batch_size : int = None , num_workers : int = 0 , pin_memory : bool = True , subset : Optional [ int ] = None , ): \"\"\"Inits the base Benchmark class. Args: num_tasks (int): the number of tasks in the benchmark. batch_size (int, optional): The train dataloader batch size. Defaults to 256. eval_batch_size (int, optional): The validation dataloader batch size. If None, `eval_batch_size` is set to `batch_size`. Defaults to None. num_workers (int, optional): Dataloader number of workers. Defaults to 0. pin_memory (bool, optional): pin_memory argument for dataloaders. Defaults to True. \"\"\" self . num_tasks = num_tasks # dataloader arguments self . batch_size = batch_size self . eval_batch_size = eval_batch_size if eval_batch_size is not None else batch_size self . num_workers = num_workers self . pin_memory = pin_memory self . subset = subset self . dl_kwargs = dict ( pin_memory = pin_memory , num_workers = num_workers ) # set up self . trains , self . tests = self . prepare_datasets () self . memory_indices = {} if subset is not None : logging . info ( \"Setting up the subset indices.\" ) assert isinstance ( subset , int ) and subset > 0 self . subset_indices = {} for k , v in self . trains . items (): indices = list ( range ( len ( v ))) random . shuffle ( indices ) self . subset_indices [ k ] = indices [: subset ] get_default_kwargs ( config ) staticmethod Utility function that covers the standard arguments for the construction of a benchmark. Used implicilty by benchmark selectors. Parameters: Name Type Description Default config omegaconf . ListConfig The user-specified experiment configuration. required Returns: Name Type Description dict dict a dictionary with argument key and value pairs for the construction of the benchmark. Source code in sequel/benchmarks/base_benchmark.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 @staticmethod def get_default_kwargs ( config : omegaconf . ListConfig ) -> dict : \"\"\"Utility function that covers the standard arguments for the construction of a benchmark. Used implicilty by benchmark selectors. Args: config (omegaconf.ListConfig): The user-specified experiment configuration. Returns: dict: a dictionary with argument key and value pairs for the construction of the benchmark. \"\"\" kwargs = {} kwargs [ \"num_tasks\" ] = config . num_tasks kwargs [ \"batch_size\" ] = config . batch_size kwargs [ \"eval_batch_size\" ] = getattr ( config , \"eval_batch_size\" , None ) kwargs [ \"num_workers\" ] = getattr ( config , \"num_workers\" , 2 ) kwargs [ \"pin_memory\" ] = getattr ( config , \"pin_memory\" , True ) kwargs [ \"subset\" ] = getattr ( config , \"subset\" , None ) return kwargs get_memories ( task ) Returns a ContinualConcatDataset containing all the memory samples for tasks up to task . Parameters: Name Type Description Default task int The current task. The final dataset consists of all memory samples up to the specified id. required Returns: Name Type Description ContinualConcatDataset ContinualConcatDataset The constructed concatenated dataset. Source code in sequel/benchmarks/base_benchmark.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 def get_memories ( self , task : int ) -> ContinualConcatDataset : \"\"\"Returns a `ContinualConcatDataset` containing all the memory samples for tasks up to `task`. Args: task (int): The current task. The final dataset consists of all memory samples up to the specified id. Returns: ContinualConcatDataset: The constructed concatenated dataset. \"\"\" self . __check_valid_task__ ( task ) memories = [ ContinualSubsetDataset ( self . get_train_dataset ( t ), self . memory_indices [ t ]) for t in range ( 1 , task + 1 ) ] return ContinualConcatDataset ( memories ) train_dataloader ( task , batch_size = None ) Constructs the train dataloader for the current task. Parameters: Name Type Description Default task int the current task id required batch_size Optional [ int ] The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. None Returns: Name Type Description DataLoader DataLoader the constructed DataLoader Source code in sequel/benchmarks/base_benchmark.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 def train_dataloader ( self , task : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Constructs the train dataloader for the current task. Args: task (int): the current task id batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. Returns: DataLoader: the constructed DataLoader \"\"\" self . __check_valid_task__ ( task ) if batch_size is None : batch_size = self . batch_size dataset = self . get_train_dataset ( task ) if self . subset : indices = self . subset_indices [ task ] logging . info ( f \"Extracting subset [ { len ( indices ) } / { len ( dataset ) } samples] for train dataset of task { task } \" ) dataset = ContinualSubsetDataset ( dataset , indices ) return DataLoader ( dataset , batch_size , shuffle = True , ** self . dl_kwargs ) train_dataloader_joint ( task , batch_size = None ) Constructs the train dataloader for the current task. Parameters: Name Type Description Default task int the current task id required batch_size Optional [ int ] The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. None Returns: Name Type Description DataLoader DataLoader the constructed DataLoader Source code in sequel/benchmarks/base_benchmark.py 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 def train_dataloader_joint ( self , task : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Constructs the train dataloader for the current task. Args: task (int): the current task id batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. Returns: DataLoader: the constructed DataLoader \"\"\" self . __check_valid_task__ ( task ) if batch_size is None : batch_size = self . batch_size dataset = ContinualConcatDataset ([ self . get_train_dataset ( t ) for t in range ( 1 , task + 1 )]) return DataLoader ( dataset , batch_size , shuffle = True , ** self . dl_kwargs ) train_dataloader_subset ( task , subset_size = None , batch_size = None ) Constructs a dataloader containing a random subset from the dataset indexed by id task . Parameters: Name Type Description Default task int the dataset task id. required batch_size Optional [ int ] The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. None Returns: Name Type Description DataLoader DataLoader the constructed dataloader. Source code in sequel/benchmarks/base_benchmark.py 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 def train_dataloader_subset ( self , task : int , subset_size : Optional [ int ] = None , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Constructs a dataloader containing a random subset from the dataset indexed by id `task`. Args: task (int): the dataset task id. batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. Returns: DataLoader: the constructed dataloader. \"\"\" self . __check_valid_task__ ( task ) if batch_size is None : batch_size = self . batch_size if subset_size is None : assert self . subset is not None subset_size = self . subset train_dataset = self . get_train_dataset ( task ) indices = torch . randperm ( len ( train_dataset ))[: subset_size ] # sampler = RandomSampler(train_dataset, replacement=True, num_samples=subset_size) train_dataset = ContinualSubsetDataset ( train_dataset , indices = indices ) return DataLoader ( train_dataset , batch_size , ** self . dl_kwargs ) train_dataloader_with_memory ( task , batch_size = None , verbose = False ) Constructs a dataloader consisting of samples coming from the current task as well as the memory samples for all previous tasks. Parameters: Name Type Description Default task int the current task id required batch_size Optional [ int ] The dataloader batch size. If set to None, the benchmark batch size is used. Defaults to None. None verbose bool boolean indicating if the method will print additional information to the console. Defaults to False. False Returns: Name Type Description Dataloader DataLoader the constructed PyTorch dataloader. Source code in sequel/benchmarks/base_benchmark.py 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 def train_dataloader_with_memory ( self , task : int , batch_size : Optional [ int ] = None , verbose : bool = False ) -> DataLoader : \"\"\"Constructs a dataloader consisting of samples coming from the current task as well as the memory samples for all previous tasks. Args: task (int): the current task id batch_size (Optional[int], optional): The dataloader batch size. If set to None, the benchmark batch size is used. Defaults to None. verbose (bool, optional): boolean indicating if the method will print additional information to the console. Defaults to False. Returns: Dataloader: the constructed PyTorch dataloader. \"\"\" self . __check_valid_task__ ( task ) current_train_dataset = self . get_train_dataset ( task ) memory = self . get_memories ( task ) dataset = ContinualConcatDataset ([ current_train_dataset , memory ]) if verbose : logging . info ( \"Samples of train dataset: \\t {} \" . format ( len ( current_train_dataset ))) logging . info ( \"Samples of memory: \\t {} \" . format ( len ( memory ))) logging . info ( \"Samples of overall dataset: \\t {} \" . format ( len ( dataset ))) if batch_size is None : batch_size = self . batch_size return DataLoader ( dataset , batch_size , ** self . dl_kwargs ) val_dataloader ( task , batch_size = None ) Constructs the val dataloader for the current task. Parameters: Name Type Description Default task int the current task id required batch_size Optional [ int ] The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. None Returns: Name Type Description DataLoader DataLoader the constructed DataLoader Source code in sequel/benchmarks/base_benchmark.py 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 def val_dataloader ( self , task : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Constructs the val dataloader for the current task. Args: task (int): the current task id batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. Returns: DataLoader: the constructed DataLoader \"\"\" self . __check_valid_task__ ( task ) if batch_size is None : batch_size = self . eval_batch_size dataset = self . get_test_dataset ( task ) return DataLoader ( dataset , batch_size , ** self . dl_kwargs )","title":"base_benchmark"},{"location":"benchmarks/base_benchmark/#sequel.benchmarks.base_benchmark.Benchmark","text":"Base class for Continual Learning datasets (called benchmarks). All benchmarks (e.g. PermutedMNIST, SplitCifar100 etc) inherit from this class. It implements basic dataset and memory handling, such as splitting the original dataset into task datasets (train+val), constructing dataloaders which include one or multiple task datasets, dataloaders only for memory samples, dataloaders for one or multiple task datasets augmented with memory samples and more! Source code in sequel/benchmarks/base_benchmark.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 class Benchmark : \"\"\"Base class for Continual Learning datasets (called benchmarks). All benchmarks (e.g. PermutedMNIST, SplitCifar100 etc) inherit from this class. It implements basic dataset and memory handling, such as splitting the original dataset into task datasets (train+val), constructing dataloaders which include one or multiple task datasets, dataloaders only for memory samples, dataloaders for one or multiple task datasets augmented with memory samples and more! \"\"\" @staticmethod def get_default_kwargs ( config : omegaconf . ListConfig ) -> dict : \"\"\"Utility function that covers the standard arguments for the construction of a benchmark. Used implicilty by benchmark selectors. Args: config (omegaconf.ListConfig): The user-specified experiment configuration. Returns: dict: a dictionary with argument key and value pairs for the construction of the benchmark. \"\"\" kwargs = {} kwargs [ \"num_tasks\" ] = config . num_tasks kwargs [ \"batch_size\" ] = config . batch_size kwargs [ \"eval_batch_size\" ] = getattr ( config , \"eval_batch_size\" , None ) kwargs [ \"num_workers\" ] = getattr ( config , \"num_workers\" , 2 ) kwargs [ \"pin_memory\" ] = getattr ( config , \"pin_memory\" , True ) kwargs [ \"subset\" ] = getattr ( config , \"subset\" , None ) return kwargs @property def dimensions ( self ) -> List [ int ]: raise NotImplementedError @property def num_classes ( self ) -> int : raise NotImplementedError def __init__ ( self , num_tasks : int , batch_size : int , eval_batch_size : int = None , num_workers : int = 0 , pin_memory : bool = True , subset : Optional [ int ] = None , ): \"\"\"Inits the base Benchmark class. Args: num_tasks (int): the number of tasks in the benchmark. batch_size (int, optional): The train dataloader batch size. Defaults to 256. eval_batch_size (int, optional): The validation dataloader batch size. If None, `eval_batch_size` is set to `batch_size`. Defaults to None. num_workers (int, optional): Dataloader number of workers. Defaults to 0. pin_memory (bool, optional): pin_memory argument for dataloaders. Defaults to True. \"\"\" self . num_tasks = num_tasks # dataloader arguments self . batch_size = batch_size self . eval_batch_size = eval_batch_size if eval_batch_size is not None else batch_size self . num_workers = num_workers self . pin_memory = pin_memory self . subset = subset self . dl_kwargs = dict ( pin_memory = pin_memory , num_workers = num_workers ) # set up self . trains , self . tests = self . prepare_datasets () self . memory_indices = {} if subset is not None : logging . info ( \"Setting up the subset indices.\" ) assert isinstance ( subset , int ) and subset > 0 self . subset_indices = {} for k , v in self . trains . items (): indices = list ( range ( len ( v ))) random . shuffle ( indices ) self . subset_indices [ k ] = indices [: subset ] def __check_valid_task__ ( self , task : int ): if task > self . num_tasks : raise ValueError ( f \"Asked to load task { task } but the benchmark has { self . num_tasks } tasks\" ) @classmethod def from_config ( cls , config : omegaconf . OmegaConf , * args , ** kwargs ): raise NotImplementedError def prepare_datasets ( self ) -> Tuple [ ContinualDataset , ContinualDataset ]: raise NotImplementedError def get_memory_indices ( self , task : int ) -> torch . Tensor : return self . memory_indices [ task ] def set_memory_indices ( self , task : int , indices : List [ int ]) -> None : self . memory_indices [ task ] = indices def get_train_dataset ( self , task : int ) -> ContinualDataset : return self . trains [ task ] def get_test_dataset ( self , task : int ) -> ContinualDataset : return self . tests [ task ] def get_memories ( self , task : int ) -> ContinualConcatDataset : \"\"\"Returns a `ContinualConcatDataset` containing all the memory samples for tasks up to `task`. Args: task (int): The current task. The final dataset consists of all memory samples up to the specified id. Returns: ContinualConcatDataset: The constructed concatenated dataset. \"\"\" self . __check_valid_task__ ( task ) memories = [ ContinualSubsetDataset ( self . get_train_dataset ( t ), self . memory_indices [ t ]) for t in range ( 1 , task + 1 ) ] return ContinualConcatDataset ( memories ) def train_dataloader ( self , task : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Constructs the train dataloader for the current task. Args: task (int): the current task id batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. Returns: DataLoader: the constructed DataLoader \"\"\" self . __check_valid_task__ ( task ) if batch_size is None : batch_size = self . batch_size dataset = self . get_train_dataset ( task ) if self . subset : indices = self . subset_indices [ task ] logging . info ( f \"Extracting subset [ { len ( indices ) } / { len ( dataset ) } samples] for train dataset of task { task } \" ) dataset = ContinualSubsetDataset ( dataset , indices ) return DataLoader ( dataset , batch_size , shuffle = True , ** self . dl_kwargs ) def val_dataloader ( self , task : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Constructs the val dataloader for the current task. Args: task (int): the current task id batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. Returns: DataLoader: the constructed DataLoader \"\"\" self . __check_valid_task__ ( task ) if batch_size is None : batch_size = self . eval_batch_size dataset = self . get_test_dataset ( task ) return DataLoader ( dataset , batch_size , ** self . dl_kwargs ) def train_dataloader_subset ( self , task : int , subset_size : Optional [ int ] = None , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Constructs a dataloader containing a random subset from the dataset indexed by id `task`. Args: task (int): the dataset task id. batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. Returns: DataLoader: the constructed dataloader. \"\"\" self . __check_valid_task__ ( task ) if batch_size is None : batch_size = self . batch_size if subset_size is None : assert self . subset is not None subset_size = self . subset train_dataset = self . get_train_dataset ( task ) indices = torch . randperm ( len ( train_dataset ))[: subset_size ] # sampler = RandomSampler(train_dataset, replacement=True, num_samples=subset_size) train_dataset = ContinualSubsetDataset ( train_dataset , indices = indices ) return DataLoader ( train_dataset , batch_size , ** self . dl_kwargs ) def train_dataloader_joint ( self , task : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Constructs the train dataloader for the current task. Args: task (int): the current task id batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. Returns: DataLoader: the constructed DataLoader \"\"\" self . __check_valid_task__ ( task ) if batch_size is None : batch_size = self . batch_size dataset = ContinualConcatDataset ([ self . get_train_dataset ( t ) for t in range ( 1 , task + 1 )]) return DataLoader ( dataset , batch_size , shuffle = True , ** self . dl_kwargs ) def memory_dataloader ( self , task : int , batch_size : Optional [ int ] = None , return_infinite_stream : bool = True ) -> DataLoader : self . __check_valid_task__ ( task ) dataset = self . get_memories ( task ) if batch_size is None : batch_size = self . batch_size if batch_size > len ( dataset ): batch_size = len ( dataset ) if return_infinite_stream : sampler = RandomSampler ( dataset , replacement = True , num_samples = 100 ** 100 ) return DataLoader ( dataset , batch_size , shuffle = False , sampler = sampler , ** self . dl_kwargs ) else : return DataLoader ( dataset , batch_size , shuffle = True , ** self . dl_kwargs ) def train_dataloader_with_memory ( self , task : int , batch_size : Optional [ int ] = None , verbose : bool = False ) -> DataLoader : \"\"\"Constructs a dataloader consisting of samples coming from the current task as well as the memory samples for all previous tasks. Args: task (int): the current task id batch_size (Optional[int], optional): The dataloader batch size. If set to None, the benchmark batch size is used. Defaults to None. verbose (bool, optional): boolean indicating if the method will print additional information to the console. Defaults to False. Returns: Dataloader: the constructed PyTorch dataloader. \"\"\" self . __check_valid_task__ ( task ) current_train_dataset = self . get_train_dataset ( task ) memory = self . get_memories ( task ) dataset = ContinualConcatDataset ([ current_train_dataset , memory ]) if verbose : logging . info ( \"Samples of train dataset: \\t {} \" . format ( len ( current_train_dataset ))) logging . info ( \"Samples of memory: \\t {} \" . format ( len ( memory ))) logging . info ( \"Samples of overall dataset: \\t {} \" . format ( len ( dataset ))) if batch_size is None : batch_size = self . batch_size return DataLoader ( dataset , batch_size , ** self . dl_kwargs )","title":"Benchmark"},{"location":"benchmarks/base_benchmark/#sequel.benchmarks.base_benchmark.Benchmark.__init__","text":"Inits the base Benchmark class. Parameters: Name Type Description Default num_tasks int the number of tasks in the benchmark. required batch_size int The train dataloader batch size. Defaults to 256. required eval_batch_size int The validation dataloader batch size. If None, eval_batch_size is set to batch_size . Defaults to None. None num_workers int Dataloader number of workers. Defaults to 0. 0 pin_memory bool pin_memory argument for dataloaders. Defaults to True. True Source code in sequel/benchmarks/base_benchmark.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 def __init__ ( self , num_tasks : int , batch_size : int , eval_batch_size : int = None , num_workers : int = 0 , pin_memory : bool = True , subset : Optional [ int ] = None , ): \"\"\"Inits the base Benchmark class. Args: num_tasks (int): the number of tasks in the benchmark. batch_size (int, optional): The train dataloader batch size. Defaults to 256. eval_batch_size (int, optional): The validation dataloader batch size. If None, `eval_batch_size` is set to `batch_size`. Defaults to None. num_workers (int, optional): Dataloader number of workers. Defaults to 0. pin_memory (bool, optional): pin_memory argument for dataloaders. Defaults to True. \"\"\" self . num_tasks = num_tasks # dataloader arguments self . batch_size = batch_size self . eval_batch_size = eval_batch_size if eval_batch_size is not None else batch_size self . num_workers = num_workers self . pin_memory = pin_memory self . subset = subset self . dl_kwargs = dict ( pin_memory = pin_memory , num_workers = num_workers ) # set up self . trains , self . tests = self . prepare_datasets () self . memory_indices = {} if subset is not None : logging . info ( \"Setting up the subset indices.\" ) assert isinstance ( subset , int ) and subset > 0 self . subset_indices = {} for k , v in self . trains . items (): indices = list ( range ( len ( v ))) random . shuffle ( indices ) self . subset_indices [ k ] = indices [: subset ]","title":"__init__()"},{"location":"benchmarks/base_benchmark/#sequel.benchmarks.base_benchmark.Benchmark.get_default_kwargs","text":"Utility function that covers the standard arguments for the construction of a benchmark. Used implicilty by benchmark selectors. Parameters: Name Type Description Default config omegaconf . ListConfig The user-specified experiment configuration. required Returns: Name Type Description dict dict a dictionary with argument key and value pairs for the construction of the benchmark. Source code in sequel/benchmarks/base_benchmark.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 @staticmethod def get_default_kwargs ( config : omegaconf . ListConfig ) -> dict : \"\"\"Utility function that covers the standard arguments for the construction of a benchmark. Used implicilty by benchmark selectors. Args: config (omegaconf.ListConfig): The user-specified experiment configuration. Returns: dict: a dictionary with argument key and value pairs for the construction of the benchmark. \"\"\" kwargs = {} kwargs [ \"num_tasks\" ] = config . num_tasks kwargs [ \"batch_size\" ] = config . batch_size kwargs [ \"eval_batch_size\" ] = getattr ( config , \"eval_batch_size\" , None ) kwargs [ \"num_workers\" ] = getattr ( config , \"num_workers\" , 2 ) kwargs [ \"pin_memory\" ] = getattr ( config , \"pin_memory\" , True ) kwargs [ \"subset\" ] = getattr ( config , \"subset\" , None ) return kwargs","title":"get_default_kwargs()"},{"location":"benchmarks/base_benchmark/#sequel.benchmarks.base_benchmark.Benchmark.get_memories","text":"Returns a ContinualConcatDataset containing all the memory samples for tasks up to task . Parameters: Name Type Description Default task int The current task. The final dataset consists of all memory samples up to the specified id. required Returns: Name Type Description ContinualConcatDataset ContinualConcatDataset The constructed concatenated dataset. Source code in sequel/benchmarks/base_benchmark.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 def get_memories ( self , task : int ) -> ContinualConcatDataset : \"\"\"Returns a `ContinualConcatDataset` containing all the memory samples for tasks up to `task`. Args: task (int): The current task. The final dataset consists of all memory samples up to the specified id. Returns: ContinualConcatDataset: The constructed concatenated dataset. \"\"\" self . __check_valid_task__ ( task ) memories = [ ContinualSubsetDataset ( self . get_train_dataset ( t ), self . memory_indices [ t ]) for t in range ( 1 , task + 1 ) ] return ContinualConcatDataset ( memories )","title":"get_memories()"},{"location":"benchmarks/base_benchmark/#sequel.benchmarks.base_benchmark.Benchmark.train_dataloader","text":"Constructs the train dataloader for the current task. Parameters: Name Type Description Default task int the current task id required batch_size Optional [ int ] The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. None Returns: Name Type Description DataLoader DataLoader the constructed DataLoader Source code in sequel/benchmarks/base_benchmark.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 def train_dataloader ( self , task : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Constructs the train dataloader for the current task. Args: task (int): the current task id batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. Returns: DataLoader: the constructed DataLoader \"\"\" self . __check_valid_task__ ( task ) if batch_size is None : batch_size = self . batch_size dataset = self . get_train_dataset ( task ) if self . subset : indices = self . subset_indices [ task ] logging . info ( f \"Extracting subset [ { len ( indices ) } / { len ( dataset ) } samples] for train dataset of task { task } \" ) dataset = ContinualSubsetDataset ( dataset , indices ) return DataLoader ( dataset , batch_size , shuffle = True , ** self . dl_kwargs )","title":"train_dataloader()"},{"location":"benchmarks/base_benchmark/#sequel.benchmarks.base_benchmark.Benchmark.train_dataloader_joint","text":"Constructs the train dataloader for the current task. Parameters: Name Type Description Default task int the current task id required batch_size Optional [ int ] The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. None Returns: Name Type Description DataLoader DataLoader the constructed DataLoader Source code in sequel/benchmarks/base_benchmark.py 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 def train_dataloader_joint ( self , task : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Constructs the train dataloader for the current task. Args: task (int): the current task id batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. Returns: DataLoader: the constructed DataLoader \"\"\" self . __check_valid_task__ ( task ) if batch_size is None : batch_size = self . batch_size dataset = ContinualConcatDataset ([ self . get_train_dataset ( t ) for t in range ( 1 , task + 1 )]) return DataLoader ( dataset , batch_size , shuffle = True , ** self . dl_kwargs )","title":"train_dataloader_joint()"},{"location":"benchmarks/base_benchmark/#sequel.benchmarks.base_benchmark.Benchmark.train_dataloader_subset","text":"Constructs a dataloader containing a random subset from the dataset indexed by id task . Parameters: Name Type Description Default task int the dataset task id. required batch_size Optional [ int ] The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. None Returns: Name Type Description DataLoader DataLoader the constructed dataloader. Source code in sequel/benchmarks/base_benchmark.py 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 def train_dataloader_subset ( self , task : int , subset_size : Optional [ int ] = None , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Constructs a dataloader containing a random subset from the dataset indexed by id `task`. Args: task (int): the dataset task id. batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. Returns: DataLoader: the constructed dataloader. \"\"\" self . __check_valid_task__ ( task ) if batch_size is None : batch_size = self . batch_size if subset_size is None : assert self . subset is not None subset_size = self . subset train_dataset = self . get_train_dataset ( task ) indices = torch . randperm ( len ( train_dataset ))[: subset_size ] # sampler = RandomSampler(train_dataset, replacement=True, num_samples=subset_size) train_dataset = ContinualSubsetDataset ( train_dataset , indices = indices ) return DataLoader ( train_dataset , batch_size , ** self . dl_kwargs )","title":"train_dataloader_subset()"},{"location":"benchmarks/base_benchmark/#sequel.benchmarks.base_benchmark.Benchmark.train_dataloader_with_memory","text":"Constructs a dataloader consisting of samples coming from the current task as well as the memory samples for all previous tasks. Parameters: Name Type Description Default task int the current task id required batch_size Optional [ int ] The dataloader batch size. If set to None, the benchmark batch size is used. Defaults to None. None verbose bool boolean indicating if the method will print additional information to the console. Defaults to False. False Returns: Name Type Description Dataloader DataLoader the constructed PyTorch dataloader. Source code in sequel/benchmarks/base_benchmark.py 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 def train_dataloader_with_memory ( self , task : int , batch_size : Optional [ int ] = None , verbose : bool = False ) -> DataLoader : \"\"\"Constructs a dataloader consisting of samples coming from the current task as well as the memory samples for all previous tasks. Args: task (int): the current task id batch_size (Optional[int], optional): The dataloader batch size. If set to None, the benchmark batch size is used. Defaults to None. verbose (bool, optional): boolean indicating if the method will print additional information to the console. Defaults to False. Returns: Dataloader: the constructed PyTorch dataloader. \"\"\" self . __check_valid_task__ ( task ) current_train_dataset = self . get_train_dataset ( task ) memory = self . get_memories ( task ) dataset = ContinualConcatDataset ([ current_train_dataset , memory ]) if verbose : logging . info ( \"Samples of train dataset: \\t {} \" . format ( len ( current_train_dataset ))) logging . info ( \"Samples of memory: \\t {} \" . format ( len ( memory ))) logging . info ( \"Samples of overall dataset: \\t {} \" . format ( len ( dataset ))) if batch_size is None : batch_size = self . batch_size return DataLoader ( dataset , batch_size , ** self . dl_kwargs )","title":"train_dataloader_with_memory()"},{"location":"benchmarks/base_benchmark/#sequel.benchmarks.base_benchmark.Benchmark.val_dataloader","text":"Constructs the val dataloader for the current task. Parameters: Name Type Description Default task int the current task id required batch_size Optional [ int ] The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. None Returns: Name Type Description DataLoader DataLoader the constructed DataLoader Source code in sequel/benchmarks/base_benchmark.py 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 def val_dataloader ( self , task : int , batch_size : Optional [ int ] = None ) -> DataLoader : \"\"\"Constructs the val dataloader for the current task. Args: task (int): the current task id batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None. Returns: DataLoader: the constructed DataLoader \"\"\" self . __check_valid_task__ ( task ) if batch_size is None : batch_size = self . eval_batch_size dataset = self . get_test_dataset ( task ) return DataLoader ( dataset , batch_size , ** self . dl_kwargs )","title":"val_dataloader()"},{"location":"benchmarks/cifar/","text":"SplitCIFAR Bases: Benchmark SplitCIFAR benchmarks. Source code in sequel/benchmarks/cifar.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 class SplitCIFAR ( Benchmark ): \"\"\"SplitCIFAR benchmarks.\"\"\" @property def num_classes ( self ) -> int : return 100 if self . is_cifar_100 else 10 @property def MEAN ( self ): if self . is_cifar_100 : return CIFAR100_MEAN else : return CIFAR10_MEAN @property def STD ( self ): if self . is_cifar_100 : return CIFAR100_STD else : return CIFAR10_STD @property def dimensions ( self ) -> List [ int ]: return [ 3 , 32 , 32 ] @property def num_classes ( self ): num_classes = 100 if self . is_cifar_100 else 10 return num_classes @property def classes_per_task ( self ): assert self . num_classes % self . num_tasks == 0 return self . num_classes // self . num_tasks def __init__ ( self , num_tasks : int , batch_size : int , fixed_class_order : Optional [ List [ int ]] = None , is_cifar_100 : bool = True , eval_batch_size : int = None , num_workers : int = 0 , pin_memory : bool = True , subset : Optional [ int ] = None , ): \"\"\"Inits the SplitCIFAR100/100 class. The `is_cifar100` boolean flag denotes which dataset is instantiated. Args: num_tasks (int): the number of tasks in the benchmark. Usually 20 for SplitCIFAR100 and 5 for SplitCIFAR10. Must be divisible by the number of classes. batch_size (int, optional): The train dataloader batch size. Defaults to 256. fixed_class_order (Optional[List[int]], optional): A list of integers denoting a custom fixed_class_order. If None, the alphabetical order is used. Defaults to None. is_cifar_100 (bool, optional): Boolean denoting whether SplitCIFAR100 or SplitCIFAR10 is selected. Defaults to True. eval_batch_size (int, optional): The validation dataloader batch size. If None, `eval_batch_size` is set to `batch_size`. Defaults to None. num_workers (int, optional): Dataloader number of workers. Defaults to 0. pin_memory (bool, optional): pin_memory argument for dataloaders. Defaults to True. \"\"\" self . is_cifar_100 = is_cifar_100 if fixed_class_order is None : fixed_class_order = list ( range ( self . num_classes )) assert ( torch . tensor ( fixed_class_order ) . sort ()[ 0 ] == torch . arange ( 0 , self . num_classes ) ) . all (), \"The fixed_class_order argument muct contain exactly once all integers from 0 to (num_classes-1).\" self . fixed_class_order = fixed_class_order super () . __init__ ( num_tasks = num_tasks , batch_size = batch_size , eval_batch_size = eval_batch_size , num_workers = num_workers , pin_memory = pin_memory , subset = subset , ) def prepare_datasets ( self ) -> Tuple [ ContinualDataset , ContinualDataset ]: transform = T . Compose ([ T . ToTensor (), T . Normalize ( self . MEAN , self . STD )]) CIFAR_dataset = torchvision . datasets . CIFAR100 if self . is_cifar_100 else torchvision . datasets . CIFAR10 self . cifar_train = CIFAR_dataset ( DEFAULT_DATASET_DIR , train = True , download = True , transform = transform ) self . cifar_test = CIFAR_dataset ( DEFAULT_DATASET_DIR , train = False , download = True , transform = transform ) self . trains , self . tests = {}, {} for t in range ( 1 , self . num_tasks + 1 ): self . trains [ t ] = SplitDataset ( t , self . classes_per_task , self . cifar_train , self . fixed_class_order ) self . tests [ t ] = SplitDataset ( t , self . classes_per_task , self . cifar_test , self . fixed_class_order ) return self . trains , self . tests @classmethod def from_config ( cls , config ): # breakpoint() kwargs = cls . get_default_kwargs ( config ) kwargs [ \"is_cifar_100\" ] = \"100\" in config . name kwargs [ \"fixed_class_order\" ] = getattr ( config , \"fixed_class_order\" , None ) return cls ( ** kwargs ) def __repr__ ( self ) -> str : return f \"SplitCIFAR { self . num_classes } (num_tasks= { self . num_tasks } , batch_size= { self . batch_size } )\" __init__ ( num_tasks , batch_size , fixed_class_order = None , is_cifar_100 = True , eval_batch_size = None , num_workers = 0 , pin_memory = True , subset = None ) Inits the SplitCIFAR100/100 class. The is_cifar100 boolean flag denotes which dataset is instantiated. Parameters: Name Type Description Default num_tasks int the number of tasks in the benchmark. Usually 20 for SplitCIFAR100 and 5 for SplitCIFAR10. Must be divisible by the number of classes. required batch_size int The train dataloader batch size. Defaults to 256. required fixed_class_order Optional [ List [ int ]] A list of integers denoting a custom fixed_class_order. If None, the alphabetical order is used. Defaults to None. None is_cifar_100 bool Boolean denoting whether SplitCIFAR100 or SplitCIFAR10 is selected. Defaults to True. True eval_batch_size int The validation dataloader batch size. If None, eval_batch_size is set to batch_size . Defaults to None. None num_workers int Dataloader number of workers. Defaults to 0. 0 pin_memory bool pin_memory argument for dataloaders. Defaults to True. True Source code in sequel/benchmarks/cifar.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 def __init__ ( self , num_tasks : int , batch_size : int , fixed_class_order : Optional [ List [ int ]] = None , is_cifar_100 : bool = True , eval_batch_size : int = None , num_workers : int = 0 , pin_memory : bool = True , subset : Optional [ int ] = None , ): \"\"\"Inits the SplitCIFAR100/100 class. The `is_cifar100` boolean flag denotes which dataset is instantiated. Args: num_tasks (int): the number of tasks in the benchmark. Usually 20 for SplitCIFAR100 and 5 for SplitCIFAR10. Must be divisible by the number of classes. batch_size (int, optional): The train dataloader batch size. Defaults to 256. fixed_class_order (Optional[List[int]], optional): A list of integers denoting a custom fixed_class_order. If None, the alphabetical order is used. Defaults to None. is_cifar_100 (bool, optional): Boolean denoting whether SplitCIFAR100 or SplitCIFAR10 is selected. Defaults to True. eval_batch_size (int, optional): The validation dataloader batch size. If None, `eval_batch_size` is set to `batch_size`. Defaults to None. num_workers (int, optional): Dataloader number of workers. Defaults to 0. pin_memory (bool, optional): pin_memory argument for dataloaders. Defaults to True. \"\"\" self . is_cifar_100 = is_cifar_100 if fixed_class_order is None : fixed_class_order = list ( range ( self . num_classes )) assert ( torch . tensor ( fixed_class_order ) . sort ()[ 0 ] == torch . arange ( 0 , self . num_classes ) ) . all (), \"The fixed_class_order argument muct contain exactly once all integers from 0 to (num_classes-1).\" self . fixed_class_order = fixed_class_order super () . __init__ ( num_tasks = num_tasks , batch_size = batch_size , eval_batch_size = eval_batch_size , num_workers = num_workers , pin_memory = pin_memory , subset = subset , ) SplitCIFAR10 Bases: SplitCIFAR Source code in sequel/benchmarks/cifar.py 120 121 122 123 124 125 126 127 128 class SplitCIFAR10 ( SplitCIFAR ): def __init__ ( self , is_cifar_100 = False , * args , ** kwargs ): \"\"\"Helper class for SplitCIFAR10. Inherits from SplitCIFAR. Look at the parent class for a description of the class arguments. Args: is_cifar_100 (bool, optional): Set to False. \"\"\" super () . __init__ ( is_cifar_100 = is_cifar_100 , * args , ** kwargs ) __init__ ( is_cifar_100 = False , * args , ** kwargs ) Helper class for SplitCIFAR10. Inherits from SplitCIFAR. Look at the parent class for a description of the class arguments. Parameters: Name Type Description Default is_cifar_100 bool Set to False. False Source code in sequel/benchmarks/cifar.py 121 122 123 124 125 126 127 128 def __init__ ( self , is_cifar_100 = False , * args , ** kwargs ): \"\"\"Helper class for SplitCIFAR10. Inherits from SplitCIFAR. Look at the parent class for a description of the class arguments. Args: is_cifar_100 (bool, optional): Set to False. \"\"\" super () . __init__ ( is_cifar_100 = is_cifar_100 , * args , ** kwargs ) SplitCIFAR100 Bases: SplitCIFAR Source code in sequel/benchmarks/cifar.py 131 132 133 134 135 136 137 138 139 class SplitCIFAR100 ( SplitCIFAR ): def __init__ ( self , is_cifar_100 = True , * args , ** kwargs ): \"\"\"Helper class for SplitCIFAR100. Inherits from SplitCIFAR. Look at the parent class for a description of the class arguments. Args: is_cifar_100 (bool, optional): Set to True. \"\"\" super () . __init__ ( is_cifar_100 = is_cifar_100 , * args , ** kwargs ) __init__ ( is_cifar_100 = True , * args , ** kwargs ) Helper class for SplitCIFAR100. Inherits from SplitCIFAR. Look at the parent class for a description of the class arguments. Parameters: Name Type Description Default is_cifar_100 bool Set to True. True Source code in sequel/benchmarks/cifar.py 132 133 134 135 136 137 138 139 def __init__ ( self , is_cifar_100 = True , * args , ** kwargs ): \"\"\"Helper class for SplitCIFAR100. Inherits from SplitCIFAR. Look at the parent class for a description of the class arguments. Args: is_cifar_100 (bool, optional): Set to True. \"\"\" super () . __init__ ( is_cifar_100 = is_cifar_100 , * args , ** kwargs )","title":"CIFAR"},{"location":"benchmarks/cifar/#sequel.benchmarks.cifar.SplitCIFAR","text":"Bases: Benchmark SplitCIFAR benchmarks. Source code in sequel/benchmarks/cifar.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 class SplitCIFAR ( Benchmark ): \"\"\"SplitCIFAR benchmarks.\"\"\" @property def num_classes ( self ) -> int : return 100 if self . is_cifar_100 else 10 @property def MEAN ( self ): if self . is_cifar_100 : return CIFAR100_MEAN else : return CIFAR10_MEAN @property def STD ( self ): if self . is_cifar_100 : return CIFAR100_STD else : return CIFAR10_STD @property def dimensions ( self ) -> List [ int ]: return [ 3 , 32 , 32 ] @property def num_classes ( self ): num_classes = 100 if self . is_cifar_100 else 10 return num_classes @property def classes_per_task ( self ): assert self . num_classes % self . num_tasks == 0 return self . num_classes // self . num_tasks def __init__ ( self , num_tasks : int , batch_size : int , fixed_class_order : Optional [ List [ int ]] = None , is_cifar_100 : bool = True , eval_batch_size : int = None , num_workers : int = 0 , pin_memory : bool = True , subset : Optional [ int ] = None , ): \"\"\"Inits the SplitCIFAR100/100 class. The `is_cifar100` boolean flag denotes which dataset is instantiated. Args: num_tasks (int): the number of tasks in the benchmark. Usually 20 for SplitCIFAR100 and 5 for SplitCIFAR10. Must be divisible by the number of classes. batch_size (int, optional): The train dataloader batch size. Defaults to 256. fixed_class_order (Optional[List[int]], optional): A list of integers denoting a custom fixed_class_order. If None, the alphabetical order is used. Defaults to None. is_cifar_100 (bool, optional): Boolean denoting whether SplitCIFAR100 or SplitCIFAR10 is selected. Defaults to True. eval_batch_size (int, optional): The validation dataloader batch size. If None, `eval_batch_size` is set to `batch_size`. Defaults to None. num_workers (int, optional): Dataloader number of workers. Defaults to 0. pin_memory (bool, optional): pin_memory argument for dataloaders. Defaults to True. \"\"\" self . is_cifar_100 = is_cifar_100 if fixed_class_order is None : fixed_class_order = list ( range ( self . num_classes )) assert ( torch . tensor ( fixed_class_order ) . sort ()[ 0 ] == torch . arange ( 0 , self . num_classes ) ) . all (), \"The fixed_class_order argument muct contain exactly once all integers from 0 to (num_classes-1).\" self . fixed_class_order = fixed_class_order super () . __init__ ( num_tasks = num_tasks , batch_size = batch_size , eval_batch_size = eval_batch_size , num_workers = num_workers , pin_memory = pin_memory , subset = subset , ) def prepare_datasets ( self ) -> Tuple [ ContinualDataset , ContinualDataset ]: transform = T . Compose ([ T . ToTensor (), T . Normalize ( self . MEAN , self . STD )]) CIFAR_dataset = torchvision . datasets . CIFAR100 if self . is_cifar_100 else torchvision . datasets . CIFAR10 self . cifar_train = CIFAR_dataset ( DEFAULT_DATASET_DIR , train = True , download = True , transform = transform ) self . cifar_test = CIFAR_dataset ( DEFAULT_DATASET_DIR , train = False , download = True , transform = transform ) self . trains , self . tests = {}, {} for t in range ( 1 , self . num_tasks + 1 ): self . trains [ t ] = SplitDataset ( t , self . classes_per_task , self . cifar_train , self . fixed_class_order ) self . tests [ t ] = SplitDataset ( t , self . classes_per_task , self . cifar_test , self . fixed_class_order ) return self . trains , self . tests @classmethod def from_config ( cls , config ): # breakpoint() kwargs = cls . get_default_kwargs ( config ) kwargs [ \"is_cifar_100\" ] = \"100\" in config . name kwargs [ \"fixed_class_order\" ] = getattr ( config , \"fixed_class_order\" , None ) return cls ( ** kwargs ) def __repr__ ( self ) -> str : return f \"SplitCIFAR { self . num_classes } (num_tasks= { self . num_tasks } , batch_size= { self . batch_size } )\"","title":"SplitCIFAR"},{"location":"benchmarks/cifar/#sequel.benchmarks.cifar.SplitCIFAR.__init__","text":"Inits the SplitCIFAR100/100 class. The is_cifar100 boolean flag denotes which dataset is instantiated. Parameters: Name Type Description Default num_tasks int the number of tasks in the benchmark. Usually 20 for SplitCIFAR100 and 5 for SplitCIFAR10. Must be divisible by the number of classes. required batch_size int The train dataloader batch size. Defaults to 256. required fixed_class_order Optional [ List [ int ]] A list of integers denoting a custom fixed_class_order. If None, the alphabetical order is used. Defaults to None. None is_cifar_100 bool Boolean denoting whether SplitCIFAR100 or SplitCIFAR10 is selected. Defaults to True. True eval_batch_size int The validation dataloader batch size. If None, eval_batch_size is set to batch_size . Defaults to None. None num_workers int Dataloader number of workers. Defaults to 0. 0 pin_memory bool pin_memory argument for dataloaders. Defaults to True. True Source code in sequel/benchmarks/cifar.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 def __init__ ( self , num_tasks : int , batch_size : int , fixed_class_order : Optional [ List [ int ]] = None , is_cifar_100 : bool = True , eval_batch_size : int = None , num_workers : int = 0 , pin_memory : bool = True , subset : Optional [ int ] = None , ): \"\"\"Inits the SplitCIFAR100/100 class. The `is_cifar100` boolean flag denotes which dataset is instantiated. Args: num_tasks (int): the number of tasks in the benchmark. Usually 20 for SplitCIFAR100 and 5 for SplitCIFAR10. Must be divisible by the number of classes. batch_size (int, optional): The train dataloader batch size. Defaults to 256. fixed_class_order (Optional[List[int]], optional): A list of integers denoting a custom fixed_class_order. If None, the alphabetical order is used. Defaults to None. is_cifar_100 (bool, optional): Boolean denoting whether SplitCIFAR100 or SplitCIFAR10 is selected. Defaults to True. eval_batch_size (int, optional): The validation dataloader batch size. If None, `eval_batch_size` is set to `batch_size`. Defaults to None. num_workers (int, optional): Dataloader number of workers. Defaults to 0. pin_memory (bool, optional): pin_memory argument for dataloaders. Defaults to True. \"\"\" self . is_cifar_100 = is_cifar_100 if fixed_class_order is None : fixed_class_order = list ( range ( self . num_classes )) assert ( torch . tensor ( fixed_class_order ) . sort ()[ 0 ] == torch . arange ( 0 , self . num_classes ) ) . all (), \"The fixed_class_order argument muct contain exactly once all integers from 0 to (num_classes-1).\" self . fixed_class_order = fixed_class_order super () . __init__ ( num_tasks = num_tasks , batch_size = batch_size , eval_batch_size = eval_batch_size , num_workers = num_workers , pin_memory = pin_memory , subset = subset , )","title":"__init__()"},{"location":"benchmarks/cifar/#sequel.benchmarks.cifar.SplitCIFAR10","text":"Bases: SplitCIFAR Source code in sequel/benchmarks/cifar.py 120 121 122 123 124 125 126 127 128 class SplitCIFAR10 ( SplitCIFAR ): def __init__ ( self , is_cifar_100 = False , * args , ** kwargs ): \"\"\"Helper class for SplitCIFAR10. Inherits from SplitCIFAR. Look at the parent class for a description of the class arguments. Args: is_cifar_100 (bool, optional): Set to False. \"\"\" super () . __init__ ( is_cifar_100 = is_cifar_100 , * args , ** kwargs )","title":"SplitCIFAR10"},{"location":"benchmarks/cifar/#sequel.benchmarks.cifar.SplitCIFAR10.__init__","text":"Helper class for SplitCIFAR10. Inherits from SplitCIFAR. Look at the parent class for a description of the class arguments. Parameters: Name Type Description Default is_cifar_100 bool Set to False. False Source code in sequel/benchmarks/cifar.py 121 122 123 124 125 126 127 128 def __init__ ( self , is_cifar_100 = False , * args , ** kwargs ): \"\"\"Helper class for SplitCIFAR10. Inherits from SplitCIFAR. Look at the parent class for a description of the class arguments. Args: is_cifar_100 (bool, optional): Set to False. \"\"\" super () . __init__ ( is_cifar_100 = is_cifar_100 , * args , ** kwargs )","title":"__init__()"},{"location":"benchmarks/cifar/#sequel.benchmarks.cifar.SplitCIFAR100","text":"Bases: SplitCIFAR Source code in sequel/benchmarks/cifar.py 131 132 133 134 135 136 137 138 139 class SplitCIFAR100 ( SplitCIFAR ): def __init__ ( self , is_cifar_100 = True , * args , ** kwargs ): \"\"\"Helper class for SplitCIFAR100. Inherits from SplitCIFAR. Look at the parent class for a description of the class arguments. Args: is_cifar_100 (bool, optional): Set to True. \"\"\" super () . __init__ ( is_cifar_100 = is_cifar_100 , * args , ** kwargs )","title":"SplitCIFAR100"},{"location":"benchmarks/cifar/#sequel.benchmarks.cifar.SplitCIFAR100.__init__","text":"Helper class for SplitCIFAR100. Inherits from SplitCIFAR. Look at the parent class for a description of the class arguments. Parameters: Name Type Description Default is_cifar_100 bool Set to True. True Source code in sequel/benchmarks/cifar.py 132 133 134 135 136 137 138 139 def __init__ ( self , is_cifar_100 = True , * args , ** kwargs ): \"\"\"Helper class for SplitCIFAR100. Inherits from SplitCIFAR. Look at the parent class for a description of the class arguments. Args: is_cifar_100 (bool, optional): Set to True. \"\"\" super () . __init__ ( is_cifar_100 = is_cifar_100 , * args , ** kwargs )","title":"__init__()"},{"location":"benchmarks/memory/","text":"MemoryMechanism Implements the memory handling/manipulation for continual learning algorithms. Source code in sequel/benchmarks/memory.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 class MemoryMechanism : \"\"\"Implements the memory handling/manipulation for continual learning algorithms.\"\"\" def __init__ ( self , per_task_memory_samples : int , groupby : str = \"class\" ): logging . info ( \"Initializing MemoryCallback\" ) self . per_task_memory_samples = per_task_memory_samples if groupby not in ( \"task\" , \"class\" ): raise ValueError ( \"Only class and task are supported as options for groupby argument.\" ) self . groupby = groupby def update_memory ( self , algo : \"BaseAlgorithm\" ): \"\"\"Updates the memory by selecting `per_task_memory_samples` samples from the current dataset. The selection process is defined by the `groupby` instance attribute. Args: algo (BaseAlgorithm): the algorithm instance. \"\"\" logging . info ( \"Setting memory indices for task {} \" . format ( algo . task_counter )) task = algo . task_counter dataset = algo . benchmark . get_train_dataset ( task ) if self . groupby == \"class\" : memory_indices = MemoryMechanism . sample_uniform_class_indices ( dataset , self . per_task_memory_samples ) else : memory_indices = MemoryMechanism . sample_uniform_task_indices ( dataset , self . per_task_memory_samples ) algo . benchmark . set_memory_indices ( task , memory_indices ) def update_memory_ ( self , benchmark , task ): \"\"\"Updates the memory by selecting `per_task_memory_samples` samples from the current dataset. The selection process is defined by the `groupby` instance attribute. \"\"\" logging . info ( \"Setting memory indices for task {} \" . format ( task )) dataset = benchmark . get_train_dataset ( task ) if self . groupby == \"class\" : memory_indices = MemoryMechanism . sample_uniform_class_indices ( dataset , self . per_task_memory_samples ) else : memory_indices = MemoryMechanism . sample_uniform_task_indices ( dataset , self . per_task_memory_samples ) benchmark . set_memory_indices ( task , memory_indices ) @staticmethod def sample_uniform_task_indices ( dataset : ContinualDataset , num_samples : int ) -> List [ int ]: \"\"\"Selects a specified number of indices uniformly at random. Args: dataset (ContinualDataset): The dataset that is sampled. num_samples (int): the number of samples to draw. Returns: List[int]: The selected dataset indices. \"\"\" to_remove = len ( dataset ) - num_samples dataset , _ = random_split ( dataset , [ num_samples , to_remove ]) return dataset . indices @staticmethod def sample_uniform_class_indices ( dataset : ContinualDataset , num_samples : int ) -> List [ int ]: \"\"\"Selects an approximately equal (ties broken arbitrarily) number of indices corresponding to each class from the input dataset. Each dataset yields ~num_samples // num_classes samples. Args: dataset (ContinualDataset): The dataset that is sampled. num_samples (int): the number of samples to draw. Returns: List[int]: The selected dataset indices. \"\"\" target_classes = dataset . targets . clone () . detach () . numpy () classes = np . unique ( target_classes ) . tolist () num_classes = len ( classes ) num_examples_per_class = MemoryMechanism . pack_bins_uniformly ( num_samples * num_classes , num_classes ) class_indices = [] for class_id , cls_number in enumerate ( classes ): candidates = np . array ([ i for i , t in enumerate ( target_classes ) if t == cls_number ]) np . random . shuffle ( candidates ) selected_indices = candidates [: num_examples_per_class [ class_id ]] class_indices += list ( selected_indices ) return class_indices @staticmethod def pack_bins_uniformly ( num_samples : int , num_categories : int ) -> List [ int ]: \"\"\"Splits an integer to a specified number of bins so that bins have approximately the same size. If `num_categories` is not a divisor of `num_samples`, the reminder is split an equal number of bins selectrd uniformly at random. Args: num_samples (int): The number of items. num_categories (int): the number of bins. Returns: List[int]: a list containing the number of items corresponding to each bin. \"\"\" num_samples_per_cat = np . ones ( num_categories ) * num_samples // num_categories remaining = num_samples % num_categories correction_vector = np . array ([ 0 ] * ( num_categories - remaining ) + [ 1 ] * remaining ) np . random . shuffle ( correction_vector ) num_samples_per_cat += correction_vector return num_samples_per_cat . astype ( \"int\" ) . tolist () pack_bins_uniformly ( num_samples , num_categories ) staticmethod Splits an integer to a specified number of bins so that bins have approximately the same size. If num_categories is not a divisor of num_samples , the reminder is split an equal number of bins selectrd uniformly at random. Parameters: Name Type Description Default num_samples int The number of items. required num_categories int the number of bins. required Returns: Type Description List [ int ] List[int]: a list containing the number of items corresponding to each bin. Source code in sequel/benchmarks/memory.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 @staticmethod def pack_bins_uniformly ( num_samples : int , num_categories : int ) -> List [ int ]: \"\"\"Splits an integer to a specified number of bins so that bins have approximately the same size. If `num_categories` is not a divisor of `num_samples`, the reminder is split an equal number of bins selectrd uniformly at random. Args: num_samples (int): The number of items. num_categories (int): the number of bins. Returns: List[int]: a list containing the number of items corresponding to each bin. \"\"\" num_samples_per_cat = np . ones ( num_categories ) * num_samples // num_categories remaining = num_samples % num_categories correction_vector = np . array ([ 0 ] * ( num_categories - remaining ) + [ 1 ] * remaining ) np . random . shuffle ( correction_vector ) num_samples_per_cat += correction_vector return num_samples_per_cat . astype ( \"int\" ) . tolist () sample_uniform_class_indices ( dataset , num_samples ) staticmethod Selects an approximately equal (ties broken arbitrarily) number of indices corresponding to each class from the input dataset. Each dataset yields ~num_samples // num_classes samples. Parameters: Name Type Description Default dataset ContinualDataset The dataset that is sampled. required num_samples int the number of samples to draw. required Returns: Type Description List [ int ] List[int]: The selected dataset indices. Source code in sequel/benchmarks/memory.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 @staticmethod def sample_uniform_class_indices ( dataset : ContinualDataset , num_samples : int ) -> List [ int ]: \"\"\"Selects an approximately equal (ties broken arbitrarily) number of indices corresponding to each class from the input dataset. Each dataset yields ~num_samples // num_classes samples. Args: dataset (ContinualDataset): The dataset that is sampled. num_samples (int): the number of samples to draw. Returns: List[int]: The selected dataset indices. \"\"\" target_classes = dataset . targets . clone () . detach () . numpy () classes = np . unique ( target_classes ) . tolist () num_classes = len ( classes ) num_examples_per_class = MemoryMechanism . pack_bins_uniformly ( num_samples * num_classes , num_classes ) class_indices = [] for class_id , cls_number in enumerate ( classes ): candidates = np . array ([ i for i , t in enumerate ( target_classes ) if t == cls_number ]) np . random . shuffle ( candidates ) selected_indices = candidates [: num_examples_per_class [ class_id ]] class_indices += list ( selected_indices ) return class_indices sample_uniform_task_indices ( dataset , num_samples ) staticmethod Selects a specified number of indices uniformly at random. Parameters: Name Type Description Default dataset ContinualDataset The dataset that is sampled. required num_samples int the number of samples to draw. required Returns: Type Description List [ int ] List[int]: The selected dataset indices. Source code in sequel/benchmarks/memory.py 53 54 55 56 57 58 59 60 61 62 63 64 65 66 @staticmethod def sample_uniform_task_indices ( dataset : ContinualDataset , num_samples : int ) -> List [ int ]: \"\"\"Selects a specified number of indices uniformly at random. Args: dataset (ContinualDataset): The dataset that is sampled. num_samples (int): the number of samples to draw. Returns: List[int]: The selected dataset indices. \"\"\" to_remove = len ( dataset ) - num_samples dataset , _ = random_split ( dataset , [ num_samples , to_remove ]) return dataset . indices update_memory ( algo ) Updates the memory by selecting per_task_memory_samples samples from the current dataset. The selection process is defined by the groupby instance attribute. Parameters: Name Type Description Default algo BaseAlgorithm the algorithm instance. required Source code in sequel/benchmarks/memory.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def update_memory ( self , algo : \"BaseAlgorithm\" ): \"\"\"Updates the memory by selecting `per_task_memory_samples` samples from the current dataset. The selection process is defined by the `groupby` instance attribute. Args: algo (BaseAlgorithm): the algorithm instance. \"\"\" logging . info ( \"Setting memory indices for task {} \" . format ( algo . task_counter )) task = algo . task_counter dataset = algo . benchmark . get_train_dataset ( task ) if self . groupby == \"class\" : memory_indices = MemoryMechanism . sample_uniform_class_indices ( dataset , self . per_task_memory_samples ) else : memory_indices = MemoryMechanism . sample_uniform_task_indices ( dataset , self . per_task_memory_samples ) algo . benchmark . set_memory_indices ( task , memory_indices ) update_memory_ ( benchmark , task ) Updates the memory by selecting per_task_memory_samples samples from the current dataset. The selection process is defined by the groupby instance attribute. Source code in sequel/benchmarks/memory.py 41 42 43 44 45 46 47 48 49 50 51 def update_memory_ ( self , benchmark , task ): \"\"\"Updates the memory by selecting `per_task_memory_samples` samples from the current dataset. The selection process is defined by the `groupby` instance attribute. \"\"\" logging . info ( \"Setting memory indices for task {} \" . format ( task )) dataset = benchmark . get_train_dataset ( task ) if self . groupby == \"class\" : memory_indices = MemoryMechanism . sample_uniform_class_indices ( dataset , self . per_task_memory_samples ) else : memory_indices = MemoryMechanism . sample_uniform_task_indices ( dataset , self . per_task_memory_samples ) benchmark . set_memory_indices ( task , memory_indices )","title":"memory"},{"location":"benchmarks/memory/#sequel.benchmarks.memory.MemoryMechanism","text":"Implements the memory handling/manipulation for continual learning algorithms. Source code in sequel/benchmarks/memory.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 class MemoryMechanism : \"\"\"Implements the memory handling/manipulation for continual learning algorithms.\"\"\" def __init__ ( self , per_task_memory_samples : int , groupby : str = \"class\" ): logging . info ( \"Initializing MemoryCallback\" ) self . per_task_memory_samples = per_task_memory_samples if groupby not in ( \"task\" , \"class\" ): raise ValueError ( \"Only class and task are supported as options for groupby argument.\" ) self . groupby = groupby def update_memory ( self , algo : \"BaseAlgorithm\" ): \"\"\"Updates the memory by selecting `per_task_memory_samples` samples from the current dataset. The selection process is defined by the `groupby` instance attribute. Args: algo (BaseAlgorithm): the algorithm instance. \"\"\" logging . info ( \"Setting memory indices for task {} \" . format ( algo . task_counter )) task = algo . task_counter dataset = algo . benchmark . get_train_dataset ( task ) if self . groupby == \"class\" : memory_indices = MemoryMechanism . sample_uniform_class_indices ( dataset , self . per_task_memory_samples ) else : memory_indices = MemoryMechanism . sample_uniform_task_indices ( dataset , self . per_task_memory_samples ) algo . benchmark . set_memory_indices ( task , memory_indices ) def update_memory_ ( self , benchmark , task ): \"\"\"Updates the memory by selecting `per_task_memory_samples` samples from the current dataset. The selection process is defined by the `groupby` instance attribute. \"\"\" logging . info ( \"Setting memory indices for task {} \" . format ( task )) dataset = benchmark . get_train_dataset ( task ) if self . groupby == \"class\" : memory_indices = MemoryMechanism . sample_uniform_class_indices ( dataset , self . per_task_memory_samples ) else : memory_indices = MemoryMechanism . sample_uniform_task_indices ( dataset , self . per_task_memory_samples ) benchmark . set_memory_indices ( task , memory_indices ) @staticmethod def sample_uniform_task_indices ( dataset : ContinualDataset , num_samples : int ) -> List [ int ]: \"\"\"Selects a specified number of indices uniformly at random. Args: dataset (ContinualDataset): The dataset that is sampled. num_samples (int): the number of samples to draw. Returns: List[int]: The selected dataset indices. \"\"\" to_remove = len ( dataset ) - num_samples dataset , _ = random_split ( dataset , [ num_samples , to_remove ]) return dataset . indices @staticmethod def sample_uniform_class_indices ( dataset : ContinualDataset , num_samples : int ) -> List [ int ]: \"\"\"Selects an approximately equal (ties broken arbitrarily) number of indices corresponding to each class from the input dataset. Each dataset yields ~num_samples // num_classes samples. Args: dataset (ContinualDataset): The dataset that is sampled. num_samples (int): the number of samples to draw. Returns: List[int]: The selected dataset indices. \"\"\" target_classes = dataset . targets . clone () . detach () . numpy () classes = np . unique ( target_classes ) . tolist () num_classes = len ( classes ) num_examples_per_class = MemoryMechanism . pack_bins_uniformly ( num_samples * num_classes , num_classes ) class_indices = [] for class_id , cls_number in enumerate ( classes ): candidates = np . array ([ i for i , t in enumerate ( target_classes ) if t == cls_number ]) np . random . shuffle ( candidates ) selected_indices = candidates [: num_examples_per_class [ class_id ]] class_indices += list ( selected_indices ) return class_indices @staticmethod def pack_bins_uniformly ( num_samples : int , num_categories : int ) -> List [ int ]: \"\"\"Splits an integer to a specified number of bins so that bins have approximately the same size. If `num_categories` is not a divisor of `num_samples`, the reminder is split an equal number of bins selectrd uniformly at random. Args: num_samples (int): The number of items. num_categories (int): the number of bins. Returns: List[int]: a list containing the number of items corresponding to each bin. \"\"\" num_samples_per_cat = np . ones ( num_categories ) * num_samples // num_categories remaining = num_samples % num_categories correction_vector = np . array ([ 0 ] * ( num_categories - remaining ) + [ 1 ] * remaining ) np . random . shuffle ( correction_vector ) num_samples_per_cat += correction_vector return num_samples_per_cat . astype ( \"int\" ) . tolist ()","title":"MemoryMechanism"},{"location":"benchmarks/memory/#sequel.benchmarks.memory.MemoryMechanism.pack_bins_uniformly","text":"Splits an integer to a specified number of bins so that bins have approximately the same size. If num_categories is not a divisor of num_samples , the reminder is split an equal number of bins selectrd uniformly at random. Parameters: Name Type Description Default num_samples int The number of items. required num_categories int the number of bins. required Returns: Type Description List [ int ] List[int]: a list containing the number of items corresponding to each bin. Source code in sequel/benchmarks/memory.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 @staticmethod def pack_bins_uniformly ( num_samples : int , num_categories : int ) -> List [ int ]: \"\"\"Splits an integer to a specified number of bins so that bins have approximately the same size. If `num_categories` is not a divisor of `num_samples`, the reminder is split an equal number of bins selectrd uniformly at random. Args: num_samples (int): The number of items. num_categories (int): the number of bins. Returns: List[int]: a list containing the number of items corresponding to each bin. \"\"\" num_samples_per_cat = np . ones ( num_categories ) * num_samples // num_categories remaining = num_samples % num_categories correction_vector = np . array ([ 0 ] * ( num_categories - remaining ) + [ 1 ] * remaining ) np . random . shuffle ( correction_vector ) num_samples_per_cat += correction_vector return num_samples_per_cat . astype ( \"int\" ) . tolist ()","title":"pack_bins_uniformly()"},{"location":"benchmarks/memory/#sequel.benchmarks.memory.MemoryMechanism.sample_uniform_class_indices","text":"Selects an approximately equal (ties broken arbitrarily) number of indices corresponding to each class from the input dataset. Each dataset yields ~num_samples // num_classes samples. Parameters: Name Type Description Default dataset ContinualDataset The dataset that is sampled. required num_samples int the number of samples to draw. required Returns: Type Description List [ int ] List[int]: The selected dataset indices. Source code in sequel/benchmarks/memory.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 @staticmethod def sample_uniform_class_indices ( dataset : ContinualDataset , num_samples : int ) -> List [ int ]: \"\"\"Selects an approximately equal (ties broken arbitrarily) number of indices corresponding to each class from the input dataset. Each dataset yields ~num_samples // num_classes samples. Args: dataset (ContinualDataset): The dataset that is sampled. num_samples (int): the number of samples to draw. Returns: List[int]: The selected dataset indices. \"\"\" target_classes = dataset . targets . clone () . detach () . numpy () classes = np . unique ( target_classes ) . tolist () num_classes = len ( classes ) num_examples_per_class = MemoryMechanism . pack_bins_uniformly ( num_samples * num_classes , num_classes ) class_indices = [] for class_id , cls_number in enumerate ( classes ): candidates = np . array ([ i for i , t in enumerate ( target_classes ) if t == cls_number ]) np . random . shuffle ( candidates ) selected_indices = candidates [: num_examples_per_class [ class_id ]] class_indices += list ( selected_indices ) return class_indices","title":"sample_uniform_class_indices()"},{"location":"benchmarks/memory/#sequel.benchmarks.memory.MemoryMechanism.sample_uniform_task_indices","text":"Selects a specified number of indices uniformly at random. Parameters: Name Type Description Default dataset ContinualDataset The dataset that is sampled. required num_samples int the number of samples to draw. required Returns: Type Description List [ int ] List[int]: The selected dataset indices. Source code in sequel/benchmarks/memory.py 53 54 55 56 57 58 59 60 61 62 63 64 65 66 @staticmethod def sample_uniform_task_indices ( dataset : ContinualDataset , num_samples : int ) -> List [ int ]: \"\"\"Selects a specified number of indices uniformly at random. Args: dataset (ContinualDataset): The dataset that is sampled. num_samples (int): the number of samples to draw. Returns: List[int]: The selected dataset indices. \"\"\" to_remove = len ( dataset ) - num_samples dataset , _ = random_split ( dataset , [ num_samples , to_remove ]) return dataset . indices","title":"sample_uniform_task_indices()"},{"location":"benchmarks/memory/#sequel.benchmarks.memory.MemoryMechanism.update_memory","text":"Updates the memory by selecting per_task_memory_samples samples from the current dataset. The selection process is defined by the groupby instance attribute. Parameters: Name Type Description Default algo BaseAlgorithm the algorithm instance. required Source code in sequel/benchmarks/memory.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def update_memory ( self , algo : \"BaseAlgorithm\" ): \"\"\"Updates the memory by selecting `per_task_memory_samples` samples from the current dataset. The selection process is defined by the `groupby` instance attribute. Args: algo (BaseAlgorithm): the algorithm instance. \"\"\" logging . info ( \"Setting memory indices for task {} \" . format ( algo . task_counter )) task = algo . task_counter dataset = algo . benchmark . get_train_dataset ( task ) if self . groupby == \"class\" : memory_indices = MemoryMechanism . sample_uniform_class_indices ( dataset , self . per_task_memory_samples ) else : memory_indices = MemoryMechanism . sample_uniform_task_indices ( dataset , self . per_task_memory_samples ) algo . benchmark . set_memory_indices ( task , memory_indices )","title":"update_memory()"},{"location":"benchmarks/memory/#sequel.benchmarks.memory.MemoryMechanism.update_memory_","text":"Updates the memory by selecting per_task_memory_samples samples from the current dataset. The selection process is defined by the groupby instance attribute. Source code in sequel/benchmarks/memory.py 41 42 43 44 45 46 47 48 49 50 51 def update_memory_ ( self , benchmark , task ): \"\"\"Updates the memory by selecting `per_task_memory_samples` samples from the current dataset. The selection process is defined by the `groupby` instance attribute. \"\"\" logging . info ( \"Setting memory indices for task {} \" . format ( task )) dataset = benchmark . get_train_dataset ( task ) if self . groupby == \"class\" : memory_indices = MemoryMechanism . sample_uniform_class_indices ( dataset , self . per_task_memory_samples ) else : memory_indices = MemoryMechanism . sample_uniform_task_indices ( dataset , self . per_task_memory_samples ) benchmark . set_memory_indices ( task , memory_indices )","title":"update_memory_()"},{"location":"benchmarks/mnist/","text":"ContinualMNIST Bases: Benchmark Base class for (Permuted/Rotated/Split)-MNIST benchmarks. Source code in sequel/benchmarks/mnist.py 32 33 34 35 36 37 38 39 40 41 42 43 44 class ContinualMNIST ( Benchmark ): \"\"\"Base class for (Permuted/Rotated/Split)-MNIST benchmarks.\"\"\" @property def dimensions ( self ) -> List [ int ]: return [ 1 , 28 , 28 ] @property def num_classes ( self ) -> int : return 10 MEAN = ( 0.1307 ,) STD = ( 0.3081 ,) PermutedMNIST Bases: ContinualMNIST Permuted MNIST benchmark. Source code in sequel/benchmarks/mnist.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 class PermutedMNIST ( ContinualMNIST ): \"\"\"Permuted MNIST benchmark.\"\"\" classes_per_task = 10 @classmethod def from_config ( cls , config ): kwargs = cls . get_default_kwargs ( config ) return cls ( ** kwargs ) def __repr__ ( self ) -> str : return f \"PermutedMNIST(num_tasks= { self . num_tasks } , batch_size= { self . batch_size } )\" def prepare_datasets ( self ): mnist_train = torchvision . datasets . MNIST ( DEFAULT_DATASET_DIR , train = True , download = True ) mnist_test = torchvision . datasets . MNIST ( DEFAULT_DATASET_DIR , train = False , download = True ) transforms = self . get_transforms ( self . num_tasks ) trains , tests = {}, {} for task in range ( 1 , self . num_tasks + 1 ): trains [ task ] = ContinualVisionDataset ( task , mnist_train . data , mnist_train . targets , transforms [ task - 1 ]) tests [ task ] = ContinualVisionDataset ( task , mnist_test . data , mnist_test . targets , transforms [ task - 1 ]) return trains , tests def get_transforms ( self , num_tasks ): transforms = [] for task in range ( 1 , num_tasks + 1 ): transform = [ T . ToTensor ()] if task > 1 : transform . append ( PermuteTransform ( torch . randperm ( 28 * 28 ))) transform . append ( T . Normalize ( self . MEAN , self . STD )) transforms . append ( T . Compose ( transform )) return transforms RotatedMNIST Bases: ContinualMNIST Rotated MNIST benchmark. Source code in sequel/benchmarks/mnist.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 class RotatedMNIST ( ContinualMNIST ): \"\"\"Rotated MNIST benchmark.\"\"\" classes_per_task = 10 def __init__ ( self , num_tasks : int , per_task_rotation : Optional [ float ] = None , * args , ** kwargs ): self . per_task_rotation = per_task_rotation super () . __init__ ( num_tasks = num_tasks , * args , ** kwargs ) @classmethod def from_config ( cls , config ): kwargs = cls . get_default_kwargs ( config ) kwargs [ \"per_task_rotation\" ] = config . per_task_rotation return cls ( ** kwargs ) def __repr__ ( self ) -> str : return f \"RotatedMNIST(num_tasks= { self . num_tasks } , per_task_rotation= { self . per_task_rotation } , batch_size= { self . batch_size } )\" def get_transforms ( self , num_tasks : int , per_task_rotation : float = None ): warnings . warn ( \"The RotatedMNIST benchmark currently supports fixed rotations of `per_task_rotation` degrees. \" \"Randomly sampling degrees will be added.\" ) if not per_task_rotation : per_task_rotation = 180.0 / num_tasks transforms = [] for t in range ( 1 , num_tasks + 1 ): rotation_degree = ( t - 1 ) * per_task_rotation transform = T . Compose ([ RotationTransform ( rotation_degree ), T . ToTensor (), T . Normalize ( self . MEAN , self . STD )]) transforms . append ( transform ) return transforms def prepare_datasets ( self ): trains , tests = {}, {} mnist_train = torchvision . datasets . MNIST ( DEFAULT_DATASET_DIR , train = True , download = True ) mnist_test = torchvision . datasets . MNIST ( DEFAULT_DATASET_DIR , train = False , download = True ) transforms = self . get_transforms ( self . num_tasks , self . per_task_rotation ) for task in range ( 1 , self . num_tasks + 1 ): trains [ task ] = ContinualVisionDataset ( task , mnist_train . data , mnist_train . targets , transforms [ task - 1 ]) tests [ task ] = ContinualVisionDataset ( task , mnist_test . data , mnist_test . targets , transforms [ task - 1 ]) return trains , tests SplitMNIST Bases: ContinualMNIST Split MNIST benchmark. The benchmark can have at most 5 tasks, each a binary classification on MNIST digits. Source code in sequel/benchmarks/mnist.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 class SplitMNIST ( ContinualMNIST ): \"\"\"Split MNIST benchmark. The benchmark can have at most 5 tasks, each a binary classification on MNIST digits. \"\"\" @property def classes_per_task ( self ): if self . num_tasks not in [ 2 , 5 ]: raise ValueError ( \"Split MNIST benchmark can have at most 5 tasks (i.e., 10 classes, 2 per task)\" ) return 10 // self . num_tasks def prepare_datasets ( self ): transform = T . Compose ([ T . ToTensor (), T . Normalize ( self . MEAN , self . STD )]) mnist_train = torchvision . datasets . MNIST ( DEFAULT_DATASET_DIR , train = True , download = True , transform = transform ) mnist_test = torchvision . datasets . MNIST ( DEFAULT_DATASET_DIR , train = False , download = True , transform = transform ) trains , tests = {}, {} for task in range ( 1 , self . num_tasks + 1 ): trains [ task ] = SplitDataset ( task , self . classes_per_task , mnist_train ) tests [ task ] = SplitDataset ( task , self . classes_per_task , mnist_test ) return trains , tests @classmethod def from_config ( cls , config ): kwargs = cls . get_default_kwargs ( config ) return cls ( ** kwargs ) def __repr__ ( self ) -> str : return f \"SplitMNIST(num_tasks= { self . num_tasks } , batch_size= { self . batch_size } )\"","title":"MNIST"},{"location":"benchmarks/mnist/#sequel.benchmarks.mnist.ContinualMNIST","text":"Bases: Benchmark Base class for (Permuted/Rotated/Split)-MNIST benchmarks. Source code in sequel/benchmarks/mnist.py 32 33 34 35 36 37 38 39 40 41 42 43 44 class ContinualMNIST ( Benchmark ): \"\"\"Base class for (Permuted/Rotated/Split)-MNIST benchmarks.\"\"\" @property def dimensions ( self ) -> List [ int ]: return [ 1 , 28 , 28 ] @property def num_classes ( self ) -> int : return 10 MEAN = ( 0.1307 ,) STD = ( 0.3081 ,)","title":"ContinualMNIST"},{"location":"benchmarks/mnist/#sequel.benchmarks.mnist.PermutedMNIST","text":"Bases: ContinualMNIST Permuted MNIST benchmark. Source code in sequel/benchmarks/mnist.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 class PermutedMNIST ( ContinualMNIST ): \"\"\"Permuted MNIST benchmark.\"\"\" classes_per_task = 10 @classmethod def from_config ( cls , config ): kwargs = cls . get_default_kwargs ( config ) return cls ( ** kwargs ) def __repr__ ( self ) -> str : return f \"PermutedMNIST(num_tasks= { self . num_tasks } , batch_size= { self . batch_size } )\" def prepare_datasets ( self ): mnist_train = torchvision . datasets . MNIST ( DEFAULT_DATASET_DIR , train = True , download = True ) mnist_test = torchvision . datasets . MNIST ( DEFAULT_DATASET_DIR , train = False , download = True ) transforms = self . get_transforms ( self . num_tasks ) trains , tests = {}, {} for task in range ( 1 , self . num_tasks + 1 ): trains [ task ] = ContinualVisionDataset ( task , mnist_train . data , mnist_train . targets , transforms [ task - 1 ]) tests [ task ] = ContinualVisionDataset ( task , mnist_test . data , mnist_test . targets , transforms [ task - 1 ]) return trains , tests def get_transforms ( self , num_tasks ): transforms = [] for task in range ( 1 , num_tasks + 1 ): transform = [ T . ToTensor ()] if task > 1 : transform . append ( PermuteTransform ( torch . randperm ( 28 * 28 ))) transform . append ( T . Normalize ( self . MEAN , self . STD )) transforms . append ( T . Compose ( transform )) return transforms","title":"PermutedMNIST"},{"location":"benchmarks/mnist/#sequel.benchmarks.mnist.RotatedMNIST","text":"Bases: ContinualMNIST Rotated MNIST benchmark. Source code in sequel/benchmarks/mnist.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 class RotatedMNIST ( ContinualMNIST ): \"\"\"Rotated MNIST benchmark.\"\"\" classes_per_task = 10 def __init__ ( self , num_tasks : int , per_task_rotation : Optional [ float ] = None , * args , ** kwargs ): self . per_task_rotation = per_task_rotation super () . __init__ ( num_tasks = num_tasks , * args , ** kwargs ) @classmethod def from_config ( cls , config ): kwargs = cls . get_default_kwargs ( config ) kwargs [ \"per_task_rotation\" ] = config . per_task_rotation return cls ( ** kwargs ) def __repr__ ( self ) -> str : return f \"RotatedMNIST(num_tasks= { self . num_tasks } , per_task_rotation= { self . per_task_rotation } , batch_size= { self . batch_size } )\" def get_transforms ( self , num_tasks : int , per_task_rotation : float = None ): warnings . warn ( \"The RotatedMNIST benchmark currently supports fixed rotations of `per_task_rotation` degrees. \" \"Randomly sampling degrees will be added.\" ) if not per_task_rotation : per_task_rotation = 180.0 / num_tasks transforms = [] for t in range ( 1 , num_tasks + 1 ): rotation_degree = ( t - 1 ) * per_task_rotation transform = T . Compose ([ RotationTransform ( rotation_degree ), T . ToTensor (), T . Normalize ( self . MEAN , self . STD )]) transforms . append ( transform ) return transforms def prepare_datasets ( self ): trains , tests = {}, {} mnist_train = torchvision . datasets . MNIST ( DEFAULT_DATASET_DIR , train = True , download = True ) mnist_test = torchvision . datasets . MNIST ( DEFAULT_DATASET_DIR , train = False , download = True ) transforms = self . get_transforms ( self . num_tasks , self . per_task_rotation ) for task in range ( 1 , self . num_tasks + 1 ): trains [ task ] = ContinualVisionDataset ( task , mnist_train . data , mnist_train . targets , transforms [ task - 1 ]) tests [ task ] = ContinualVisionDataset ( task , mnist_test . data , mnist_test . targets , transforms [ task - 1 ]) return trains , tests","title":"RotatedMNIST"},{"location":"benchmarks/mnist/#sequel.benchmarks.mnist.SplitMNIST","text":"Bases: ContinualMNIST Split MNIST benchmark. The benchmark can have at most 5 tasks, each a binary classification on MNIST digits. Source code in sequel/benchmarks/mnist.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 class SplitMNIST ( ContinualMNIST ): \"\"\"Split MNIST benchmark. The benchmark can have at most 5 tasks, each a binary classification on MNIST digits. \"\"\" @property def classes_per_task ( self ): if self . num_tasks not in [ 2 , 5 ]: raise ValueError ( \"Split MNIST benchmark can have at most 5 tasks (i.e., 10 classes, 2 per task)\" ) return 10 // self . num_tasks def prepare_datasets ( self ): transform = T . Compose ([ T . ToTensor (), T . Normalize ( self . MEAN , self . STD )]) mnist_train = torchvision . datasets . MNIST ( DEFAULT_DATASET_DIR , train = True , download = True , transform = transform ) mnist_test = torchvision . datasets . MNIST ( DEFAULT_DATASET_DIR , train = False , download = True , transform = transform ) trains , tests = {}, {} for task in range ( 1 , self . num_tasks + 1 ): trains [ task ] = SplitDataset ( task , self . classes_per_task , mnist_train ) tests [ task ] = SplitDataset ( task , self . classes_per_task , mnist_test ) return trains , tests @classmethod def from_config ( cls , config ): kwargs = cls . get_default_kwargs ( config ) return cls ( ** kwargs ) def __repr__ ( self ) -> str : return f \"SplitMNIST(num_tasks= { self . num_tasks } , batch_size= { self . batch_size } )\"","title":"SplitMNIST"},{"location":"benchmarks/tinyimagenet/","text":"SplitTinyImagenet Bases: Benchmark Source code in sequel/benchmarks/tinyimagenet.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 class SplitTinyImagenet ( Benchmark ): root = DEFAULT_DATASET_DIR @property def num_classes ( self ) -> int : return 200 def __init__ ( self , num_tasks : int = 10 , task_input_transforms : Optional [ list ] = _default_input_transform , task_target_transforms : Optional [ list ] = None , ): \"\"\"Inits the SplitTinyImagenet class. The number of `classes_per_task` is equal to the ratio of 200 and `num_tasks`. Args: num_tasks (int, optional): The number of tasks. Defaults to 10. task_input_transforms (Optional[list], optional): If set, the benchmark will use the provided torchvision input transform. Defaults to _default_input_transform. task_target_transforms (Optional[list], optional): If set, the benchmark will use the provided torchvision target transform. Defaults to None. Raises: ValueError: The number of tasks must be divisible by the number of classes (200). \"\"\" if self . num_classes % num_tasks != 0 : raise ValueError ( \"The number of tasks must be divisible by the number of classes (200).\" ) self . classes_per_task = self . num_classes // num_tasks super () . __init__ ( num_tasks = num_tasks , task_input_transforms = task_input_transforms , task_target_transforms = task_target_transforms , ) logging . info ( f \"Classes_per_task= { self . classes_per_task } \" ) logging . info ( f \"num_tasks= { self . num_tasks } \" ) @classmethod def from_config ( cls , config ): num_tasks = config . benchmark . num_tasks return cls ( num_tasks = num_tasks ) def prepare_datasets ( self ): trains , tests = {}, {} self . __load_tinyimagenet () for task in range ( 1 , self . num_tasks + 1 ): trains [ task ] = SplitDataset ( task , self . classes_per_task , self . tiny_train ) tests [ task ] = SplitDataset ( task , self . classes_per_task , self . tiny_test ) return trains , tests def __load_tinyimagenet ( self ): \"\"\"Loads the tinyimagenet dataset. The original dataset does not have labels for the test dataset. For this reason, the validation dataset is used. \"\"\" self . tiny_train = torchvision . datasets . ImageFolder ( self . root + \"train\" , transform = self . task_input_transforms ) tiny_val = torchvision . datasets . ImageFolder ( self . root + \"val\" , transform = self . task_input_transforms ) self . tiny_test = tiny_val def __repr__ ( self ) -> str : return f \"SplitTinyImageNet(num_tasks= { self . num_tasks } , batch_size= { self . batch_size } )\" __init__ ( num_tasks = 10 , task_input_transforms = _default_input_transform , task_target_transforms = None ) Inits the SplitTinyImagenet class. The number of classes_per_task is equal to the ratio of 200 and num_tasks . Parameters: Name Type Description Default num_tasks int The number of tasks. Defaults to 10. 10 task_input_transforms Optional [ list ] If set, the benchmark will use the provided torchvision input transform. Defaults to _default_input_transform. _default_input_transform task_target_transforms Optional [ list ] If set, the benchmark will use the provided torchvision target transform. Defaults to None. None Raises: Type Description ValueError The number of tasks must be divisible by the number of classes (200). Source code in sequel/benchmarks/tinyimagenet.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def __init__ ( self , num_tasks : int = 10 , task_input_transforms : Optional [ list ] = _default_input_transform , task_target_transforms : Optional [ list ] = None , ): \"\"\"Inits the SplitTinyImagenet class. The number of `classes_per_task` is equal to the ratio of 200 and `num_tasks`. Args: num_tasks (int, optional): The number of tasks. Defaults to 10. task_input_transforms (Optional[list], optional): If set, the benchmark will use the provided torchvision input transform. Defaults to _default_input_transform. task_target_transforms (Optional[list], optional): If set, the benchmark will use the provided torchvision target transform. Defaults to None. Raises: ValueError: The number of tasks must be divisible by the number of classes (200). \"\"\" if self . num_classes % num_tasks != 0 : raise ValueError ( \"The number of tasks must be divisible by the number of classes (200).\" ) self . classes_per_task = self . num_classes // num_tasks super () . __init__ ( num_tasks = num_tasks , task_input_transforms = task_input_transforms , task_target_transforms = task_target_transforms , ) logging . info ( f \"Classes_per_task= { self . classes_per_task } \" ) logging . info ( f \"num_tasks= { self . num_tasks } \" ) __load_tinyimagenet () Loads the tinyimagenet dataset. The original dataset does not have labels for the test dataset. For this reason, the validation dataset is used. Source code in sequel/benchmarks/tinyimagenet.py 70 71 72 73 74 75 76 77 78 def __load_tinyimagenet ( self ): \"\"\"Loads the tinyimagenet dataset. The original dataset does not have labels for the test dataset. For this reason, the validation dataset is used. \"\"\" self . tiny_train = torchvision . datasets . ImageFolder ( self . root + \"train\" , transform = self . task_input_transforms ) tiny_val = torchvision . datasets . ImageFolder ( self . root + \"val\" , transform = self . task_input_transforms ) self . tiny_test = tiny_val","title":"TinyImageNet"},{"location":"benchmarks/tinyimagenet/#sequel.benchmarks.tinyimagenet.SplitTinyImagenet","text":"Bases: Benchmark Source code in sequel/benchmarks/tinyimagenet.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 class SplitTinyImagenet ( Benchmark ): root = DEFAULT_DATASET_DIR @property def num_classes ( self ) -> int : return 200 def __init__ ( self , num_tasks : int = 10 , task_input_transforms : Optional [ list ] = _default_input_transform , task_target_transforms : Optional [ list ] = None , ): \"\"\"Inits the SplitTinyImagenet class. The number of `classes_per_task` is equal to the ratio of 200 and `num_tasks`. Args: num_tasks (int, optional): The number of tasks. Defaults to 10. task_input_transforms (Optional[list], optional): If set, the benchmark will use the provided torchvision input transform. Defaults to _default_input_transform. task_target_transforms (Optional[list], optional): If set, the benchmark will use the provided torchvision target transform. Defaults to None. Raises: ValueError: The number of tasks must be divisible by the number of classes (200). \"\"\" if self . num_classes % num_tasks != 0 : raise ValueError ( \"The number of tasks must be divisible by the number of classes (200).\" ) self . classes_per_task = self . num_classes // num_tasks super () . __init__ ( num_tasks = num_tasks , task_input_transforms = task_input_transforms , task_target_transforms = task_target_transforms , ) logging . info ( f \"Classes_per_task= { self . classes_per_task } \" ) logging . info ( f \"num_tasks= { self . num_tasks } \" ) @classmethod def from_config ( cls , config ): num_tasks = config . benchmark . num_tasks return cls ( num_tasks = num_tasks ) def prepare_datasets ( self ): trains , tests = {}, {} self . __load_tinyimagenet () for task in range ( 1 , self . num_tasks + 1 ): trains [ task ] = SplitDataset ( task , self . classes_per_task , self . tiny_train ) tests [ task ] = SplitDataset ( task , self . classes_per_task , self . tiny_test ) return trains , tests def __load_tinyimagenet ( self ): \"\"\"Loads the tinyimagenet dataset. The original dataset does not have labels for the test dataset. For this reason, the validation dataset is used. \"\"\" self . tiny_train = torchvision . datasets . ImageFolder ( self . root + \"train\" , transform = self . task_input_transforms ) tiny_val = torchvision . datasets . ImageFolder ( self . root + \"val\" , transform = self . task_input_transforms ) self . tiny_test = tiny_val def __repr__ ( self ) -> str : return f \"SplitTinyImageNet(num_tasks= { self . num_tasks } , batch_size= { self . batch_size } )\"","title":"SplitTinyImagenet"},{"location":"benchmarks/tinyimagenet/#sequel.benchmarks.tinyimagenet.SplitTinyImagenet.__init__","text":"Inits the SplitTinyImagenet class. The number of classes_per_task is equal to the ratio of 200 and num_tasks . Parameters: Name Type Description Default num_tasks int The number of tasks. Defaults to 10. 10 task_input_transforms Optional [ list ] If set, the benchmark will use the provided torchvision input transform. Defaults to _default_input_transform. _default_input_transform task_target_transforms Optional [ list ] If set, the benchmark will use the provided torchvision target transform. Defaults to None. None Raises: Type Description ValueError The number of tasks must be divisible by the number of classes (200). Source code in sequel/benchmarks/tinyimagenet.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def __init__ ( self , num_tasks : int = 10 , task_input_transforms : Optional [ list ] = _default_input_transform , task_target_transforms : Optional [ list ] = None , ): \"\"\"Inits the SplitTinyImagenet class. The number of `classes_per_task` is equal to the ratio of 200 and `num_tasks`. Args: num_tasks (int, optional): The number of tasks. Defaults to 10. task_input_transforms (Optional[list], optional): If set, the benchmark will use the provided torchvision input transform. Defaults to _default_input_transform. task_target_transforms (Optional[list], optional): If set, the benchmark will use the provided torchvision target transform. Defaults to None. Raises: ValueError: The number of tasks must be divisible by the number of classes (200). \"\"\" if self . num_classes % num_tasks != 0 : raise ValueError ( \"The number of tasks must be divisible by the number of classes (200).\" ) self . classes_per_task = self . num_classes // num_tasks super () . __init__ ( num_tasks = num_tasks , task_input_transforms = task_input_transforms , task_target_transforms = task_target_transforms , ) logging . info ( f \"Classes_per_task= { self . classes_per_task } \" ) logging . info ( f \"num_tasks= { self . num_tasks } \" )","title":"__init__()"},{"location":"benchmarks/tinyimagenet/#sequel.benchmarks.tinyimagenet.SplitTinyImagenet.__load_tinyimagenet","text":"Loads the tinyimagenet dataset. The original dataset does not have labels for the test dataset. For this reason, the validation dataset is used. Source code in sequel/benchmarks/tinyimagenet.py 70 71 72 73 74 75 76 77 78 def __load_tinyimagenet ( self ): \"\"\"Loads the tinyimagenet dataset. The original dataset does not have labels for the test dataset. For this reason, the validation dataset is used. \"\"\" self . tiny_train = torchvision . datasets . ImageFolder ( self . root + \"train\" , transform = self . task_input_transforms ) tiny_val = torchvision . datasets . ImageFolder ( self . root + \"val\" , transform = self . task_input_transforms ) self . tiny_test = tiny_val","title":"__load_tinyimagenet()"},{"location":"benchmarks/utils/","text":"ContinualDataset Bases: torch . utils . data . Dataset Source code in sequel/benchmarks/utils.py 9 10 11 12 13 14 15 16 17 18 19 20 21 class ContinualDataset ( torch . utils . data . Dataset ): def __init__ ( self , task_id : int , * args , ** kwargs ) -> None : \"\"\"Inits the ContinualDataset class. Args: task_id (int): The id of the current task. \"\"\" super () . __init__ ( * args , ** kwargs ) self . task_id = task_id def __getitem__ ( self , index : int ) -> Tuple [ Tensor , Union [ Tensor , int ], int ]: x , y = super () . __getitem__ ( index = index ) return x , y , self . task_id __init__ ( task_id , * args , ** kwargs ) Inits the ContinualDataset class. Parameters: Name Type Description Default task_id int The id of the current task. required Source code in sequel/benchmarks/utils.py 10 11 12 13 14 15 16 17 def __init__ ( self , task_id : int , * args , ** kwargs ) -> None : \"\"\"Inits the ContinualDataset class. Args: task_id (int): The id of the current task. \"\"\" super () . __init__ ( * args , ** kwargs ) self . task_id = task_id","title":"utils"},{"location":"benchmarks/utils/#sequel.benchmarks.utils.ContinualDataset","text":"Bases: torch . utils . data . Dataset Source code in sequel/benchmarks/utils.py 9 10 11 12 13 14 15 16 17 18 19 20 21 class ContinualDataset ( torch . utils . data . Dataset ): def __init__ ( self , task_id : int , * args , ** kwargs ) -> None : \"\"\"Inits the ContinualDataset class. Args: task_id (int): The id of the current task. \"\"\" super () . __init__ ( * args , ** kwargs ) self . task_id = task_id def __getitem__ ( self , index : int ) -> Tuple [ Tensor , Union [ Tensor , int ], int ]: x , y = super () . __getitem__ ( index = index ) return x , y , self . task_id","title":"ContinualDataset"},{"location":"benchmarks/utils/#sequel.benchmarks.utils.ContinualDataset.__init__","text":"Inits the ContinualDataset class. Parameters: Name Type Description Default task_id int The id of the current task. required Source code in sequel/benchmarks/utils.py 10 11 12 13 14 15 16 17 def __init__ ( self , task_id : int , * args , ** kwargs ) -> None : \"\"\"Inits the ContinualDataset class. Args: task_id (int): The id of the current task. \"\"\" super () . __init__ ( * args , ** kwargs ) self . task_id = task_id","title":"__init__()"},{"location":"utils/callbacks/base_callback/","text":"BaseCallback Base class for callbacks. Defines methods for all the various callback points in the trainer. Source code in sequel/utils/callbacks/base_callback.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 class BaseCallback : \"\"\"Base class for callbacks. Defines methods for all the various callback points in the trainer. \"\"\" def __init__ ( self ): pass def connect ( self , * args , ** kwargs ): pass def on_before_setup ( self , * args , ** kwargs ): pass def on_after_setup ( self , * args , ** kwargs ): pass def on_before_teardown ( self , * args , ** kwargs ): pass def on_after_teardown ( self , * args , ** kwargs ): pass def on_before_fit ( self , * args , ** kwargs ): pass def on_after_fit ( self , * args , ** kwargs ): pass def on_before_training_epoch ( self , * args , ** kwargs ): pass def on_after_training_epoch ( self , * args , ** kwargs ): pass def on_before_val_epoch ( self , * args , ** kwargs ): pass def on_after_val_epoch ( self , * args , ** kwargs ): pass def on_before_testing_epoch ( self , * args , ** kwargs ): pass def on_after_testing_epoch ( self , * args , ** kwargs ): pass def on_before_training_step ( self , * args , ** kwargs ): pass def on_after_training_step ( self , * args , ** kwargs ): pass def on_before_backward ( self , * args , ** kwargs ): pass def on_after_backward ( self , * args , ** kwargs ): pass def on_before_forward ( self , * args , ** kwargs ): pass def on_after_forward ( self , * args , ** kwargs ): pass def on_before_optimizer_step ( self , * args , ** kwargs ): pass def on_after_optimizer_step ( self , * args , ** kwargs ): pass def on_before_val_step ( self , * args , ** kwargs ): pass def on_after_val_step ( self , * args , ** kwargs ): pass def on_before_testing_step ( self , * args , ** kwargs ): pass def on_after_testing_step ( self , * args , ** kwargs ): pass def on_before_training_task ( self , * args , ** kwargs ): pass def on_after_training_task ( self , * args , ** kwargs ): pass def on_before_validating_algorithm_on_all_tasks ( self , * args , ** kwargs ): pass def on_after_validating_algorithm_on_all_tasks ( self , * args , ** kwargs ): pass","title":"BaseCallback"},{"location":"utils/callbacks/base_callback/#sequel.utils.callbacks.base_callback.BaseCallback","text":"Base class for callbacks. Defines methods for all the various callback points in the trainer. Source code in sequel/utils/callbacks/base_callback.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 class BaseCallback : \"\"\"Base class for callbacks. Defines methods for all the various callback points in the trainer. \"\"\" def __init__ ( self ): pass def connect ( self , * args , ** kwargs ): pass def on_before_setup ( self , * args , ** kwargs ): pass def on_after_setup ( self , * args , ** kwargs ): pass def on_before_teardown ( self , * args , ** kwargs ): pass def on_after_teardown ( self , * args , ** kwargs ): pass def on_before_fit ( self , * args , ** kwargs ): pass def on_after_fit ( self , * args , ** kwargs ): pass def on_before_training_epoch ( self , * args , ** kwargs ): pass def on_after_training_epoch ( self , * args , ** kwargs ): pass def on_before_val_epoch ( self , * args , ** kwargs ): pass def on_after_val_epoch ( self , * args , ** kwargs ): pass def on_before_testing_epoch ( self , * args , ** kwargs ): pass def on_after_testing_epoch ( self , * args , ** kwargs ): pass def on_before_training_step ( self , * args , ** kwargs ): pass def on_after_training_step ( self , * args , ** kwargs ): pass def on_before_backward ( self , * args , ** kwargs ): pass def on_after_backward ( self , * args , ** kwargs ): pass def on_before_forward ( self , * args , ** kwargs ): pass def on_after_forward ( self , * args , ** kwargs ): pass def on_before_optimizer_step ( self , * args , ** kwargs ): pass def on_after_optimizer_step ( self , * args , ** kwargs ): pass def on_before_val_step ( self , * args , ** kwargs ): pass def on_after_val_step ( self , * args , ** kwargs ): pass def on_before_testing_step ( self , * args , ** kwargs ): pass def on_after_testing_step ( self , * args , ** kwargs ): pass def on_before_training_task ( self , * args , ** kwargs ): pass def on_after_training_task ( self , * args , ** kwargs ): pass def on_before_validating_algorithm_on_all_tasks ( self , * args , ** kwargs ): pass def on_after_validating_algorithm_on_all_tasks ( self , * args , ** kwargs ): pass","title":"BaseCallback"},{"location":"utils/callbacks/input_visualization_callback/","text":"InputVisualizationCallback Bases: AlgoCallback Visualizes random samples from each task and uses the loggers to save the plots. Source code in sequel/utils/callbacks/input_visualization_callback.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class InputVisualizationCallback ( AlgoCallback ): \"\"\"Visualizes random samples from each task and uses the loggers to save the plots.\"\"\" def __init__ ( self , samples_per_task = 5 ): \"\"\"Inits the InputVisualizationCallback. Args: samples_per_task (int, optional): number of samples to be saved for each tasks. Defaults to 5. \"\"\" super () . __init__ () self . samples_per_task = samples_per_task def select_random_samples ( self , dataset : torch . utils . data . Dataset ) -> List [ torch . Tensor ]: \"\"\"Selects a prefefined number of samples per each CL dataset. Each task corresponds to a different dataset. Args: dataset (torch.data.utils.Dataset): The PyTorch Datatet. Returns: List[torch.Tensor]: The Tensors corresponding to the selected input samples. \"\"\" indices = np . random . choice ( len ( dataset ), self . samples_per_task , replace = False ) samples = [ dataset [ i ] for i in indices ] return samples def on_before_fit ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ) -> None : \"\"\"Retrieves and diplays in a single plot the input images from all tasks of the benchmark that the algorithm has been initialized with. The final plot is saved via the loggers. Args: algo (BaseAlgorithm): The BaseAlgorithm instance. \"\"\" datasets = algo . benchmark . trains num_tasks = algo . num_tasks samples = [] for dataset in datasets . values (): task_samples = self . select_random_samples ( dataset ) samples . append ( task_samples ) s = 2 figure , axes = plt . subplots ( nrows = num_tasks , ncols = self . samples_per_task , figsize = ( s * self . samples_per_task , s * num_tasks ), ) for i , task_samples in enumerate ( samples ): for j , ( x , y , t ) in enumerate ( task_samples ): if x . dim () == 2 : x = x . unsqueeze ( 0 ) axes [ i ][ j ] . imshow ( x . permute ( 1 , 2 , 0 )) axes [ i ][ j ] . title . set_text ( f \"t= { t } : y= { y } \" ) plt . setp ( axes , xticks = [], yticks = []) figure . subplots_adjust ( wspace = 0.5 ) # save the plot via the algorithm loggers algo . log_figure ( name = \"input/viz\" , figure = figure ) __init__ ( samples_per_task = 5 ) Inits the InputVisualizationCallback. Parameters: Name Type Description Default samples_per_task int number of samples to be saved for each tasks. Defaults to 5. 5 Source code in sequel/utils/callbacks/input_visualization_callback.py 16 17 18 19 20 21 22 23 def __init__ ( self , samples_per_task = 5 ): \"\"\"Inits the InputVisualizationCallback. Args: samples_per_task (int, optional): number of samples to be saved for each tasks. Defaults to 5. \"\"\" super () . __init__ () self . samples_per_task = samples_per_task on_before_fit ( algo , * args , ** kwargs ) Retrieves and diplays in a single plot the input images from all tasks of the benchmark that the algorithm has been initialized with. The final plot is saved via the loggers. Parameters: Name Type Description Default algo BaseAlgorithm The BaseAlgorithm instance. required Source code in sequel/utils/callbacks/input_visualization_callback.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 def on_before_fit ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ) -> None : \"\"\"Retrieves and diplays in a single plot the input images from all tasks of the benchmark that the algorithm has been initialized with. The final plot is saved via the loggers. Args: algo (BaseAlgorithm): The BaseAlgorithm instance. \"\"\" datasets = algo . benchmark . trains num_tasks = algo . num_tasks samples = [] for dataset in datasets . values (): task_samples = self . select_random_samples ( dataset ) samples . append ( task_samples ) s = 2 figure , axes = plt . subplots ( nrows = num_tasks , ncols = self . samples_per_task , figsize = ( s * self . samples_per_task , s * num_tasks ), ) for i , task_samples in enumerate ( samples ): for j , ( x , y , t ) in enumerate ( task_samples ): if x . dim () == 2 : x = x . unsqueeze ( 0 ) axes [ i ][ j ] . imshow ( x . permute ( 1 , 2 , 0 )) axes [ i ][ j ] . title . set_text ( f \"t= { t } : y= { y } \" ) plt . setp ( axes , xticks = [], yticks = []) figure . subplots_adjust ( wspace = 0.5 ) # save the plot via the algorithm loggers algo . log_figure ( name = \"input/viz\" , figure = figure ) select_random_samples ( dataset ) Selects a prefefined number of samples per each CL dataset. Each task corresponds to a different dataset. Parameters: Name Type Description Default dataset torch . data . utils . Dataset The PyTorch Datatet. required Returns: Type Description List [ torch . Tensor ] List[torch.Tensor]: The Tensors corresponding to the selected input samples. Source code in sequel/utils/callbacks/input_visualization_callback.py 25 26 27 28 29 30 31 32 33 34 35 36 def select_random_samples ( self , dataset : torch . utils . data . Dataset ) -> List [ torch . Tensor ]: \"\"\"Selects a prefefined number of samples per each CL dataset. Each task corresponds to a different dataset. Args: dataset (torch.data.utils.Dataset): The PyTorch Datatet. Returns: List[torch.Tensor]: The Tensors corresponding to the selected input samples. \"\"\" indices = np . random . choice ( len ( dataset ), self . samples_per_task , replace = False ) samples = [ dataset [ i ] for i in indices ] return samples","title":"InputVisualizationCallback"},{"location":"utils/callbacks/input_visualization_callback/#sequel.utils.callbacks.input_visualization_callback.InputVisualizationCallback","text":"Bases: AlgoCallback Visualizes random samples from each task and uses the loggers to save the plots. Source code in sequel/utils/callbacks/input_visualization_callback.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class InputVisualizationCallback ( AlgoCallback ): \"\"\"Visualizes random samples from each task and uses the loggers to save the plots.\"\"\" def __init__ ( self , samples_per_task = 5 ): \"\"\"Inits the InputVisualizationCallback. Args: samples_per_task (int, optional): number of samples to be saved for each tasks. Defaults to 5. \"\"\" super () . __init__ () self . samples_per_task = samples_per_task def select_random_samples ( self , dataset : torch . utils . data . Dataset ) -> List [ torch . Tensor ]: \"\"\"Selects a prefefined number of samples per each CL dataset. Each task corresponds to a different dataset. Args: dataset (torch.data.utils.Dataset): The PyTorch Datatet. Returns: List[torch.Tensor]: The Tensors corresponding to the selected input samples. \"\"\" indices = np . random . choice ( len ( dataset ), self . samples_per_task , replace = False ) samples = [ dataset [ i ] for i in indices ] return samples def on_before_fit ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ) -> None : \"\"\"Retrieves and diplays in a single plot the input images from all tasks of the benchmark that the algorithm has been initialized with. The final plot is saved via the loggers. Args: algo (BaseAlgorithm): The BaseAlgorithm instance. \"\"\" datasets = algo . benchmark . trains num_tasks = algo . num_tasks samples = [] for dataset in datasets . values (): task_samples = self . select_random_samples ( dataset ) samples . append ( task_samples ) s = 2 figure , axes = plt . subplots ( nrows = num_tasks , ncols = self . samples_per_task , figsize = ( s * self . samples_per_task , s * num_tasks ), ) for i , task_samples in enumerate ( samples ): for j , ( x , y , t ) in enumerate ( task_samples ): if x . dim () == 2 : x = x . unsqueeze ( 0 ) axes [ i ][ j ] . imshow ( x . permute ( 1 , 2 , 0 )) axes [ i ][ j ] . title . set_text ( f \"t= { t } : y= { y } \" ) plt . setp ( axes , xticks = [], yticks = []) figure . subplots_adjust ( wspace = 0.5 ) # save the plot via the algorithm loggers algo . log_figure ( name = \"input/viz\" , figure = figure )","title":"InputVisualizationCallback"},{"location":"utils/callbacks/input_visualization_callback/#sequel.utils.callbacks.input_visualization_callback.InputVisualizationCallback.__init__","text":"Inits the InputVisualizationCallback. Parameters: Name Type Description Default samples_per_task int number of samples to be saved for each tasks. Defaults to 5. 5 Source code in sequel/utils/callbacks/input_visualization_callback.py 16 17 18 19 20 21 22 23 def __init__ ( self , samples_per_task = 5 ): \"\"\"Inits the InputVisualizationCallback. Args: samples_per_task (int, optional): number of samples to be saved for each tasks. Defaults to 5. \"\"\" super () . __init__ () self . samples_per_task = samples_per_task","title":"__init__()"},{"location":"utils/callbacks/input_visualization_callback/#sequel.utils.callbacks.input_visualization_callback.InputVisualizationCallback.on_before_fit","text":"Retrieves and diplays in a single plot the input images from all tasks of the benchmark that the algorithm has been initialized with. The final plot is saved via the loggers. Parameters: Name Type Description Default algo BaseAlgorithm The BaseAlgorithm instance. required Source code in sequel/utils/callbacks/input_visualization_callback.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 def on_before_fit ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ) -> None : \"\"\"Retrieves and diplays in a single plot the input images from all tasks of the benchmark that the algorithm has been initialized with. The final plot is saved via the loggers. Args: algo (BaseAlgorithm): The BaseAlgorithm instance. \"\"\" datasets = algo . benchmark . trains num_tasks = algo . num_tasks samples = [] for dataset in datasets . values (): task_samples = self . select_random_samples ( dataset ) samples . append ( task_samples ) s = 2 figure , axes = plt . subplots ( nrows = num_tasks , ncols = self . samples_per_task , figsize = ( s * self . samples_per_task , s * num_tasks ), ) for i , task_samples in enumerate ( samples ): for j , ( x , y , t ) in enumerate ( task_samples ): if x . dim () == 2 : x = x . unsqueeze ( 0 ) axes [ i ][ j ] . imshow ( x . permute ( 1 , 2 , 0 )) axes [ i ][ j ] . title . set_text ( f \"t= { t } : y= { y } \" ) plt . setp ( axes , xticks = [], yticks = []) figure . subplots_adjust ( wspace = 0.5 ) # save the plot via the algorithm loggers algo . log_figure ( name = \"input/viz\" , figure = figure )","title":"on_before_fit()"},{"location":"utils/callbacks/input_visualization_callback/#sequel.utils.callbacks.input_visualization_callback.InputVisualizationCallback.select_random_samples","text":"Selects a prefefined number of samples per each CL dataset. Each task corresponds to a different dataset. Parameters: Name Type Description Default dataset torch . data . utils . Dataset The PyTorch Datatet. required Returns: Type Description List [ torch . Tensor ] List[torch.Tensor]: The Tensors corresponding to the selected input samples. Source code in sequel/utils/callbacks/input_visualization_callback.py 25 26 27 28 29 30 31 32 33 34 35 36 def select_random_samples ( self , dataset : torch . utils . data . Dataset ) -> List [ torch . Tensor ]: \"\"\"Selects a prefefined number of samples per each CL dataset. Each task corresponds to a different dataset. Args: dataset (torch.data.utils.Dataset): The PyTorch Datatet. Returns: List[torch.Tensor]: The Tensors corresponding to the selected input samples. \"\"\" indices = np . random . choice ( len ( dataset ), self . samples_per_task , replace = False ) samples = [ dataset [ i ] for i in indices ] return samples","title":"select_random_samples()"},{"location":"utils/callbacks/jax_metric_callback/","text":"JaxMetricCallback Bases: MetricCallback Handles the computation and logging of metrics. Callback hooks after train/val/test steps/epochs etc. Inherits from Callback. Source code in sequel/utils/callbacks/metrics/jax_metric_callback.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class JaxMetricCallback ( MetricCallback ): \"\"\"Handles the computation and logging of metrics. Callback hooks after train/val/test steps/epochs etc. Inherits from Callback. \"\"\" def __init__ ( self , metrics , logging_freq = 10 ): super () . __init__ ( metrics , logging_freq ) def on_before_fit ( self , algo : \"JaxBaseAlgorithm\" , * args , ** kwargs ): super () . on_before_fit ( algo , * args , ** kwargs ) self . forgetting = [ ForgettingMetric () for i in range ( self . num_tasks )] def identify_seen_tasks ( self , algo ) -> List [ int ]: return jnp . unique ( algo . t - 1 ) . tolist () def _reset_metrics ( self , prefix ): self . metrics = [ self . original_metrics . clone ( postfix = f \"/ { self . get_task_id ( i ) } \" , prefix = prefix ) for i in range ( self . num_tasks ) ] self . avg_loss = MeanMetric () def compute_mask ( self , algo , task_id ): mask = super () . compute_mask ( algo , task_id ) return np . array ( mask ) def on_after_val_step ( self , algo ): self . avg_loss ( algo . loss ) tasks_seen = self . identify_seen_tasks ( algo ) assert len ( tasks_seen ) == 1 task_id = tasks_seen [ 0 ] self . metrics [ task_id ]( algo . y_hat , algo . y ) if ( algo . batch_idx + 1 ) % self . logging_freq == 0 : msg : dict = self . metrics [ algo . current_val_task - 1 ] . compute () msg . update ({ \"val/avg_loss\" : self . avg_loss . compute ()}) msg = self . register_metric_callback_message ( msg , algo )","title":"JaxMetricCallback"},{"location":"utils/callbacks/jax_metric_callback/#sequel.utils.callbacks.metrics.jax_metric_callback.JaxMetricCallback","text":"Bases: MetricCallback Handles the computation and logging of metrics. Callback hooks after train/val/test steps/epochs etc. Inherits from Callback. Source code in sequel/utils/callbacks/metrics/jax_metric_callback.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class JaxMetricCallback ( MetricCallback ): \"\"\"Handles the computation and logging of metrics. Callback hooks after train/val/test steps/epochs etc. Inherits from Callback. \"\"\" def __init__ ( self , metrics , logging_freq = 10 ): super () . __init__ ( metrics , logging_freq ) def on_before_fit ( self , algo : \"JaxBaseAlgorithm\" , * args , ** kwargs ): super () . on_before_fit ( algo , * args , ** kwargs ) self . forgetting = [ ForgettingMetric () for i in range ( self . num_tasks )] def identify_seen_tasks ( self , algo ) -> List [ int ]: return jnp . unique ( algo . t - 1 ) . tolist () def _reset_metrics ( self , prefix ): self . metrics = [ self . original_metrics . clone ( postfix = f \"/ { self . get_task_id ( i ) } \" , prefix = prefix ) for i in range ( self . num_tasks ) ] self . avg_loss = MeanMetric () def compute_mask ( self , algo , task_id ): mask = super () . compute_mask ( algo , task_id ) return np . array ( mask ) def on_after_val_step ( self , algo ): self . avg_loss ( algo . loss ) tasks_seen = self . identify_seen_tasks ( algo ) assert len ( tasks_seen ) == 1 task_id = tasks_seen [ 0 ] self . metrics [ task_id ]( algo . y_hat , algo . y ) if ( algo . batch_idx + 1 ) % self . logging_freq == 0 : msg : dict = self . metrics [ algo . current_val_task - 1 ] . compute () msg . update ({ \"val/avg_loss\" : self . avg_loss . compute ()}) msg = self . register_metric_callback_message ( msg , algo )","title":"JaxMetricCallback"},{"location":"utils/callbacks/memory_callback/","text":"MemoryMechanismCallback Bases: AlgoCallback Wraps an AlgoCallback around the MemoryMechanism for ease of use. Source code in sequel/utils/callbacks/memory_callback.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class MemoryMechanismCallback ( AlgoCallback ): \"\"\"Wraps an AlgoCallback around the MemoryMechanism for ease of use.\"\"\" def __init__ ( self , per_task_memory_samples : int , groupby : str = \"class\" ): super () . __init__ () self . memory = MemoryMechanism ( per_task_memory_samples , groupby ) self . per_task_memory_samples = per_task_memory_samples self . groupby = groupby def on_after_training_task ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ): \"\"\"Updates the memory Mechanism. Args: algo (BaseAlgorithm): The current BaseAlgorithm instance. \"\"\" self . memory . update_memory ( algo ) algo . update_episodic_memory () on_after_training_task ( algo , * args , ** kwargs ) Updates the memory Mechanism. Parameters: Name Type Description Default algo BaseAlgorithm The current BaseAlgorithm instance. required Source code in sequel/utils/callbacks/memory_callback.py 19 20 21 22 23 24 25 26 def on_after_training_task ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ): \"\"\"Updates the memory Mechanism. Args: algo (BaseAlgorithm): The current BaseAlgorithm instance. \"\"\" self . memory . update_memory ( algo ) algo . update_episodic_memory ()","title":"MemoryCallback"},{"location":"utils/callbacks/memory_callback/#sequel.utils.callbacks.memory_callback.MemoryMechanismCallback","text":"Bases: AlgoCallback Wraps an AlgoCallback around the MemoryMechanism for ease of use. Source code in sequel/utils/callbacks/memory_callback.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class MemoryMechanismCallback ( AlgoCallback ): \"\"\"Wraps an AlgoCallback around the MemoryMechanism for ease of use.\"\"\" def __init__ ( self , per_task_memory_samples : int , groupby : str = \"class\" ): super () . __init__ () self . memory = MemoryMechanism ( per_task_memory_samples , groupby ) self . per_task_memory_samples = per_task_memory_samples self . groupby = groupby def on_after_training_task ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ): \"\"\"Updates the memory Mechanism. Args: algo (BaseAlgorithm): The current BaseAlgorithm instance. \"\"\" self . memory . update_memory ( algo ) algo . update_episodic_memory ()","title":"MemoryMechanismCallback"},{"location":"utils/callbacks/memory_callback/#sequel.utils.callbacks.memory_callback.MemoryMechanismCallback.on_after_training_task","text":"Updates the memory Mechanism. Parameters: Name Type Description Default algo BaseAlgorithm The current BaseAlgorithm instance. required Source code in sequel/utils/callbacks/memory_callback.py 19 20 21 22 23 24 25 26 def on_after_training_task ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ): \"\"\"Updates the memory Mechanism. Args: algo (BaseAlgorithm): The current BaseAlgorithm instance. \"\"\" self . memory . update_memory ( algo ) algo . update_episodic_memory ()","title":"on_after_training_task()"},{"location":"utils/callbacks/metric_callback/","text":"MetricCallback Bases: AlgoCallback MetricCallback is the parent clas for the PyTorch and Jax metric callbacks. Handles the computation of metrics during training, validation etc. Source code in sequel/utils/callbacks/metrics/metric_callback.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 class MetricCallback ( AlgoCallback ): \"\"\"MetricCallback is the parent clas for the PyTorch and Jax metric callbacks. Handles the computation of metrics during training, validation etc.\"\"\" forgetting : List [ Union [ torchmetrics . Metric , JaxMetric ]] def __init__ ( self , metrics , logging_freq = 10 ): super () . __init__ () self . logging_freq = logging_freq self . original_metrics = metrics . clone () def on_before_fit ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ): self . num_tasks = algo . num_tasks return super () . on_before_fit ( algo , * args , ** kwargs ) def _reset_metrics ( self , prefix ): raise NotImplementedError def log ( self , algo : \"BaseAlgorithm\" , key , value ): algo . log ({ key : value }) def get_task_id ( self , i ): return f \"task- { i } \" def register_metric_callback_message ( self , msg : dict , algo : \"BaseAlgorithm\" ): # some weird bug due to wandb. it adds _timestamp and _runtime to the msg dict msg = { k : v for k , v in msg . items () if not k . startswith ( \"_\" )} msg = { k . split ( \"/\" )[ 1 ]: safe_conversion ( v ) for k , v in msg . items ()} setattr ( algo , \"metric_callback_msg\" , msg ) return msg def identify_seen_tasks ( self , algo : \"BaseAlgorithm\" ) -> List [ int ]: raise NotImplementedError def compute_mask ( self , algo , task_id ): return ( algo . t - 1 ) == task_id # ------- STEPS ------- def on_after_training_step ( self , algo : \"BaseAlgorithm\" ): self . avg_loss ( algo . loss ) tasks_seen = self . identify_seen_tasks ( algo ) for task_id in tasks_seen : mask = self . compute_mask ( algo , task_id ) self . metrics [ task_id ]( algo . y_hat [ mask ], algo . y [ mask ]) if ( algo . batch_idx + 1 ) % self . logging_freq == 0 : msg : dict = self . metrics [ algo . task_counter - 1 ] . compute () msg . update ({ \"train/avg_loss\" : self . avg_loss . compute ()}) algo . log ( copy . deepcopy ( msg )) msg = self . register_metric_callback_message ( msg , algo ) def on_after_val_step ( self , algo : \"BaseAlgorithm\" ): self . avg_loss ( algo . loss ) tasks_seen = self . identify_seen_tasks ( algo ) for task_id in tasks_seen : mask = self . compute_mask ( algo , task_id ) self . metrics [ task_id ]( algo . y_hat [ mask ], algo . y [ mask ]) if ( algo . batch_idx + 1 ) % self . logging_freq == 0 : msg : dict = self . metrics [ algo . current_val_task - 1 ] . compute () msg . update ({ \"val/avg_loss\" : self . avg_loss . compute ()}) msg = self . register_metric_callback_message ( msg , algo ) # ------- EPOCHS - before ------- def on_before_training_epoch ( self , * args , ** kwargs ): self . _reset_metrics ( prefix = \"train/\" ) def on_before_val_epoch ( self , * args , ** kwargs ): self . _reset_metrics ( prefix = \"val/\" ) def on_before_testing_epoch ( self , * args , ** kwargs ): self . _reset_metrics ( prefix = \"test/\" ) def on_before_validating_algorithm_on_all_tasks ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ): self . metric_results = [] # ------- EPOCHS - after ------- def on_after_val_epoch ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ): res = self . metrics [ algo . current_val_task - 1 ] . compute () self . task_counter_metrics = res self . metric_results . append ( res ) to_log = copy . deepcopy ( res ) to_log [ \"epoch\" ] = algo . epoch_counter algo . log ( to_log ) key = list ( filter ( lambda x : \"acc\" in x , list ( self . task_counter_metrics . keys ())))[ 0 ] self . forgetting [ algo . current_val_task - 1 ]( self . task_counter_metrics [ key ]) def on_after_validating_algorithm_on_all_tasks ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ): forgetting = { f \"val/forgetting/task- { i + 1 } \" : safe_conversion ( k . compute ()) for i , k in enumerate ( self . forgetting ) if i < algo . task_counter } algo . log ( forgetting ) # compute averages avg = {} for key in self . original_metrics : temp = [[ v for k , v in m . items () if key in k ][ 0 ] for m in self . metric_results ] avg [ key ] = safe_conversion ( sum ( temp )) / len ( temp ) avg = { f \"avg/ { k } \" : v for k , v in avg . items ()} avg [ \"avg/forgetting\" ] = sum ( forgetting . values ()) / len ( forgetting ) algo . log ( avg ) # only print table at the end of fitting one task if algo . epoch_counter % algo . epochs == 0 : self . print_task_metrics ( self . metric_results , epoch = algo . epoch_counter ) else : logging . info ({ k : round ( v , 3 ) for k , v in avg . items ()}) logging . info ({ k : round ( safe_conversion ( v ), 3 ) for k , v in self . metric_results [ - 1 ] . items ()}) _metrics = dict ( ChainMap ( * self . metric_results )) _metrics = { k : round ( safe_conversion ( v ), 3 ) for k , v in _metrics . items ()} self . register_results_to_algo ( algo , \"val_metrics\" , _metrics ) def on_after_fit ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ): if algo . loggers is not None : for logger in algo . loggers : logger . log_all_results () def register_results_to_algo ( self , algo , results_name , results_dict ): setattr ( algo , results_name , results_dict ) def print_task_metrics ( self , metrics : list , epoch ): table = BeautifulTable ( default_alignment = BeautifulTable . ALIGN_LEFT , default_padding = 1 , maxwidth = 250 ) table . set_style ( BeautifulTable . STYLE_BOX_ROUNDED ) keys = list ( metrics [ 0 ] . keys ()) keys = [ k . split ( \"/\" )[ 1 ] for k in keys ] table . rows . header = keys for i , m in enumerate ( metrics ): column_name = f \"Task- { i + 1 } \" table . columns . append ( m . values (), header = column_name ) table . columns . alignment [ column_name ] = BeautifulTable . ALIGN_RIGHT avg = {} for key in keys : temp = [[ v for k , v in m . items () if key in k ][ 0 ] for m in metrics ] avg [ key ] = sum ( temp ) / len ( temp ) table . columns . append ( avg . values (), header = \"AVG\" ) table . columns . alignment [ \"AVG\" ] = BeautifulTable . ALIGN_RIGHT f = [ safe_conversion ( k . compute ()) for i , k in enumerate ( self . forgetting ) if i < len ( metrics )] f . append ( sum ( f ) / len ( f )) table . rows . append ( f , header = \"Forgetting\" ) logging . info ( f \"EVAL METRICS for epoch { epoch } : \\n { table } \" ) BackwardTranferMetric Bases: ForgettingMetric How much learning the current experience improves my performance on previous experiences? Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 53 54 55 56 57 class BackwardTranferMetric ( ForgettingMetric ): \"\"\"How much learning the current experience improves my performance on previous experiences?\"\"\" def compute ( self ): return - super () . compute () CrossEntropyLossMetric Bases: MeanMetric Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 15 16 17 18 19 20 21 22 23 24 25 26 27 class CrossEntropyLossMetric ( MeanMetric ): def update ( self , preds : torch . Tensor , target : torch . Tensor ) -> torch . Tensor : \"\"\"Wraps CrossEntropy into a torchmetrics MeanMetric. Args: preds (torch.Tensor): the logits of the current batch. target (torch.Tensor): the targets of the current batch. Returns: torch.Tensor: the computed cross-entropy loss. \"\"\" value = F . cross_entropy ( input = preds , target = target ) return super () . update ( value ) update ( preds , target ) Wraps CrossEntropy into a torchmetrics MeanMetric. Parameters: Name Type Description Default preds torch . Tensor the logits of the current batch. required target torch . Tensor the targets of the current batch. required Returns: Type Description torch . Tensor torch.Tensor: the computed cross-entropy loss. Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 16 17 18 19 20 21 22 23 24 25 26 27 def update ( self , preds : torch . Tensor , target : torch . Tensor ) -> torch . Tensor : \"\"\"Wraps CrossEntropy into a torchmetrics MeanMetric. Args: preds (torch.Tensor): the logits of the current batch. target (torch.Tensor): the targets of the current batch. Returns: torch.Tensor: the computed cross-entropy loss. \"\"\" value = F . cross_entropy ( input = preds , target = target ) return super () . update ( value ) PytorchMetricCallback Bases: MetricCallback Base class for the MetricCallback in case of PyTorch. Inherits from MetricCallback . Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 class PytorchMetricCallback ( MetricCallback ): \"\"\"Base class for the MetricCallback in case of PyTorch. Inherits from `MetricCallback`. \"\"\" def __init__ ( self , metrics : MetricCollection , logging_freq = 10 ): super () . __init__ ( metrics , logging_freq ) def on_before_fit ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ): super () . on_before_fit ( algo , * args , ** kwargs ) self . forgetting = [ ForgettingMetric () for i in range ( self . num_tasks )] def connect ( self , algo , * args , ** kwargs ): self . device = algo . device super () . connect ( algo , * args , ** kwargs ) def identify_seen_tasks ( self , algo ) -> List [ int ]: return torch . unique ( algo . t - 1 ) def _reset_metrics ( self , prefix ): self . metrics = nn . ModuleList ( self . original_metrics . clone ( postfix = f \"/ { self . get_task_id ( i ) } \" , prefix = prefix ) . to ( self . device ) for i in range ( self . num_tasks ) ) . to ( self . device ) self . avg_loss = MeanMetric ( prefix = prefix ) . to ( self . device ) StandardMetricCallback Bases: PytorchMetricCallback Defines the standard Metric Callback used for classificaiton. Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 88 89 90 91 92 93 94 95 96 97 98 class StandardMetricCallback ( PytorchMetricCallback ): \"\"\"Defines the standard Metric Callback used for classificaiton.\"\"\" def __init__ ( self , logging_freq = 1 ): metrics = torchmetrics . MetricCollection ( { \"acc\" : torchmetrics . Accuracy (), \"loss\" : CrossEntropyLossMetric (), }, ) super () . __init__ ( metrics , logging_freq ) JaxMetricCallback Bases: MetricCallback Handles the computation and logging of metrics. Callback hooks after train/val/test steps/epochs etc. Inherits from Callback. Source code in sequel/utils/callbacks/metrics/jax_metric_callback.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class JaxMetricCallback ( MetricCallback ): \"\"\"Handles the computation and logging of metrics. Callback hooks after train/val/test steps/epochs etc. Inherits from Callback. \"\"\" def __init__ ( self , metrics , logging_freq = 10 ): super () . __init__ ( metrics , logging_freq ) def on_before_fit ( self , algo : \"JaxBaseAlgorithm\" , * args , ** kwargs ): super () . on_before_fit ( algo , * args , ** kwargs ) self . forgetting = [ ForgettingMetric () for i in range ( self . num_tasks )] def identify_seen_tasks ( self , algo ) -> List [ int ]: return jnp . unique ( algo . t - 1 ) . tolist () def _reset_metrics ( self , prefix ): self . metrics = [ self . original_metrics . clone ( postfix = f \"/ { self . get_task_id ( i ) } \" , prefix = prefix ) for i in range ( self . num_tasks ) ] self . avg_loss = MeanMetric () def compute_mask ( self , algo , task_id ): mask = super () . compute_mask ( algo , task_id ) return np . array ( mask ) def on_after_val_step ( self , algo ): self . avg_loss ( algo . loss ) tasks_seen = self . identify_seen_tasks ( algo ) assert len ( tasks_seen ) == 1 task_id = tasks_seen [ 0 ] self . metrics [ task_id ]( algo . y_hat , algo . y ) if ( algo . batch_idx + 1 ) % self . logging_freq == 0 : msg : dict = self . metrics [ algo . current_val_task - 1 ] . compute () msg . update ({ \"val/avg_loss\" : self . avg_loss . compute ()}) msg = self . register_metric_callback_message ( msg , algo )","title":"MetricCallback"},{"location":"utils/callbacks/metric_callback/#sequel.utils.callbacks.metrics.metric_callback.MetricCallback","text":"Bases: AlgoCallback MetricCallback is the parent clas for the PyTorch and Jax metric callbacks. Handles the computation of metrics during training, validation etc. Source code in sequel/utils/callbacks/metrics/metric_callback.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 class MetricCallback ( AlgoCallback ): \"\"\"MetricCallback is the parent clas for the PyTorch and Jax metric callbacks. Handles the computation of metrics during training, validation etc.\"\"\" forgetting : List [ Union [ torchmetrics . Metric , JaxMetric ]] def __init__ ( self , metrics , logging_freq = 10 ): super () . __init__ () self . logging_freq = logging_freq self . original_metrics = metrics . clone () def on_before_fit ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ): self . num_tasks = algo . num_tasks return super () . on_before_fit ( algo , * args , ** kwargs ) def _reset_metrics ( self , prefix ): raise NotImplementedError def log ( self , algo : \"BaseAlgorithm\" , key , value ): algo . log ({ key : value }) def get_task_id ( self , i ): return f \"task- { i } \" def register_metric_callback_message ( self , msg : dict , algo : \"BaseAlgorithm\" ): # some weird bug due to wandb. it adds _timestamp and _runtime to the msg dict msg = { k : v for k , v in msg . items () if not k . startswith ( \"_\" )} msg = { k . split ( \"/\" )[ 1 ]: safe_conversion ( v ) for k , v in msg . items ()} setattr ( algo , \"metric_callback_msg\" , msg ) return msg def identify_seen_tasks ( self , algo : \"BaseAlgorithm\" ) -> List [ int ]: raise NotImplementedError def compute_mask ( self , algo , task_id ): return ( algo . t - 1 ) == task_id # ------- STEPS ------- def on_after_training_step ( self , algo : \"BaseAlgorithm\" ): self . avg_loss ( algo . loss ) tasks_seen = self . identify_seen_tasks ( algo ) for task_id in tasks_seen : mask = self . compute_mask ( algo , task_id ) self . metrics [ task_id ]( algo . y_hat [ mask ], algo . y [ mask ]) if ( algo . batch_idx + 1 ) % self . logging_freq == 0 : msg : dict = self . metrics [ algo . task_counter - 1 ] . compute () msg . update ({ \"train/avg_loss\" : self . avg_loss . compute ()}) algo . log ( copy . deepcopy ( msg )) msg = self . register_metric_callback_message ( msg , algo ) def on_after_val_step ( self , algo : \"BaseAlgorithm\" ): self . avg_loss ( algo . loss ) tasks_seen = self . identify_seen_tasks ( algo ) for task_id in tasks_seen : mask = self . compute_mask ( algo , task_id ) self . metrics [ task_id ]( algo . y_hat [ mask ], algo . y [ mask ]) if ( algo . batch_idx + 1 ) % self . logging_freq == 0 : msg : dict = self . metrics [ algo . current_val_task - 1 ] . compute () msg . update ({ \"val/avg_loss\" : self . avg_loss . compute ()}) msg = self . register_metric_callback_message ( msg , algo ) # ------- EPOCHS - before ------- def on_before_training_epoch ( self , * args , ** kwargs ): self . _reset_metrics ( prefix = \"train/\" ) def on_before_val_epoch ( self , * args , ** kwargs ): self . _reset_metrics ( prefix = \"val/\" ) def on_before_testing_epoch ( self , * args , ** kwargs ): self . _reset_metrics ( prefix = \"test/\" ) def on_before_validating_algorithm_on_all_tasks ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ): self . metric_results = [] # ------- EPOCHS - after ------- def on_after_val_epoch ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ): res = self . metrics [ algo . current_val_task - 1 ] . compute () self . task_counter_metrics = res self . metric_results . append ( res ) to_log = copy . deepcopy ( res ) to_log [ \"epoch\" ] = algo . epoch_counter algo . log ( to_log ) key = list ( filter ( lambda x : \"acc\" in x , list ( self . task_counter_metrics . keys ())))[ 0 ] self . forgetting [ algo . current_val_task - 1 ]( self . task_counter_metrics [ key ]) def on_after_validating_algorithm_on_all_tasks ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ): forgetting = { f \"val/forgetting/task- { i + 1 } \" : safe_conversion ( k . compute ()) for i , k in enumerate ( self . forgetting ) if i < algo . task_counter } algo . log ( forgetting ) # compute averages avg = {} for key in self . original_metrics : temp = [[ v for k , v in m . items () if key in k ][ 0 ] for m in self . metric_results ] avg [ key ] = safe_conversion ( sum ( temp )) / len ( temp ) avg = { f \"avg/ { k } \" : v for k , v in avg . items ()} avg [ \"avg/forgetting\" ] = sum ( forgetting . values ()) / len ( forgetting ) algo . log ( avg ) # only print table at the end of fitting one task if algo . epoch_counter % algo . epochs == 0 : self . print_task_metrics ( self . metric_results , epoch = algo . epoch_counter ) else : logging . info ({ k : round ( v , 3 ) for k , v in avg . items ()}) logging . info ({ k : round ( safe_conversion ( v ), 3 ) for k , v in self . metric_results [ - 1 ] . items ()}) _metrics = dict ( ChainMap ( * self . metric_results )) _metrics = { k : round ( safe_conversion ( v ), 3 ) for k , v in _metrics . items ()} self . register_results_to_algo ( algo , \"val_metrics\" , _metrics ) def on_after_fit ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ): if algo . loggers is not None : for logger in algo . loggers : logger . log_all_results () def register_results_to_algo ( self , algo , results_name , results_dict ): setattr ( algo , results_name , results_dict ) def print_task_metrics ( self , metrics : list , epoch ): table = BeautifulTable ( default_alignment = BeautifulTable . ALIGN_LEFT , default_padding = 1 , maxwidth = 250 ) table . set_style ( BeautifulTable . STYLE_BOX_ROUNDED ) keys = list ( metrics [ 0 ] . keys ()) keys = [ k . split ( \"/\" )[ 1 ] for k in keys ] table . rows . header = keys for i , m in enumerate ( metrics ): column_name = f \"Task- { i + 1 } \" table . columns . append ( m . values (), header = column_name ) table . columns . alignment [ column_name ] = BeautifulTable . ALIGN_RIGHT avg = {} for key in keys : temp = [[ v for k , v in m . items () if key in k ][ 0 ] for m in metrics ] avg [ key ] = sum ( temp ) / len ( temp ) table . columns . append ( avg . values (), header = \"AVG\" ) table . columns . alignment [ \"AVG\" ] = BeautifulTable . ALIGN_RIGHT f = [ safe_conversion ( k . compute ()) for i , k in enumerate ( self . forgetting ) if i < len ( metrics )] f . append ( sum ( f ) / len ( f )) table . rows . append ( f , header = \"Forgetting\" ) logging . info ( f \"EVAL METRICS for epoch { epoch } : \\n { table } \" )","title":"MetricCallback"},{"location":"utils/callbacks/metric_callback/#sequel.utils.callbacks.metrics.pytorch_metric_callback.BackwardTranferMetric","text":"Bases: ForgettingMetric How much learning the current experience improves my performance on previous experiences? Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 53 54 55 56 57 class BackwardTranferMetric ( ForgettingMetric ): \"\"\"How much learning the current experience improves my performance on previous experiences?\"\"\" def compute ( self ): return - super () . compute ()","title":"BackwardTranferMetric"},{"location":"utils/callbacks/metric_callback/#sequel.utils.callbacks.metrics.pytorch_metric_callback.CrossEntropyLossMetric","text":"Bases: MeanMetric Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 15 16 17 18 19 20 21 22 23 24 25 26 27 class CrossEntropyLossMetric ( MeanMetric ): def update ( self , preds : torch . Tensor , target : torch . Tensor ) -> torch . Tensor : \"\"\"Wraps CrossEntropy into a torchmetrics MeanMetric. Args: preds (torch.Tensor): the logits of the current batch. target (torch.Tensor): the targets of the current batch. Returns: torch.Tensor: the computed cross-entropy loss. \"\"\" value = F . cross_entropy ( input = preds , target = target ) return super () . update ( value )","title":"CrossEntropyLossMetric"},{"location":"utils/callbacks/metric_callback/#sequel.utils.callbacks.metrics.pytorch_metric_callback.CrossEntropyLossMetric.update","text":"Wraps CrossEntropy into a torchmetrics MeanMetric. Parameters: Name Type Description Default preds torch . Tensor the logits of the current batch. required target torch . Tensor the targets of the current batch. required Returns: Type Description torch . Tensor torch.Tensor: the computed cross-entropy loss. Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 16 17 18 19 20 21 22 23 24 25 26 27 def update ( self , preds : torch . Tensor , target : torch . Tensor ) -> torch . Tensor : \"\"\"Wraps CrossEntropy into a torchmetrics MeanMetric. Args: preds (torch.Tensor): the logits of the current batch. target (torch.Tensor): the targets of the current batch. Returns: torch.Tensor: the computed cross-entropy loss. \"\"\" value = F . cross_entropy ( input = preds , target = target ) return super () . update ( value )","title":"update()"},{"location":"utils/callbacks/metric_callback/#sequel.utils.callbacks.metrics.pytorch_metric_callback.PytorchMetricCallback","text":"Bases: MetricCallback Base class for the MetricCallback in case of PyTorch. Inherits from MetricCallback . Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 class PytorchMetricCallback ( MetricCallback ): \"\"\"Base class for the MetricCallback in case of PyTorch. Inherits from `MetricCallback`. \"\"\" def __init__ ( self , metrics : MetricCollection , logging_freq = 10 ): super () . __init__ ( metrics , logging_freq ) def on_before_fit ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ): super () . on_before_fit ( algo , * args , ** kwargs ) self . forgetting = [ ForgettingMetric () for i in range ( self . num_tasks )] def connect ( self , algo , * args , ** kwargs ): self . device = algo . device super () . connect ( algo , * args , ** kwargs ) def identify_seen_tasks ( self , algo ) -> List [ int ]: return torch . unique ( algo . t - 1 ) def _reset_metrics ( self , prefix ): self . metrics = nn . ModuleList ( self . original_metrics . clone ( postfix = f \"/ { self . get_task_id ( i ) } \" , prefix = prefix ) . to ( self . device ) for i in range ( self . num_tasks ) ) . to ( self . device ) self . avg_loss = MeanMetric ( prefix = prefix ) . to ( self . device )","title":"PytorchMetricCallback"},{"location":"utils/callbacks/metric_callback/#sequel.utils.callbacks.metrics.pytorch_metric_callback.StandardMetricCallback","text":"Bases: PytorchMetricCallback Defines the standard Metric Callback used for classificaiton. Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 88 89 90 91 92 93 94 95 96 97 98 class StandardMetricCallback ( PytorchMetricCallback ): \"\"\"Defines the standard Metric Callback used for classificaiton.\"\"\" def __init__ ( self , logging_freq = 1 ): metrics = torchmetrics . MetricCollection ( { \"acc\" : torchmetrics . Accuracy (), \"loss\" : CrossEntropyLossMetric (), }, ) super () . __init__ ( metrics , logging_freq )","title":"StandardMetricCallback"},{"location":"utils/callbacks/metric_callback/#sequel.utils.callbacks.metrics.jax_metric_callback.JaxMetricCallback","text":"Bases: MetricCallback Handles the computation and logging of metrics. Callback hooks after train/val/test steps/epochs etc. Inherits from Callback. Source code in sequel/utils/callbacks/metrics/jax_metric_callback.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class JaxMetricCallback ( MetricCallback ): \"\"\"Handles the computation and logging of metrics. Callback hooks after train/val/test steps/epochs etc. Inherits from Callback. \"\"\" def __init__ ( self , metrics , logging_freq = 10 ): super () . __init__ ( metrics , logging_freq ) def on_before_fit ( self , algo : \"JaxBaseAlgorithm\" , * args , ** kwargs ): super () . on_before_fit ( algo , * args , ** kwargs ) self . forgetting = [ ForgettingMetric () for i in range ( self . num_tasks )] def identify_seen_tasks ( self , algo ) -> List [ int ]: return jnp . unique ( algo . t - 1 ) . tolist () def _reset_metrics ( self , prefix ): self . metrics = [ self . original_metrics . clone ( postfix = f \"/ { self . get_task_id ( i ) } \" , prefix = prefix ) for i in range ( self . num_tasks ) ] self . avg_loss = MeanMetric () def compute_mask ( self , algo , task_id ): mask = super () . compute_mask ( algo , task_id ) return np . array ( mask ) def on_after_val_step ( self , algo ): self . avg_loss ( algo . loss ) tasks_seen = self . identify_seen_tasks ( algo ) assert len ( tasks_seen ) == 1 task_id = tasks_seen [ 0 ] self . metrics [ task_id ]( algo . y_hat , algo . y ) if ( algo . batch_idx + 1 ) % self . logging_freq == 0 : msg : dict = self . metrics [ algo . current_val_task - 1 ] . compute () msg . update ({ \"val/avg_loss\" : self . avg_loss . compute ()}) msg = self . register_metric_callback_message ( msg , algo )","title":"JaxMetricCallback"},{"location":"utils/callbacks/pytorch_metric_callback/","text":"BackwardTranferMetric Bases: ForgettingMetric How much learning the current experience improves my performance on previous experiences? Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 53 54 55 56 57 class BackwardTranferMetric ( ForgettingMetric ): \"\"\"How much learning the current experience improves my performance on previous experiences?\"\"\" def compute ( self ): return - super () . compute () CrossEntropyLossMetric Bases: MeanMetric Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 15 16 17 18 19 20 21 22 23 24 25 26 27 class CrossEntropyLossMetric ( MeanMetric ): def update ( self , preds : torch . Tensor , target : torch . Tensor ) -> torch . Tensor : \"\"\"Wraps CrossEntropy into a torchmetrics MeanMetric. Args: preds (torch.Tensor): the logits of the current batch. target (torch.Tensor): the targets of the current batch. Returns: torch.Tensor: the computed cross-entropy loss. \"\"\" value = F . cross_entropy ( input = preds , target = target ) return super () . update ( value ) update ( preds , target ) Wraps CrossEntropy into a torchmetrics MeanMetric. Parameters: Name Type Description Default preds torch . Tensor the logits of the current batch. required target torch . Tensor the targets of the current batch. required Returns: Type Description torch . Tensor torch.Tensor: the computed cross-entropy loss. Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 16 17 18 19 20 21 22 23 24 25 26 27 def update ( self , preds : torch . Tensor , target : torch . Tensor ) -> torch . Tensor : \"\"\"Wraps CrossEntropy into a torchmetrics MeanMetric. Args: preds (torch.Tensor): the logits of the current batch. target (torch.Tensor): the targets of the current batch. Returns: torch.Tensor: the computed cross-entropy loss. \"\"\" value = F . cross_entropy ( input = preds , target = target ) return super () . update ( value ) PytorchMetricCallback Bases: MetricCallback Base class for the MetricCallback in case of PyTorch. Inherits from MetricCallback . Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 class PytorchMetricCallback ( MetricCallback ): \"\"\"Base class for the MetricCallback in case of PyTorch. Inherits from `MetricCallback`. \"\"\" def __init__ ( self , metrics : MetricCollection , logging_freq = 10 ): super () . __init__ ( metrics , logging_freq ) def on_before_fit ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ): super () . on_before_fit ( algo , * args , ** kwargs ) self . forgetting = [ ForgettingMetric () for i in range ( self . num_tasks )] def connect ( self , algo , * args , ** kwargs ): self . device = algo . device super () . connect ( algo , * args , ** kwargs ) def identify_seen_tasks ( self , algo ) -> List [ int ]: return torch . unique ( algo . t - 1 ) def _reset_metrics ( self , prefix ): self . metrics = nn . ModuleList ( self . original_metrics . clone ( postfix = f \"/ { self . get_task_id ( i ) } \" , prefix = prefix ) . to ( self . device ) for i in range ( self . num_tasks ) ) . to ( self . device ) self . avg_loss = MeanMetric ( prefix = prefix ) . to ( self . device ) StandardMetricCallback Bases: PytorchMetricCallback Defines the standard Metric Callback used for classificaiton. Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 88 89 90 91 92 93 94 95 96 97 98 class StandardMetricCallback ( PytorchMetricCallback ): \"\"\"Defines the standard Metric Callback used for classificaiton.\"\"\" def __init__ ( self , logging_freq = 1 ): metrics = torchmetrics . MetricCollection ( { \"acc\" : torchmetrics . Accuracy (), \"loss\" : CrossEntropyLossMetric (), }, ) super () . __init__ ( metrics , logging_freq )","title":"PytorchMetricCallback"},{"location":"utils/callbacks/pytorch_metric_callback/#sequel.utils.callbacks.metrics.pytorch_metric_callback.BackwardTranferMetric","text":"Bases: ForgettingMetric How much learning the current experience improves my performance on previous experiences? Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 53 54 55 56 57 class BackwardTranferMetric ( ForgettingMetric ): \"\"\"How much learning the current experience improves my performance on previous experiences?\"\"\" def compute ( self ): return - super () . compute ()","title":"BackwardTranferMetric"},{"location":"utils/callbacks/pytorch_metric_callback/#sequel.utils.callbacks.metrics.pytorch_metric_callback.CrossEntropyLossMetric","text":"Bases: MeanMetric Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 15 16 17 18 19 20 21 22 23 24 25 26 27 class CrossEntropyLossMetric ( MeanMetric ): def update ( self , preds : torch . Tensor , target : torch . Tensor ) -> torch . Tensor : \"\"\"Wraps CrossEntropy into a torchmetrics MeanMetric. Args: preds (torch.Tensor): the logits of the current batch. target (torch.Tensor): the targets of the current batch. Returns: torch.Tensor: the computed cross-entropy loss. \"\"\" value = F . cross_entropy ( input = preds , target = target ) return super () . update ( value )","title":"CrossEntropyLossMetric"},{"location":"utils/callbacks/pytorch_metric_callback/#sequel.utils.callbacks.metrics.pytorch_metric_callback.CrossEntropyLossMetric.update","text":"Wraps CrossEntropy into a torchmetrics MeanMetric. Parameters: Name Type Description Default preds torch . Tensor the logits of the current batch. required target torch . Tensor the targets of the current batch. required Returns: Type Description torch . Tensor torch.Tensor: the computed cross-entropy loss. Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 16 17 18 19 20 21 22 23 24 25 26 27 def update ( self , preds : torch . Tensor , target : torch . Tensor ) -> torch . Tensor : \"\"\"Wraps CrossEntropy into a torchmetrics MeanMetric. Args: preds (torch.Tensor): the logits of the current batch. target (torch.Tensor): the targets of the current batch. Returns: torch.Tensor: the computed cross-entropy loss. \"\"\" value = F . cross_entropy ( input = preds , target = target ) return super () . update ( value )","title":"update()"},{"location":"utils/callbacks/pytorch_metric_callback/#sequel.utils.callbacks.metrics.pytorch_metric_callback.PytorchMetricCallback","text":"Bases: MetricCallback Base class for the MetricCallback in case of PyTorch. Inherits from MetricCallback . Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 class PytorchMetricCallback ( MetricCallback ): \"\"\"Base class for the MetricCallback in case of PyTorch. Inherits from `MetricCallback`. \"\"\" def __init__ ( self , metrics : MetricCollection , logging_freq = 10 ): super () . __init__ ( metrics , logging_freq ) def on_before_fit ( self , algo : \"BaseAlgorithm\" , * args , ** kwargs ): super () . on_before_fit ( algo , * args , ** kwargs ) self . forgetting = [ ForgettingMetric () for i in range ( self . num_tasks )] def connect ( self , algo , * args , ** kwargs ): self . device = algo . device super () . connect ( algo , * args , ** kwargs ) def identify_seen_tasks ( self , algo ) -> List [ int ]: return torch . unique ( algo . t - 1 ) def _reset_metrics ( self , prefix ): self . metrics = nn . ModuleList ( self . original_metrics . clone ( postfix = f \"/ { self . get_task_id ( i ) } \" , prefix = prefix ) . to ( self . device ) for i in range ( self . num_tasks ) ) . to ( self . device ) self . avg_loss = MeanMetric ( prefix = prefix ) . to ( self . device )","title":"PytorchMetricCallback"},{"location":"utils/callbacks/pytorch_metric_callback/#sequel.utils.callbacks.metrics.pytorch_metric_callback.StandardMetricCallback","text":"Bases: PytorchMetricCallback Defines the standard Metric Callback used for classificaiton. Source code in sequel/utils/callbacks/metrics/pytorch_metric_callback.py 88 89 90 91 92 93 94 95 96 97 98 class StandardMetricCallback ( PytorchMetricCallback ): \"\"\"Defines the standard Metric Callback used for classificaiton.\"\"\" def __init__ ( self , logging_freq = 1 ): metrics = torchmetrics . MetricCollection ( { \"acc\" : torchmetrics . Accuracy (), \"loss\" : CrossEntropyLossMetric (), }, ) super () . __init__ ( metrics , logging_freq )","title":"StandardMetricCallback"},{"location":"utils/loggers/base_logger/","text":"Logger Bases: abc . ABC The base class of the Logger Module. ALl loging services, such as TensorBoard of Weights and Biases, implement their own logger modules which are children of this class. This class shows the API of all loggers. The logger module is invoked by the Algorithm class via the homonym methods. Source code in sequel/utils/loggers/base_logger.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 class Logger ( abc . ABC ): \"\"\"The base class of the Logger Module. ALl loging services, such as TensorBoard of Weights and Biases, implement their own logger modules which are children of this class. This class shows the API of all loggers. The logger module is invoked by the [`Algorithm class`][sequel.algos.base_algo.BaseAlgorithm] via the homonym methods. \"\"\" def __init__ ( self ): \"\"\"Inits the base class for the Loggers module.\"\"\" pass def log ( self , item , step = None , epoch = None ): raise NotImplementedError def log_parameters ( self , config : dict ): raise NotImplementedError def log_code ( self ): raise NotImplementedError def log_figure ( self , figure , name , step = None , epoch = None ): raise NotImplementedError def terminate ( self ): raise NotImplementedError def log_all_results ( self ): pass __init__ () Inits the base class for the Loggers module. Source code in sequel/utils/loggers/base_logger.py 12 13 14 def __init__ ( self ): \"\"\"Inits the base class for the Loggers module.\"\"\" pass","title":"BaseLogger"},{"location":"utils/loggers/base_logger/#sequel.utils.loggers.base_logger.Logger","text":"Bases: abc . ABC The base class of the Logger Module. ALl loging services, such as TensorBoard of Weights and Biases, implement their own logger modules which are children of this class. This class shows the API of all loggers. The logger module is invoked by the Algorithm class via the homonym methods. Source code in sequel/utils/loggers/base_logger.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 class Logger ( abc . ABC ): \"\"\"The base class of the Logger Module. ALl loging services, such as TensorBoard of Weights and Biases, implement their own logger modules which are children of this class. This class shows the API of all loggers. The logger module is invoked by the [`Algorithm class`][sequel.algos.base_algo.BaseAlgorithm] via the homonym methods. \"\"\" def __init__ ( self ): \"\"\"Inits the base class for the Loggers module.\"\"\" pass def log ( self , item , step = None , epoch = None ): raise NotImplementedError def log_parameters ( self , config : dict ): raise NotImplementedError def log_code ( self ): raise NotImplementedError def log_figure ( self , figure , name , step = None , epoch = None ): raise NotImplementedError def terminate ( self ): raise NotImplementedError def log_all_results ( self ): pass","title":"Logger"},{"location":"utils/loggers/base_logger/#sequel.utils.loggers.base_logger.Logger.__init__","text":"Inits the base class for the Loggers module. Source code in sequel/utils/loggers/base_logger.py 12 13 14 def __init__ ( self ): \"\"\"Inits the base class for the Loggers module.\"\"\" pass","title":"__init__()"},{"location":"utils/loggers/comet_logger/","text":"CometLogger Bases: Logger Comet Logger. Handles the logging for the Comet service. Inherits from Logger. Source code in sequel/utils/loggers/comet_logger.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 class CometLogger ( Logger ): \"\"\"[Comet](https://www.comet.com/docs/v2/) Logger. Handles the logging for the Comet service. Inherits from Logger. \"\"\" def __init__ ( self , config : omegaconf . OmegaConf , api_key : Optional [ str ] = None ): \"\"\"Inits the CometLogger class. Args: config (omegaconf.OmegaConf): The experiment config file. It is automatically logged to Comet. api_key (Optional[str], optional): The COMET api key. If None, the API is inferred via the environment variables. Defaults to None. Raises: KeyError: If the `api_key` is None and the `COMET_API_KEY` environment variable is not set. \"\"\" super () . __init__ () self . config = config if api_key is None : if os . environ . get ( \"COMET_API_KEY\" ) is None : raise KeyError ( \"The COMET_API_KEY has not been set up as an environment variable. In order to add the \" \"COMET_API_KEY to the environment variables, run in your terminal: \" \"export COMET_API_KEY='YOUR_API_TOKEN'.\" ) else : api_key = os . environ . get ( \"COMET_API_KEY\" ) self . experiment = Experiment ( api_key = api_key , project_name = \"rot-mnist-20\" , display_summary_level = 0 , ) self . log_parameters ( config ) self . log_code () def log ( self , item , step = None , epoch = None ): self . experiment . log_metrics ( item , step = step , epoch = epoch ) def log_figure ( self , figure , name , step = None , epoch = None ): self . experiment . log_image ( figure , name = name , step = step ) def log_code ( self ): self . experiment . log_code ( folder = get_original_source_code_root_dir ()) def log_parameters ( self , config : dict ): self . experiment . log_parameters ( convert_omegaconf_to_flat_dict ( config )) def terminate ( self ): pass __init__ ( config , api_key = None ) Inits the CometLogger class. Parameters: Name Type Description Default config omegaconf . OmegaConf The experiment config file. It is automatically logged to Comet. required api_key Optional [ str ] The COMET api key. If None, the API is inferred via the environment variables. Defaults to None. None Raises: Type Description KeyError If the api_key is None and the COMET_API_KEY environment variable is not set. Source code in sequel/utils/loggers/comet_logger.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , config : omegaconf . OmegaConf , api_key : Optional [ str ] = None ): \"\"\"Inits the CometLogger class. Args: config (omegaconf.OmegaConf): The experiment config file. It is automatically logged to Comet. api_key (Optional[str], optional): The COMET api key. If None, the API is inferred via the environment variables. Defaults to None. Raises: KeyError: If the `api_key` is None and the `COMET_API_KEY` environment variable is not set. \"\"\" super () . __init__ () self . config = config if api_key is None : if os . environ . get ( \"COMET_API_KEY\" ) is None : raise KeyError ( \"The COMET_API_KEY has not been set up as an environment variable. In order to add the \" \"COMET_API_KEY to the environment variables, run in your terminal: \" \"export COMET_API_KEY='YOUR_API_TOKEN'.\" ) else : api_key = os . environ . get ( \"COMET_API_KEY\" ) self . experiment = Experiment ( api_key = api_key , project_name = \"rot-mnist-20\" , display_summary_level = 0 , ) self . log_parameters ( config ) self . log_code ()","title":"CometLogger"},{"location":"utils/loggers/comet_logger/#sequel.utils.loggers.comet_logger.CometLogger","text":"Bases: Logger Comet Logger. Handles the logging for the Comet service. Inherits from Logger. Source code in sequel/utils/loggers/comet_logger.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 class CometLogger ( Logger ): \"\"\"[Comet](https://www.comet.com/docs/v2/) Logger. Handles the logging for the Comet service. Inherits from Logger. \"\"\" def __init__ ( self , config : omegaconf . OmegaConf , api_key : Optional [ str ] = None ): \"\"\"Inits the CometLogger class. Args: config (omegaconf.OmegaConf): The experiment config file. It is automatically logged to Comet. api_key (Optional[str], optional): The COMET api key. If None, the API is inferred via the environment variables. Defaults to None. Raises: KeyError: If the `api_key` is None and the `COMET_API_KEY` environment variable is not set. \"\"\" super () . __init__ () self . config = config if api_key is None : if os . environ . get ( \"COMET_API_KEY\" ) is None : raise KeyError ( \"The COMET_API_KEY has not been set up as an environment variable. In order to add the \" \"COMET_API_KEY to the environment variables, run in your terminal: \" \"export COMET_API_KEY='YOUR_API_TOKEN'.\" ) else : api_key = os . environ . get ( \"COMET_API_KEY\" ) self . experiment = Experiment ( api_key = api_key , project_name = \"rot-mnist-20\" , display_summary_level = 0 , ) self . log_parameters ( config ) self . log_code () def log ( self , item , step = None , epoch = None ): self . experiment . log_metrics ( item , step = step , epoch = epoch ) def log_figure ( self , figure , name , step = None , epoch = None ): self . experiment . log_image ( figure , name = name , step = step ) def log_code ( self ): self . experiment . log_code ( folder = get_original_source_code_root_dir ()) def log_parameters ( self , config : dict ): self . experiment . log_parameters ( convert_omegaconf_to_flat_dict ( config )) def terminate ( self ): pass","title":"CometLogger"},{"location":"utils/loggers/comet_logger/#sequel.utils.loggers.comet_logger.CometLogger.__init__","text":"Inits the CometLogger class. Parameters: Name Type Description Default config omegaconf . OmegaConf The experiment config file. It is automatically logged to Comet. required api_key Optional [ str ] The COMET api key. If None, the API is inferred via the environment variables. Defaults to None. None Raises: Type Description KeyError If the api_key is None and the COMET_API_KEY environment variable is not set. Source code in sequel/utils/loggers/comet_logger.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , config : omegaconf . OmegaConf , api_key : Optional [ str ] = None ): \"\"\"Inits the CometLogger class. Args: config (omegaconf.OmegaConf): The experiment config file. It is automatically logged to Comet. api_key (Optional[str], optional): The COMET api key. If None, the API is inferred via the environment variables. Defaults to None. Raises: KeyError: If the `api_key` is None and the `COMET_API_KEY` environment variable is not set. \"\"\" super () . __init__ () self . config = config if api_key is None : if os . environ . get ( \"COMET_API_KEY\" ) is None : raise KeyError ( \"The COMET_API_KEY has not been set up as an environment variable. In order to add the \" \"COMET_API_KEY to the environment variables, run in your terminal: \" \"export COMET_API_KEY='YOUR_API_TOKEN'.\" ) else : api_key = os . environ . get ( \"COMET_API_KEY\" ) self . experiment = Experiment ( api_key = api_key , project_name = \"rot-mnist-20\" , display_summary_level = 0 , ) self . log_parameters ( config ) self . log_code ()","title":"__init__()"},{"location":"utils/loggers/console_logger/","text":"LocalLogger Bases: Logger Handles the local logging; the metrics are saved in local .npy files. Inherits from Logger. Note The LocalLogger does not handle hyperparameter/config file saving. Source code in sequel/utils/loggers/console_logger.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 class LocalLogger ( Logger ): \"\"\"Handles the local logging; the metrics are saved in local .npy files. Inherits from Logger. Note: The LocalLogger does not handle hyperparameter/config file saving. \"\"\" def __init__ ( self ): \"\"\"Inits the LocalLogger.\"\"\" super () . __init__ () self . metric_history = MetricHistory () def log ( self , item , step = None , epoch = None ): self . metric_history . update ( item ) def log_figure ( self , figure , name , step = None , epoch = None ): pass def log_all_results ( self ): \"\"\"Saves the results in the .npy format. This method should be called after fitting. \"\"\" print ( f \"Saving in { get_experiment_root_dir () } \" ) self . metric_history . save_metrics ( root_dir = get_experiment_root_dir ()) __init__ () Inits the LocalLogger. Source code in sequel/utils/loggers/console_logger.py 53 54 55 56 def __init__ ( self ): \"\"\"Inits the LocalLogger.\"\"\" super () . __init__ () self . metric_history = MetricHistory () log_all_results () Saves the results in the .npy format. This method should be called after fitting. Source code in sequel/utils/loggers/console_logger.py 64 65 66 67 68 69 70 def log_all_results ( self ): \"\"\"Saves the results in the .npy format. This method should be called after fitting. \"\"\" print ( f \"Saving in { get_experiment_root_dir () } \" ) self . metric_history . save_metrics ( root_dir = get_experiment_root_dir ())","title":"ConsoleLogger"},{"location":"utils/loggers/console_logger/#sequel.utils.loggers.console_logger.LocalLogger","text":"Bases: Logger Handles the local logging; the metrics are saved in local .npy files. Inherits from Logger. Note The LocalLogger does not handle hyperparameter/config file saving. Source code in sequel/utils/loggers/console_logger.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 class LocalLogger ( Logger ): \"\"\"Handles the local logging; the metrics are saved in local .npy files. Inherits from Logger. Note: The LocalLogger does not handle hyperparameter/config file saving. \"\"\" def __init__ ( self ): \"\"\"Inits the LocalLogger.\"\"\" super () . __init__ () self . metric_history = MetricHistory () def log ( self , item , step = None , epoch = None ): self . metric_history . update ( item ) def log_figure ( self , figure , name , step = None , epoch = None ): pass def log_all_results ( self ): \"\"\"Saves the results in the .npy format. This method should be called after fitting. \"\"\" print ( f \"Saving in { get_experiment_root_dir () } \" ) self . metric_history . save_metrics ( root_dir = get_experiment_root_dir ())","title":"LocalLogger"},{"location":"utils/loggers/console_logger/#sequel.utils.loggers.console_logger.LocalLogger.__init__","text":"Inits the LocalLogger. Source code in sequel/utils/loggers/console_logger.py 53 54 55 56 def __init__ ( self ): \"\"\"Inits the LocalLogger.\"\"\" super () . __init__ () self . metric_history = MetricHistory ()","title":"__init__()"},{"location":"utils/loggers/console_logger/#sequel.utils.loggers.console_logger.LocalLogger.log_all_results","text":"Saves the results in the .npy format. This method should be called after fitting. Source code in sequel/utils/loggers/console_logger.py 64 65 66 67 68 69 70 def log_all_results ( self ): \"\"\"Saves the results in the .npy format. This method should be called after fitting. \"\"\" print ( f \"Saving in { get_experiment_root_dir () } \" ) self . metric_history . save_metrics ( root_dir = get_experiment_root_dir ())","title":"log_all_results()"},{"location":"utils/loggers/tensorboard_logger/","text":"","title":"TensorBoardLogger"},{"location":"utils/loggers/wandb_logger/","text":"WandbLogger Bases: Logger Source code in sequel/utils/loggers/wandb_logger.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 class WandbLogger ( Logger ): def __init__ ( self , config : Optional [ OmegaConf ] = None , disabled : bool = False ): \"\"\"Inits the Weights & Biases Logger. The class handles the initialization of the experiment, saving of source code, and metric tracking. Args: config (Optional[OmegaConf], optional): The configuration of the current experiment. Defaults to None. disabled (bool, optional): A utility boolean to quickly disable Weight&Biases logging. Useful when debugging. Defaults to False. \"\"\" super () . __init__ () if config is None and not disabled : wandb . init () elif config is None and disabled : wandb . init ( mode = \"disabled\" ) else : if disabled : mode = \"disabled\" else : mode = getattr ( config . wandb , \"mode\" , \"disabled\" ) wandb . init ( entity = config . wandb . entity , project = config . wandb . project , config = OmegaConf . to_container ( config ), tags = getattr ( config . wandb , \"tags\" , []), mode = mode , group = getattr ( config . wandb , \"group\" , None ), name = getattr ( config . wandb , \"name\" , None ), ) self . log_code () # make sure that validation metrics are logged with epoch as the x-axis wandb . define_metric ( \"epoch\" ) wandb . define_metric ( \"val/*\" , step_metric = \"epoch\" ) wandb . define_metric ( \"val/accuracy/*\" , step_metric = \"epoch\" ) wandb . define_metric ( \"val/loss/*\" , step_metric = \"epoch\" ) def log ( self , item , step = None , epoch = None ): wandb . log ( item ) def log_code ( self ): wandb . run . log_code ( get_original_root_dir ()) def log_parameters ( self , config : dict ): # The hyperparameters are logged when calling `wandb.init` via the config argument. pass def log_figure ( self , figure , name , step = None , epoch = None ): wandb . log ({ name : wandb . Image ( figure )}) def terminate ( self ): wandb . finish () __init__ ( config = None , disabled = False ) Inits the Weights & Biases Logger. The class handles the initialization of the experiment, saving of source code, and metric tracking. Parameters: Name Type Description Default config Optional [ OmegaConf ] The configuration of the current experiment. Defaults to None. None disabled bool A utility boolean to quickly disable Weight&Biases logging. Useful when debugging. Defaults to False. False Source code in sequel/utils/loggers/wandb_logger.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def __init__ ( self , config : Optional [ OmegaConf ] = None , disabled : bool = False ): \"\"\"Inits the Weights & Biases Logger. The class handles the initialization of the experiment, saving of source code, and metric tracking. Args: config (Optional[OmegaConf], optional): The configuration of the current experiment. Defaults to None. disabled (bool, optional): A utility boolean to quickly disable Weight&Biases logging. Useful when debugging. Defaults to False. \"\"\" super () . __init__ () if config is None and not disabled : wandb . init () elif config is None and disabled : wandb . init ( mode = \"disabled\" ) else : if disabled : mode = \"disabled\" else : mode = getattr ( config . wandb , \"mode\" , \"disabled\" ) wandb . init ( entity = config . wandb . entity , project = config . wandb . project , config = OmegaConf . to_container ( config ), tags = getattr ( config . wandb , \"tags\" , []), mode = mode , group = getattr ( config . wandb , \"group\" , None ), name = getattr ( config . wandb , \"name\" , None ), ) self . log_code () # make sure that validation metrics are logged with epoch as the x-axis wandb . define_metric ( \"epoch\" ) wandb . define_metric ( \"val/*\" , step_metric = \"epoch\" ) wandb . define_metric ( \"val/accuracy/*\" , step_metric = \"epoch\" ) wandb . define_metric ( \"val/loss/*\" , step_metric = \"epoch\" )","title":"WandbLogger"},{"location":"utils/loggers/wandb_logger/#sequel.utils.loggers.wandb_logger.WandbLogger","text":"Bases: Logger Source code in sequel/utils/loggers/wandb_logger.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 class WandbLogger ( Logger ): def __init__ ( self , config : Optional [ OmegaConf ] = None , disabled : bool = False ): \"\"\"Inits the Weights & Biases Logger. The class handles the initialization of the experiment, saving of source code, and metric tracking. Args: config (Optional[OmegaConf], optional): The configuration of the current experiment. Defaults to None. disabled (bool, optional): A utility boolean to quickly disable Weight&Biases logging. Useful when debugging. Defaults to False. \"\"\" super () . __init__ () if config is None and not disabled : wandb . init () elif config is None and disabled : wandb . init ( mode = \"disabled\" ) else : if disabled : mode = \"disabled\" else : mode = getattr ( config . wandb , \"mode\" , \"disabled\" ) wandb . init ( entity = config . wandb . entity , project = config . wandb . project , config = OmegaConf . to_container ( config ), tags = getattr ( config . wandb , \"tags\" , []), mode = mode , group = getattr ( config . wandb , \"group\" , None ), name = getattr ( config . wandb , \"name\" , None ), ) self . log_code () # make sure that validation metrics are logged with epoch as the x-axis wandb . define_metric ( \"epoch\" ) wandb . define_metric ( \"val/*\" , step_metric = \"epoch\" ) wandb . define_metric ( \"val/accuracy/*\" , step_metric = \"epoch\" ) wandb . define_metric ( \"val/loss/*\" , step_metric = \"epoch\" ) def log ( self , item , step = None , epoch = None ): wandb . log ( item ) def log_code ( self ): wandb . run . log_code ( get_original_root_dir ()) def log_parameters ( self , config : dict ): # The hyperparameters are logged when calling `wandb.init` via the config argument. pass def log_figure ( self , figure , name , step = None , epoch = None ): wandb . log ({ name : wandb . Image ( figure )}) def terminate ( self ): wandb . finish ()","title":"WandbLogger"},{"location":"utils/loggers/wandb_logger/#sequel.utils.loggers.wandb_logger.WandbLogger.__init__","text":"Inits the Weights & Biases Logger. The class handles the initialization of the experiment, saving of source code, and metric tracking. Parameters: Name Type Description Default config Optional [ OmegaConf ] The configuration of the current experiment. Defaults to None. None disabled bool A utility boolean to quickly disable Weight&Biases logging. Useful when debugging. Defaults to False. False Source code in sequel/utils/loggers/wandb_logger.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def __init__ ( self , config : Optional [ OmegaConf ] = None , disabled : bool = False ): \"\"\"Inits the Weights & Biases Logger. The class handles the initialization of the experiment, saving of source code, and metric tracking. Args: config (Optional[OmegaConf], optional): The configuration of the current experiment. Defaults to None. disabled (bool, optional): A utility boolean to quickly disable Weight&Biases logging. Useful when debugging. Defaults to False. \"\"\" super () . __init__ () if config is None and not disabled : wandb . init () elif config is None and disabled : wandb . init ( mode = \"disabled\" ) else : if disabled : mode = \"disabled\" else : mode = getattr ( config . wandb , \"mode\" , \"disabled\" ) wandb . init ( entity = config . wandb . entity , project = config . wandb . project , config = OmegaConf . to_container ( config ), tags = getattr ( config . wandb , \"tags\" , []), mode = mode , group = getattr ( config . wandb , \"group\" , None ), name = getattr ( config . wandb , \"name\" , None ), ) self . log_code () # make sure that validation metrics are logged with epoch as the x-axis wandb . define_metric ( \"epoch\" ) wandb . define_metric ( \"val/*\" , step_metric = \"epoch\" ) wandb . define_metric ( \"val/accuracy/*\" , step_metric = \"epoch\" ) wandb . define_metric ( \"val/loss/*\" , step_metric = \"epoch\" )","title":"__init__()"}]}