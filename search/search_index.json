{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the repo!","text":""},{"location":"#getting-started","title":"Getting started","text":""},{"location":"#installation","title":"Installation","text":"<pre><code>conda create -n sequel python=3.10 -y\nconda activate sequel\n\npip install -r requirements.txt\n</code></pre>"},{"location":"#launching-the-docs","title":"Launching the docs","text":"Build docs from scratchLaunching already built docs <pre><code># navigate to the root of the repo, i.e,\n# where the file `mkdocs.yml` resides. \nmkdocs serve\n\n# Docs are launched in http://127.0.0.1:8000/\n</code></pre> <pre><code># navigate to the `site/` directory\n# The directory contains the file 'index.html'\n# serve the website\npython3 -m http.server\n\n# The website is hosted in http://127.0.0.1:8000/\n</code></pre>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml      # The configuration file for the documentation.\ndocs/\n    index.md    # The documentation homepage.\n    ...         # Other markdown pages, images and other files.\n\nsequel/         # The source code lies here.\n    algos/      # The Continual Learning Algorithms, e.g. EWC.\n    backbones/  # The Neural Net classes.\n    benchmarks/ # The benchmarks such as SplitMNIST.\n    utils/      # Utility functions such as logging, callbacks etc.\n</code></pre>"},{"location":"#examples","title":"Examples","text":"<p>The API for both JAX and PyTorch is the same. In the following example, we only need to change <code>pytorch</code> to <code>jax</code>  and define the optimizer in a framework-specific way.</p> PyTorchJAX <pre><code>from sequel import benchmarks, backbones, algos, loggers, callbacks\nimport torch\n\n# define the Continual Learning benchmark.\nbenchmark = benchmarks.PermutedMNIST(num_tasks=3, batch_size=512)\n\n# define the backbone model, i.e., the neural network, and the optimizer\nbackbone = backbones.pytorch.MLP(width=256, n_hidden_layers=2, num_classes=10)\noptimizer = torch.optim.SGD(backbone.parameters(), lr=0.1)\n\n# initialize the algorithm\nalgo = algos.pytorch.EWC(\n    backbone=backbone,\n    optimizer=optimizer,\n    benchmark=benchmark,\n    callbacks=[\n        callbacks.PyTorchMetricCallback(),\n        callbacks.TqdmCallback(),\n    ],\n    loggers=[loggers.WandbLogger()],\n    # algorithm-specific arguments\n    ewc_lambda=1,\n)\n\n# start training\nalgo.fit(epochs=1)\n</code></pre> <pre><code>from sequel import benchmarks, backbones, algos, loggers, callbacks\nimport optax as tx\n\n# define the Continual Learning benchmark.\nbenchmark = benchmarks.PermutedMNIST(num_tasks=3, batch_size=512)\n\n# define the backbone model, i.e., the neural network, and the optimizer\nbackbone = backbones.jax.MLP(width=256, n_hidden_layers=2, num_classes=10)\noptimizer = tx.inject_hyperparams(tx.sgd)(learning_rate=0.1)\n\n# initialize the algorithm\nalgo = algos.jax.EWC(\n    backbone=backbone,\n    optimizer=optimizer,\n    benchmark=benchmark,\n    callbacks=[\n        callbacks.JaxMetricCallback(),\n        callbacks.TqdmCallback(),\n    ],\n    loggers=[loggers.WandbLogger()],\n    # algorithm-specific arguments\n    ewc_lambda=1,\n)\n\n# start training\nalgo.fit(epochs=1)\n</code></pre>"},{"location":"algos/base_algo/","title":"base_algo","text":""},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm","title":"<code>BaseAlgorithm</code>","text":"<p>         Bases: <code>BaseStateManager</code>, <code>BaseCallbackHook</code>, <code>BaseCallback</code></p> <p>Base class for Trainer component. Handles all the engineering code. Connects the algorighm with callback and logging functionallities. The class also inherits from BaseCallback and the user can implement desired functionalities either as standalone callbacks or by overwriting the parent callback hooks of the algorithm.</p> <p>Attributes:</p> Name Type Description <code>metric_callback_msg</code> <code>Optional[str]</code> <p>A message set by the MetricCallback that informs about the progress of training/validation etc. Can be used by other callbacks, e.g., TqdmCallback, to display such information in the console.</p> <code>num_tasks</code> <code>int</code> <p>number of tasks. Set by <code>parse_benchmark</code>.</p> <code>classes_per_task</code> <code>int</code> <p>the number of classes per task. For the moment, all tasks should have the same number of classes. Set by <code>parse_benchmark</code>.</p> <code>episodic_memory_loader</code> <code>torch.utils.data.DataLoader</code> <p>The dataloader for the memory. Applies to methods that utilize memoreis, such as GEM.</p> <code>episodic_memory_iter</code> <code>Iterable[torch.utils.data.DataLoader]</code> <p>An iterator for <code>episodic_memory_loader</code></p> <code>loss</code> <code>Union[torch.Tensor, numpy.array]</code> <p>The loss of the current batch.</p> <code>current_dataloader</code> <code>torch.utils.data.DataLoader</code> <p>The current training/validation/testing dataloader.</p> <code>x</code> <code>Union[torch.Tensor, numpy.array]</code> <p>The input tensors of the current batch. Set by <code>unpack_batch</code>.</p> <code>y</code> <code>Union[torch.Tensor, numpy.array]</code> <p>The targets of the current batch. Set by <code>unpack_batch</code>.</p> <code>t</code> <code>Union[torch.Tensor, numpy.array]</code> <p>The task ids of the current batch. Set by <code>unpack_batch</code>.</p> <code>bs</code> <code>int</code> <p>The size of the current batch. Set by <code>unpack_batch</code>.</p> <code>epochs</code> <code>int</code> <p>The epochs each task is trained for.</p> Source code in <code>sequel/algos/base_algo.py</code> <pre><code>class BaseAlgorithm(BaseStateManager, BaseCallbackHook, BaseCallback):\n\"\"\"Base class for Trainer component. Handles all the engineering code. Connects the algorighm with callback and\n    logging functionallities. The class also inherits from BaseCallback and the user can implement desired\n    functionalities either as standalone callbacks or by overwriting the parent callback hooks of the algorithm.\n\n    Attributes:\n        metric_callback_msg (Optional[str]): A message set by the MetricCallback that informs about the progress of\n            training/validation etc. Can be used by other callbacks, e.g., TqdmCallback, to display such information\n            in the console.\n        num_tasks (int): number of tasks. Set by [`parse_benchmark`][sequel.algos.base_algo.BaseAlgorithm.parse_benchmark].\n        classes_per_task (int): the number of classes per task. For the moment, all tasks should have the same number\n            of classes. Set by [`parse_benchmark`][sequel.algos.base_algo.BaseAlgorithm.parse_benchmark].\n        episodic_memory_loader (torch.utils.data.DataLoader): The dataloader for the memory. Applies to methods that\n            utilize memoreis, such as GEM.\n        episodic_memory_iter (Iterable[torch.utils.data.DataLoader]): An iterator for `episodic_memory_loader`\n        loss (Union[torch.Tensor, numpy.array]): The loss of the current batch.\n        current_dataloader (torch.utils.data.DataLoader): The current training/validation/testing dataloader.\n        x (Union[torch.Tensor, numpy.array]): The input tensors of the current batch. Set by\n            [`unpack_batch`][sequel.algos.base_algo.BaseAlgorithm.unpack_batch].\n        y (Union[torch.Tensor, numpy.array]): The targets of the current batch. Set by\n            [`unpack_batch`][sequel.algos.base_algo.BaseAlgorithm.unpack_batch].\n        t (Union[torch.Tensor, numpy.array]): The task ids of the current batch. Set by\n            [`unpack_batch`][sequel.algos.base_algo.BaseAlgorithm.unpack_batch].\n        bs (int): The size of the current batch. Set by [`unpack_batch`][sequel.algos.base_algo.BaseAlgorithm.unpack_batch].\n        epochs (int): The epochs each task is trained for.\n    \"\"\"\n\n    metric_callback_msg = None\n    episodic_memory_loader = None\n    episodic_memory_iter = None\n\n    def __init__(\n        self,\n        backbone: Union[PytorchBaseBackbone, JaxBaseBackbone],\n        benchmark: Benchmark,\n        optimizer: Union[torch.optim.Optimizer, optax.GradientTransformation],\n        callbacks: Iterable[BaseCallback] = [],\n        loggers: Optional[Iterable[Logger]] = None,\n        lr_decay: Optional[float] = None,\n        grad_clip: Optional[float] = None,\n        reinit_optimizer: bool = True,\n    ) -&gt; None:\n\"\"\"Inits the BaseAlgorithm class. Handles all the engineering code. Base classes for algorithms in Pytorch and\n        Jax inherit from this class.\n\n        Args:\n            backbone (Union[PytorchBaseBackbone, JaxBaseBackbone]): The backbone model, e.g., a CNN.\n            benchmark (Benchmark): The benchmark, e.g., SplitMNIST.\n            optimizer (Union[torch.optim.Optimizer, optax.GradientTransformation]): The optimizer used to update the\n                backbone weights.\n            callbacks (Iterable[BaseCallback], optional): A list of callbacks. At least one instance of MetricCallback\n                should be given. Defaults to [].\n            loggers (Optional[Logger], optional): A list of logger, e.g. for Weights&amp;Biases logging functionality.\n                Defaults to None.\n            lr_decay (Optional[float], optional): A learning rate decay used for every new task. Defaults to None.\n            reinit_optimizer (bool): Indicates whether the optimizer state is reinitialized before fitting a new task.\n                Defaults to True.\n        \"\"\"\n\n        install_logging()\n        self.benchmark = benchmark\n        self.parse_benchmark()\n        self.backbone = backbone\n\n        self.callbacks = self.check_and_parse_callbacks(callbacks)\n        self.loggers = loggers\n        self.optimizer = optimizer\n\n        self.lr_decay = lr_decay\n        self.reinit_optimizer = reinit_optimizer\n        self.grad_clip = grad_clip\n\n        if self.grad_clip is not None:\n            logging.info(f\"Gradient clipping has been set to {self.grad_clip}.\")\n\n        logging.info(f\"The backbone model has {self.count_parameters()/1e6:.3f}m parameters\")\n\n    def check_and_parse_callbacks(self, callbacks: Iterable[BaseCallback]) -&gt; Iterable[BaseCallback]:\n\"\"\"Checks that the callbacks is a list containing exaclty one MetricCallback.\n\n        Args:\n            callbacks (Iterable[BaseCallback]): list of callbacks\n\n        Returns:\n            Iterable[BaseCallback]: the parsed list of callbacks.\n        \"\"\"\n        from sequel.utils.callbacks.metrics.metric_callback import MetricCallback\n\n        assert isinstance(callbacks, list), \"The callbacks should be given as a list.\"\n        assert (\n            sum([isinstance(c, MetricCallback) for c in callbacks]) == 1\n        ), \"Exactly one instance of MetricCallback should be given.\"\n\n        # make sure that the MetricCallback is last.\n        parsed_callbacks = [c for c in callbacks if not isinstance(c, MetricCallback)]\n        parsed_callbacks += [c for c in callbacks if isinstance(c, MetricCallback)]\n        return parsed_callbacks\n\n    def parse_benchmark(self):\n\"\"\"Extracts attributes from the benchmark and registers them to the algo for quick access.\"\"\"\n        self.num_tasks = self.benchmark.num_tasks\n        self.classes_per_task = self.benchmark.classes_per_task\n        self.input_dimensions = self.benchmark.dimensions\n\n    def update_episodic_memory(self) -&gt; None:\n\"\"\"Updates the episodic memory. This funciton is called after fitting one task.\"\"\"\n        logging.info(\"Updating episodic memory for task {}\".format(self.task_counter))\n        self.episodic_memory_loader = self.benchmark.memory_dataloader(self.task_counter)\n        self.episodic_memory_iter = iter(self.episodic_memory_loader)\n\n    def sample_batch_from_memory(self):\n        try:\n            batch = next(self.episodic_memory_iter)\n        except StopIteration:\n            # makes the dataloader an infinite stream\n            self.episodic_memory_iter = iter(self.episodic_memory_loader)\n            batch = next(self.episodic_memory_iter)\n\n        return batch\n\n    def log(self, item):\n        # logger: Logger\n        if self.loggers is not None:\n            for logger in self.loggers:\n                logger.log(item, step=self.step_counter, epoch=self.epoch_counter)\n\n    def log_figure(self, figure, name):\n        if self.loggers is not None:\n            for logger in self.loggers:\n                logger.log_figure(name=name, figure=figure)\n\n    def count_parameters(self):\n        raise NotImplementedError\n\n    def setup(self):\n        for cb in self.callbacks:\n            cb.connect(self)\n\n    def teardown(self):\n        pass\n\n    def _configure_criterion(self, task_id=None):\n        raise NotImplementedError\n\n    def forward(self, *args, **kwargs):\n\"\"\"Calls the forward function of the model.\"\"\"\n        raise NotImplementedError\n\n    def update_tqdm(self, msg):\n        self.metric_callback_msg = msg\n        # self.tqdm_dl.set_postfix(msg)\n\n    def unpack_batch(self, batch: Any):\n\"\"\"Unpacks the batch and registers to the algorithm the current batch input, targets and task ids as `self.x`,\n        `self.y` and `self.t`, respectively. It also registers the current batch size as `self.bs`\"\"\"\n        raise NotImplementedError\n\n    def optimizer_zero_grad(self):\n        raise NotImplementedError\n\n    def backpropagate_loss(self):\n        raise NotImplementedError\n\n    def optimizer_step(self):\n        raise NotImplementedError\n\n    def perform_gradient_clipping(self):\n        raise NotImplementedError\n\n    def training_step(self, *args, **kwargs):\n\"\"\"The training step, i.e. training for each batch.\n\n        Goes through the usual hoops of zeroing out the optimizer, forwarding the input, computing the loss,\n        backpropagating and updating the weights. For each different steps, callabacks are offered for maximum\n        versatility and ease of use.\n        \"\"\"\n        self.optimizer_zero_grad()\n        y_hat = self.forward()\n        self.loss = self.compute_loss(y_hat, self.y, self.t)\n\n        self.on_before_backward()\n        self.on_before_backward_callbacks()\n        self.backpropagate_loss()\n        self.on_after_backward()\n        self.on_after_backward_callbacks()\n\n        self.perform_gradient_clipping()\n\n        self.on_before_optimizer_step()\n        self.on_before_optimizer_step_callbacks()\n        self.optimizer_step()\n        self.on_after_optimizer_step()\n        self.on_after_optimizer_step_callbacks()\n\n    def valid_step(self, *args, **kwargs):\n\"\"\"Performs the validation step.Callbacks are offered for each step of the process.\"\"\"\n        raise NotImplementedError\n\n    def test_step(self, *args, **kwargs):\n\"\"\"Performs the testing step. Callbacks are offered for each step of the process.\"\"\"\n        pass\n\n    def training_epoch(self, *args, **kwargs):\n\"\"\"Trains the model for a single epoch. Callbacks are offered for each method.\"\"\"\n        self.increment(\"epoch\")\n        self.set_training_mode()\n        self.current_dataloader = self.train_loader\n        for self.batch_idx, batch in enumerate(self.current_dataloader):\n            self.unpack_batch(batch)\n            self.on_before_training_step()\n            self.on_before_training_step_callbacks()\n            self.increment(\"step\")\n            self.training_step()\n            self.on_after_training_step()\n            self.on_after_training_step_callbacks()\n\n    def eval_epoch(self, *args, **kwargs):\n\"\"\"Performs the evaluation of the model on the validation set. If no validation dataloader is provided, the\n        method returns without any computation.\"\"\"\n        if self.valid_loader is None:\n            return\n\n        self.set_evaluation_mode()\n        self.current_dataloader = self.valid_loader\n\n        for self.batch_idx, batch in enumerate(self.current_dataloader):\n            self.unpack_batch(batch)\n            self.on_before_val_step()\n            self.on_before_val_step_callbacks()\n            self.valid_step()\n            self.on_after_val_step()\n            self.on_after_val_step_callbacks()\n\n    def test_epoch(self, *args, **kwargs):\n        pass\n\n    def prepare_for_next_task(self, task):\n        raise NotImplementedError\n\n    def prepare_train_loader(self, task):\n        return self.benchmark.train_dataloader(task)\n\n    def train_algorithm_on_task(self, task: int):\n\"\"\"Fits a *single* task.\"\"\"\n        self.train_loader = self.prepare_train_loader(task)\n        self.prepare_for_next_task(task)\n\n        assert isinstance(self._epochs, (list, int, omegaconf.listconfig.ListConfig))\n        if not isinstance(self._epochs, int):\n            self.epochs = self._epochs[self.task_counter - 1]\n        else:\n            self.epochs = self._epochs\n\n        for self.current_task_epoch in range(1, self.epochs + 1):\n            self._train_loop()\n            self._val_loop()\n\n    def _train_loop(self):\n        self.on_before_training_epoch()\n        self.on_before_training_epoch_callbacks()\n        self.training_epoch()\n        self.on_after_training_epoch()\n        self.on_after_training_epoch_callbacks()\n\n    def _val_loop(self):\n        # after each epoch, the model is validated on current and previous tasks.\n        self.on_before_validating_algorithm_on_all_tasks()\n        self.on_before_validating_algorithm_on_all_tasks_callbacks()\n        self.validate_algorithm_on_all_tasks()\n        self.on_after_validating_algorithm_on_all_tasks()\n        self.on_after_validating_algorithm_on_all_tasks_callbacks()\n\n    def validate_algorithm_on_all_tasks(self) -&gt; Dict[str, float]:\n        for task in range(1, self.task_counter + 1):\n            self.current_val_task = task\n            self.valid_loader = self.benchmark.val_dataloader(task)\n\n            self.on_before_val_epoch()\n            self.on_before_val_epoch_callbacks()\n            self.eval_epoch()\n            self.on_after_val_epoch()\n            self.on_after_val_epoch_callbacks()\n\n    def _fit(self):\n\"\"\"Fits all tasks to the model, one after the other.\"\"\"\n        for task in range(1, self.num_tasks + 1):\n            self.on_before_training_task()\n            self.on_before_training_task_callbacks()\n            self.increment(\"task\")\n            self.train_algorithm_on_task(task)\n            self.on_after_training_task()\n            self.on_after_training_task_callbacks()\n\n    def _run_setup(self):\n        self.on_before_setup()\n        self.on_before_setup_callbacks()\n        self.setup()\n        self.on_after_setup()\n        self.on_after_setup_callbacks()\n\n    def _run_fit(self):\n        self.on_before_fit()\n        self.on_before_fit_callbacks()\n        self._fit()\n        self.on_after_fit()\n        self.on_after_fit_callbacks()\n\n    def _run_teardown(self):\n        self.on_before_teardown()\n        self.on_before_teardown_callbacks()\n        self.teardown()\n        self.on_after_teardown()\n        self.on_after_teardown_callbacks()\n\n    def fit(self, epochs):\n        self._epochs = epochs\n\n        self._run_setup()\n        self._run_fit()\n        self._run_teardown()\n\n    def compute_loss(self, predictions, targets, task_ids, *args, **kwargs):\n        raise NotImplementedError\n</code></pre>"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.__init__","title":"<code>__init__(backbone, benchmark, optimizer, callbacks=[], loggers=None, lr_decay=None, grad_clip=None, reinit_optimizer=True)</code>","text":"<p>Inits the BaseAlgorithm class. Handles all the engineering code. Base classes for algorithms in Pytorch and Jax inherit from this class.</p> <p>Parameters:</p> Name Type Description Default <code>backbone</code> <code>Union[PytorchBaseBackbone, JaxBaseBackbone]</code> <p>The backbone model, e.g., a CNN.</p> required <code>benchmark</code> <code>Benchmark</code> <p>The benchmark, e.g., SplitMNIST.</p> required <code>optimizer</code> <code>Union[torch.optim.Optimizer, optax.GradientTransformation]</code> <p>The optimizer used to update the backbone weights.</p> required <code>callbacks</code> <code>Iterable[BaseCallback]</code> <p>A list of callbacks. At least one instance of MetricCallback should be given. Defaults to [].</p> <code>[]</code> <code>loggers</code> <code>Optional[Logger]</code> <p>A list of logger, e.g. for Weights&amp;Biases logging functionality. Defaults to None.</p> <code>None</code> <code>lr_decay</code> <code>Optional[float]</code> <p>A learning rate decay used for every new task. Defaults to None.</p> <code>None</code> <code>reinit_optimizer</code> <code>bool</code> <p>Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True.</p> <code>True</code> Source code in <code>sequel/algos/base_algo.py</code> <pre><code>def __init__(\n    self,\n    backbone: Union[PytorchBaseBackbone, JaxBaseBackbone],\n    benchmark: Benchmark,\n    optimizer: Union[torch.optim.Optimizer, optax.GradientTransformation],\n    callbacks: Iterable[BaseCallback] = [],\n    loggers: Optional[Iterable[Logger]] = None,\n    lr_decay: Optional[float] = None,\n    grad_clip: Optional[float] = None,\n    reinit_optimizer: bool = True,\n) -&gt; None:\n\"\"\"Inits the BaseAlgorithm class. Handles all the engineering code. Base classes for algorithms in Pytorch and\n    Jax inherit from this class.\n\n    Args:\n        backbone (Union[PytorchBaseBackbone, JaxBaseBackbone]): The backbone model, e.g., a CNN.\n        benchmark (Benchmark): The benchmark, e.g., SplitMNIST.\n        optimizer (Union[torch.optim.Optimizer, optax.GradientTransformation]): The optimizer used to update the\n            backbone weights.\n        callbacks (Iterable[BaseCallback], optional): A list of callbacks. At least one instance of MetricCallback\n            should be given. Defaults to [].\n        loggers (Optional[Logger], optional): A list of logger, e.g. for Weights&amp;Biases logging functionality.\n            Defaults to None.\n        lr_decay (Optional[float], optional): A learning rate decay used for every new task. Defaults to None.\n        reinit_optimizer (bool): Indicates whether the optimizer state is reinitialized before fitting a new task.\n            Defaults to True.\n    \"\"\"\n\n    install_logging()\n    self.benchmark = benchmark\n    self.parse_benchmark()\n    self.backbone = backbone\n\n    self.callbacks = self.check_and_parse_callbacks(callbacks)\n    self.loggers = loggers\n    self.optimizer = optimizer\n\n    self.lr_decay = lr_decay\n    self.reinit_optimizer = reinit_optimizer\n    self.grad_clip = grad_clip\n\n    if self.grad_clip is not None:\n        logging.info(f\"Gradient clipping has been set to {self.grad_clip}.\")\n\n    logging.info(f\"The backbone model has {self.count_parameters()/1e6:.3f}m parameters\")\n</code></pre>"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.check_and_parse_callbacks","title":"<code>check_and_parse_callbacks(callbacks)</code>","text":"<p>Checks that the callbacks is a list containing exaclty one MetricCallback.</p> <p>Parameters:</p> Name Type Description Default <code>callbacks</code> <code>Iterable[BaseCallback]</code> <p>list of callbacks</p> required <p>Returns:</p> Type Description <code>Iterable[BaseCallback]</code> <p>Iterable[BaseCallback]: the parsed list of callbacks.</p> Source code in <code>sequel/algos/base_algo.py</code> <pre><code>def check_and_parse_callbacks(self, callbacks: Iterable[BaseCallback]) -&gt; Iterable[BaseCallback]:\n\"\"\"Checks that the callbacks is a list containing exaclty one MetricCallback.\n\n    Args:\n        callbacks (Iterable[BaseCallback]): list of callbacks\n\n    Returns:\n        Iterable[BaseCallback]: the parsed list of callbacks.\n    \"\"\"\n    from sequel.utils.callbacks.metrics.metric_callback import MetricCallback\n\n    assert isinstance(callbacks, list), \"The callbacks should be given as a list.\"\n    assert (\n        sum([isinstance(c, MetricCallback) for c in callbacks]) == 1\n    ), \"Exactly one instance of MetricCallback should be given.\"\n\n    # make sure that the MetricCallback is last.\n    parsed_callbacks = [c for c in callbacks if not isinstance(c, MetricCallback)]\n    parsed_callbacks += [c for c in callbacks if isinstance(c, MetricCallback)]\n    return parsed_callbacks\n</code></pre>"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.eval_epoch","title":"<code>eval_epoch(*args, **kwargs)</code>","text":"<p>Performs the evaluation of the model on the validation set. If no validation dataloader is provided, the method returns without any computation.</p> Source code in <code>sequel/algos/base_algo.py</code> <pre><code>def eval_epoch(self, *args, **kwargs):\n\"\"\"Performs the evaluation of the model on the validation set. If no validation dataloader is provided, the\n    method returns without any computation.\"\"\"\n    if self.valid_loader is None:\n        return\n\n    self.set_evaluation_mode()\n    self.current_dataloader = self.valid_loader\n\n    for self.batch_idx, batch in enumerate(self.current_dataloader):\n        self.unpack_batch(batch)\n        self.on_before_val_step()\n        self.on_before_val_step_callbacks()\n        self.valid_step()\n        self.on_after_val_step()\n        self.on_after_val_step_callbacks()\n</code></pre>"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.forward","title":"<code>forward(*args, **kwargs)</code>","text":"<p>Calls the forward function of the model.</p> Source code in <code>sequel/algos/base_algo.py</code> <pre><code>def forward(self, *args, **kwargs):\n\"\"\"Calls the forward function of the model.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.parse_benchmark","title":"<code>parse_benchmark()</code>","text":"<p>Extracts attributes from the benchmark and registers them to the algo for quick access.</p> Source code in <code>sequel/algos/base_algo.py</code> <pre><code>def parse_benchmark(self):\n\"\"\"Extracts attributes from the benchmark and registers them to the algo for quick access.\"\"\"\n    self.num_tasks = self.benchmark.num_tasks\n    self.classes_per_task = self.benchmark.classes_per_task\n    self.input_dimensions = self.benchmark.dimensions\n</code></pre>"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.test_step","title":"<code>test_step(*args, **kwargs)</code>","text":"<p>Performs the testing step. Callbacks are offered for each step of the process.</p> Source code in <code>sequel/algos/base_algo.py</code> <pre><code>def test_step(self, *args, **kwargs):\n\"\"\"Performs the testing step. Callbacks are offered for each step of the process.\"\"\"\n    pass\n</code></pre>"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.train_algorithm_on_task","title":"<code>train_algorithm_on_task(task)</code>","text":"<p>Fits a single task.</p> Source code in <code>sequel/algos/base_algo.py</code> <pre><code>def train_algorithm_on_task(self, task: int):\n\"\"\"Fits a *single* task.\"\"\"\n    self.train_loader = self.prepare_train_loader(task)\n    self.prepare_for_next_task(task)\n\n    assert isinstance(self._epochs, (list, int, omegaconf.listconfig.ListConfig))\n    if not isinstance(self._epochs, int):\n        self.epochs = self._epochs[self.task_counter - 1]\n    else:\n        self.epochs = self._epochs\n\n    for self.current_task_epoch in range(1, self.epochs + 1):\n        self._train_loop()\n        self._val_loop()\n</code></pre>"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.training_epoch","title":"<code>training_epoch(*args, **kwargs)</code>","text":"<p>Trains the model for a single epoch. Callbacks are offered for each method.</p> Source code in <code>sequel/algos/base_algo.py</code> <pre><code>def training_epoch(self, *args, **kwargs):\n\"\"\"Trains the model for a single epoch. Callbacks are offered for each method.\"\"\"\n    self.increment(\"epoch\")\n    self.set_training_mode()\n    self.current_dataloader = self.train_loader\n    for self.batch_idx, batch in enumerate(self.current_dataloader):\n        self.unpack_batch(batch)\n        self.on_before_training_step()\n        self.on_before_training_step_callbacks()\n        self.increment(\"step\")\n        self.training_step()\n        self.on_after_training_step()\n        self.on_after_training_step_callbacks()\n</code></pre>"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.training_step","title":"<code>training_step(*args, **kwargs)</code>","text":"<p>The training step, i.e. training for each batch.</p> <p>Goes through the usual hoops of zeroing out the optimizer, forwarding the input, computing the loss, backpropagating and updating the weights. For each different steps, callabacks are offered for maximum versatility and ease of use.</p> Source code in <code>sequel/algos/base_algo.py</code> <pre><code>def training_step(self, *args, **kwargs):\n\"\"\"The training step, i.e. training for each batch.\n\n    Goes through the usual hoops of zeroing out the optimizer, forwarding the input, computing the loss,\n    backpropagating and updating the weights. For each different steps, callabacks are offered for maximum\n    versatility and ease of use.\n    \"\"\"\n    self.optimizer_zero_grad()\n    y_hat = self.forward()\n    self.loss = self.compute_loss(y_hat, self.y, self.t)\n\n    self.on_before_backward()\n    self.on_before_backward_callbacks()\n    self.backpropagate_loss()\n    self.on_after_backward()\n    self.on_after_backward_callbacks()\n\n    self.perform_gradient_clipping()\n\n    self.on_before_optimizer_step()\n    self.on_before_optimizer_step_callbacks()\n    self.optimizer_step()\n    self.on_after_optimizer_step()\n    self.on_after_optimizer_step_callbacks()\n</code></pre>"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.unpack_batch","title":"<code>unpack_batch(batch)</code>","text":"<p>Unpacks the batch and registers to the algorithm the current batch input, targets and task ids as <code>self.x</code>, <code>self.y</code> and <code>self.t</code>, respectively. It also registers the current batch size as <code>self.bs</code></p> Source code in <code>sequel/algos/base_algo.py</code> <pre><code>def unpack_batch(self, batch: Any):\n\"\"\"Unpacks the batch and registers to the algorithm the current batch input, targets and task ids as `self.x`,\n    `self.y` and `self.t`, respectively. It also registers the current batch size as `self.bs`\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.update_episodic_memory","title":"<code>update_episodic_memory()</code>","text":"<p>Updates the episodic memory. This funciton is called after fitting one task.</p> Source code in <code>sequel/algos/base_algo.py</code> <pre><code>def update_episodic_memory(self) -&gt; None:\n\"\"\"Updates the episodic memory. This funciton is called after fitting one task.\"\"\"\n    logging.info(\"Updating episodic memory for task {}\".format(self.task_counter))\n    self.episodic_memory_loader = self.benchmark.memory_dataloader(self.task_counter)\n    self.episodic_memory_iter = iter(self.episodic_memory_loader)\n</code></pre>"},{"location":"algos/base_algo/#sequel.algos.base_algo.BaseAlgorithm.valid_step","title":"<code>valid_step(*args, **kwargs)</code>","text":"<p>Performs the validation step.Callbacks are offered for each step of the process.</p> Source code in <code>sequel/algos/base_algo.py</code> <pre><code>def valid_step(self, *args, **kwargs):\n\"\"\"Performs the validation step.Callbacks are offered for each step of the process.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"algos/jax/agem/","title":"AGEM","text":""},{"location":"algos/jax/agem/#sequel.algos.jax.agem.AGEM","title":"<code>AGEM</code>","text":"<p>         Bases: <code>JaxBaseAlgorithm</code></p> <p>A-GEM: Averaged-Gradient Episodic Memory. Maintains a memory of samples from past tasks. The gradients for the current batch are projected to the convex hull of the task gradients produced by the the aforementioned memory. Inherits from BaseAlgorithm.</p> <p>The equivalent PyTorch implementation is <code>A-GEM in Pytorch</code>.</p> References <p>[1] Chaudhry, A., Ranzato, M., Rohrbach, M. &amp; Elhoseiny, M. Efficient Lifelong Learning with A-GEM. in 7th     International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019.</p> Source code in <code>sequel/algos/jax/agem.py</code> <pre><code>class AGEM(JaxBaseAlgorithm):\n\"\"\"A-GEM: Averaged-Gradient Episodic Memory. Maintains a memory of samples from past tasks.\n    The gradients for the current batch are projected to the convex hull of the task gradients\n    produced by the the aforementioned memory. Inherits from BaseAlgorithm.\n\n    The equivalent PyTorch implementation is [`A-GEM in Pytorch`][sequel.algos.pytorch.agem.AGEM].\n\n    References:\n        [1] Chaudhry, A., Ranzato, M., Rohrbach, M. &amp; Elhoseiny, M. Efficient Lifelong Learning with A-GEM. in 7th\n            International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019.\n    \"\"\"\n\n    def __init__(\n        self,\n        per_task_memory_samples: int,\n        memory_batch_size: int,\n        memory_group_by: Literal[\"task\", \"class\"],\n        *args,\n        **kwargs,\n    ):\n\"\"\"Inits the A-GEM algorithm class.\n\n        Args:\n            per_task_memory_samples (int): number of exemplars per experience in the memory.\n            memory_batch_size (int): the batch size of the memory samples used to modify the gradient update.\n            memory_group_by (Literal[\"task\", \"class\"]): Determines the selection process of samples for the memory.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self.memory = MemoryMechanism(per_task_memory_samples=per_task_memory_samples, groupby=memory_group_by)\n        self.per_task_memory_samples = per_task_memory_samples\n        self.memory_batch_size = memory_batch_size\n\n    def __repr__(self) -&gt; str:\n        return (\n            f\"AGEM(memory_batch_size={self.memory_batch_size}, per_task_memory_samples={self.per_task_memory_samples})\"\n        )\n\n    def on_after_training_task(self, *args, **kwargs):\n        self.memory.update_memory(self)\n        self.update_episodic_memory()\n        logging.info(\"The episodic memory now stores {} samples\".format(len(self.episodic_memory_loader.dataset)))\n\n    def update_episodic_memory(self):\n        logging.info(\"Updating episodic memory for task {}\".format(self.task_counter))\n        self.episodic_memory_loader = self.benchmark.memory_dataloader(\n            self.task_counter,\n            self.memory_batch_size,\n            return_infinite_stream=True,\n        )\n        self.episodic_memory_iter = iter(self.episodic_memory_loader)\n\n    def sample_batch_from_memory(self):\n        try:\n            return next(self.episodic_memory_iter)\n        except StopIteration:\n            # makes the dataloader an infinite stream\n            # The exception is only reached if the argument `return_infinite_stream` is set to False in\n            # [`memory_dataloader`][sequel.benchmarks.base_benchmark.return_infinite_stream] set in\n            # [`update_episodic_memory`][sequel.algos.jax.agem.update_episodic_memory].\n            self.episodic_memory_iter = iter(self.episodic_memory_loader)\n            return next(self.episodic_memory_iter)\n\n    def training_step(self):\n        if self.task_counter == 1:\n            super().training_step()\n        else:\n            self.batch_outputs = self.agem_training_step(\n                self.state, self.x, self.y, self.t, self.mem_x, self.mem_y, self.mem_t, self.step_counter\n            )\n            self.register_batch_outputs(self.batch_outputs)\n\n    def on_before_training_step(self, *args, **kwargs):\n        if self.task_counter &gt; 1:\n            batch = self.sample_batch_from_memory()\n            x, y, t = self.unpack_batch_functional(batch)\n            self.mem_x, self.mem_y, self.mem_t = x, y, t\n\n    @partial(jax.jit, static_argnums=(0,))\n    def agem_training_step(self, state: TrainState, x, y, t, mem_x, mem_y, mem_t, step):\n\"\"\"The A-GEM training step that uses the memory samples to modify the gradient.\n\n        Note:\n            this implementation is suboptimal since it computes mem_norm and performs the tree_map operation even if not\n            needed (case of dotg nonnegative). However, it has been implemented in this way in order to jit in a single\n            function the gradient updates.\n        \"\"\"\n        grad_fn = jax.value_and_grad(self.cross_entropy, has_aux=True, allow_int=True)\n\n        (loss, logits), old_grads = grad_fn(state.params, x, y, t, self.is_training, step=step)\n        # 1000000 is added so that steps are different. This applie for the rng of some modules, e.g. dropout\n        _, mem_grads = grad_fn(state.params, mem_x, mem_y, mem_t, self.is_training, step=step + 1000000)\n        dotg = jnp.minimum(dot_product(old_grads, mem_grads), 0)\n        mem_norm = dot_product(mem_grads, mem_grads)\n\n        alpha = dotg / mem_norm\n        grads = jax.tree_map(lambda o, m: o - m * alpha, old_grads, mem_grads)\n\n        state = state.apply_gradients(grads=grads)\n        return dict(state=state, logits=logits, loss=loss, grads=grads)\n</code></pre>"},{"location":"algos/jax/agem/#sequel.algos.jax.agem.AGEM.__init__","title":"<code>__init__(per_task_memory_samples, memory_batch_size, memory_group_by, *args, **kwargs)</code>","text":"<p>Inits the A-GEM algorithm class.</p> <p>Parameters:</p> Name Type Description Default <code>per_task_memory_samples</code> <code>int</code> <p>number of exemplars per experience in the memory.</p> required <code>memory_batch_size</code> <code>int</code> <p>the batch size of the memory samples used to modify the gradient update.</p> required <code>memory_group_by</code> <code>Literal['task', 'class']</code> <p>Determines the selection process of samples for the memory.</p> required Source code in <code>sequel/algos/jax/agem.py</code> <pre><code>def __init__(\n    self,\n    per_task_memory_samples: int,\n    memory_batch_size: int,\n    memory_group_by: Literal[\"task\", \"class\"],\n    *args,\n    **kwargs,\n):\n\"\"\"Inits the A-GEM algorithm class.\n\n    Args:\n        per_task_memory_samples (int): number of exemplars per experience in the memory.\n        memory_batch_size (int): the batch size of the memory samples used to modify the gradient update.\n        memory_group_by (Literal[\"task\", \"class\"]): Determines the selection process of samples for the memory.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n    self.memory = MemoryMechanism(per_task_memory_samples=per_task_memory_samples, groupby=memory_group_by)\n    self.per_task_memory_samples = per_task_memory_samples\n    self.memory_batch_size = memory_batch_size\n</code></pre>"},{"location":"algos/jax/agem/#sequel.algos.jax.agem.AGEM.agem_training_step","title":"<code>agem_training_step(state, x, y, t, mem_x, mem_y, mem_t, step)</code>","text":"<p>The A-GEM training step that uses the memory samples to modify the gradient.</p> Note <p>this implementation is suboptimal since it computes mem_norm and performs the tree_map operation even if not needed (case of dotg nonnegative). However, it has been implemented in this way in order to jit in a single function the gradient updates.</p> Source code in <code>sequel/algos/jax/agem.py</code> <pre><code>@partial(jax.jit, static_argnums=(0,))\ndef agem_training_step(self, state: TrainState, x, y, t, mem_x, mem_y, mem_t, step):\n\"\"\"The A-GEM training step that uses the memory samples to modify the gradient.\n\n    Note:\n        this implementation is suboptimal since it computes mem_norm and performs the tree_map operation even if not\n        needed (case of dotg nonnegative). However, it has been implemented in this way in order to jit in a single\n        function the gradient updates.\n    \"\"\"\n    grad_fn = jax.value_and_grad(self.cross_entropy, has_aux=True, allow_int=True)\n\n    (loss, logits), old_grads = grad_fn(state.params, x, y, t, self.is_training, step=step)\n    # 1000000 is added so that steps are different. This applie for the rng of some modules, e.g. dropout\n    _, mem_grads = grad_fn(state.params, mem_x, mem_y, mem_t, self.is_training, step=step + 1000000)\n    dotg = jnp.minimum(dot_product(old_grads, mem_grads), 0)\n    mem_norm = dot_product(mem_grads, mem_grads)\n\n    alpha = dotg / mem_norm\n    grads = jax.tree_map(lambda o, m: o - m * alpha, old_grads, mem_grads)\n\n    state = state.apply_gradients(grads=grads)\n    return dict(state=state, logits=logits, loss=loss, grads=grads)\n</code></pre>"},{"location":"algos/jax/base_algo/","title":"base_algo_jax","text":""},{"location":"algos/jax/base_algo/#sequel.algos.jax.jax_base_algo.JaxBaseAlgorithm","title":"<code>JaxBaseAlgorithm</code>","text":"<p>         Bases: <code>BaseAlgorithm</code></p> <p>Base class for algorithms implemented in JAX.</p> Source code in <code>sequel/algos/jax/jax_base_algo.py</code> <pre><code>class JaxBaseAlgorithm(BaseAlgorithm):\n\"\"\"Base class for algorithms implemented in JAX.\"\"\"\n\n    def __init__(\n        self,\n        backbone: JaxBaseBackbone,\n        benchmark: Benchmark,\n        optimizer: optax.GradientTransformation,\n        callbacks: Iterable[BaseCallback] = [],\n        loggers: Optional[Iterable[Logger]] = None,\n        lr_decay: Optional[float] = None,\n        grad_clip: Optional[float] = None,\n        reinit_optimizer: bool = True,\n        seed=0,\n    ) -&gt; None:\n\"\"\"Inits JaxBaseAlgorithm class.\n\n        Args:\n            backbone (JaxBaseBackbone): The backbone model, e.g., a CNN.\n            benchmark (Benchmark): The benchmark, e.g., SplitMNIST.\n            optimizer (optax.GradientTransformation):  The optimizer used to update the backbone weights.\n            callbacks (Iterable[BaseCallback], optional): A list of callbacks. At least one instance of MetricCallback\n                should be given. Defaults to [].\n            loggers (Optional[Logger], optional): A list of logger, e.g. for Weights&amp;Biases logging functionality.\n                Defaults to None.\n            lr_decay (Optional[float], optional): A learning rate decay used for every new task. Defaults to None.\n            grad_clip (Optional[float], optional): The gradient clipping norm. Defaults to None.\n            reinit_optimizer (bool): Indicates whether the optimizer state is reinitialized before fitting a new task.\n                Defaults to True.\n            seed (int, optional): The seed used by JAX. Sets the corresponding `PRNGKey`. Defaults to 0.\n\n        Note:\n            1. the `_configure_optimizers` method will be moved to a dedicated Callback.\n        \"\"\"\n\n        assert isinstance(backbone, BaseBackbone)\n        super().__init__(\n            backbone=backbone,\n            benchmark=benchmark,\n            optimizer=optimizer,\n            callbacks=callbacks,\n            loggers=loggers,\n            lr_decay=lr_decay,\n            grad_clip=grad_clip,\n            reinit_optimizer=reinit_optimizer,\n        )\n        print(\"&gt;\" * 100)\n        print(self.benchmark.num_classes)\n        print(\"&gt;\" * 100)\n        self.seed = seed\n        rng = jax.random.PRNGKey(seed)\n        self.rng, init_rng = jax.random.split(rng)\n        self.state: TrainState = self.create_train_state(self.backbone, init_rng, task=None)\n        self.apply_fn = self.state.apply_fn\n        self.original_optimizer = copy.deepcopy(self.optimizer)\n\n    def create_train_state(self, model: nn.Module, rng: PRNGKey, task=None) -&gt; TrainState:\n\"\"\"Creates initial `TrainState`.\"\"\"\n        dims = self.benchmark.dimensions\n        dimensions = [1] + dims[1:] + [dims[0]]\n        params = model.init(rng, x=jnp.ones(dimensions), task_ids=None, training=False)\n        tx = self.optimizer\n\n        rng, self.dropout_key = jax.random.split(rng)\n        del rng\n\n        return TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n\n    def prepare_for_next_task(self, task: int):\n        if self.reinit_optimizer:\n            logging.info(\"Reinitializing optimizer for next task\")\n            params = self.state.params\n            apply_fn = self.state.apply_fn\n            tx: optax.GradientTransformation = copy.deepcopy(self.original_optimizer)\n            if self.lr_decay is not None and task &gt; 1:\n                assert isinstance(self.lr_decay, float)\n                assert self.lr_decay &gt; 0 and self.lr_decay &lt;= 1, \"lr decay should be in the interval (0,1]\"\n                new_lr = self.state.opt_state.hyperparams[\"learning_rate\"] * self.lr_decay\n                logging.info(f\"Decaying the learning rate by a factor of {self.lr_decay} to the next lr={new_lr}\")\n            else:\n                new_lr = self.state.opt_state.hyperparams[\"learning_rate\"]\n            self.state = TrainState.create(apply_fn=apply_fn, params=params, tx=tx)\n            print(self.state.opt_state.hyperparams)\n            self.state.opt_state.hyperparams[\"learning_rate\"] = new_lr\n            print(self.state.opt_state.hyperparams)\n\n    def count_parameters(self):\n        dims = self.benchmark.dimensions\n        dimensions = [1] + dims[1:] + [dims[0]]\n        print(dimensions)\n        rng = jax.random.PRNGKey(0)\n        params = self.backbone.init(rng, jnp.ones(dimensions), task_ids=None, training=False)\n        return sum(x.size for x in jax.tree_util.tree_leaves(params))\n\n    def _configure_criterion(self, task_id=None):\n        logging.debug(\"_configure_criterion should change?\")\n\n    def unpack_batch(self, batch):\n        self.x, self.y, self.t = self.unpack_batch_functional(batch)\n        self.bs = len(self.x)\n\n    def unpack_batch_functional(self, batch):\n        x, y, t = batch\n        if x.dim() &gt; 2:\n            # in case of image datasets\n            x = x.permute(0, 2, 3, 1)\n        return np.array(x), np.array(y), np.array(t)\n\n    def perform_gradient_clipping(self):\n        warnings.warn(\"Gradient Clipping has not been implemented for JAX.\")\n        pass\n\n    @partial(jax.jit, static_argnums=(0, 4))\n    def forward(self, params, x, t, training, step):\n        dropout_train_key = jax.random.fold_in(key=self.dropout_key, data=step)\n        logits = self.apply_fn(\n            params,\n            x=x,\n            task_ids=t,\n            training=training,\n            rngs={\"dropout\": dropout_train_key},\n            # This applies to ResNet; BathcNorm are not updated for the moment.\n            mutable=False,\n        )\n        return logits\n\n    @partial(jax.jit, static_argnums=(0, 5))\n    def cross_entropy(self, params, x, y, t, training, step=None):\n        logits = self.forward(params, x, t, training, step=step)\n        loss = cross_entropy_loss(logits=logits, labels=y, num_classes=self.benchmark.num_classes)\n        return loss, logits\n\n    @partial(jax.jit, static_argnums=(0,))\n    def base_training_step(self, state: TrainState, x, y, t, step):\n\"\"\"Train for a single step.\"\"\"\n        grad_fn = jax.value_and_grad(self.cross_entropy, has_aux=True, allow_int=True)\n        (loss, logits), grads = grad_fn(state.params, x=x, y=y, t=t, training=True, step=step)\n        state = state.apply_gradients(grads=grads)\n        return dict(state=state, logits=logits, loss=loss, grads=grads)\n\n    def register_batch_outputs(self, batch_outputs):\n        self.state = batch_outputs[\"state\"]\n        self.loss = batch_outputs[\"loss\"]\n        self.y_hat = batch_outputs[\"logits\"]\n        self.grads = batch_outputs[\"grads\"]\n\n    def training_step(self):\n        self.batch_outputs = self.base_training_step(self.state, self.x, self.y, self.t, step=self.step_counter)\n        self.register_batch_outputs(self.batch_outputs)\n\n    @partial(jax.jit, static_argnums=(0,))\n    def base_eval_step(self, state: TrainState, x, t):\n        return state.apply_fn(state.params, x, t, training=False)\n\n    def valid_step(self):\n        self.y_hat = self.base_eval_step(self.state, self.x, self.t)\n</code></pre>"},{"location":"algos/jax/base_algo/#sequel.algos.jax.jax_base_algo.JaxBaseAlgorithm.__init__","title":"<code>__init__(backbone, benchmark, optimizer, callbacks=[], loggers=None, lr_decay=None, grad_clip=None, reinit_optimizer=True, seed=0)</code>","text":"<p>Inits JaxBaseAlgorithm class.</p> <p>Parameters:</p> Name Type Description Default <code>backbone</code> <code>JaxBaseBackbone</code> <p>The backbone model, e.g., a CNN.</p> required <code>benchmark</code> <code>Benchmark</code> <p>The benchmark, e.g., SplitMNIST.</p> required <code>optimizer</code> <code>optax.GradientTransformation</code> <p>The optimizer used to update the backbone weights.</p> required <code>callbacks</code> <code>Iterable[BaseCallback]</code> <p>A list of callbacks. At least one instance of MetricCallback should be given. Defaults to [].</p> <code>[]</code> <code>loggers</code> <code>Optional[Logger]</code> <p>A list of logger, e.g. for Weights&amp;Biases logging functionality. Defaults to None.</p> <code>None</code> <code>lr_decay</code> <code>Optional[float]</code> <p>A learning rate decay used for every new task. Defaults to None.</p> <code>None</code> <code>grad_clip</code> <code>Optional[float]</code> <p>The gradient clipping norm. Defaults to None.</p> <code>None</code> <code>reinit_optimizer</code> <code>bool</code> <p>Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True.</p> <code>True</code> <code>seed</code> <code>int</code> <p>The seed used by JAX. Sets the corresponding <code>PRNGKey</code>. Defaults to 0.</p> <code>0</code> Note <ol> <li>the <code>_configure_optimizers</code> method will be moved to a dedicated Callback.</li> </ol> Source code in <code>sequel/algos/jax/jax_base_algo.py</code> <pre><code>def __init__(\n    self,\n    backbone: JaxBaseBackbone,\n    benchmark: Benchmark,\n    optimizer: optax.GradientTransformation,\n    callbacks: Iterable[BaseCallback] = [],\n    loggers: Optional[Iterable[Logger]] = None,\n    lr_decay: Optional[float] = None,\n    grad_clip: Optional[float] = None,\n    reinit_optimizer: bool = True,\n    seed=0,\n) -&gt; None:\n\"\"\"Inits JaxBaseAlgorithm class.\n\n    Args:\n        backbone (JaxBaseBackbone): The backbone model, e.g., a CNN.\n        benchmark (Benchmark): The benchmark, e.g., SplitMNIST.\n        optimizer (optax.GradientTransformation):  The optimizer used to update the backbone weights.\n        callbacks (Iterable[BaseCallback], optional): A list of callbacks. At least one instance of MetricCallback\n            should be given. Defaults to [].\n        loggers (Optional[Logger], optional): A list of logger, e.g. for Weights&amp;Biases logging functionality.\n            Defaults to None.\n        lr_decay (Optional[float], optional): A learning rate decay used for every new task. Defaults to None.\n        grad_clip (Optional[float], optional): The gradient clipping norm. Defaults to None.\n        reinit_optimizer (bool): Indicates whether the optimizer state is reinitialized before fitting a new task.\n            Defaults to True.\n        seed (int, optional): The seed used by JAX. Sets the corresponding `PRNGKey`. Defaults to 0.\n\n    Note:\n        1. the `_configure_optimizers` method will be moved to a dedicated Callback.\n    \"\"\"\n\n    assert isinstance(backbone, BaseBackbone)\n    super().__init__(\n        backbone=backbone,\n        benchmark=benchmark,\n        optimizer=optimizer,\n        callbacks=callbacks,\n        loggers=loggers,\n        lr_decay=lr_decay,\n        grad_clip=grad_clip,\n        reinit_optimizer=reinit_optimizer,\n    )\n    print(\"&gt;\" * 100)\n    print(self.benchmark.num_classes)\n    print(\"&gt;\" * 100)\n    self.seed = seed\n    rng = jax.random.PRNGKey(seed)\n    self.rng, init_rng = jax.random.split(rng)\n    self.state: TrainState = self.create_train_state(self.backbone, init_rng, task=None)\n    self.apply_fn = self.state.apply_fn\n    self.original_optimizer = copy.deepcopy(self.optimizer)\n</code></pre>"},{"location":"algos/jax/base_algo/#sequel.algos.jax.jax_base_algo.JaxBaseAlgorithm.base_training_step","title":"<code>base_training_step(state, x, y, t, step)</code>","text":"<p>Train for a single step.</p> Source code in <code>sequel/algos/jax/jax_base_algo.py</code> <pre><code>@partial(jax.jit, static_argnums=(0,))\ndef base_training_step(self, state: TrainState, x, y, t, step):\n\"\"\"Train for a single step.\"\"\"\n    grad_fn = jax.value_and_grad(self.cross_entropy, has_aux=True, allow_int=True)\n    (loss, logits), grads = grad_fn(state.params, x=x, y=y, t=t, training=True, step=step)\n    state = state.apply_gradients(grads=grads)\n    return dict(state=state, logits=logits, loss=loss, grads=grads)\n</code></pre>"},{"location":"algos/jax/base_algo/#sequel.algos.jax.jax_base_algo.JaxBaseAlgorithm.create_train_state","title":"<code>create_train_state(model, rng, task=None)</code>","text":"<p>Creates initial <code>TrainState</code>.</p> Source code in <code>sequel/algos/jax/jax_base_algo.py</code> <pre><code>def create_train_state(self, model: nn.Module, rng: PRNGKey, task=None) -&gt; TrainState:\n\"\"\"Creates initial `TrainState`.\"\"\"\n    dims = self.benchmark.dimensions\n    dimensions = [1] + dims[1:] + [dims[0]]\n    params = model.init(rng, x=jnp.ones(dimensions), task_ids=None, training=False)\n    tx = self.optimizer\n\n    rng, self.dropout_key = jax.random.split(rng)\n    del rng\n\n    return TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n</code></pre>"},{"location":"algos/jax/base_algo/#sequel.algos.jax.jax_base_algo.JaxRegularizationBaseAlgorithm","title":"<code>JaxRegularizationBaseAlgorithm</code>","text":"<p>         Bases: <code>JaxBaseAlgorithm</code></p> <p>JaxRegularizationBaseAlgorithm inherits from <code>JaxBaseAlgorithm</code> and implements a few utility functions that are used by all regularization-based algorithms such as calculating the regularization loss and computing the per-parameter importance.</p> Source code in <code>sequel/algos/jax/jax_base_algo.py</code> <pre><code>class JaxRegularizationBaseAlgorithm(JaxBaseAlgorithm):\n\"\"\"JaxRegularizationBaseAlgorithm inherits from `JaxBaseAlgorithm` and implements a few utility functions that are\n    used by all regularization-based algorithms such as calculating the regularization loss and computing the\n    per-parameter importance.\n    \"\"\"\n\n    def __init__(self, regularization_coefficient: float, *args, **kwargs) -&gt; None:\n\"\"\"Base class for regularization-based algorithms implemented in JAX, such as EWC and SI\n\n        Args:\n            regularization_coefficient (float): the coefficient used to weigh the regularization loss.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self.regularization_coefficient = regularization_coefficient\n        self.old_params = None\n        self.importance = None\n\n    @partial(jax.jit, static_argnums=(0,))\n    def calculate_regularization_loss(self, params):\n        assert self.task_counter &gt; 1\n        return tree_reduce(\n            lambda x, y: jnp.sum(x) + jnp.sum(y),\n            tree_map(\n                lambda a, b, w: jnp.sum(w * (a - b) ** 2.0),\n                params,\n                self.old_params,\n                self.importance,\n            ),\n        )\n\n    @partial(jax.jit, static_argnums=(0,))\n    def compute_overall_loss(self, params, x, y, t, step):\n        ewc_loss = self.calculate_regularization_loss(params)\n        loss, logits = self.cross_entropy(params, x, y, t, training=True, step=step)\n        loss += self.regularization_coefficient * ewc_loss\n        return loss, logits\n\n    @partial(jax.jit, static_argnums=(0,))\n    def regularization_training_step(self, state: TrainState, x, y, t, step):\n        grad_fn = jax.value_and_grad(self.compute_overall_loss, has_aux=True, allow_int=True)\n        (loss, logits), grads = grad_fn(state.params, x, y, t, step=step)\n        state = state.apply_gradients(grads=grads)\n        return dict(state=state, logits=logits, loss=loss, grads=grads)\n\n    def training_step(self, *args, **kwargs):\n        if self.task_counter == 1:\n            return super().training_step()\n        else:\n            self.batch_outputs = self.regularization_training_step(\n                self.state, self.x, self.y, self.t, step=self.step_counter\n            )\n            self.register_batch_outputs(self.batch_outputs)\n</code></pre>"},{"location":"algos/jax/base_algo/#sequel.algos.jax.jax_base_algo.JaxRegularizationBaseAlgorithm.__init__","title":"<code>__init__(regularization_coefficient, *args, **kwargs)</code>","text":"<p>Base class for regularization-based algorithms implemented in JAX, such as EWC and SI</p> <p>Parameters:</p> Name Type Description Default <code>regularization_coefficient</code> <code>float</code> <p>the coefficient used to weigh the regularization loss.</p> required Source code in <code>sequel/algos/jax/jax_base_algo.py</code> <pre><code>def __init__(self, regularization_coefficient: float, *args, **kwargs) -&gt; None:\n\"\"\"Base class for regularization-based algorithms implemented in JAX, such as EWC and SI\n\n    Args:\n        regularization_coefficient (float): the coefficient used to weigh the regularization loss.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n    self.regularization_coefficient = regularization_coefficient\n    self.old_params = None\n    self.importance = None\n</code></pre>"},{"location":"algos/jax/der/","title":"DER","text":""},{"location":"algos/jax/der/#sequel.algos.jax.der.DER","title":"<code>DER</code>","text":"<p>         Bases: <code>JaxBaseAlgorithm</code></p> <p>Dark Experience Replay algorithm implemented in JAX.</p> <p>The equivalent PyTorch implementation is <code>DER in Pytorch</code>.</p> References <p>[1] Buzzega, P., Boschini, M., Porrello, A., Abati, D. &amp; Calderara, S. Dark experience for general continual     learning: a strong, simple baseline. in Advances in neural information processing systems 2020.</p> Source code in <code>sequel/algos/jax/der.py</code> <pre><code>class DER(JaxBaseAlgorithm):\n\"\"\"Dark Experience Replay algorithm implemented in JAX.\n\n    The equivalent PyTorch implementation is [`DER in Pytorch`][sequel.algos.pytorch.der.DER].\n\n    References:\n        [1] Buzzega, P., Boschini, M., Porrello, A., Abati, D. &amp; Calderara, S. Dark experience for general continual\n            learning: a strong, simple baseline. in Advances in neural information processing systems 2020.\n    \"\"\"\n\n    def __init__(self, memory_size: int, alpha: float, beta: Optional[float] = None, *args, **kwargs):\n\"\"\"Inits the DER class. Implements the Dark Experience Replay algorithm.\n\n        Args:\n            memory_size (int): The size of the memory.\n            alpha (float): The regularization coefficient for the DER objective.\n            beta (Optional[float], optional): The regulrization coefficent for the DER++ objective. If set to None or\n                zero, the algorithm corresponds to DER. Defaults to None.\n        \"\"\"\n\n        super().__init__(*args, **kwargs)\n        self.buffer = Buffer(memory_size=memory_size, return_logits=True)\n        self.memory_size = memory_size\n        self.alpha = alpha\n\n        # Beta is used for DER++\n        self.beta = beta\n\n    def __repr__(self) -&gt; str:\n        if self.beta is None:\n            return f\"DER(memory_size={self.memory_size}, alpha={self.alpha})\"\n        else:\n            return f\"DER++(memory_size={self.memory_size}, alpha={self.alpha}, beta={self.beta})\"\n\n    @partial(jax.jit, static_argnums=(0,))\n    def der_loss(self, params, x, y, t):\n        # TODO: add task id support\n        dropout_train_key = jax.random.fold_in(key=self.dropout_key, data=self.state.step)\n        logits = self.apply_fn(params, x=x, training=self.is_training, rngs={\"dropout\": dropout_train_key})\n        loss = cross_entropy_loss(logits=logits, labels=y)\n        # DER LOSS\n        dropout_key = jax.random.fold_in(key=dropout_train_key, data=self.state.step)\n        mem_y_hat = self.apply_fn(params, x=x, training=self.is_training, rngs={\"dropout\": dropout_key})\n        der_loss = jnp.mean((self.mem_logits - mem_y_hat) ** 2)\n\n        loss += self.alpha * der_loss\n        return loss, logits\n\n    @partial(jax.jit, static_argnums=(0,))\n    def derpp_loss(self, params, x, y, t):\n        # TODO: add task id support\n        dropout_key = jax.random.fold_in(key=self.dropout_key, data=self.state.step)\n        logits = self.apply_fn(params, x=x, t=t, training=self.is_training, rngs={\"dropout\": dropout_key})\n        loss = cross_entropy_loss(logits=logits, labels=y)\n        # DER LOSS\n        dropout_key = jax.random.fold_in(key=dropout_key, data=self.state.step)\n        mem_y_hat = self.apply_fn(params, x=self.mem_x, training=self.is_training, rngs={\"dropout\": dropout_key})\n        der_loss = jnp.mean((self.mem_logits - mem_y_hat) ** 2)\n\n        # DER++ LOSS\n        dropout_key = jax.random.fold_in(key=dropout_key, data=self.state.step)\n        mem_y_hat2 = self.apply_fn(params, x=x, training=self.is_training, rngs={\"dropout\": dropout_key})\n        derpp_loss = cross_entropy_loss(logits=mem_y_hat2, labels=self.mem_y2)\n\n        loss += self.alpha * der_loss + self.beta * derpp_loss\n        return loss, logits\n\n    @partial(jax.jit, static_argnums=(0, 5))\n    def custom_training_step(self, state: TrainState, x, y, t, loss_fn):\n\"\"\"Train for a single step.\"\"\"\n        grad_fn = jax.value_and_grad(loss_fn, has_aux=True, allow_int=True)\n        (loss, logits), grads = grad_fn(state.params, x=x, y=y, t=t)\n        state = state.apply_gradients(grads=grads)\n        return dict(state=state, logits=logits, loss=loss, grads=grads)\n\n    def training_step(self, *args, **kwargs):\n        if self.task_counter == 1:\n            self.batch_outputs = self.base_training_step(self.state, self.x, self.y, self.t)\n        else:\n            x, y, t, logits = self.buffer.sample_from_buffer(batch_size=self.benchmark.batch_size)\n            self.mem_x, self.mem_y, self.mem_t, self.mem_logits = x, y, t, logits\n            if self.beta is None:\n                self.batch_outputs = self.custom_training_step(self.state, self.x, self.y, self.t, self.der_loss)\n            else:\n                x, y, t, _ = self.buffer.sample_from_buffer(batch_size=self.benchmark.batch_size)\n                self.mem_x2, self.mem_y2, self.mem_t2 = x, y, t\n                self.batch_outputs = self.custom_training_step(self.state, self.x, self.y, self.t, self.derpp_loss)\n        self.register_batch_outputs(self.batch_outputs)\n\n    def on_after_training_step(self, *args, **kwargs):\n        self.buffer.add_data(self.x, self.y, self.t, self.y_hat)\n</code></pre>"},{"location":"algos/jax/der/#sequel.algos.jax.der.DER.__init__","title":"<code>__init__(memory_size, alpha, beta=None, *args, **kwargs)</code>","text":"<p>Inits the DER class. Implements the Dark Experience Replay algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>memory_size</code> <code>int</code> <p>The size of the memory.</p> required <code>alpha</code> <code>float</code> <p>The regularization coefficient for the DER objective.</p> required <code>beta</code> <code>Optional[float]</code> <p>The regulrization coefficent for the DER++ objective. If set to None or zero, the algorithm corresponds to DER. Defaults to None.</p> <code>None</code> Source code in <code>sequel/algos/jax/der.py</code> <pre><code>def __init__(self, memory_size: int, alpha: float, beta: Optional[float] = None, *args, **kwargs):\n\"\"\"Inits the DER class. Implements the Dark Experience Replay algorithm.\n\n    Args:\n        memory_size (int): The size of the memory.\n        alpha (float): The regularization coefficient for the DER objective.\n        beta (Optional[float], optional): The regulrization coefficent for the DER++ objective. If set to None or\n            zero, the algorithm corresponds to DER. Defaults to None.\n    \"\"\"\n\n    super().__init__(*args, **kwargs)\n    self.buffer = Buffer(memory_size=memory_size, return_logits=True)\n    self.memory_size = memory_size\n    self.alpha = alpha\n\n    # Beta is used for DER++\n    self.beta = beta\n</code></pre>"},{"location":"algos/jax/der/#sequel.algos.jax.der.DER.custom_training_step","title":"<code>custom_training_step(state, x, y, t, loss_fn)</code>","text":"<p>Train for a single step.</p> Source code in <code>sequel/algos/jax/der.py</code> <pre><code>@partial(jax.jit, static_argnums=(0, 5))\ndef custom_training_step(self, state: TrainState, x, y, t, loss_fn):\n\"\"\"Train for a single step.\"\"\"\n    grad_fn = jax.value_and_grad(loss_fn, has_aux=True, allow_int=True)\n    (loss, logits), grads = grad_fn(state.params, x=x, y=y, t=t)\n    state = state.apply_gradients(grads=grads)\n    return dict(state=state, logits=logits, loss=loss, grads=grads)\n</code></pre>"},{"location":"algos/jax/ewc/","title":"EWC","text":""},{"location":"algos/jax/ewc/#sequel.algos.jax.ewc.EWC","title":"<code>EWC</code>","text":"<p>         Bases: <code>JaxRegularizationBaseAlgorithm</code></p> <p>The Elastic Weight Consolidation algorithm.</p> <p>The equivalent PyTorch implementation is <code>EWC in Pytorch</code>.</p> References <p>[1] Kirkpatrick, J. et al. Overcoming catastrophic forgetting in neural networks. PNAS 114, 3521-3526 (2017).</p> Source code in <code>sequel/algos/jax/ewc.py</code> <pre><code>class EWC(JaxRegularizationBaseAlgorithm):\n\"\"\"The Elastic Weight Consolidation algorithm.\n\n    The equivalent PyTorch implementation is [`EWC in Pytorch`][sequel.algos.pytorch.ewc.EWC].\n\n    References:\n        [1] Kirkpatrick, J. et al. Overcoming catastrophic forgetting in neural networks. PNAS 114, 3521-3526 (2017).\n    \"\"\"\n\n    def __init__(self, ewc_lambda: float, *args, **kwargs) -&gt; None:\n        super().__init__(regularization_coefficient=ewc_lambda, *args, **kwargs)\n\n    def __repr__(self) -&gt; str:\n        return f\"EWC(ewc_lambda={self.regularization_coefficient})\"\n\n    @partial(jax.jit, static_argnums=(0,))\n    def fisher_training_step(self, state, x, y, t, step):\n        grad_fn = jax.value_and_grad(self.cross_entropy, has_aux=True, allow_int=True)\n        (loss, logits), grads = grad_fn(state.params, x, y, t, training=True, step=step)\n        return grads\n\n    def on_after_training_task(self, *args, **kwargs):\n        self.train_loader = self.benchmark.train_dataloader(self.task_counter)\n        # initialize fisher diagonals to zero\n        fisher_diagonals = jax.tree_map(lambda x: 0 * x, self.state.params)\n        num_samples = 0\n        for self.batch_idx, batch in enumerate(self.train_loader):\n            self.unpack_batch(batch)\n            num_samples += self.bs\n            grads = self.fisher_training_step(self.state, self.x, self.y, self.t, self.step_counter)\n            fisher_diagonals = jax.tree_map(lambda a, b: a**2 + b, grads, fisher_diagonals)\n\n        self.importance = jax.tree_map(lambda x: x / num_samples, fisher_diagonals)\n        self.old_params = copy.deepcopy(self.state.params)\n</code></pre>"},{"location":"algos/jax/joint/","title":"Joint","text":""},{"location":"algos/jax/joint/#sequel.algos.jax.joint.JointTraining","title":"<code>JointTraining</code>","text":"<p>         Bases: <code>JaxBaseAlgorithm</code></p> <p>The JoinTraining algorithm. It is a variant of MultiTask Learning, where the model is trained with increasingly more samples. Specifically, during the t-th task, the model sees samples from all the previous and the current task.</p> <p>Inherits from BaseAlgorithm. Only the <code>prepare_train_loader</code> method is overwritten.</p> <p>The equivalent PyTorch implementation is <code>JointTraining in Pytorch</code>.</p> Source code in <code>sequel/algos/jax/joint.py</code> <pre><code>class JointTraining(JaxBaseAlgorithm):\n\"\"\"The JoinTraining algorithm. It is a variant of MultiTask Learning, where the model is trained with increasingly\n    more samples. Specifically, during the t-th task, the model sees samples from all the previous and the current\n    task.\n\n    Inherits from BaseAlgorithm. Only the `prepare_train_loader` method is overwritten.\n\n    The equivalent PyTorch implementation is [`JointTraining in Pytorch`][sequel.algos.pytorch.joint.JointTraining].\n    \"\"\"\n\n    def __init__(self, *args, **kwargs) -&gt; None:\n        super().__init__(*args, **kwargs)\n\n    def __repr__(self) -&gt; str:\n        return f\"JointTraining()\"\n\n    def prepare_train_loader(self, task_id: int, batch_size: Optional[int] = None) -&gt; DataLoader:\n\"\"\"Prepares the train_loader for Joint Training. The dataloader consists of all samples up to task `task_id`.\n\n        Args:\n            task_id (int): The last task to be loaded.\n            batch_size (Optional[int], optional): The dataloader batch size. Defaults to None.\n\n        Returns:\n            DataLoader: The JointTraining train dataloder.\n        \"\"\"\n        return self.benchmark.train_dataloader_joint(task_id, batch_size=batch_size)\n</code></pre>"},{"location":"algos/jax/joint/#sequel.algos.jax.joint.JointTraining.prepare_train_loader","title":"<code>prepare_train_loader(task_id, batch_size=None)</code>","text":"<p>Prepares the train_loader for Joint Training. The dataloader consists of all samples up to task <code>task_id</code>.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>int</code> <p>The last task to be loaded.</p> required <code>batch_size</code> <code>Optional[int]</code> <p>The dataloader batch size. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DataLoader</code> <code>DataLoader</code> <p>The JointTraining train dataloder.</p> Source code in <code>sequel/algos/jax/joint.py</code> <pre><code>def prepare_train_loader(self, task_id: int, batch_size: Optional[int] = None) -&gt; DataLoader:\n\"\"\"Prepares the train_loader for Joint Training. The dataloader consists of all samples up to task `task_id`.\n\n    Args:\n        task_id (int): The last task to be loaded.\n        batch_size (Optional[int], optional): The dataloader batch size. Defaults to None.\n\n    Returns:\n        DataLoader: The JointTraining train dataloder.\n    \"\"\"\n    return self.benchmark.train_dataloader_joint(task_id, batch_size=batch_size)\n</code></pre>"},{"location":"algos/jax/lfl/","title":"LFL","text":""},{"location":"algos/jax/lfl/#sequel.algos.jax.lfl.LFL","title":"<code>LFL</code>","text":"<p>         Bases: <code>JaxBaseAlgorithm</code></p> <p>Less-Forgetting Learning implementation in JAX.</p> <p>The equivalent PyTorch implementation is <code>LFL in Pytorch</code>.</p> References <p>[1] Jung, H., Ju, J., Jung, M. &amp; Kim, J. Less-forgetful learning for domain expansion in deep neural     networks. Proceedings of the AAAI Conference on Artificial Intelligence 32, (2018).</p> Source code in <code>sequel/algos/jax/lfl.py</code> <pre><code>class LFL(JaxBaseAlgorithm):\n\"\"\"Less-Forgetting Learning implementation in JAX.\n\n    The equivalent PyTorch implementation is [`LFL in Pytorch`][sequel.algos.pytorch.lfl.LFL].\n\n    References:\n        [1] Jung, H., Ju, J., Jung, M. &amp; Kim, J. Less-forgetful learning for domain expansion in deep neural\n            networks. Proceedings of the AAAI Conference on Artificial Intelligence 32, (2018).\n    \"\"\"\n\n    def __init__(self, lfl_lambda: float, *args, **kwargs):\n\"\"\"Inits the LFL class.\n\n        Args:\n            lfl_lambda (float): the regularization coefficient.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self.regularization_coefficient = lfl_lambda\n\n    def __repr__(self) -&gt; str:\n        return f\"LFL(regularization_coefficient={self.regularization_coefficient})\"\n\n    def on_after_training_task(self, *args, **kwargs):\n        # freeze previous model\n        # assert isinstance\n        self.prev_params = copy.deepcopy(self.state.params)\n\n    @partial(jax.jit, static_argnums=(0,))\n    def lfl_loss(self, params, x, y, t):\n        dropout_train_key = jax.random.fold_in(key=self.dropout_key, data=self.state.step)\n\n        logits = self.apply_fn(params, x=x, training=self.is_training, rngs={\"dropout\": dropout_train_key})\n        loss = cross_entropy_loss(logits=logits, labels=y)\n\n        # disable dropout, etc for features. Equivalent to model.eval() in PyTorch\n        features = self.apply_fn(\n            params,\n            x,\n            training=False,\n            method=lambda module, x, training: module.encoder(x, training),\n        )\n\n        old_features = self.apply_fn(\n            self.prev_params,\n            x,\n            training=False,\n            method=lambda module, x, training: module.encoder(x, training),\n        )\n\n        lfl_loss = jnp.mean((old_features - features) ** 2)\n        loss += self.regularization_coefficient * lfl_loss\n        return loss, logits\n\n    @partial(jax.jit, static_argnums=(0,))\n    def lfl_training_step(self, state: TrainState, x, y, t):\n\"\"\"Train for a single step.\"\"\"\n        grad_fn = jax.value_and_grad(self.lfl_loss, has_aux=True, allow_int=True)\n        (loss, logits), grads = grad_fn(state.params, x=x, y=y, t=t)\n        state = state.apply_gradients(grads=grads)\n        return dict(state=state, logits=logits, loss=loss, grads=grads)\n\n    def training_step(self):\n        if self.task_counter == 1:\n            self.batch_outputs = self.base_training_step(self.state, self.x, self.y, self.t)\n        else:\n            self.batch_outputs = self.lfl_training_step(self.state, self.x, self.y, self.t)\n        self.register_batch_outputs(self.batch_outputs)\n</code></pre>"},{"location":"algos/jax/lfl/#sequel.algos.jax.lfl.LFL.__init__","title":"<code>__init__(lfl_lambda, *args, **kwargs)</code>","text":"<p>Inits the LFL class.</p> <p>Parameters:</p> Name Type Description Default <code>lfl_lambda</code> <code>float</code> <p>the regularization coefficient.</p> required Source code in <code>sequel/algos/jax/lfl.py</code> <pre><code>def __init__(self, lfl_lambda: float, *args, **kwargs):\n\"\"\"Inits the LFL class.\n\n    Args:\n        lfl_lambda (float): the regularization coefficient.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n    self.regularization_coefficient = lfl_lambda\n</code></pre>"},{"location":"algos/jax/lfl/#sequel.algos.jax.lfl.LFL.lfl_training_step","title":"<code>lfl_training_step(state, x, y, t)</code>","text":"<p>Train for a single step.</p> Source code in <code>sequel/algos/jax/lfl.py</code> <pre><code>@partial(jax.jit, static_argnums=(0,))\ndef lfl_training_step(self, state: TrainState, x, y, t):\n\"\"\"Train for a single step.\"\"\"\n    grad_fn = jax.value_and_grad(self.lfl_loss, has_aux=True, allow_int=True)\n    (loss, logits), grads = grad_fn(state.params, x=x, y=y, t=t)\n    state = state.apply_gradients(grads=grads)\n    return dict(state=state, logits=logits, loss=loss, grads=grads)\n</code></pre>"},{"location":"algos/jax/mas/","title":"MAS","text":""},{"location":"algos/jax/mas/#sequel.algos.jax.mas.MAS","title":"<code>MAS</code>","text":"<p>         Bases: <code>JaxRegularizationBaseAlgorithm</code></p> <p>Memory Aware Synapses. Algorithm Class. Inherits from BaseAlgorithm.</p> <p>The equivalent PyTorch implementation is <code>MAS in Pytorch</code>.</p> References <p>[1] Aljundi, R., Babiloni, F., Elhoseiny, M., Rohrbach, M. &amp; Tuytelaars, T. Memory Aware Synapses: Learning     What (not) to Forget. in Computer Vision - ECCV 2018.</p> Source code in <code>sequel/algos/jax/mas.py</code> <pre><code>class MAS(JaxRegularizationBaseAlgorithm):\n\"\"\"Memory Aware Synapses. Algorithm Class. Inherits from BaseAlgorithm.\n\n    The equivalent PyTorch implementation is [`MAS in Pytorch`][sequel.algos.pytorch.mas.MAS].\n\n    References:\n        [1] Aljundi, R., Babiloni, F., Elhoseiny, M., Rohrbach, M. &amp; Tuytelaars, T. Memory Aware Synapses: Learning\n            What (not) to Forget. in Computer Vision - ECCV 2018.\n    \"\"\"\n\n    def __init__(self, mas_lambda: float = 1.0, *args, **kwargs):\n        super().__init__(regularization_coefficient=mas_lambda, *args, **kwargs)\n        self.w = jax.tree_map(lambda x: 0 * x, self.state.params)\n\n    def __repr__(self) -&gt; str:\n        return f\"MAS(mas_lambda={self.regularization_coefficient})\"\n\n    def calculate_parameter_importance(self):\n        if self.task_counter == 1:\n            importance = jax.tree_map(lambda x: 0 * x, self.state.params)\n        else:\n            importance = self.importance\n        importance = jax.tree_map(lambda i, w: i + w, importance, self.w)\n        self.w = jax.tree_map(lambda x: 0 * x, self.state.params)\n        return importance\n\n    def on_before_training_step(self, *args, **kwargs):\n        self.old_params = copy.deepcopy(self.state.params)\n\n    def on_after_training_step(self, *args, **kwargs):\n        @jax.jit\n        def secondary_loss(params, x, t, training=True):\n            logits = self.apply_fn(params, x, t, training=training)\n            loss = jnp.mean(jnp.square(logits))\n            return loss, logits\n\n        grad_fn = jax.value_and_grad(secondary_loss, has_aux=True, allow_int=True)\n        _, grads = grad_fn(self.state.params, self.x, self.t, self.is_training)\n        self.w = jax.tree_map(lambda w, g: w + jnp.abs(g) / len(self.y), self.w, grads)\n\n    def on_after_training_task(self, *args, **kwargs):\n        self.old_params = copy.deepcopy(self.state.params)\n        self.importance = self.calculate_parameter_importance()\n</code></pre>"},{"location":"algos/jax/mcsgd/","title":"MC-SGD","text":""},{"location":"algos/jax/mcsgd/#sequel.algos.jax.mcsgd.MCSGD","title":"<code>MCSGD</code>","text":"<p>         Bases: <code>JaxBaseAlgorithm</code></p> <p>MC-SGD: Mode Connectivity-Stochastic Gradient Descent. Inherits from BaseAlgorithm.</p> <p>The equivalent PyTorch implementation is <code>MCSGD in Pytorch</code>.</p> References <p>[1] Mirzadeh, S.-I., Farajtabar, M., G\u00f6r\u00fcr, D., Pascanu, R. &amp; Ghasemzadeh, H. Linear Mode Connectivity in     Multitask and Continual Learning. in 9th International Conference on Learning Representations, ICLR 2021.</p> Source code in <code>sequel/algos/jax/mcsgd.py</code> <pre><code>class MCSGD(JaxBaseAlgorithm):\n\"\"\"MC-SGD: Mode Connectivity-Stochastic Gradient Descent. Inherits from BaseAlgorithm.\n\n    The equivalent PyTorch implementation is [`MCSGD in Pytorch`][sequel.algos.pytorch.mcsgd.MCSGD].\n\n    References:\n        [1] Mirzadeh, S.-I., Farajtabar, M., G\u00f6r\u00fcr, D., Pascanu, R. &amp; Ghasemzadeh, H. Linear Mode Connectivity in\n            Multitask and Continual Learning. in 9th International Conference on Learning Representations, ICLR 2021.\n    \"\"\"\n\n    state: TrainState\n\n    def __init__(\n        self,\n        per_task_memory_samples: int = 100,\n        memory_group_by: Literal[\"task\", \"class\"] = \"task\",\n        lmc_policy=\"offline\",\n        lmc_interpolation=\"linear\",\n        lmc_lr=0.05,\n        lmc_momentum=0.8,\n        lmc_batch_size=64,\n        lmc_init_position=0.1,\n        lmc_line_samples=10,\n        lmc_epochs=1,\n        *args,\n        **kwargs,\n    ):\n        super().__init__(*args, **kwargs)\n        self.memory = MemoryMechanism(per_task_memory_samples=per_task_memory_samples, groupby=memory_group_by)\n        self.w_bar_prev = None\n        self.w_hat_curr = None\n\n        # parse init arguments\n        self.per_task_memory_samples = per_task_memory_samples\n        self.lmc_policy = lmc_policy\n        self.lmc_interpolation = lmc_interpolation\n        self.lmc_lr = lmc_lr\n        self.lmc_momentum = lmc_momentum\n        self.lmc_batch_size = lmc_batch_size\n        self.lmc_init_position = lmc_init_position\n        self.lmc_line_samples = lmc_line_samples\n        self.lmc_epochs = lmc_epochs\n\n    def __repr__(self) -&gt; str:\n        return (\n            \"MCSGD(\"\n            + f\"per_task_memory_samples={self.per_task_memory_samples}, \"\n            + f\"policy={self.lmc_policy}, \"\n            + f\"interpolation={self.lmc_interpolation}, \"\n            + f\"lr={self.lmc_lr}, \"\n            + f\"momentum={self.lmc_momentum}, \"\n            + f\"batch_size={self.lmc_batch_size}, \"\n            + f\"init_position={self.lmc_init_position}, \"\n            + f\"line_samples={self.lmc_line_samples}, \"\n            + f\"epochs={self.lmc_epochs}\"\n            + \")\"\n        )\n\n    def calculate_line_loss(self, w_start, w_end, loader):\n        line_samples = np.arange(0.0, 1.01, 1.0 / float(self.lmc_line_samples))\n        grads = tree_map(lambda x: 0 * x, w_start)\n        for t in tqdm(line_samples, desc=\"Line samples\"):\n            params = tree_map(lambda a, b: a + (b - a) * t, w_start, w_end)\n            g = self.calculate_point_loss(params, loader)\n            grads = tree_map(lambda a, b: a + b, grads, g)\n        return grads\n\n    @partial(jax.jit, static_argnums=(0,))\n    def simple_training_step(self, params, x, y, t, step):\n        grad_fn = jax.value_and_grad(self.cross_entropy, has_aux=True, allow_int=True)\n        (loss, logits), grads = grad_fn(params, x, y, t, self.is_training, step=step)\n        return grads\n\n    def calculate_point_loss(self, params, loader):\n        total_count = 0.0\n        grads = tree_map(lambda x: 0 * x, params)\n        for batch in loader:\n            self.unpack_batch(batch)\n            g = self.simple_training_step(params, self.x, self.y, self.t, self.step_counter)\n            grads = tree_map(lambda a, b: a + b, grads, g)\n            total_count += self.bs\n\n        return tree_map(lambda a: a / total_count, grads)\n\n    def find_connected_minima(self, task):\n        bs = self.lmc_batch_size\n        loader_curr = self.benchmark.train_dataloader_subset(\n            task, batch_size=bs, subset_size=self.per_task_memory_samples\n        )\n        loader_prev = self.benchmark.memory_dataloader(task, batch_size=bs, return_infinite_stream=False)\n\n        params = tree_map(lambda a, b: a + (b - a) * self.lmc_init_position, self.w_bar_prev, self.w_hat_curr)\n        tx = optax.sgd(learning_rate=self.lmc_lr, momentum=self.lmc_momentum)\n        state = TrainState.create(apply_fn=self.apply_fn, params=params, tx=tx)\n\n        grads_prev = self.calculate_line_loss(self.w_bar_prev, state.params, loader_prev)\n        grads_curr = self.calculate_line_loss(self.w_hat_curr, state.params, loader_curr)\n\n        grads = tree_map(lambda a, b: a + b, grads_prev, grads_curr)\n        state = state.apply_gradients(grads=grads)\n        return state\n\n    def on_after_training_epoch(self, *args, **kwargs):\n        self.w_hat_curr = copy.deepcopy(self.state.params)\n        self.old_state = copy.deepcopy(self.state)\n\n    def validate_algorithm_on_all_tasks(self) -&gt; Dict[str, float]:\n        if self.task_counter == 1:\n            super().validate_algorithm_on_all_tasks()\n\n    def on_after_validating_algorithm_on_all_tasks_callbacks(self):\n        if self.task_counter == 1:\n            return super().on_after_validating_algorithm_on_all_tasks_callbacks()\n\n    def on_after_training_task(self, *args, **kwargs):\n        self.memory.update_memory(self)\n        if self.task_counter &gt; 1:\n            # save the backbone obtained from the mode-connectivity updates\n            # as the Multi-Task approximate solution\n\n            self.w_bar_prev = self.find_connected_minima(self.task_counter).params\n            # perform the validation with the weights obtained after the mode-connectivity updates\n            self.state = self.state.replace(params=self.w_bar_prev)\n            super().on_before_validating_algorithm_on_all_tasks_callbacks()\n            super().validate_algorithm_on_all_tasks()\n            super().on_after_validating_algorithm_on_all_tasks_callbacks()\n        else:\n            self.w_bar_prev = copy.deepcopy(self.state.params)\n\n        # revert the weights of the backbone to the Continual Learning solution\n        self.state = copy.deepcopy(self.old_state)\n</code></pre>"},{"location":"algos/jax/si/","title":"SI","text":""},{"location":"algos/jax/si/#sequel.algos.jax.si.SI","title":"<code>SI</code>","text":"<p>         Bases: <code>JaxRegularizationBaseAlgorithm</code></p> <p>Synaptic Intelligence Algorithm.</p> <p>The equivalent PyTorch implementation is <code>SI in Pytorch</code>.</p> References <p>[1] Zenke, F., Poole, B. &amp; Ganguli, S. Continual Learning Through Synaptic Intelligence. in Proceedings of the     34th International Conference on Machine Learning, ICML 2017.</p> Source code in <code>sequel/algos/jax/si.py</code> <pre><code>class SI(JaxRegularizationBaseAlgorithm):\n\"\"\"Synaptic Intelligence Algorithm.\n\n    The equivalent PyTorch implementation is [`SI in Pytorch`][sequel.algos.pytorch.si.SI].\n\n    References:\n        [1] Zenke, F., Poole, B. &amp; Ganguli, S. Continual Learning Through Synaptic Intelligence. in Proceedings of the\n            34th International Conference on Machine Learning, ICML 2017.\n    \"\"\"\n\n    def __init__(self, si_lambda: float = 1.0, xi: float = 0.1, *args, **kwargs):\n        super().__init__(regularization_coefficient=si_lambda, *args, **kwargs)\n        self.xi = xi\n        self.w = jax.tree_map(lambda a: 0 * a, self.state.params)\n\n    def __repr__(self) -&gt; str:\n        return f\"SI(si_lambda={self.regularization_coefficient}, xi={self.xi})\"\n\n    def calculate_parameter_importance(self):\n        if self.task_counter == 1:\n            importance = jax.tree_map(lambda x: 0 * x, self.state.params)\n        else:\n            importance = self.importance\n        delta = jax.tree_map(lambda w_cur, w_old: w_cur - w_old, self.state.params, self.old_params)\n        importance = jax.tree_map(lambda i, w, dt: i + w / (dt**2 + self.xi), importance, self.w, delta)\n        self.w = jax.tree_map(lambda x: 0 * x, self.state.params)\n        return importance\n\n    def on_before_training_step(self, *args, **kwargs):\n        self.prev_params = copy.deepcopy(self.state.params)\n\n    # @partial(jax.jit, static_argnums=(0,))\n    def on_after_training_step(self, *args, **kwargs):\n        grads = self.batch_outputs[\"grads\"]\n        delta = jax.tree_map(lambda w_cur, w_old: w_cur - w_old, self.state.params, self.prev_params)\n        self.w = jax.tree_map(lambda w, g, d: w - g * d, self.w, grads, delta)\n\n    def on_after_training_task(self, *args, **kwargs):\n        self.old_params = copy.deepcopy(self.state.params)\n        self.importance = self.calculate_parameter_importance()\n</code></pre>"},{"location":"algos/pytorch/agem/","title":"AGEM","text":""},{"location":"algos/pytorch/agem/#sequel.algos.pytorch.agem.AGEM","title":"<code>AGEM</code>","text":"<p>         Bases: <code>PytorchBaseAlgorithm</code></p> <p>A-GEM: Averaged-Gradient Episodic Memory. Maintains a memory of samples from past tasks. The gradients for the current batch are projected to the convex hull of the task gradients produced by the the aforementioned memory. Inherits from BaseAlgorithm.</p> <p>The equivalent JAX implementation is <code>A-GEM in JAX</code>.</p> References <p>[1] Chaudhry, A., Ranzato, M., Rohrbach, M. &amp; Elhoseiny, M. Efficient Lifelong Learning with A-GEM. in 7th     International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019.</p> Source code in <code>sequel/algos/pytorch/agem.py</code> <pre><code>class AGEM(PytorchBaseAlgorithm):\n\"\"\"A-GEM: Averaged-Gradient Episodic Memory. Maintains a memory of samples from past tasks.\n    The gradients for the current batch are projected to the convex hull of the task gradients\n    produced by the the aforementioned memory. Inherits from BaseAlgorithm.\n\n    The equivalent JAX implementation is [`A-GEM in JAX`][sequel.algos.jax.agem.AGEM].\n\n    References:\n        [1] Chaudhry, A., Ranzato, M., Rohrbach, M. &amp; Elhoseiny, M. Efficient Lifelong Learning with A-GEM. in 7th\n            International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019.\n    \"\"\"\n\n    def __init__(\n        self,\n        per_task_memory_samples: int,\n        memory_batch_size: int,\n        memory_group_by: Literal[\"task\", \"class\"],\n        *args,\n        **kwargs,\n    ):\n\"\"\"Inits the AGEM algorithm class.\n\n        Args:\n            per_task_memory_samples (int): number of exemplars per experience in the memory.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self.memory = MemoryMechanism(per_task_memory_samples=per_task_memory_samples, groupby=memory_group_by)\n        self.per_task_memory_samples = per_task_memory_samples\n        self.memory_batch_size = memory_batch_size\n\n    def __repr__(self) -&gt; str:\n        return (\n            f\"AGEM(memory_batch_size={self.memory_batch_size}, per_task_memory_samples={self.per_task_memory_samples})\"\n        )\n\n    def on_after_training_task(self, *args, **kwargs):\n        self.memory.update_memory(self)\n        self.update_episodic_memory()\n        logging.info(\"The episodic memory now stores {} samples\".format(len(self.episodic_memory_loader.dataset)))\n\n    def update_episodic_memory(self):\n        logging.info(\"Updating episodic memory for task {}\".format(self.task_counter))\n        self.episodic_memory_loader = self.benchmark.memory_dataloader(self.task_counter, self.memory_batch_size)\n        self.episodic_memory_iter = iter(self.episodic_memory_loader)\n\n    def sample_batch_from_memory(self):\n        try:\n            return next(self.episodic_memory_iter)\n        except StopIteration:\n            # makes the dataloader an infinite stream\n            self.episodic_memory_iter = iter(self.episodic_memory_loader)\n            return next(self.episodic_memory_iter)\n\n    def on_before_optimizer_step(self, *args, **kwargs):\n        if self.task_counter == 1:\n            return\n\n        # save gradients from current task and flush optimizer gradients\n        old_grads = get_grads(self.backbone).detach().clone()\n        self.optimizer_zero_grad()\n\n        # sample from memory and compute corresponding gradients.\n        x, y, t = self.sample_batch_from_memory()\n        x, y = x.to(self.device), y.to(self.device)\n        y_hat = self.backbone(x, t)\n        loss = self.compute_loss(y_hat, y, t)\n        loss.backward()\n\n        # gradients from memory\n        mem_grads = get_grads(self.backbone).detach().clone()\n\n        assert old_grads.shape == mem_grads.shape, \"Different model parameters in AGEM projection\"\n\n        dotg = torch.dot(old_grads, mem_grads)\n        if dotg &lt; 0:\n            # if current task and memory gradients have negative angle (negative cosine similarity),\n            # perform the A-GEM projection.\n            alpha2 = dotg / torch.dot(mem_grads, mem_grads)\n            new_grads = old_grads - mem_grads * alpha2\n\n            self.backbone = set_grads(self.backbone, new_grads)\n        else:\n            self.backbone = set_grads(self.backbone, old_grads)\n\n        return super().on_before_optimizer_step(*args, **kwargs)\n</code></pre>"},{"location":"algos/pytorch/agem/#sequel.algos.pytorch.agem.AGEM.__init__","title":"<code>__init__(per_task_memory_samples, memory_batch_size, memory_group_by, *args, **kwargs)</code>","text":"<p>Inits the AGEM algorithm class.</p> <p>Parameters:</p> Name Type Description Default <code>per_task_memory_samples</code> <code>int</code> <p>number of exemplars per experience in the memory.</p> required Source code in <code>sequel/algos/pytorch/agem.py</code> <pre><code>def __init__(\n    self,\n    per_task_memory_samples: int,\n    memory_batch_size: int,\n    memory_group_by: Literal[\"task\", \"class\"],\n    *args,\n    **kwargs,\n):\n\"\"\"Inits the AGEM algorithm class.\n\n    Args:\n        per_task_memory_samples (int): number of exemplars per experience in the memory.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n    self.memory = MemoryMechanism(per_task_memory_samples=per_task_memory_samples, groupby=memory_group_by)\n    self.per_task_memory_samples = per_task_memory_samples\n    self.memory_batch_size = memory_batch_size\n</code></pre>"},{"location":"algos/pytorch/base_algo/","title":"base_algo_pytorch","text":""},{"location":"algos/pytorch/base_algo/#sequel.algos.pytorch.pytorch_base_algo.PytorchBaseAlgorithm","title":"<code>PytorchBaseAlgorithm</code>","text":"<p>         Bases: <code>BaseAlgorithm</code></p> Source code in <code>sequel/algos/pytorch/pytorch_base_algo.py</code> <pre><code>class PytorchBaseAlgorithm(BaseAlgorithm):\n    optimizer: torch.optim.Optimizer\n    backbone: torch.nn.Module\n\n    def __init__(\n        self,\n        backbone: PytorchBaseBackbone,\n        benchmark: Benchmark,\n        optimizer: torch.optim.Optimizer,\n        callbacks: Iterable[BaseCallback] = [],\n        loggers: Optional[Iterable[Logger]] = None,\n        lr_decay: Optional[float] = None,\n        grad_clip: Optional[float] = None,\n        reinit_optimizer: bool = True,\n        device=\"cuda:0\",\n        min_lr=0.00005,\n    ) -&gt; None:\n\"\"\"Inits the PytorchBaseAlgorithm class.\n\n        Args:\n            backbone (PytorchBaseBackbone): The backbone model, e.g., a CNN.\n            benchmark (Benchmark): The benchmark, e.g., SplitMNIST.\n            optimizer (torch.optim.Optimizer):  The optimizer used to update the backbone weights.\n            callbacks (Iterable[BaseCallback], optional): A list of callbacks. At least one instance of MetricCallback\n                should be given. Defaults to [].\n            loggers (Optional[Logger], optional): A list of logger, e.g. for Weights&amp;Biases logging functionality.\n                Defaults to None.\n            lr_decay (Optional[float], optional): A learning rate decay used for every new task. Defaults to None.\n            grad_clip (Optional[float], optional): The gradient clipping norm. Defaults to None.\n            reinit_optimizer (bool): Indicates whether the optimizer state is reinitialized before fitting a new task.\n                Defaults to True.\n            device (str, optional): _description_. Defaults to \"cuda:0\".\n            min_lr (float, optional): _description_. Defaults to 0.00005.\n\n        Note:\n            1. the `_configure_optimizers` method will be moved to a dedicated Callback.\n        \"\"\"\n        self.device = device\n        if not isinstance(backbone, BaseBackbone):\n            backbone = BackboneWrapper(backbone)\n        super().__init__(\n            backbone=backbone,\n            benchmark=benchmark,\n            optimizer=optimizer,\n            callbacks=callbacks,\n            loggers=loggers,\n            lr_decay=lr_decay,\n            grad_clip=grad_clip,\n            reinit_optimizer=reinit_optimizer,\n        )\n        self.backbone = self.backbone.to(self.device)\n        self.min_lr = min_lr\n\n    def count_parameters(self):\n        device = next(self.backbone.parameters()).device\n        self.backbone(torch.ones(self.input_dimensions).unsqueeze(0).to(device), torch.ones((1)))\n        return sum([p.numel() for p in self.backbone.parameters() if p.requires_grad])\n\n    def _configure_optimizers(self, task):\n        if self.task_counter == 1 or self.reinit_optimizer:\n            assert len(self.optimizer.param_groups) == 1\n            lr = self.optimizer.param_groups[0][\"lr\"]\n            self.optimizer.state = defaultdict(dict)\n            self.optimizer.param_groups[0][\"params\"] = list(self.backbone.parameters())\n            if self.lr_decay is not None and task &gt; 1:\n                assert isinstance(self.lr_decay, float)\n                assert self.lr_decay &gt; 0 and self.lr_decay &lt;= 1, \"lr decay should be in the interval (0,1]\"\n                new_lr = max(lr * self.lr_decay, self.min_lr)\n                self.optimizer.param_groups[0][\"lr\"] = new_lr\n                logging.info(f\"Decaying the learning rate by a factor of {self.lr_decay}\")\n\n            logging.info(self.optimizer)\n\n    def _configure_criterion(self, task_id=None):\n        return torch.nn.CrossEntropyLoss()\n\n    def forward(self, *args, **kwargs):\n\"\"\"Calls the forward function of the model.\"\"\"\n        outs = self.backbone(self.x, self.t)\n        self.y_hat = outs\n        return outs\n\n    def unpack_batch(self, batch):\n        device = self.device\n        x, y, t = batch\n        self.x, self.y, self.t = x.to(device), y.to(device), t.to(device)\n        self.bs = len(x)\n\n    def optimizer_zero_grad(self):\n        self.optimizer.zero_grad()\n\n    def backpropagate_loss(self):\n        self.loss.backward()\n\n    def optimizer_step(self):\n        self.optimizer.step()\n\n    def perform_gradient_clipping(self):\n        if self.grad_clip is not None:\n            assert self.grad_clip &gt; 0\n            torch.nn.utils.clip_grad_norm_(self.backbone.parameters(), self.grad_clip)\n\n    def valid_step(self, *args, **kwargs):\n\"\"\"Performs the validation step. Callbacks are offered for each step of the process.\"\"\"\n        with torch.no_grad():\n            y_hat = self.forward()\n            self.loss = self.compute_loss(y_hat, self.y, self.t)\n\n    def test_step(self, *args, **kwargs):\n\"\"\"Performs the testing step. Callbacks are offered for each step of the process.\"\"\"\n        pass\n\n    def prepare_for_next_task(self, task):\n        self._configure_optimizers(task)\n\n    def set_training_mode(self):\n        self.backbone.train()\n        super().set_training_mode()\n\n    def set_evaluation_mode(self):\n        self.backbone.eval()\n        super().set_evaluation_mode()\n\n    def fit(self, epochs):\n        self.backbone = self.backbone.to(self.device)\n        return super().fit(epochs=epochs)\n\n    def compute_loss(self, predictions, targets, task_ids=None, *args, **kwargs) -&gt; torch.Tensor:\n        return F.cross_entropy(predictions, targets)\n</code></pre>"},{"location":"algos/pytorch/base_algo/#sequel.algos.pytorch.pytorch_base_algo.PytorchBaseAlgorithm.__init__","title":"<code>__init__(backbone, benchmark, optimizer, callbacks=[], loggers=None, lr_decay=None, grad_clip=None, reinit_optimizer=True, device='cuda:0', min_lr=5e-05)</code>","text":"<p>Inits the PytorchBaseAlgorithm class.</p> <p>Parameters:</p> Name Type Description Default <code>backbone</code> <code>PytorchBaseBackbone</code> <p>The backbone model, e.g., a CNN.</p> required <code>benchmark</code> <code>Benchmark</code> <p>The benchmark, e.g., SplitMNIST.</p> required <code>optimizer</code> <code>torch.optim.Optimizer</code> <p>The optimizer used to update the backbone weights.</p> required <code>callbacks</code> <code>Iterable[BaseCallback]</code> <p>A list of callbacks. At least one instance of MetricCallback should be given. Defaults to [].</p> <code>[]</code> <code>loggers</code> <code>Optional[Logger]</code> <p>A list of logger, e.g. for Weights&amp;Biases logging functionality. Defaults to None.</p> <code>None</code> <code>lr_decay</code> <code>Optional[float]</code> <p>A learning rate decay used for every new task. Defaults to None.</p> <code>None</code> <code>grad_clip</code> <code>Optional[float]</code> <p>The gradient clipping norm. Defaults to None.</p> <code>None</code> <code>reinit_optimizer</code> <code>bool</code> <p>Indicates whether the optimizer state is reinitialized before fitting a new task. Defaults to True.</p> <code>True</code> <code>device</code> <code>str</code> <p>description. Defaults to \"cuda:0\".</p> <code>'cuda:0'</code> <code>min_lr</code> <code>float</code> <p>description. Defaults to 0.00005.</p> <code>5e-05</code> Note <ol> <li>the <code>_configure_optimizers</code> method will be moved to a dedicated Callback.</li> </ol> Source code in <code>sequel/algos/pytorch/pytorch_base_algo.py</code> <pre><code>def __init__(\n    self,\n    backbone: PytorchBaseBackbone,\n    benchmark: Benchmark,\n    optimizer: torch.optim.Optimizer,\n    callbacks: Iterable[BaseCallback] = [],\n    loggers: Optional[Iterable[Logger]] = None,\n    lr_decay: Optional[float] = None,\n    grad_clip: Optional[float] = None,\n    reinit_optimizer: bool = True,\n    device=\"cuda:0\",\n    min_lr=0.00005,\n) -&gt; None:\n\"\"\"Inits the PytorchBaseAlgorithm class.\n\n    Args:\n        backbone (PytorchBaseBackbone): The backbone model, e.g., a CNN.\n        benchmark (Benchmark): The benchmark, e.g., SplitMNIST.\n        optimizer (torch.optim.Optimizer):  The optimizer used to update the backbone weights.\n        callbacks (Iterable[BaseCallback], optional): A list of callbacks. At least one instance of MetricCallback\n            should be given. Defaults to [].\n        loggers (Optional[Logger], optional): A list of logger, e.g. for Weights&amp;Biases logging functionality.\n            Defaults to None.\n        lr_decay (Optional[float], optional): A learning rate decay used for every new task. Defaults to None.\n        grad_clip (Optional[float], optional): The gradient clipping norm. Defaults to None.\n        reinit_optimizer (bool): Indicates whether the optimizer state is reinitialized before fitting a new task.\n            Defaults to True.\n        device (str, optional): _description_. Defaults to \"cuda:0\".\n        min_lr (float, optional): _description_. Defaults to 0.00005.\n\n    Note:\n        1. the `_configure_optimizers` method will be moved to a dedicated Callback.\n    \"\"\"\n    self.device = device\n    if not isinstance(backbone, BaseBackbone):\n        backbone = BackboneWrapper(backbone)\n    super().__init__(\n        backbone=backbone,\n        benchmark=benchmark,\n        optimizer=optimizer,\n        callbacks=callbacks,\n        loggers=loggers,\n        lr_decay=lr_decay,\n        grad_clip=grad_clip,\n        reinit_optimizer=reinit_optimizer,\n    )\n    self.backbone = self.backbone.to(self.device)\n    self.min_lr = min_lr\n</code></pre>"},{"location":"algos/pytorch/base_algo/#sequel.algos.pytorch.pytorch_base_algo.PytorchBaseAlgorithm.forward","title":"<code>forward(*args, **kwargs)</code>","text":"<p>Calls the forward function of the model.</p> Source code in <code>sequel/algos/pytorch/pytorch_base_algo.py</code> <pre><code>def forward(self, *args, **kwargs):\n\"\"\"Calls the forward function of the model.\"\"\"\n    outs = self.backbone(self.x, self.t)\n    self.y_hat = outs\n    return outs\n</code></pre>"},{"location":"algos/pytorch/base_algo/#sequel.algos.pytorch.pytorch_base_algo.PytorchBaseAlgorithm.test_step","title":"<code>test_step(*args, **kwargs)</code>","text":"<p>Performs the testing step. Callbacks are offered for each step of the process.</p> Source code in <code>sequel/algos/pytorch/pytorch_base_algo.py</code> <pre><code>def test_step(self, *args, **kwargs):\n\"\"\"Performs the testing step. Callbacks are offered for each step of the process.\"\"\"\n    pass\n</code></pre>"},{"location":"algos/pytorch/base_algo/#sequel.algos.pytorch.pytorch_base_algo.PytorchBaseAlgorithm.valid_step","title":"<code>valid_step(*args, **kwargs)</code>","text":"<p>Performs the validation step. Callbacks are offered for each step of the process.</p> Source code in <code>sequel/algos/pytorch/pytorch_base_algo.py</code> <pre><code>def valid_step(self, *args, **kwargs):\n\"\"\"Performs the validation step. Callbacks are offered for each step of the process.\"\"\"\n    with torch.no_grad():\n        y_hat = self.forward()\n        self.loss = self.compute_loss(y_hat, self.y, self.t)\n</code></pre>"},{"location":"algos/pytorch/base_algo/#sequel.algos.pytorch.pytorch_base_algo.PytorchRegularizationBaseAlgorithm","title":"<code>PytorchRegularizationBaseAlgorithm</code>","text":"<p>         Bases: <code>PytorchBaseAlgorithm</code></p> Source code in <code>sequel/algos/pytorch/pytorch_base_algo.py</code> <pre><code>class PytorchRegularizationBaseAlgorithm(PytorchBaseAlgorithm):\n    def __init__(self, regularization_coefficient, *args, **kwargs) -&gt; None:\n        super().__init__(*args, **kwargs)\n        self.regularization_coefficient = regularization_coefficient\n        self.w = {}\n        for name, param in self.backbone.named_parameters():\n            name = name.replace(\".\", \"_\")\n            # register old parameters and importance weight\n            self.backbone.register_buffer(f\"{name}_old\", torch.zeros_like(param))\n            self.backbone.register_buffer(f\"{name}_importance\", torch.zeros_like(param))\n\n    def calculate_regularization_loss(self):\n\"\"\"Calculates the regularization loss:\n\n        $$\n        \\\\mathcal{L}_{\\\\textrm{reg}} = \\\\sum\\\\limits_{i} \\\\Omega_i(\\\\theta_i-\\\\theta_{i, \\\\textrm{old}})^2\n        $$\n\n        where $\\\\Omega_i$ is the importance of parameter $i$, $\\\\theta_i$ and $\\\\theta_{i, \\\\textrm{old}}$ are the current and previous task's parameters.\n\n        The parameter importances $\\\\Omega_i$ are calculated by the method `calculate_parameter_importance`.\n\n        \"\"\"\n        assert self.task_counter &gt; 1\n        # shouldn't be called for the first task\n        # because we have not calculate_parameter_importanced anything yet\n        losses = []\n        for name, param in self.backbone.named_parameters():\n            name = name.replace(\".\", \"_\")\n            old_param = getattr(self.backbone, f\"{name}_old\")\n            importance = getattr(self.backbone, f\"{name}_importance\")\n            losses.append((importance * (param - old_param) ** 2).sum())\n\n        return sum(losses)\n\n    def compute_loss(self, predictions: Tensor, targets: Tensor, task_ids: Tensor, *args, **kwargs) -&gt; Tensor:\n\"\"\"Computes the loss. For tasks excluding the initial one, the loss also includes the regularization term.\n\n        Args:\n            predictions (Tensor): Model predictions.\n            targets (Tensor): Targets of the current batch.\n            task_ids (Tensor): Task ids of the current batch.\n\n        Returns:\n            Tensor: the overall loss.\n        \"\"\"\n        loss = super().compute_loss(predictions, targets, task_ids, *args, **kwargs)\n        if self.task_counter &gt; 1:\n            reg_loss = self.calculate_regularization_loss()\n            loss += self.regularization_coefficient * (reg_loss / 2)\n\n        return loss\n\n    def calculate_parameter_importance(self) -&gt; Dict[str, Tensor]:\nr\"\"\"Calculcates the per-parameter importance. Should return a dictionary with keys in the format\n        \"{name}_importance\" where name corresponds the `torch.nn.Parameter` the importance is attached to.\n\n        Raises:\n            NotImplementedError: Should be implemented according to each algorithm.\n        \"\"\"\n        raise NotImplementedError\n\n    def on_after_training_task(self, *args, **kwargs):\n        importances = self.calculate_parameter_importance()\n\n        for name, param in self.backbone.named_parameters():\n            name = name.replace(\".\", \"_\")\n            setattr(self.backbone, f\"{name}_importance\", importances[name].clone())\n            setattr(self.backbone, f\"{name}_old\", param.data.clone())\n\n        return super().on_after_training_task(*args, **kwargs)\n</code></pre>"},{"location":"algos/pytorch/base_algo/#sequel.algos.pytorch.pytorch_base_algo.PytorchRegularizationBaseAlgorithm.calculate_parameter_importance","title":"<code>calculate_parameter_importance()</code>","text":"<p>Calculcates the per-parameter importance. Should return a dictionary with keys in the format \"{name}_importance\" where name corresponds the <code>torch.nn.Parameter</code> the importance is attached to.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Should be implemented according to each algorithm.</p> Source code in <code>sequel/algos/pytorch/pytorch_base_algo.py</code> <pre><code>def calculate_parameter_importance(self) -&gt; Dict[str, Tensor]:\nr\"\"\"Calculcates the per-parameter importance. Should return a dictionary with keys in the format\n    \"{name}_importance\" where name corresponds the `torch.nn.Parameter` the importance is attached to.\n\n    Raises:\n        NotImplementedError: Should be implemented according to each algorithm.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"algos/pytorch/base_algo/#sequel.algos.pytorch.pytorch_base_algo.PytorchRegularizationBaseAlgorithm.calculate_regularization_loss","title":"<code>calculate_regularization_loss()</code>","text":"<p>Calculates the regularization loss:</p>  \\mathcal{L}_{\\textrm{reg}} = \\sum\\limits_{i} \\Omega_i(\\theta_i-\\theta_{i, \\textrm{old}})^2  <p>where \\Omega_i\\Omega_i is the importance of parameter ii, \\theta_i\\theta_i and \\theta_{i, \\textrm{old}}\\theta_{i, \\textrm{old}} are the current and previous task's parameters.</p> <p>The parameter importances \\Omega_i\\Omega_i are calculated by the method <code>calculate_parameter_importance</code>.</p> Source code in <code>sequel/algos/pytorch/pytorch_base_algo.py</code> <pre><code>def calculate_regularization_loss(self):\n\"\"\"Calculates the regularization loss:\n\n    $$\n    \\\\mathcal{L}_{\\\\textrm{reg}} = \\\\sum\\\\limits_{i} \\\\Omega_i(\\\\theta_i-\\\\theta_{i, \\\\textrm{old}})^2\n    $$\n\n    where $\\\\Omega_i$ is the importance of parameter $i$, $\\\\theta_i$ and $\\\\theta_{i, \\\\textrm{old}}$ are the current and previous task's parameters.\n\n    The parameter importances $\\\\Omega_i$ are calculated by the method `calculate_parameter_importance`.\n\n    \"\"\"\n    assert self.task_counter &gt; 1\n    # shouldn't be called for the first task\n    # because we have not calculate_parameter_importanced anything yet\n    losses = []\n    for name, param in self.backbone.named_parameters():\n        name = name.replace(\".\", \"_\")\n        old_param = getattr(self.backbone, f\"{name}_old\")\n        importance = getattr(self.backbone, f\"{name}_importance\")\n        losses.append((importance * (param - old_param) ** 2).sum())\n\n    return sum(losses)\n</code></pre>"},{"location":"algos/pytorch/base_algo/#sequel.algos.pytorch.pytorch_base_algo.PytorchRegularizationBaseAlgorithm.compute_loss","title":"<code>compute_loss(predictions, targets, task_ids, *args, **kwargs)</code>","text":"<p>Computes the loss. For tasks excluding the initial one, the loss also includes the regularization term.</p> <p>Parameters:</p> Name Type Description Default <code>predictions</code> <code>Tensor</code> <p>Model predictions.</p> required <code>targets</code> <code>Tensor</code> <p>Targets of the current batch.</p> required <code>task_ids</code> <code>Tensor</code> <p>Task ids of the current batch.</p> required <p>Returns:</p> Name Type Description <code>Tensor</code> <code>Tensor</code> <p>the overall loss.</p> Source code in <code>sequel/algos/pytorch/pytorch_base_algo.py</code> <pre><code>def compute_loss(self, predictions: Tensor, targets: Tensor, task_ids: Tensor, *args, **kwargs) -&gt; Tensor:\n\"\"\"Computes the loss. For tasks excluding the initial one, the loss also includes the regularization term.\n\n    Args:\n        predictions (Tensor): Model predictions.\n        targets (Tensor): Targets of the current batch.\n        task_ids (Tensor): Task ids of the current batch.\n\n    Returns:\n        Tensor: the overall loss.\n    \"\"\"\n    loss = super().compute_loss(predictions, targets, task_ids, *args, **kwargs)\n    if self.task_counter &gt; 1:\n        reg_loss = self.calculate_regularization_loss()\n        loss += self.regularization_coefficient * (reg_loss / 2)\n\n    return loss\n</code></pre>"},{"location":"algos/pytorch/der/","title":"DER","text":""},{"location":"algos/pytorch/der/#sequel.algos.pytorch.der.DER","title":"<code>DER</code>","text":"<p>         Bases: <code>PytorchBaseAlgorithm</code></p> <p>Dark Experience Replay algorithm implemented in PyTorch.</p> <p>The equivalent JAX implementation is <code>DER in JAX</code>.</p> References <p>[1] Buzzega, P., Boschini, M., Porrello, A., Abati, D. &amp; Calderara, S. Dark experience for general continual     learning: a strong, simple baseline. in Advances in neural information processing systems 2020.</p> Source code in <code>sequel/algos/pytorch/der.py</code> <pre><code>class DER(PytorchBaseAlgorithm):\n\"\"\"Dark Experience Replay algorithm implemented in PyTorch.\n\n    The equivalent JAX implementation is [`DER in JAX`][sequel.algos.jax.der.DER].\n\n    References:\n        [1] Buzzega, P., Boschini, M., Porrello, A., Abati, D. &amp; Calderara, S. Dark experience for general continual\n            learning: a strong, simple baseline. in Advances in neural information processing systems 2020.\n    \"\"\"\n\n    def __init__(self, memory_size: int, alpha: float, beta: Optional[float] = None, *args, **kwargs):\n\n        super().__init__(*args, **kwargs)\n        self.buffer = Buffer(memory_size=memory_size, return_logits=True)\n        self.memory_size = memory_size\n        self.alpha = alpha\n\n        # Beta is used for DER++\n        self.beta = beta\n\n    def on_before_backward(self, *args, **kwargs):\n        if len(self.buffer) &gt; 0:\n            # if self.task_counter &gt; 1:\n            x, y, t, logits = self.buffer.sample_from_buffer(batch_size=self.benchmark.batch_size)\n            self.mem_x, self.mem_y, self.mem_t, self.mem_logits = x, y, t, logits\n            self.mem_y_hat = self.backbone(self.mem_x, self.mem_t)\n            loss = F.mse_loss(self.mem_y_hat, self.mem_logits)\n            self.loss += self.alpha * loss\n\n            if self.beta is not None:\n                x, y, t, _ = self.buffer.sample_from_buffer(batch_size=self.benchmark.batch_size)\n                self.mem_x2, self.mem_y2, self.mem_t2 = x.to(self.device), y.to(self.device), t.to(self.device)\n                self.mem_y_hat2 = self.backbone(self.mem_x2, self.mem_t2)\n                self.loss += self.beta * self.compute_loss(self.mem_y_hat2, self.mem_y2, self.mem_t2)\n\n    def on_before_optimizer_step(self, *args, **kwargs):\n        if self.task_counter &gt; 1:\n\n            return super().on_before_optimizer_step(*args, **kwargs)\n\n    def on_after_training_step(self, *args, **kwargs):\n        self.buffer.add_data(self.x, self.y, self.t, self.y_hat.data)\n\n    def __repr__(self) -&gt; str:\n        if self.beta is None:\n            return f\"DER(memory_size={self.memory_size}, alpha={self.alpha})\"\n        else:\n            return f\"DER++(memory_size={self.memory_size}, alpha={self.alpha}, beta={self.beta})\"\n</code></pre>"},{"location":"algos/pytorch/er/","title":"ER","text":""},{"location":"algos/pytorch/ewc/","title":"EWC","text":""},{"location":"algos/pytorch/ewc/#sequel.algos.pytorch.ewc.EWC","title":"<code>EWC</code>","text":"<p>         Bases: <code>PytorchRegularizationBaseAlgorithm</code></p> <p>Elastic Weight Consolidation Algorithm Class. Inherits from BaseAlgorithm.</p> <p>The equivalent JAX implementation is <code>EWC in JAX</code>.</p> References <p>[1] Kirkpatrick, J. et al. Overcoming catastrophic forgetting in neural networks. PNAS 114, 3521-3526 (2017).</p> Source code in <code>sequel/algos/pytorch/ewc.py</code> <pre><code>class EWC(PytorchRegularizationBaseAlgorithm):\n\"\"\"Elastic Weight Consolidation Algorithm Class. Inherits from BaseAlgorithm.\n\n    The equivalent JAX implementation is [`EWC in JAX`][sequel.algos.jax.ewc.EWC].\n\n    References:\n        [1] Kirkpatrick, J. et al. Overcoming catastrophic forgetting in neural networks. PNAS 114, 3521-3526 (2017).\n    \"\"\"\n\n    def __init__(self, ewc_lambda: float = 1.0, *args, **kwargs):\n\"\"\"Inits the Elastic Weight Consolidation algorithm.\n\n        Args:\n            ewc_lambda (float): The lambda coefficient of EWC algorithm.\n        \"\"\"\n        super().__init__(regularization_coefficient=ewc_lambda, *args, **kwargs)\n\n    def __repr__(self) -&gt; str:\n        return f\"EWC(ewc_lambda={self.regularization_coefficient})\"\n\n    def calculate_parameter_importance(self):\n        train_loader = self.benchmark.train_dataloader(self.task_counter)\n        self.backbone = self.backbone.to(self.device)\n\n        importances = {}\n        for ii, batch in enumerate(train_loader):\n            self.unpack_batch(batch)\n            outs = self.backbone(self.x, self.t)\n            loss = super().compute_loss(outs, self.y, self.t)\n            loss.backward()\n\n            for (name, p) in self.backbone.named_parameters():\n                name = name.replace(\".\", \"_\")\n                if p.grad is not None:\n                    if getattr(importances, name, None) is None:\n                        importances[name] = p.grad.data.clone().pow(2) / len(train_loader)\n                    else:\n                        importances[name] += p.grad.data.clone().pow(2) / len(train_loader)\n\n        return importances\n</code></pre>"},{"location":"algos/pytorch/ewc/#sequel.algos.pytorch.ewc.EWC.__init__","title":"<code>__init__(ewc_lambda=1.0, *args, **kwargs)</code>","text":"<p>Inits the Elastic Weight Consolidation algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>ewc_lambda</code> <code>float</code> <p>The lambda coefficient of EWC algorithm.</p> <code>1.0</code> Source code in <code>sequel/algos/pytorch/ewc.py</code> <pre><code>def __init__(self, ewc_lambda: float = 1.0, *args, **kwargs):\n\"\"\"Inits the Elastic Weight Consolidation algorithm.\n\n    Args:\n        ewc_lambda (float): The lambda coefficient of EWC algorithm.\n    \"\"\"\n    super().__init__(regularization_coefficient=ewc_lambda, *args, **kwargs)\n</code></pre>"},{"location":"algos/pytorch/icarl/","title":"iCaRL","text":""},{"location":"algos/pytorch/icarl/#sequel.algos.pytorch.icarl.FeatureExtractor","title":"<code>FeatureExtractor</code>","text":"<p>         Bases: <code>nn.Module</code></p> <p>Wrapper that returns a flattened version of the output of specific PyTorch model. It is used to retrieve the feature representations (e.g. for iCaRL algorithm).</p> Source code in <code>sequel/algos/pytorch/icarl.py</code> <pre><code>class FeatureExtractor(nn.Module):\n\"\"\"Wrapper that returns a flattened version of the output of specific PyTorch model. It is used to retrieve the\n    feature representations (e.g. for iCaRL algorithm).\n    \"\"\"\n\n    def __init__(self, model: nn.Module) -&gt; None:\n        super().__init__()\n        self.model = model\n        self.model.eval()\n\n    def forward(self, x: Tensor, *agrs, **kwargs) -&gt; Tensor:\n        bs = x.size(0)\n        x = self.model(x)\n        return x.view(bs, -1)\n</code></pre>"},{"location":"algos/pytorch/icarl/#sequel.algos.pytorch.icarl.Icarl","title":"<code>Icarl</code>","text":"<p>         Bases: <code>PytorchBaseAlgorithm</code></p> <p>iCaRL: Incremental Classifier and Representation Learning algorithm. Inherits from BaseAlgorithm.</p> Source code in <code>sequel/algos/pytorch/icarl.py</code> <pre><code>class Icarl(PytorchBaseAlgorithm):\n\"\"\"iCaRL: Incremental Classifier and Representation Learning algorithm. Inherits from BaseAlgorithm.\"\"\"\n\n    def __init__(self, memory_size: int, *args, **kwargs):\n\"\"\"Inits the iCaRL algorithm.\n\n        Args:\n            memory_size (int): The overall memory size used by the algorithm.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self.memory_size = memory_size\n\n    @classmethod\n    def from_config(cls, config, callbacks, loggers, *args, **kwargs):\n        memory_size = config.algo.memory_size\n        return cls(\n            memory_size=memory_size,\n            config=config,\n            callbacks=callbacks,\n            loggers=loggers,\n            *args,\n            **kwargs,\n        )\n\n    def prepare_train_loader(self, task_id: int, batch_size: Optional[int] = None) -&gt; DataLoader:\n\"\"\"Prepares the train_loader. After the initical task, the train dataloader is augmented with the memory\n        samples.\n\n        Args:\n            task_id (int): The id of the task to be loaded.\n            batch_size (Optional[int], optional): The batch size for the dataloader. If set to None,\n                the default batch size (for the current experiment) is used. Defaults to None.\n\n        Returns:\n            DataLoader: The train dataloader for the current epoch.\n        \"\"\"\n\n        if task_id == 1:\n            return super().prepare_train_loader(task_id, batch_size)\n        else:\n            return self.benchmark.train_dataloader_with_memory(task_id, batch_size=batch_size, verbose=True)\n\n    def on_after_training_task(self, *args, **kwargs):\n\"\"\"Handles memory specifics for the iCaRL algorithm, such as memory resizing and selecting new memory indices\n        using the Herding algorithm.\n\n        Raises:\n            ValueError: The current task must not have memory yet, since this methods sets it.\n        \"\"\"\n        k = self.memory_size // self.task_counter\n        for task in range(1, self.task_counter):\n            old_indices = self.benchmark.get_memory_indices(task)\n            new_indices = self.resize_memory(old_indices, k)\n            self.benchmark.set_memory_indices(task, new_indices)\n\n        # compute current task indices. The excess of exemplars goes to the last task for simplicity.\n        num_indices = k + self.memory_size % self.task_counter\n        indices = self.compute_new_indices(num_indices=num_indices)\n\n        if self.task_counter in self.benchmark.memory_indices.keys():\n            raise ValueError(\"Overwriting memory...Is something wrong?\")\n\n        self.benchmark.set_memory_indices(self.task_counter, indices)\n\n    @torch.no_grad()\n    def compute_new_indices(self, num_indices: int) -&gt; List[int]:\n\"\"\"Selects the indices for the current task, using the herding algorithm.\n\n        Args:\n            num_indices (int): The number of indices to be selected.\n\n        Returns:\n            List[int]: The selected indices.\n        \"\"\"\n        dataloader = super().prepare_data_loader(self.task_counter)\n        self.backbone.eval()\n        model = FeatureExtractor(self.backbone.encoder)\n        model.eval()\n        features = torch.cat([model(batch[0].to(self.device)) for batch in dataloader])\n        indices = self.select_indices_with_herding(features, num_indices)\n        return indices\n\n    def select_indices_with_herding(self, features: torch.Tensor, num_indices: int) -&gt; List[int]:\n\"\"\"Implements the herding algorithm. The most representative `num_indices` samples are selected based on their\n        L2 distance to the feature mean.\n\n        Args:\n            features (torch.Tensor): The features of all samples.\n            num_indices (int): The number of samples to be selected.\n\n        Raises:\n            ValueError: The features must be given in a 2D tensor.\n\n        Returns:\n            List[int]: The indices of the selected samples.\n        \"\"\"\n        if features.dim() != 2:\n            raise ValueError(\n                \"The features must be a Tensor of two dimensions, where the first dimension \\\n                corresponds to the number of samples.\"\n            )\n\n        selected_indices = []\n\n        center = features.mean(dim=0)\n        current_center = center * 0\n\n        for i in range(num_indices):\n            # Compute distances with real center\n            candidate_centers = current_center * i / (i + 1) + features / (i + 1)\n            distances = pow(candidate_centers - center, 2).sum(dim=1)\n            distances[selected_indices] = torch.inf\n\n            # Select best candidate\n            new_index = distances.argmin().tolist()\n            selected_indices.append(new_index)\n            current_center = candidate_centers[new_index]\n\n        return selected_indices\n\n    @staticmethod\n    def resize_memory(indices: List[int], k: int) -&gt; list[int]:\n\"\"\"Resizes memory by selecting the first `k` indices.\n\n        Args:\n            indices (List[int]): The current memory indices.\n            k (int): the new size of the memory.\n\n        Raises:\n            ValueError: The new memory size `k` cannot be larger than the previous one.\n\n        Returns:\n            list[int]: the new memory indices.\n        \"\"\"\n        if k &gt; len(indices):\n            raise ValueError(\"The new memory cannot be larger than the current.\")\n\n        return indices[:k]\n</code></pre>"},{"location":"algos/pytorch/icarl/#sequel.algos.pytorch.icarl.Icarl.__init__","title":"<code>__init__(memory_size, *args, **kwargs)</code>","text":"<p>Inits the iCaRL algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>memory_size</code> <code>int</code> <p>The overall memory size used by the algorithm.</p> required Source code in <code>sequel/algos/pytorch/icarl.py</code> <pre><code>def __init__(self, memory_size: int, *args, **kwargs):\n\"\"\"Inits the iCaRL algorithm.\n\n    Args:\n        memory_size (int): The overall memory size used by the algorithm.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n    self.memory_size = memory_size\n</code></pre>"},{"location":"algos/pytorch/icarl/#sequel.algos.pytorch.icarl.Icarl.compute_new_indices","title":"<code>compute_new_indices(num_indices)</code>","text":"<p>Selects the indices for the current task, using the herding algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>num_indices</code> <code>int</code> <p>The number of indices to be selected.</p> required <p>Returns:</p> Type Description <code>List[int]</code> <p>List[int]: The selected indices.</p> Source code in <code>sequel/algos/pytorch/icarl.py</code> <pre><code>@torch.no_grad()\ndef compute_new_indices(self, num_indices: int) -&gt; List[int]:\n\"\"\"Selects the indices for the current task, using the herding algorithm.\n\n    Args:\n        num_indices (int): The number of indices to be selected.\n\n    Returns:\n        List[int]: The selected indices.\n    \"\"\"\n    dataloader = super().prepare_data_loader(self.task_counter)\n    self.backbone.eval()\n    model = FeatureExtractor(self.backbone.encoder)\n    model.eval()\n    features = torch.cat([model(batch[0].to(self.device)) for batch in dataloader])\n    indices = self.select_indices_with_herding(features, num_indices)\n    return indices\n</code></pre>"},{"location":"algos/pytorch/icarl/#sequel.algos.pytorch.icarl.Icarl.on_after_training_task","title":"<code>on_after_training_task(*args, **kwargs)</code>","text":"<p>Handles memory specifics for the iCaRL algorithm, such as memory resizing and selecting new memory indices using the Herding algorithm.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>The current task must not have memory yet, since this methods sets it.</p> Source code in <code>sequel/algos/pytorch/icarl.py</code> <pre><code>def on_after_training_task(self, *args, **kwargs):\n\"\"\"Handles memory specifics for the iCaRL algorithm, such as memory resizing and selecting new memory indices\n    using the Herding algorithm.\n\n    Raises:\n        ValueError: The current task must not have memory yet, since this methods sets it.\n    \"\"\"\n    k = self.memory_size // self.task_counter\n    for task in range(1, self.task_counter):\n        old_indices = self.benchmark.get_memory_indices(task)\n        new_indices = self.resize_memory(old_indices, k)\n        self.benchmark.set_memory_indices(task, new_indices)\n\n    # compute current task indices. The excess of exemplars goes to the last task for simplicity.\n    num_indices = k + self.memory_size % self.task_counter\n    indices = self.compute_new_indices(num_indices=num_indices)\n\n    if self.task_counter in self.benchmark.memory_indices.keys():\n        raise ValueError(\"Overwriting memory...Is something wrong?\")\n\n    self.benchmark.set_memory_indices(self.task_counter, indices)\n</code></pre>"},{"location":"algos/pytorch/icarl/#sequel.algos.pytorch.icarl.Icarl.prepare_train_loader","title":"<code>prepare_train_loader(task_id, batch_size=None)</code>","text":"<p>Prepares the train_loader. After the initical task, the train dataloader is augmented with the memory samples.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>int</code> <p>The id of the task to be loaded.</p> required <code>batch_size</code> <code>Optional[int]</code> <p>The batch size for the dataloader. If set to None, the default batch size (for the current experiment) is used. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DataLoader</code> <code>DataLoader</code> <p>The train dataloader for the current epoch.</p> Source code in <code>sequel/algos/pytorch/icarl.py</code> <pre><code>def prepare_train_loader(self, task_id: int, batch_size: Optional[int] = None) -&gt; DataLoader:\n\"\"\"Prepares the train_loader. After the initical task, the train dataloader is augmented with the memory\n    samples.\n\n    Args:\n        task_id (int): The id of the task to be loaded.\n        batch_size (Optional[int], optional): The batch size for the dataloader. If set to None,\n            the default batch size (for the current experiment) is used. Defaults to None.\n\n    Returns:\n        DataLoader: The train dataloader for the current epoch.\n    \"\"\"\n\n    if task_id == 1:\n        return super().prepare_train_loader(task_id, batch_size)\n    else:\n        return self.benchmark.train_dataloader_with_memory(task_id, batch_size=batch_size, verbose=True)\n</code></pre>"},{"location":"algos/pytorch/icarl/#sequel.algos.pytorch.icarl.Icarl.resize_memory","title":"<code>resize_memory(indices, k)</code>  <code>staticmethod</code>","text":"<p>Resizes memory by selecting the first <code>k</code> indices.</p> <p>Parameters:</p> Name Type Description Default <code>indices</code> <code>List[int]</code> <p>The current memory indices.</p> required <code>k</code> <code>int</code> <p>the new size of the memory.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>The new memory size <code>k</code> cannot be larger than the previous one.</p> <p>Returns:</p> Type Description <code>list[int]</code> <p>list[int]: the new memory indices.</p> Source code in <code>sequel/algos/pytorch/icarl.py</code> <pre><code>@staticmethod\ndef resize_memory(indices: List[int], k: int) -&gt; list[int]:\n\"\"\"Resizes memory by selecting the first `k` indices.\n\n    Args:\n        indices (List[int]): The current memory indices.\n        k (int): the new size of the memory.\n\n    Raises:\n        ValueError: The new memory size `k` cannot be larger than the previous one.\n\n    Returns:\n        list[int]: the new memory indices.\n    \"\"\"\n    if k &gt; len(indices):\n        raise ValueError(\"The new memory cannot be larger than the current.\")\n\n    return indices[:k]\n</code></pre>"},{"location":"algos/pytorch/icarl/#sequel.algos.pytorch.icarl.Icarl.select_indices_with_herding","title":"<code>select_indices_with_herding(features, num_indices)</code>","text":"<p>Implements the herding algorithm. The most representative <code>num_indices</code> samples are selected based on their L2 distance to the feature mean.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>torch.Tensor</code> <p>The features of all samples.</p> required <code>num_indices</code> <code>int</code> <p>The number of samples to be selected.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>The features must be given in a 2D tensor.</p> <p>Returns:</p> Type Description <code>List[int]</code> <p>List[int]: The indices of the selected samples.</p> Source code in <code>sequel/algos/pytorch/icarl.py</code> <pre><code>def select_indices_with_herding(self, features: torch.Tensor, num_indices: int) -&gt; List[int]:\n\"\"\"Implements the herding algorithm. The most representative `num_indices` samples are selected based on their\n    L2 distance to the feature mean.\n\n    Args:\n        features (torch.Tensor): The features of all samples.\n        num_indices (int): The number of samples to be selected.\n\n    Raises:\n        ValueError: The features must be given in a 2D tensor.\n\n    Returns:\n        List[int]: The indices of the selected samples.\n    \"\"\"\n    if features.dim() != 2:\n        raise ValueError(\n            \"The features must be a Tensor of two dimensions, where the first dimension \\\n            corresponds to the number of samples.\"\n        )\n\n    selected_indices = []\n\n    center = features.mean(dim=0)\n    current_center = center * 0\n\n    for i in range(num_indices):\n        # Compute distances with real center\n        candidate_centers = current_center * i / (i + 1) + features / (i + 1)\n        distances = pow(candidate_centers - center, 2).sum(dim=1)\n        distances[selected_indices] = torch.inf\n\n        # Select best candidate\n        new_index = distances.argmin().tolist()\n        selected_indices.append(new_index)\n        current_center = candidate_centers[new_index]\n\n    return selected_indices\n</code></pre>"},{"location":"algos/pytorch/joint/","title":"Joint","text":""},{"location":"algos/pytorch/joint/#sequel.algos.pytorch.joint.JointTraining","title":"<code>JointTraining</code>","text":"<p>         Bases: <code>PytorchBaseAlgorithm</code></p> <p>The JoinTraining algorithm. It is a variant of MultiTask Learning, where the model is trained with increasingly more samples. Specifically, during the t-th task, the model sees samples from all the previous and the current task.</p> <p>Inherits from BaseAlgorithm. Only the <code>prepare_train_loader</code> method is overwritten.</p> <p>The equivalent JAX implementation is <code>JointTraining in JAX</code>.</p> Source code in <code>sequel/algos/pytorch/joint.py</code> <pre><code>class JointTraining(PytorchBaseAlgorithm):\n\"\"\"The JoinTraining algorithm. It is a variant of MultiTask Learning, where the model is trained with increasingly\n    more samples. Specifically, during the t-th task, the model sees samples from all the previous and the current\n    task.\n\n    Inherits from BaseAlgorithm. Only the `prepare_train_loader` method is overwritten.\n\n    The equivalent JAX implementation is [`JointTraining in JAX`][sequel.algos.jax.joint.JointTraining].\n\n    \"\"\"\n\n    def __init__(self, *args, **kwargs) -&gt; None:\n        super().__init__(*args, **kwargs)\n\n    def __repr__(self) -&gt; str:\n        return f\"JointTraining()\"\n\n    def prepare_train_loader(self, task_id: int, batch_size: Optional[int] = None) -&gt; DataLoader:\n\"\"\"Prepares the train_loader for Joint Training. The dataloader consists of all samples up to task `task_id`.\n\n        Args:\n            task_id (int): The last task to be loaded.\n            batch_size (Optional[int], optional): The dataloader batch size. Defaults to None.\n\n        Returns:\n            DataLoader: The JointTraining train dataloder.\n        \"\"\"\n        return self.benchmark.train_dataloader_joint(task_id, batch_size=batch_size)\n</code></pre>"},{"location":"algos/pytorch/joint/#sequel.algos.pytorch.joint.JointTraining.prepare_train_loader","title":"<code>prepare_train_loader(task_id, batch_size=None)</code>","text":"<p>Prepares the train_loader for Joint Training. The dataloader consists of all samples up to task <code>task_id</code>.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>int</code> <p>The last task to be loaded.</p> required <code>batch_size</code> <code>Optional[int]</code> <p>The dataloader batch size. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DataLoader</code> <code>DataLoader</code> <p>The JointTraining train dataloder.</p> Source code in <code>sequel/algos/pytorch/joint.py</code> <pre><code>def prepare_train_loader(self, task_id: int, batch_size: Optional[int] = None) -&gt; DataLoader:\n\"\"\"Prepares the train_loader for Joint Training. The dataloader consists of all samples up to task `task_id`.\n\n    Args:\n        task_id (int): The last task to be loaded.\n        batch_size (Optional[int], optional): The dataloader batch size. Defaults to None.\n\n    Returns:\n        DataLoader: The JointTraining train dataloder.\n    \"\"\"\n    return self.benchmark.train_dataloader_joint(task_id, batch_size=batch_size)\n</code></pre>"},{"location":"algos/pytorch/kcl/","title":"KCL","text":""},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.Amortized","title":"<code>Amortized</code>","text":"<p>         Bases: <code>nn.Module</code></p> Source code in <code>sequel/algos/pytorch/kcl.py</code> <pre><code>class Amortized(nn.Module):\n    def __init__(self, input_units: int, d_theta: int, output_units: int):\n\"\"\"Inits the inference block used by the Kernel Continual Learning algorithm.\n\n        Args:\n            input_units (int): dimensionality of the input.\n            d_theta (int): dimensionality of the intermediate hidden layers.\n            output_units (int): dimensionality of the output.\n        \"\"\"\n        super(Amortized, self).__init__()\n        self.output_units = output_units\n        self.weight_mean = InferenceBlock(input_units, d_theta, output_units)\n        self.weight_log_variance = InferenceBlock(input_units, d_theta, output_units)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        weight_mean = self.weight_mean(x)\n        weight_log_variance = self.weight_log_variance(x)\n        return weight_mean, weight_log_variance\n</code></pre>"},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.Amortized.__init__","title":"<code>__init__(input_units, d_theta, output_units)</code>","text":"<p>Inits the inference block used by the Kernel Continual Learning algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>input_units</code> <code>int</code> <p>dimensionality of the input.</p> required <code>d_theta</code> <code>int</code> <p>dimensionality of the intermediate hidden layers.</p> required <code>output_units</code> <code>int</code> <p>dimensionality of the output.</p> required Source code in <code>sequel/algos/pytorch/kcl.py</code> <pre><code>def __init__(self, input_units: int, d_theta: int, output_units: int):\n\"\"\"Inits the inference block used by the Kernel Continual Learning algorithm.\n\n    Args:\n        input_units (int): dimensionality of the input.\n        d_theta (int): dimensionality of the intermediate hidden layers.\n        output_units (int): dimensionality of the output.\n    \"\"\"\n    super(Amortized, self).__init__()\n    self.output_units = output_units\n    self.weight_mean = InferenceBlock(input_units, d_theta, output_units)\n    self.weight_log_variance = InferenceBlock(input_units, d_theta, output_units)\n</code></pre>"},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.InferenceBlock","title":"<code>InferenceBlock</code>","text":"<p>         Bases: <code>nn.Module</code></p> Source code in <code>sequel/algos/pytorch/kcl.py</code> <pre><code>class InferenceBlock(nn.Module):\n    def __init__(self, input_units: int, d_theta: int, output_units: int):\n\"\"\"Inits the inference block used by the Kernel Continual Learning algorithm.\n\n        Args:\n            input_units (int): dimensionality of the input.\n            d_theta (int): dimensionality of the intermediate hidden layers.\n            output_units (int): dimensionality of the output.\n        \"\"\"\n        super(InferenceBlock, self).__init__()\n        self.module = nn.Sequential(\n            nn.Linear(input_units, d_theta, bias=True),\n            nn.ELU(inplace=True),\n            nn.Linear(d_theta, d_theta, bias=True),\n            nn.ELU(inplace=True),\n            nn.Linear(d_theta, output_units, bias=True),\n        )\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        return self.module(x)\n</code></pre>"},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.InferenceBlock.__init__","title":"<code>__init__(input_units, d_theta, output_units)</code>","text":"<p>Inits the inference block used by the Kernel Continual Learning algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>input_units</code> <code>int</code> <p>dimensionality of the input.</p> required <code>d_theta</code> <code>int</code> <p>dimensionality of the intermediate hidden layers.</p> required <code>output_units</code> <code>int</code> <p>dimensionality of the output.</p> required Source code in <code>sequel/algos/pytorch/kcl.py</code> <pre><code>def __init__(self, input_units: int, d_theta: int, output_units: int):\n\"\"\"Inits the inference block used by the Kernel Continual Learning algorithm.\n\n    Args:\n        input_units (int): dimensionality of the input.\n        d_theta (int): dimensionality of the intermediate hidden layers.\n        output_units (int): dimensionality of the output.\n    \"\"\"\n    super(InferenceBlock, self).__init__()\n    self.module = nn.Sequential(\n        nn.Linear(input_units, d_theta, bias=True),\n        nn.ELU(inplace=True),\n        nn.Linear(d_theta, d_theta, bias=True),\n        nn.ELU(inplace=True),\n        nn.Linear(d_theta, output_units, bias=True),\n    )\n</code></pre>"},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.KCL","title":"<code>KCL</code>","text":"<p>         Bases: <code>PytorchBaseAlgorithm</code></p> <p>Kernel Continual Learning algorithm. The code is adapted from https://github.com/mmderakhshani/KCL/blob/main/stable_sgd/main.py</p> <p>KCL is not yet implemented in JAX.</p> References <p>[1] Derakhshani, M. M., Zhen, X., Shao, L. &amp; Snoek, C. Kernel Continual Learning. in Proceedings of the 38th     International Conference on Machine Learning, ICML 2021.</p> Source code in <code>sequel/algos/pytorch/kcl.py</code> <pre><code>class KCL(PytorchBaseAlgorithm):\n\"\"\"Kernel Continual Learning algorithm. The code is adapted from https://github.com/mmderakhshani/KCL/blob/main/stable_sgd/main.py\n\n    KCL is not yet implemented in JAX.\n\n    References:\n        [1] Derakhshani, M. M., Zhen, X., Shao, L. &amp; Snoek, C. Kernel Continual Learning. in Proceedings of the 38th\n            International Conference on Machine Learning, ICML 2021.\n    \"\"\"\n\n    def __init__(\n        self,\n        lmd: float,\n        core_size: int,\n        d_rn_f: int,\n        kernel_type: Literal[\"rbf\", \"rff\", \"linear\", \"poly\"],\n        tau: float,\n        *args,\n        **kwargs,\n    ):\n        super().__init__(*args, **kwargs)\n        self.__check_valid__()\n\n        self.core_size = core_size\n        self.kernel_type = kernel_type\n        self.tau = tau\n        self.coresets = {}\n\n        device = next(self.backbone.parameters()).device\n        embedding = self.backbone.encoder(torch.ones(self.input_dimensions).unsqueeze(0).to(device))\n\n        self.backbone = KernelBackboneWrapper(\n            self.backbone, hiddens=embedding.numel(), lmd=lmd, num_tasks=self.num_tasks, d_rn_f=d_rn_f\n        ).to(device)\n\n    def __check_valid__(self):\n        if getattr(self.backbone, \"encoder\", None) is None:\n            raise AttributeError(\n                \"The backbone must have an encoder subnetwork to be compatible with the implementation of Kernel \"\n                \"Continual Learning. The encoder consists of the entire original backbone except from the last Linear \"\n                \"layer, i.e., the classifier.\"\n            )\n\n    def count_parameters(self) -&gt; int:\n        if not isinstance(self.backbone, KernelBackboneWrapper):\n            return super().count_parameters()\n        return sum([p.numel() for p in self.backbone.parameters() if p.requires_grad])\n\n    def prepare_train_loader(self, task: int) -&gt; DataLoader:\n\"\"\"Splits the training dataset of the given `task` to training and coreset.\"\"\"\n        dataset = self.benchmark.get_train_dataset(task)\n        dataset, coreset = random_split(dataset, lengths=[len(dataset) - self.core_size, self.core_size])\n        self.coresets[task] = coreset\n        self.register_coreset(coreset)\n        return DataLoader(dataset, self.benchmark.batch_size, shuffle=True, **self.benchmark.dl_kwargs)\n\n    def register_coreset(self, coreset):\n        num_classes = self.benchmark.num_classes\n        x = [sample[0] for sample in coreset]\n        y = [sample[1] for sample in coreset]\n        self.coreset_input = torch.stack(x).to(self.device)\n        self.coreset_target = F.one_hot(torch.tensor(y), num_classes=num_classes).to(self.device).float()\n\n    def forward(self):\n\"\"\"Performs the forward for the Kernel Continual Learning backbone.\"\"\"\n        self.y_hat = self.backbone.forward(self.x, self.t, self.coreset_input, self.coreset_target)\n        return self.y_hat\n\n    def kl_div(self, m: torch.Tensor, log_v: torch.Tensor, m0: torch.Tensor, log_v0: torch.Tensor) -&gt; torch.Tensor:\n\"\"\"Computes the Kullback-Leibler divergence assuming two normal distributions parameterized by the arguments.\"\"\"\n        v = log_v.exp()\n        v0 = log_v0.exp()\n\n        dout, din = m.shape\n        const_term = -0.5 * dout * din\n\n        log_std_diff = 0.5 * torch.sum(torch.log(v0) - torch.log(v))\n        mu_diff_term = 0.5 * torch.sum((v + (m0 - m) ** 2) / v0)\n        kl = const_term + log_std_diff + mu_diff_term\n        return kl\n\n    def training_step(self, *args, **kwargs):\n        self.optimizer_zero_grad()\n\n        self.y_hat = self.forward()\n        self.loss = F.cross_entropy(self.y_hat, self.y)\n\n        if self.kernel_type == \"rff\":\n            r_mu, r_log_var = self.backbone.r_mu, self.backbone.r_log_var\n            p_mu, p_log_var = self.backbone.p_mu, self.backbone.p_log_var\n            self.loss += self.tau * self.kl_div(r_mu, r_log_var, p_mu, p_log_var)\n        self.loss.backward()\n        self.optimizer.step()\n\n    def on_before_val_epoch(self, *args, **kwargs):\n        logging.info(f\"Setting the coreset for validating task {self.current_val_task}.\")\n        self.register_coreset(self.coresets[self.current_val_task])\n        return super().on_before_val_epoch(*args, **kwargs)\n</code></pre>"},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.KCL.forward","title":"<code>forward()</code>","text":"<p>Performs the forward for the Kernel Continual Learning backbone.</p> Source code in <code>sequel/algos/pytorch/kcl.py</code> <pre><code>def forward(self):\n\"\"\"Performs the forward for the Kernel Continual Learning backbone.\"\"\"\n    self.y_hat = self.backbone.forward(self.x, self.t, self.coreset_input, self.coreset_target)\n    return self.y_hat\n</code></pre>"},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.KCL.kl_div","title":"<code>kl_div(m, log_v, m0, log_v0)</code>","text":"<p>Computes the Kullback-Leibler divergence assuming two normal distributions parameterized by the arguments.</p> Source code in <code>sequel/algos/pytorch/kcl.py</code> <pre><code>def kl_div(self, m: torch.Tensor, log_v: torch.Tensor, m0: torch.Tensor, log_v0: torch.Tensor) -&gt; torch.Tensor:\n\"\"\"Computes the Kullback-Leibler divergence assuming two normal distributions parameterized by the arguments.\"\"\"\n    v = log_v.exp()\n    v0 = log_v0.exp()\n\n    dout, din = m.shape\n    const_term = -0.5 * dout * din\n\n    log_std_diff = 0.5 * torch.sum(torch.log(v0) - torch.log(v))\n    mu_diff_term = 0.5 * torch.sum((v + (m0 - m) ** 2) / v0)\n    kl = const_term + log_std_diff + mu_diff_term\n    return kl\n</code></pre>"},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.KCL.prepare_train_loader","title":"<code>prepare_train_loader(task)</code>","text":"<p>Splits the training dataset of the given <code>task</code> to training and coreset.</p> Source code in <code>sequel/algos/pytorch/kcl.py</code> <pre><code>def prepare_train_loader(self, task: int) -&gt; DataLoader:\n\"\"\"Splits the training dataset of the given `task` to training and coreset.\"\"\"\n    dataset = self.benchmark.get_train_dataset(task)\n    dataset, coreset = random_split(dataset, lengths=[len(dataset) - self.core_size, self.core_size])\n    self.coresets[task] = coreset\n    self.register_coreset(coreset)\n    return DataLoader(dataset, self.benchmark.batch_size, shuffle=True, **self.benchmark.dl_kwargs)\n</code></pre>"},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.KernelBackboneWrapper","title":"<code>KernelBackboneWrapper</code>","text":"<p>         Bases: <code>BaseBackbone</code></p> Source code in <code>sequel/algos/pytorch/kcl.py</code> <pre><code>class KernelBackboneWrapper(BaseBackbone):\n    def __init__(\n        self,\n        model: BaseBackbone,\n        hiddens: int,\n        lmd: float,\n        num_tasks: int,\n        d_rn_f: int,\n        kernel_type: Literal[\"rbf\", \"rff\", \"linear\", \"poly\"] = \"rff\",\n    ):\n\"\"\"Model Wrapper for Kernel Continual Learning. Extracts the encoder of the original backbone and performs the k\n        ernel computations outlined in [1].\n\n\n        Notes:\n            The `hiddens` argument can be removed and instead inferred.\n\n        Args:\n            model (BaseBackbone): the original backbone. The model must have an encoder component.\n            hiddens (int): the dimensionality of the hidden dimensions for the kernel-specific modules.\n            lmd (float): The initial value for the lmd Parameter.\n            num_tasks (int): the number of tasks to be solved.\n            d_rn_f (int): dimensionality of the Random Fourier Features (RFFs). Applicable only if `kernel_type` is 'rff'.\n            kernel_type (str, optional): _description_. Defaults to \"rbf\".\n        \"\"\"\n        multihead, classes_per_task, masking_value = model.multihead, model.classes_per_task, model.masking_value\n        super().__init__(multihead=multihead, classes_per_task=classes_per_task, masking_value=masking_value)\n        self.encoder = model.encoder\n        self.d_rn_f = d_rn_f\n\n        self.post = Amortized(hiddens, hiddens, hiddens)\n        self.prior = Amortized(hiddens, hiddens, hiddens)\n\n        device = next(model.parameters()).device\n        self.lmd = nn.Parameter(torch.tensor([lmd for _ in range(num_tasks)])).to(device)\n        self.gma = nn.Parameter(torch.tensor([1.0 for _ in range(num_tasks)])).to(device)\n        self.bta = nn.Parameter(torch.tensor([0.0 for _ in range(num_tasks)])).to(device)\n        self.kernel_type = kernel_type\n        self.bias = 2 * math.pi * torch.rand(d_rn_f, 1).to(device)\n\n    def inner_forward(self, x: torch.Tensor, post: bool = False) -&gt; Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n        out = self.encoder(x)\n        out_features = self.normalize(out)\n        out_mean = torch.mean(out_features, dim=0, keepdim=True)\n        if post:\n            mu, logvar = self.post(out_mean)\n        else:\n            mu, logvar = self.prior(out_mean)\n        return out_features, mu, logvar\n\n    def kernel(self, x: torch.Tensor, y: torch.Tensor) -&gt; torch.Tensor:\n        if self.kernel_type == \"rbf\":\n            support_kernel = torch.exp(-0.25 * torch.norm(x.unsqueeze(1) - y, dim=2, p=1))\n        elif self.kernel_type == \"linear\":\n            support_kernel = x @ y.T\n        elif self.kernel_type == \"poly\":\n            support_kernel = (torch.matmul(x, y.T) + 1).pow(3)\n        elif self.kernel_type == \"rff\":\n            support_kernel = x.T @ y\n        else:\n            raise Exception(f\"Unknown kenrel. Only support RBF, RFF, POLY, LIN.\")\n        return support_kernel\n\n    @staticmethod\n    def sample(mu: torch.Tensor, logvar: torch.Tensor, L: int, device) -&gt; torch.Tensor:\n        shape = (L,) + mu.size()\n        eps = torch.randn(shape).to(device)\n        return mu.unsqueeze(0) + eps * logvar.exp().sqrt().unsqueeze(0)\n\n    def rand_features(self, bases: torch.Tensor, features: torch.Tensor) -&gt; torch.Tensor:\n        return math.sqrt(2 / self.bias.shape[0]) * torch.cos(torch.matmul(bases, features) + self.bias)\n\n    def compute_kernels(\n        self, features_train: torch.Tensor, features_coreset: torch.Tensor\n    ) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        device = features_coreset.device\n        if self.kernel_type == \"rff\":\n            # project to random features\n            rs = self.sample(self.r_mu, self.r_log_var, self.d_rn_f, device).squeeze()\n            features_coreset = self.rand_features(rs, torch.transpose(features_coreset, 1, 0))\n            features_train = self.rand_features(rs, torch.transpose(features_train, 1, 0))\n\n        support_kernel = self.kernel(features_coreset, features_coreset)\n        cross_kernel = self.kernel(features_coreset, features_train)\n        return support_kernel, cross_kernel\n\n    def forward(\n        self, x: torch.Tensor, task_ids: torch.Tensor, coreset_input: torch.Tensor, coreset_target: torch.Tensor\n    ) -&gt; torch.Tensor:\n        current_task = torch.unique(task_ids)\n        assert len(current_task) == 1\n        features_train, self.p_mu, self.p_log_var = self.inner_forward(x, post=False)\n        features_coreset, self.r_mu, self.r_log_var = self.inner_forward(coreset_input, post=True)\n\n        support_kernel, cross_kernel = self.compute_kernels(features_train, features_coreset)\n\n        alpha = torch.matmul(\n            torch.inverse(\n                support_kernel\n                + (torch.abs(self.lmd[current_task - 1]) + 0.01) * torch.eye(support_kernel.shape[0]).to(x.device)\n            ),\n            coreset_target,\n        )\n\n        out = self.gma[current_task - 1] * torch.matmul(cross_kernel.T, alpha) + self.bta[current_task - 1]\n\n        if self.multihead:\n            out = self.select_output_head(out, task_ids)\n\n        return out\n\n    def normalize(self, x: torch.Tensor) -&gt; torch.Tensor:\n        max_val = x.max()\n        min_val = x.min()\n        return (x - min_val) / (max_val - min_val)\n</code></pre>"},{"location":"algos/pytorch/kcl/#sequel.algos.pytorch.kcl.KernelBackboneWrapper.__init__","title":"<code>__init__(model, hiddens, lmd, num_tasks, d_rn_f, kernel_type='rff')</code>","text":"<p>Model Wrapper for Kernel Continual Learning. Extracts the encoder of the original backbone and performs the k ernel computations outlined in [1].</p> Notes <p>The <code>hiddens</code> argument can be removed and instead inferred.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>BaseBackbone</code> <p>the original backbone. The model must have an encoder component.</p> required <code>hiddens</code> <code>int</code> <p>the dimensionality of the hidden dimensions for the kernel-specific modules.</p> required <code>lmd</code> <code>float</code> <p>The initial value for the lmd Parameter.</p> required <code>num_tasks</code> <code>int</code> <p>the number of tasks to be solved.</p> required <code>d_rn_f</code> <code>int</code> <p>dimensionality of the Random Fourier Features (RFFs). Applicable only if <code>kernel_type</code> is 'rff'.</p> required <code>kernel_type</code> <code>str</code> <p>description. Defaults to \"rbf\".</p> <code>'rff'</code> Source code in <code>sequel/algos/pytorch/kcl.py</code> <pre><code>def __init__(\n    self,\n    model: BaseBackbone,\n    hiddens: int,\n    lmd: float,\n    num_tasks: int,\n    d_rn_f: int,\n    kernel_type: Literal[\"rbf\", \"rff\", \"linear\", \"poly\"] = \"rff\",\n):\n\"\"\"Model Wrapper for Kernel Continual Learning. Extracts the encoder of the original backbone and performs the k\n    ernel computations outlined in [1].\n\n\n    Notes:\n        The `hiddens` argument can be removed and instead inferred.\n\n    Args:\n        model (BaseBackbone): the original backbone. The model must have an encoder component.\n        hiddens (int): the dimensionality of the hidden dimensions for the kernel-specific modules.\n        lmd (float): The initial value for the lmd Parameter.\n        num_tasks (int): the number of tasks to be solved.\n        d_rn_f (int): dimensionality of the Random Fourier Features (RFFs). Applicable only if `kernel_type` is 'rff'.\n        kernel_type (str, optional): _description_. Defaults to \"rbf\".\n    \"\"\"\n    multihead, classes_per_task, masking_value = model.multihead, model.classes_per_task, model.masking_value\n    super().__init__(multihead=multihead, classes_per_task=classes_per_task, masking_value=masking_value)\n    self.encoder = model.encoder\n    self.d_rn_f = d_rn_f\n\n    self.post = Amortized(hiddens, hiddens, hiddens)\n    self.prior = Amortized(hiddens, hiddens, hiddens)\n\n    device = next(model.parameters()).device\n    self.lmd = nn.Parameter(torch.tensor([lmd for _ in range(num_tasks)])).to(device)\n    self.gma = nn.Parameter(torch.tensor([1.0 for _ in range(num_tasks)])).to(device)\n    self.bta = nn.Parameter(torch.tensor([0.0 for _ in range(num_tasks)])).to(device)\n    self.kernel_type = kernel_type\n    self.bias = 2 * math.pi * torch.rand(d_rn_f, 1).to(device)\n</code></pre>"},{"location":"algos/pytorch/lamaml/","title":"LaMAML","text":""},{"location":"algos/pytorch/lamaml/#sequel.algos.pytorch.lamaml.LaMAML","title":"<code>LaMAML</code>","text":"<p>         Bases: <code>PytorchBaseAlgorithm</code></p> <p>Look-Ahead Model Agnostic Meta Learning implementation in PyTorch.</p> <p>LaMAML is not yet implemented in JAX.</p> References <p>[1] Gupta, G., Yadav, K. &amp; Paull, L. Look-ahead meta learning for continual learning. in Advances in neural     information processing systems 202.</p> Source code in <code>sequel/algos/pytorch/lamaml.py</code> <pre><code>class LaMAML(PytorchBaseAlgorithm):\n\"\"\"Look-Ahead Model Agnostic Meta Learning implementation in PyTorch.\n\n    LaMAML is not yet implemented in JAX.\n\n    References:\n        [1] Gupta, G., Yadav, K. &amp; Paull, L. Look-ahead meta learning for continual learning. in Advances in neural\n            information processing systems 202.\n    \"\"\"\n\n    backbone_func: FunctionalModule\n    params: List[torch.nn.Parameter]\n\n    def __init__(\n        self,\n        mem_size: int,\n        glances: int = 5,\n        n_inner_updates: int = 5,\n        second_order: bool = False,\n        grad_clip_norm: float = 2.0,\n        learn_lr: bool = True,\n        lr_alpha: float = 0.3,\n        sync_update: bool = False,\n        initial_alpha_value: float = 0.15,\n        lr_weights: float = 0.1,\n        *args,\n        **kwargs\n    ):\n\"\"\"Inits the LaMAML algorithm class.\n\n        Args:\n            mem_size (int): The size of the memory.\n            glances (int, optional): The number of gradient steps performed on the current batch. Defaults to 5.\n            n_inner_updates (int, optional): The number of updates performed for the inner step of the Meta Learning\n                process. The batch is split into `n_inner_updates` sub-batches. Defaults to 5.\n            second_order (bool, optional): Boolean denoting whether the computational graph is kept for second-order\n                derivative calculations. Defaults to False.\n            grad_clip_norm (float, optional): The max norm of the gradients. Defaults to 2.0.\n            learn_lr (bool, optional): Boolean denoting whether the per-parameter learning rate is learned or not.\n                Defaults to True.\n            lr_alpha (float, optional): The learning rate for the parameters corresponding to the learnt learning rate\n                for the weights. Defaults to 0.3.\n            sync_update (bool, optional): _description_. Defaults to False.\n            initial_alpha_value (float, optional): The initial value for the per-parameter learning rate. Defaults to 0.15.\n            lr_weights (float, optional): The learning rate for the weights. Applies onl if `sync_update` is set to\n                True. Defaults to 0.1.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n\n        self.glances = glances\n        self.n_inner_updates = n_inner_updates\n        self.second_order = second_order\n        self.grad_clip_norm = grad_clip_norm\n        self.learn_lr = learn_lr\n        self.lr_alpha = lr_alpha\n        self.sync_update = sync_update\n        self.initial_alpha_value = initial_alpha_value\n        self.mem_size = mem_size\n        self.lr_weights = lr_weights\n        self.buffer = Buffer(memory_size=mem_size)\n\n        self.backbone_func, self.params = make_functional(self.backbone)\n\n        alpha_params = [nn.Parameter(initial_alpha_value * torch.ones_like(p)) for p in self.params]\n        self.alpha_lr = nn.ParameterList(alpha_params).to(self.device)\n\n        self.opt_lr = torch.optim.SGD(self.alpha_lr.parameters(), lr=lr_alpha)\n        if self.sync_update:\n            self.opt_wt = torch.optim.SGD(self.params, lr=self.lr_weights)\n\n        warnings.warn(\n            \"The LaMAML implementation disposes of the optimizer provided in the class arguments. The newly-defined\"\n            \" optimizer concerns the parameters responsible for the learning rate of the underlying backbone parameters.\"\n        )\n\n        warnings.warn(\n            \"The argument `n_inner_updates` is not used at the moment. It is automatically set to the number of \"\n            \"samples in a batch. Hence, the inner update is performed with only one sample.\"\n        )\n\n        warnings.warn(\"LaMAML does not currently support benchmarks with task ids, such as SPlitCIFAR100.\")\n\n    def forward(self) -&gt; torch.Tensor:\n        self.y_hat = self.backbone_func(self.params, self.x)\n        return self.y_hat\n\n    def meta_loss(self, fast_weights, x, y, t) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        logits = self.backbone_func(fast_weights, x)\n        loss_q = self.compute_loss(logits.squeeze(1), y)\n        return loss_q, logits\n\n    def inner_update(self, fast_weights, x, y, t) -&gt; List[torch.nn.Parameter]:\n        if fast_weights is None:\n            fast_weights = self.params\n\n        logits = self.backbone_func(fast_weights, x)\n        loss = self.compute_loss(logits.squeeze(), y)\n\n        # NOTE if we want higher order grads to be allowed, change create_graph=False to True\n        graph_required = self.second_order\n        grads = torch.autograd.grad(loss, fast_weights, create_graph=graph_required, retain_graph=graph_required)\n        grads = [torch.clamp(g, min=-self.grad_clip_norm, max=self.grad_clip_norm) for g in grads]\n\n        fast_weights = list(map(lambda p, g, a: p - g * F.relu(a), fast_weights, grads, self.alpha_lr))\n        return fast_weights\n\n    def observe(self, x: torch.Tensor, y: torch.Tensor, t: torch.Tensor) -&gt; float:\n        # self.backbone.train()\n        self.orig_x, self.orig_y, self.orig_t = x, y, t\n        for self.glance_idx in range(self.glances):\n            perm = torch.randperm(x.size(0))\n            x = x[perm]\n            y = y[perm]\n\n            self.opt_lr.zero_grad()\n\n            fast_weights = None\n            meta_losses = []\n\n            self.x, self.y, self.t = self.buffer.augment_batch_with_memory(x, y, t)\n            # `n_inner_updates` is set to the batch size implicitly.\n            for batch_x, batch_y, batch_t in zip(x, y, t):\n                fast_weights = self.inner_update(fast_weights, batch_x, batch_y, batch_t)\n                if self.current_task_epoch == 1:\n                    self.buffer.add_data(batch_x, batch_y, batch_t)\n\n                meta_loss, self.y_hat = self.meta_loss(fast_weights, self.x, self.y, self.t)\n                meta_losses.append(meta_loss)\n\n            # Taking the meta gradient step (will update the learning rates)\n            self.opt_lr.zero_grad()\n            meta_loss: torch.Tensor = sum(meta_losses) / len(meta_losses)\n            meta_loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(self.params, self.grad_clip_norm)\n            torch.nn.utils.clip_grad_norm_(self.alpha_lr.parameters(), self.grad_clip_norm)\n\n            if self.learn_lr:\n                self.opt_lr.step()\n\n            if self.sync_update:\n                self.opt_wt.step()\n                self.opt_wt.zero_grad()\n                self.alpha_lr.zero_grad()\n            else:\n                for i, p in enumerate(self.params):\n                    p.data = p.data - p.grad * F.relu(self.alpha_lr[i])\n                for p in self.params:\n                    p.grad.zero_()\n                self.alpha_lr.zero_grad()\n\n        self.loss = meta_loss\n        return meta_loss.item()\n\n    def training_step(self, *args, **kwargs):\n        self.observe(self.x, self.y, self.t)\n\n    def _configure_optimizers(self, task):\n        pass\n</code></pre>"},{"location":"algos/pytorch/lamaml/#sequel.algos.pytorch.lamaml.LaMAML.__init__","title":"<code>__init__(mem_size, glances=5, n_inner_updates=5, second_order=False, grad_clip_norm=2.0, learn_lr=True, lr_alpha=0.3, sync_update=False, initial_alpha_value=0.15, lr_weights=0.1, *args, **kwargs)</code>","text":"<p>Inits the LaMAML algorithm class.</p> <p>Parameters:</p> Name Type Description Default <code>mem_size</code> <code>int</code> <p>The size of the memory.</p> required <code>glances</code> <code>int</code> <p>The number of gradient steps performed on the current batch. Defaults to 5.</p> <code>5</code> <code>n_inner_updates</code> <code>int</code> <p>The number of updates performed for the inner step of the Meta Learning process. The batch is split into <code>n_inner_updates</code> sub-batches. Defaults to 5.</p> <code>5</code> <code>second_order</code> <code>bool</code> <p>Boolean denoting whether the computational graph is kept for second-order derivative calculations. Defaults to False.</p> <code>False</code> <code>grad_clip_norm</code> <code>float</code> <p>The max norm of the gradients. Defaults to 2.0.</p> <code>2.0</code> <code>learn_lr</code> <code>bool</code> <p>Boolean denoting whether the per-parameter learning rate is learned or not. Defaults to True.</p> <code>True</code> <code>lr_alpha</code> <code>float</code> <p>The learning rate for the parameters corresponding to the learnt learning rate for the weights. Defaults to 0.3.</p> <code>0.3</code> <code>sync_update</code> <code>bool</code> <p>description. Defaults to False.</p> <code>False</code> <code>initial_alpha_value</code> <code>float</code> <p>The initial value for the per-parameter learning rate. Defaults to 0.15.</p> <code>0.15</code> <code>lr_weights</code> <code>float</code> <p>The learning rate for the weights. Applies onl if <code>sync_update</code> is set to True. Defaults to 0.1.</p> <code>0.1</code> Source code in <code>sequel/algos/pytorch/lamaml.py</code> <pre><code>def __init__(\n    self,\n    mem_size: int,\n    glances: int = 5,\n    n_inner_updates: int = 5,\n    second_order: bool = False,\n    grad_clip_norm: float = 2.0,\n    learn_lr: bool = True,\n    lr_alpha: float = 0.3,\n    sync_update: bool = False,\n    initial_alpha_value: float = 0.15,\n    lr_weights: float = 0.1,\n    *args,\n    **kwargs\n):\n\"\"\"Inits the LaMAML algorithm class.\n\n    Args:\n        mem_size (int): The size of the memory.\n        glances (int, optional): The number of gradient steps performed on the current batch. Defaults to 5.\n        n_inner_updates (int, optional): The number of updates performed for the inner step of the Meta Learning\n            process. The batch is split into `n_inner_updates` sub-batches. Defaults to 5.\n        second_order (bool, optional): Boolean denoting whether the computational graph is kept for second-order\n            derivative calculations. Defaults to False.\n        grad_clip_norm (float, optional): The max norm of the gradients. Defaults to 2.0.\n        learn_lr (bool, optional): Boolean denoting whether the per-parameter learning rate is learned or not.\n            Defaults to True.\n        lr_alpha (float, optional): The learning rate for the parameters corresponding to the learnt learning rate\n            for the weights. Defaults to 0.3.\n        sync_update (bool, optional): _description_. Defaults to False.\n        initial_alpha_value (float, optional): The initial value for the per-parameter learning rate. Defaults to 0.15.\n        lr_weights (float, optional): The learning rate for the weights. Applies onl if `sync_update` is set to\n            True. Defaults to 0.1.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n\n    self.glances = glances\n    self.n_inner_updates = n_inner_updates\n    self.second_order = second_order\n    self.grad_clip_norm = grad_clip_norm\n    self.learn_lr = learn_lr\n    self.lr_alpha = lr_alpha\n    self.sync_update = sync_update\n    self.initial_alpha_value = initial_alpha_value\n    self.mem_size = mem_size\n    self.lr_weights = lr_weights\n    self.buffer = Buffer(memory_size=mem_size)\n\n    self.backbone_func, self.params = make_functional(self.backbone)\n\n    alpha_params = [nn.Parameter(initial_alpha_value * torch.ones_like(p)) for p in self.params]\n    self.alpha_lr = nn.ParameterList(alpha_params).to(self.device)\n\n    self.opt_lr = torch.optim.SGD(self.alpha_lr.parameters(), lr=lr_alpha)\n    if self.sync_update:\n        self.opt_wt = torch.optim.SGD(self.params, lr=self.lr_weights)\n\n    warnings.warn(\n        \"The LaMAML implementation disposes of the optimizer provided in the class arguments. The newly-defined\"\n        \" optimizer concerns the parameters responsible for the learning rate of the underlying backbone parameters.\"\n    )\n\n    warnings.warn(\n        \"The argument `n_inner_updates` is not used at the moment. It is automatically set to the number of \"\n        \"samples in a batch. Hence, the inner update is performed with only one sample.\"\n    )\n\n    warnings.warn(\"LaMAML does not currently support benchmarks with task ids, such as SPlitCIFAR100.\")\n</code></pre>"},{"location":"algos/pytorch/lfl/","title":"LFL","text":""},{"location":"algos/pytorch/lfl/#sequel.algos.pytorch.lfl.LFL","title":"<code>LFL</code>","text":"<p>         Bases: <code>PytorchBaseAlgorithm</code></p> <p>Less-Forgetting Learning implementation in PyTorch.</p> <p>The equivalent JAX implementation is <code>LFL in JAX</code>.</p> References <p>[1] Jung, H., Ju, J., Jung, M. &amp; Kim, J. Less-forgetful learning for domain expansion in deep neural     networks. Proceedings of the AAAI Conference on Artificial Intelligence 32, (2018).</p> Source code in <code>sequel/algos/pytorch/lfl.py</code> <pre><code>class LFL(PytorchBaseAlgorithm):\n\"\"\"Less-Forgetting Learning implementation in PyTorch.\n\n    The equivalent JAX implementation is [`LFL in JAX`][sequel.algos.jax.lfl.LFL].\n\n    References:\n        [1] Jung, H., Ju, J., Jung, M. &amp; Kim, J. Less-forgetful learning for domain expansion in deep neural\n            networks. Proceedings of the AAAI Conference on Artificial Intelligence 32, (2018).\n    \"\"\"\n\n    def __init__(self, lfl_lambda: float, *args, **kwargs):\n\"\"\"Inits the LFL class.\n\n        Args:\n            lfl_lambda (float): the regularization coefficient.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self.regularization_coefficient = lfl_lambda\n\n    def __repr__(self) -&gt; str:\n        return f\"LFL(regularization_coefficient={self.regularization_coefficient})\"\n\n    def on_after_training_task(self, *args, **kwargs):\n        # freeze previous model\n        # assert isinstance\n        self.prev_backbone = copy.deepcopy(self.backbone)\n        self.prev_backbone.eval()\n\n        for p in self.prev_backbone.parameters():\n            p.requires_grad = False\n\n    def on_before_backward(self, *args, **kwargs):\n        if self.task_counter &gt; 1:\n            self.prev_backbone.eval()\n            self.backbone.eval()\n\n            features = self.backbone.encoder(self.x)\n            prev_features = self.prev_backbone.encoder(self.x)\n            self.loss += self.regularization_coefficient * F.mse_loss(features, prev_features)\n</code></pre>"},{"location":"algos/pytorch/lfl/#sequel.algos.pytorch.lfl.LFL.__init__","title":"<code>__init__(lfl_lambda, *args, **kwargs)</code>","text":"<p>Inits the LFL class.</p> <p>Parameters:</p> Name Type Description Default <code>lfl_lambda</code> <code>float</code> <p>the regularization coefficient.</p> required Source code in <code>sequel/algos/pytorch/lfl.py</code> <pre><code>def __init__(self, lfl_lambda: float, *args, **kwargs):\n\"\"\"Inits the LFL class.\n\n    Args:\n        lfl_lambda (float): the regularization coefficient.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n    self.regularization_coefficient = lfl_lambda\n</code></pre>"},{"location":"algos/pytorch/mas/","title":"MAS","text":""},{"location":"algos/pytorch/mas/#sequel.algos.pytorch.mas.MAS","title":"<code>MAS</code>","text":"<p>         Bases: <code>PytorchRegularizationBaseAlgorithm</code></p> <p>Memory Aware Synapses. Algorithm Class. Inherits from BaseAlgorithm.</p> <p>The equivalent JAX implementation is <code>MAS in JAX</code>.</p> References <p>[1] Aljundi, R., Babiloni, F., Elhoseiny, M., Rohrbach, M. &amp; Tuytelaars, T. Memory Aware Synapses: Learning     What (not) to Forget. in Computer Vision - ECCV 2018.</p> Source code in <code>sequel/algos/pytorch/mas.py</code> <pre><code>class MAS(PytorchRegularizationBaseAlgorithm):\n\"\"\"Memory Aware Synapses. Algorithm Class. Inherits from BaseAlgorithm.\n\n    The equivalent JAX implementation is [`MAS in JAX`][sequel.algos.jax.mas.MAS].\n\n    References:\n        [1] Aljundi, R., Babiloni, F., Elhoseiny, M., Rohrbach, M. &amp; Tuytelaars, T. Memory Aware Synapses: Learning\n            What (not) to Forget. in Computer Vision - ECCV 2018.\n    \"\"\"\n\n    def __init__(self, mas_lambda: float = 1.0, *args, **kwargs):\n\"\"\"Inits the Memory Aware Synapses algorithm.\n\n        Args:\n            mas_lambda (float): The c coefficient of the algorithm.\n        \"\"\"\n        super().__init__(regularization_coefficient=mas_lambda, *args, **kwargs)\n\n        torch.autograd.set_detect_anomaly(True)\n        for name, param in self.backbone.named_parameters():\n            name = name.replace(\".\", \"_\")\n            self.backbone.register_buffer(f\"{name}_w\", torch.zeros_like(param))\n\n    def __repr__(self) -&gt; str:\n        return f\"MAS(mas_lambda={self.regularization_coefficient})\"\n\n    def on_after_training_step(self, *args, **kwargs):\n        # perform the forward pass once again with the new parameters.\n        self.forward()\n        self.optimizer_zero_grad()\n        f_loss: torch.Tensor = self.y_hat.pow_(2).mean()\n        f_loss.backward()\n        for name, param in self.backbone.named_parameters():\n            name = name.replace(\".\", \"_\")\n            w = getattr(self.backbone, f\"{name}_w\")\n            if param.grad is not None:\n                setattr(self.backbone, f\"{name}_w\", w + param.grad.abs() / len(self.train_loader))\n        return super().on_after_training_step(*args, **kwargs)\n\n    def calculate_parameter_importance(self):\n        importances = {}\n        for name, param in self.backbone.named_parameters():\n            name = name.replace(\".\", \"_\")\n            importances[name] = getattr(self.backbone, f\"{name}_w\")\n\n        return importances\n</code></pre>"},{"location":"algos/pytorch/mas/#sequel.algos.pytorch.mas.MAS.__init__","title":"<code>__init__(mas_lambda=1.0, *args, **kwargs)</code>","text":"<p>Inits the Memory Aware Synapses algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>mas_lambda</code> <code>float</code> <p>The c coefficient of the algorithm.</p> <code>1.0</code> Source code in <code>sequel/algos/pytorch/mas.py</code> <pre><code>def __init__(self, mas_lambda: float = 1.0, *args, **kwargs):\n\"\"\"Inits the Memory Aware Synapses algorithm.\n\n    Args:\n        mas_lambda (float): The c coefficient of the algorithm.\n    \"\"\"\n    super().__init__(regularization_coefficient=mas_lambda, *args, **kwargs)\n\n    torch.autograd.set_detect_anomaly(True)\n    for name, param in self.backbone.named_parameters():\n        name = name.replace(\".\", \"_\")\n        self.backbone.register_buffer(f\"{name}_w\", torch.zeros_like(param))\n</code></pre>"},{"location":"algos/pytorch/mcsgd/","title":"MC-SGD","text":""},{"location":"algos/pytorch/mcsgd/#sequel.algos.pytorch.mcsgd.MCSGD","title":"<code>MCSGD</code>","text":"<p>         Bases: <code>PytorchBaseAlgorithm</code></p> <p>MC-SGD: Mode Connectivity-Stochastic Gradient Descent. Inherits from BaseAlgorithm.</p> <p>The equivalent JAX implementation is <code>MCSGD in JAX</code>.</p> References <p>[1] Mirzadeh, S.-I., Farajtabar, M., G\u00f6r\u00fcr, D., Pascanu, R. &amp; Ghasemzadeh, H. Linear Mode Connectivity in     Multitask and Continual Learning. in 9th International Conference on Learning Representations, ICLR 2021.</p> Source code in <code>sequel/algos/pytorch/mcsgd.py</code> <pre><code>class MCSGD(PytorchBaseAlgorithm):\n\"\"\"MC-SGD: Mode Connectivity-Stochastic Gradient Descent. Inherits from BaseAlgorithm.\n\n    The equivalent JAX implementation is [`MCSGD in JAX`][sequel.algos.jax.mcsgd.MCSGD].\n\n    References:\n        [1] Mirzadeh, S.-I., Farajtabar, M., G\u00f6r\u00fcr, D., Pascanu, R. &amp; Ghasemzadeh, H. Linear Mode Connectivity in\n            Multitask and Continual Learning. in 9th International Conference on Learning Representations, ICLR 2021.\n    \"\"\"\n\n    def __init__(\n        self,\n        per_task_memory_samples: int = 100,\n        memory_group_by: Literal[\"task\", \"class\"] = \"task\",\n        lmc_policy=\"offline\",\n        lmc_interpolation=\"linear\",\n        lmc_lr=0.05,\n        lmc_momentum=0.8,\n        lmc_batch_size=64,\n        lmc_init_position=0.1,\n        lmc_line_samples=10,\n        lmc_epochs=1,\n        *args,\n        **kwargs,\n    ):\n        super().__init__(*args, **kwargs)\n        self.memory = MemoryMechanism(per_task_memory_samples=per_task_memory_samples, groupby=memory_group_by)\n        self.w_bar_prev = None\n        self.w_hat_curr = None\n\n        # parse init arguments\n        self.per_task_memory_samples = per_task_memory_samples\n        self.lmc_policy = lmc_policy\n        self.lmc_interpolation = lmc_interpolation\n        self.lmc_lr = lmc_lr\n        self.lmc_momentum = lmc_momentum\n        self.lmc_batch_size = lmc_batch_size\n        self.lmc_init_position = lmc_init_position\n        self.lmc_line_samples = lmc_line_samples\n        self.lmc_epochs = lmc_epochs\n\n    def __repr__(self) -&gt; str:\n        return (\n            \"MCSGD(\"\n            + f\"per_task_memory_samples={self.per_task_memory_samples}, \"\n            + f\"policy={self.lmc_policy}, \"\n            + f\"interpolation={self.lmc_interpolation}, \"\n            + f\"lr={self.lmc_lr}, \"\n            + f\"momentum={self.lmc_momentum}, \"\n            + f\"batch_size={self.lmc_batch_size}, \"\n            + f\"init_position={self.lmc_init_position}, \"\n            + f\"line_samples={self.lmc_line_samples}, \"\n            + f\"epochs={self.lmc_epochs}\"\n            + \")\"\n        )\n\n    def calculate_line_loss(self, w_start, w_end, loader):\n        line_samples = np.arange(0.0, 1.01, 1.0 / float(self.lmc_line_samples))\n        grads = 0\n        for t in tqdm(line_samples, desc=\"Line samples\"):\n            w_mid = w_start + (w_end - w_start) * t\n            m = set_weights(self.backbone, w_mid)\n            self.calculate_point_loss(m, loader).backward()\n            grads += torch.cat([p.grad.view(-1) for _, p in m.named_parameters()])\n        return grads\n\n    def calculate_point_loss(self, model, loader):\n        criterion = self._configure_criterion()\n        model.eval()\n        total_loss, total_count = 0.0, 0.0\n        for batch in loader:\n            self.unpack_batch(batch)\n            self.y_hat = model(self.x, self.t)\n\n            total_loss += criterion(self.y_hat, self.y)\n            total_count += self.bs\n\n        return total_loss / total_count\n\n    def find_connected_minima(self, task):\n        bs = self.lmc_batch_size\n        loader_curr = self.benchmark.train_dataloader_subset(\n            task, batch_size=bs, subset_size=self.per_task_memory_samples\n        )\n        loader_prev = self.benchmark.memory_dataloader(task, batch_size=bs, return_infinite_stream=False)\n\n        mc_model = set_weights(\n            self.backbone, self.w_bar_prev + (self.w_hat_curr - self.w_bar_prev) * self.lmc_init_position\n        )\n        optimizer = torch.optim.SGD(mc_model.parameters(), lr=self.lmc_lr, momentum=self.lmc_momentum)\n\n        mc_model.train()\n        optimizer.zero_grad()\n        grads_prev = self.calculate_line_loss(self.w_bar_prev, get_weights(mc_model), loader_prev)\n        grads_curr = self.calculate_line_loss(self.w_hat_curr, get_weights(mc_model), loader_curr)\n        mc_model = set_grads(mc_model, (grads_prev + grads_curr))\n        optimizer.step()\n        return mc_model\n\n    def on_after_training_epoch(self, *args, **kwargs):\n        # save the weights of the current Continual Learning solution\n        self.w_hat_curr = get_weights(self.backbone)\n\n    def validate_algorithm_on_all_tasks(self) -&gt; Dict[str, float]:\n        if self.task_counter == 1:\n            super().validate_algorithm_on_all_tasks()\n\n    def on_after_validating_algorithm_on_all_tasks_callbacks(self):\n        if self.task_counter == 1:\n            return super().on_after_validating_algorithm_on_all_tasks_callbacks()\n\n    def on_after_training_task(self, *args, **kwargs):\n\"\"\"After training for a task similarly to the na\u00efve algorithm, MCSGD performs another round of epochs\n        corresponding to the linear connectivity updates of the algorithm.\n\n        Note that the validation is performed with the weights obtained at the end of these updates.\n        \"\"\"\n\n        # update the memory to include samples from the current task\n        self.memory.update_memory(self)\n        if self.task_counter &gt; 1:\n            self.backbone = self.find_connected_minima(self.task_counter)\n            # perform the validation with the weights obtained after the mode-connectivity updates\n            super().on_before_validating_algorithm_on_all_tasks_callbacks()\n            super().validate_algorithm_on_all_tasks()\n            super().on_after_validating_algorithm_on_all_tasks_callbacks()\n\n        # save the backbone obtained from the mode-connectivity updates\n        # as the Multi-Task approximate solution\n        self.w_bar_prev = get_weights(self.backbone)\n\n        # revert the weights of the backbone to the Continual Learning solution\n        self.backbone = set_weights(self.backbone, self.w_hat_curr)\n</code></pre>"},{"location":"algos/pytorch/mcsgd/#sequel.algos.pytorch.mcsgd.MCSGD.on_after_training_task","title":"<code>on_after_training_task(*args, **kwargs)</code>","text":"<p>After training for a task similarly to the na\u00efve algorithm, MCSGD performs another round of epochs corresponding to the linear connectivity updates of the algorithm.</p> <p>Note that the validation is performed with the weights obtained at the end of these updates.</p> Source code in <code>sequel/algos/pytorch/mcsgd.py</code> <pre><code>def on_after_training_task(self, *args, **kwargs):\n\"\"\"After training for a task similarly to the na\u00efve algorithm, MCSGD performs another round of epochs\n    corresponding to the linear connectivity updates of the algorithm.\n\n    Note that the validation is performed with the weights obtained at the end of these updates.\n    \"\"\"\n\n    # update the memory to include samples from the current task\n    self.memory.update_memory(self)\n    if self.task_counter &gt; 1:\n        self.backbone = self.find_connected_minima(self.task_counter)\n        # perform the validation with the weights obtained after the mode-connectivity updates\n        super().on_before_validating_algorithm_on_all_tasks_callbacks()\n        super().validate_algorithm_on_all_tasks()\n        super().on_after_validating_algorithm_on_all_tasks_callbacks()\n\n    # save the backbone obtained from the mode-connectivity updates\n    # as the Multi-Task approximate solution\n    self.w_bar_prev = get_weights(self.backbone)\n\n    # revert the weights of the backbone to the Continual Learning solution\n    self.backbone = set_weights(self.backbone, self.w_hat_curr)\n</code></pre>"},{"location":"algos/pytorch/si/","title":"SI","text":""},{"location":"algos/pytorch/si/#sequel.algos.pytorch.si.SI","title":"<code>SI</code>","text":"<p>         Bases: <code>PytorchRegularizationBaseAlgorithm</code></p> <p>Synaptic Intelligence Algorithm Class. Inherits from PytorchBaseAlgorithm.</p> <p>The equivalent JAX implementation is <code>SI in JAX</code>.</p> References <p>[1] Zenke, F., Poole, B. &amp; Ganguli, S. Continual Learning Through Synaptic Intelligence. in Proceedings of the     34th International Conference on Machine Learning, ICML 2017.</p> Source code in <code>sequel/algos/pytorch/si.py</code> <pre><code>class SI(PytorchRegularizationBaseAlgorithm):\n\"\"\"Synaptic Intelligence Algorithm Class. Inherits from PytorchBaseAlgorithm.\n\n    The equivalent JAX implementation is [`SI in JAX`][sequel.algos.jax.si.SI].\n\n    References:\n        [1] Zenke, F., Poole, B. &amp; Ganguli, S. Continual Learning Through Synaptic Intelligence. in Proceedings of the\n            34th International Conference on Machine Learning, ICML 2017.\n    \"\"\"\n\n    def __init__(self, si_lambda: float = 1.0, xi: float = 0.1, *args, **kwargs):\n        super().__init__(regularization_coefficient=si_lambda, *args, **kwargs)\n        # hyperparameters\n        self.xi = xi\n\n        for name, param in self.backbone.named_parameters():\n            name = name.replace(\".\", \"_\")\n            self.backbone.register_buffer(f\"{name}_w\", torch.zeros_like(param))\n\n    def __repr__(self) -&gt; str:\n        return f\"SI(si_lambda={self.regularization_coefficient}, xi={self.xi})\"\n\n    def on_before_training_step(self, *args, **kwargs):\n        for name, param in self.backbone.named_parameters():\n            name = name.replace(\".\", \"_\")\n            setattr(self.backbone, f\"{name}_prev\", param.data.clone())\n\n    def on_after_training_step(self, *args, **kwargs):\n        for name, param in self.backbone.named_parameters():\n            name = name.replace(\".\", \"_\")\n            if param.grad is not None:\n                delta = param.clone().detach() - getattr(self.backbone, f\"{name}_prev\")\n                w = getattr(self.backbone, f\"{name}_w\")\n                setattr(self.backbone, f\"{name}_w\", w - w * delta)\n\n    def calculate_parameter_importance(self):\n        logging.info(\"Updating importance parameters for Synaptic Intelligence\")\n        importances = {}\n        for (name, p) in self.backbone.named_parameters():\n            name = name.replace(\".\", \"_\")\n            old_importance = getattr(self.backbone, f\"{name}_importance\")\n            omega: Tensor = getattr(self.backbone, f\"{name}_w\")\n            delta: Tensor = p.detach() - getattr(self.backbone, f\"{name}_old\")\n\n            # see Eq. 5 from paper.\n            importances[name] = old_importance + omega / (delta.pow(2) + self.xi)\n\n            # reset (small) omega for next task\n            setattr(self.backbone, f\"{name}_w\", omega.clone().zero_())\n\n        return importances\n</code></pre>"},{"location":"algos/utils/callback_hooks/","title":"callback_hooks","text":""},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook","title":"<code>BaseCallbackHook</code>","text":"<p>         Bases: <code>abc.ABC</code></p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>class BaseCallbackHook(abc.ABC):\n    callbacks: List[BaseCallback] = []\n\n    def on_before_setup_callbacks(self):\n\"\"\"Callbacks before the setup.\"\"\"\n        for cb in self.callbacks:\n            cb.on_before_setup(self)\n\n    def on_after_setup_callbacks(self):\n\"\"\"Callbacks after the setup.\"\"\"\n        for cb in self.callbacks:\n            cb.on_after_setup(self)\n\n    def on_before_teardown_callbacks(self):\n\"\"\"Callbacks before the teardown.\"\"\"\n        for cb in self.callbacks:\n            cb.on_before_teardown(self)\n\n    def on_after_teardown_callbacks(self):\n\"\"\"Callbacks after the teardown.\"\"\"\n        for cb in self.callbacks:\n            cb.on_after_teardown(self)\n\n    def on_before_fit_callbacks(self):\n\"\"\"Callbacks before fitting the data.\"\"\"\n        for cb in self.callbacks:\n            cb.on_before_fit(self)\n\n    def on_after_fit_callbacks(self):\n\"\"\"Callbacks after fitting the data.\"\"\"\n        for cb in self.callbacks:\n            cb.on_after_fit(self)\n\n    def on_before_training_task_callbacks(self):\n\"\"\"Callbacks before training a single task.\"\"\"\n        for cb in self.callbacks:\n            cb.on_before_training_task(self)\n\n    def on_after_training_task_callbacks(self):\n\"\"\"Callbacks after training a single task.\"\"\"\n        for cb in self.callbacks:\n            cb.on_after_training_task(self)\n\n    def on_before_training_epoch_callbacks(self):\n\"\"\"Callbacks before training one epoch.\"\"\"\n        for cb in self.callbacks:\n            cb.on_before_training_epoch(self)\n\n    def on_after_training_epoch_callbacks(self):\n\"\"\"Callbacks after training one epoch.\"\"\"\n        for cb in self.callbacks:\n            cb.on_after_training_epoch(self)\n\n    def on_before_val_epoch_callbacks(self):\n\"\"\"Callbacks before validating one epoch.\"\"\"\n        for cb in self.callbacks:\n            cb.on_before_val_epoch(self)\n\n    def on_after_val_epoch_callbacks(self):\n\"\"\"Callbacks after validating one epoch.\"\"\"\n        for cb in self.callbacks:\n            cb.on_after_val_epoch(self)\n\n    def on_before_val_step_callbacks(self):\n\"\"\"Callbacks before the val step (single batch step).\"\"\"\n        for cb in self.callbacks:\n            cb.on_before_val_step(self)\n\n    def on_after_val_step_callbacks(self):\n\"\"\"Callbacks after the val step.\"\"\"\n        for cb in self.callbacks:\n            cb.on_after_val_step(self)\n\n    def on_before_training_step_callbacks(self):\n\"\"\"Callbacks before the training step (single batch step).\"\"\"\n        for cb in self.callbacks:\n            cb.on_before_training_step(self)\n\n    def on_after_training_step_callbacks(self):\n\"\"\"Callbacks after the training step.\"\"\"\n        for cb in self.callbacks:\n            cb.on_after_training_step(self)\n\n    def on_before_backward_callbacks(self):\n\"\"\"Callbacks before backpropagation.\"\"\"\n        for cb in self.callbacks:\n            cb.on_before_backward(self)\n\n    def on_after_backward_callbacks(self):\n\"\"\"Callbacks after backpropagation.\"\"\"\n        for cb in self.callbacks:\n            cb.on_after_backward(self)\n\n    def on_before_optimizer_step_callbacks(self):\n\"\"\"Callbacks before optimizer step.\"\"\"\n        for cb in self.callbacks:\n            cb.on_before_optimizer_step(self)\n\n    def on_after_optimizer_step_callbacks(self):\n\"\"\"Callbacks after optimizer step.\"\"\"\n        for cb in self.callbacks:\n            cb.on_after_optimizer_step(self)\n\n    def on_before_validating_algorithm_on_all_tasks_callbacks(self):\n        for cb in self.callbacks:\n            cb.on_before_validating_algorithm_on_all_tasks(self)\n\n    def on_after_validating_algorithm_on_all_tasks_callbacks(self):\n        for cb in self.callbacks:\n            cb.on_after_validating_algorithm_on_all_tasks(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_backward_callbacks","title":"<code>on_after_backward_callbacks()</code>","text":"<p>Callbacks after backpropagation.</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_after_backward_callbacks(self):\n\"\"\"Callbacks after backpropagation.\"\"\"\n    for cb in self.callbacks:\n        cb.on_after_backward(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_fit_callbacks","title":"<code>on_after_fit_callbacks()</code>","text":"<p>Callbacks after fitting the data.</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_after_fit_callbacks(self):\n\"\"\"Callbacks after fitting the data.\"\"\"\n    for cb in self.callbacks:\n        cb.on_after_fit(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_optimizer_step_callbacks","title":"<code>on_after_optimizer_step_callbacks()</code>","text":"<p>Callbacks after optimizer step.</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_after_optimizer_step_callbacks(self):\n\"\"\"Callbacks after optimizer step.\"\"\"\n    for cb in self.callbacks:\n        cb.on_after_optimizer_step(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_setup_callbacks","title":"<code>on_after_setup_callbacks()</code>","text":"<p>Callbacks after the setup.</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_after_setup_callbacks(self):\n\"\"\"Callbacks after the setup.\"\"\"\n    for cb in self.callbacks:\n        cb.on_after_setup(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_teardown_callbacks","title":"<code>on_after_teardown_callbacks()</code>","text":"<p>Callbacks after the teardown.</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_after_teardown_callbacks(self):\n\"\"\"Callbacks after the teardown.\"\"\"\n    for cb in self.callbacks:\n        cb.on_after_teardown(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_training_epoch_callbacks","title":"<code>on_after_training_epoch_callbacks()</code>","text":"<p>Callbacks after training one epoch.</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_after_training_epoch_callbacks(self):\n\"\"\"Callbacks after training one epoch.\"\"\"\n    for cb in self.callbacks:\n        cb.on_after_training_epoch(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_training_step_callbacks","title":"<code>on_after_training_step_callbacks()</code>","text":"<p>Callbacks after the training step.</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_after_training_step_callbacks(self):\n\"\"\"Callbacks after the training step.\"\"\"\n    for cb in self.callbacks:\n        cb.on_after_training_step(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_training_task_callbacks","title":"<code>on_after_training_task_callbacks()</code>","text":"<p>Callbacks after training a single task.</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_after_training_task_callbacks(self):\n\"\"\"Callbacks after training a single task.\"\"\"\n    for cb in self.callbacks:\n        cb.on_after_training_task(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_val_epoch_callbacks","title":"<code>on_after_val_epoch_callbacks()</code>","text":"<p>Callbacks after validating one epoch.</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_after_val_epoch_callbacks(self):\n\"\"\"Callbacks after validating one epoch.\"\"\"\n    for cb in self.callbacks:\n        cb.on_after_val_epoch(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_after_val_step_callbacks","title":"<code>on_after_val_step_callbacks()</code>","text":"<p>Callbacks after the val step.</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_after_val_step_callbacks(self):\n\"\"\"Callbacks after the val step.\"\"\"\n    for cb in self.callbacks:\n        cb.on_after_val_step(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_backward_callbacks","title":"<code>on_before_backward_callbacks()</code>","text":"<p>Callbacks before backpropagation.</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_before_backward_callbacks(self):\n\"\"\"Callbacks before backpropagation.\"\"\"\n    for cb in self.callbacks:\n        cb.on_before_backward(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_fit_callbacks","title":"<code>on_before_fit_callbacks()</code>","text":"<p>Callbacks before fitting the data.</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_before_fit_callbacks(self):\n\"\"\"Callbacks before fitting the data.\"\"\"\n    for cb in self.callbacks:\n        cb.on_before_fit(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_optimizer_step_callbacks","title":"<code>on_before_optimizer_step_callbacks()</code>","text":"<p>Callbacks before optimizer step.</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_before_optimizer_step_callbacks(self):\n\"\"\"Callbacks before optimizer step.\"\"\"\n    for cb in self.callbacks:\n        cb.on_before_optimizer_step(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_setup_callbacks","title":"<code>on_before_setup_callbacks()</code>","text":"<p>Callbacks before the setup.</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_before_setup_callbacks(self):\n\"\"\"Callbacks before the setup.\"\"\"\n    for cb in self.callbacks:\n        cb.on_before_setup(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_teardown_callbacks","title":"<code>on_before_teardown_callbacks()</code>","text":"<p>Callbacks before the teardown.</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_before_teardown_callbacks(self):\n\"\"\"Callbacks before the teardown.\"\"\"\n    for cb in self.callbacks:\n        cb.on_before_teardown(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_training_epoch_callbacks","title":"<code>on_before_training_epoch_callbacks()</code>","text":"<p>Callbacks before training one epoch.</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_before_training_epoch_callbacks(self):\n\"\"\"Callbacks before training one epoch.\"\"\"\n    for cb in self.callbacks:\n        cb.on_before_training_epoch(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_training_step_callbacks","title":"<code>on_before_training_step_callbacks()</code>","text":"<p>Callbacks before the training step (single batch step).</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_before_training_step_callbacks(self):\n\"\"\"Callbacks before the training step (single batch step).\"\"\"\n    for cb in self.callbacks:\n        cb.on_before_training_step(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_training_task_callbacks","title":"<code>on_before_training_task_callbacks()</code>","text":"<p>Callbacks before training a single task.</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_before_training_task_callbacks(self):\n\"\"\"Callbacks before training a single task.\"\"\"\n    for cb in self.callbacks:\n        cb.on_before_training_task(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_val_epoch_callbacks","title":"<code>on_before_val_epoch_callbacks()</code>","text":"<p>Callbacks before validating one epoch.</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_before_val_epoch_callbacks(self):\n\"\"\"Callbacks before validating one epoch.\"\"\"\n    for cb in self.callbacks:\n        cb.on_before_val_epoch(self)\n</code></pre>"},{"location":"algos/utils/callback_hooks/#sequel.algos.utils.callback_hooks.BaseCallbackHook.on_before_val_step_callbacks","title":"<code>on_before_val_step_callbacks()</code>","text":"<p>Callbacks before the val step (single batch step).</p> Source code in <code>sequel/algos/utils/callback_hooks.py</code> <pre><code>def on_before_val_step_callbacks(self):\n\"\"\"Callbacks before the val step (single batch step).\"\"\"\n    for cb in self.callbacks:\n        cb.on_before_val_step(self)\n</code></pre>"},{"location":"algos/utils/state_manager/","title":"state_manager","text":""},{"location":"backbones/jax/base/","title":"Base","text":""},{"location":"backbones/jax/base/#sequel.backbones.jax.base_backbone.BaseBackbone","title":"<code>BaseBackbone</code>","text":"<p>         Bases: <code>nn.Module</code></p> <p>Inits the BaseBackbone class. This class defines the Jax base class for neural networks. All models should inherit from this class. Inherits from flax.nn.Module and the BaseCallback class that endows callbacks for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc.</p> <p>Attributes:</p> Name Type Description <code>multihead</code> <code>bool</code> <p>Set to True if the backbone is multi-headed. Defaults to False.</p> <code>classes_per_task</code> <code>Optional[int]</code> <p>The number of classes per task. Defaults to None.</p> <code>masking_value</code> <code>float</code> <p>The value that replaces the logits. Only used if multihead is set to True. Defaults to -10e10.</p> Note <p>Currently, the BaseBackbone only considers tasks with equal number of classes.</p> Source code in <code>sequel/backbones/jax/base_backbone.py</code> <pre><code>class BaseBackbone(nn.Module):\n\"\"\"Inits the BaseBackbone class. This class defines the Jax base class for neural networks. All models\n    should inherit from this class. Inherits from flax.nn.Module and the BaseCallback class that endows callbacks\n    for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc.\n\n    Attributes:\n        multihead (bool, optional): Set to True if the backbone is multi-headed. Defaults to False.\n        classes_per_task (Optional[int], optional): The number of classes per task. Defaults to None.\n        masking_value (float, optional): The value that replaces the logits. Only used if multihead is set to True. Defaults to -10e10.\n\n    Note:\n        Currently, the BaseBackbone only considers tasks with equal number of classes.\n    \"\"\"\n\n    masking_value = -10e10\n    classes_per_task: int\n    multihead: bool\n\n    @nn.compact\n    def __call__(self, x: jnp.ndarray, task_ids: jnp.ndarray, training: bool = True) -&gt; jnp.ndarray:\n        raise NotImplementedError\n\n    def select_output_head(self, x, task_ids):\n        assert self.multihead\n        assert isinstance(x, jnp.ndarray)\n        mask = jnp.ones_like(x)\n        z = jnp.zeros((1, self.classes_per_task))\n        for i, task_id in enumerate(task_ids):\n            task_id = task_id - 1\n            mask = dynamic_update_slice(mask, z, (i, task_id * self.classes_per_task))\n\n        x = jnp.where(mask, other_fun(), x)\n\n        return x\n</code></pre>"},{"location":"backbones/jax/cnn/","title":"CNN","text":""},{"location":"backbones/jax/mlp/","title":"MLP","text":""},{"location":"backbones/pytorch/base/","title":"Base","text":""},{"location":"backbones/pytorch/base/#sequel.backbones.pytorch.base_backbone.BaseBackbone","title":"<code>BaseBackbone</code>","text":"<p>         Bases: <code>nn.Module</code></p> <p>The PyTorch base class for neural networks.</p> <p>Inherits from torch.nn.Module and the BaseCallback class that endows callbacks for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc.</p> Source code in <code>sequel/backbones/pytorch/base_backbone.py</code> <pre><code>class BaseBackbone(nn.Module):\n\"\"\"The PyTorch base class for neural networks.\n\n    Inherits from torch.nn.Module and the BaseCallback class that endows callbacks for each stage of training, e.g.,\n    before and after trainining/validation steps/epochs/tasks etc.\n    \"\"\"\n\n    def __init__(self, multihead: bool = False, classes_per_task: Optional[int] = None, masking_value: float = -10e10):\n\"\"\"Inits the BaseBackbone class. This class defines the PyTorch base class for neural networks. All models\n        should inherit from this class. Inherits from torch.nn.Module and the BaseCallback class that endows callbacks\n        for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc.\n\n        Args:\n            multihead (bool, optional): Set to True if the backbone is multi-headed. Defaults to False.\n            classes_per_task (Optional[int], optional): The number of classes per task. Defaults to None.\n            masking_value (float, optional): The value that replaces the logits. Only used if multihead is set to True. Defaults to -10e10.\n\n        Note:\n            Currently, the BaseBackbone only considers tasks with equal number of classes.\n        \"\"\"\n        super().__init__()\n        self.multihead = multihead\n        logging.info(f\"multihead is set to {self.multihead}\")\n        if self.multihead:\n            assert classes_per_task is not None\n        self.classes_per_task = classes_per_task\n        self.masking_value = masking_value\n\n    def select_output_head(self, x: torch.Tensor, task_ids: torch.Tensor) -&gt; torch.Tensor:\n\"\"\"Utility function in case `multihead=True` that replaces the original logits by a low value so that almost\n        zero probability is given to the corresponding classes.\n\n        Args:\n            x (torch.Tensor): The original logits.\n            task_ids (torch.Tensor): The task id for each sample in the batch.\n\n        Returns:\n            torch.Tensor: the manipulated logits.\n        \"\"\"\n        assert self.multihead\n        assert isinstance(x, torch.Tensor)\n        for i, task_id in enumerate(task_ids):\n            task_id = task_id - 1\n            if isinstance(task_id, torch.Tensor):\n                task_id = task_id.cpu().int().item()\n            start = task_id * self.classes_per_task\n            end = (task_id + 1) * self.classes_per_task\n            x[i, :start].data.fill_(self.masking_value)\n            x[i, end:].data.fill_(self.masking_value)\n        return x\n\n    def forward(self, x: torch.Tensor, task_ids: torch.Tensor) -&gt; torch.Tensor:\n\"\"\"Implements the forward function of the backbone. Models must ovveride this method.\n\n        Example:\n            # perform the forward.\n            x = ...\n            # select the correct output head.\n            if self.multihead:\n                return self.select_output_head(x, task_ids)\n\n        Args:\n            x (torch.Tensor): The batch inputs.\n            task_ids (torch.Tensor): The batch task ids.\n\n        Returns:\n            torch.Tensor: The batch predicitons.\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"backbones/pytorch/base/#sequel.backbones.pytorch.base_backbone.BaseBackbone.__init__","title":"<code>__init__(multihead=False, classes_per_task=None, masking_value=-100000000000.0)</code>","text":"<p>Inits the BaseBackbone class. This class defines the PyTorch base class for neural networks. All models should inherit from this class. Inherits from torch.nn.Module and the BaseCallback class that endows callbacks for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc.</p> <p>Parameters:</p> Name Type Description Default <code>multihead</code> <code>bool</code> <p>Set to True if the backbone is multi-headed. Defaults to False.</p> <code>False</code> <code>classes_per_task</code> <code>Optional[int]</code> <p>The number of classes per task. Defaults to None.</p> <code>None</code> <code>masking_value</code> <code>float</code> <p>The value that replaces the logits. Only used if multihead is set to True. Defaults to -10e10.</p> <code>-100000000000.0</code> Note <p>Currently, the BaseBackbone only considers tasks with equal number of classes.</p> Source code in <code>sequel/backbones/pytorch/base_backbone.py</code> <pre><code>def __init__(self, multihead: bool = False, classes_per_task: Optional[int] = None, masking_value: float = -10e10):\n\"\"\"Inits the BaseBackbone class. This class defines the PyTorch base class for neural networks. All models\n    should inherit from this class. Inherits from torch.nn.Module and the BaseCallback class that endows callbacks\n    for each stage of training, e.g., before and after trainining/validation steps/epochs/tasks etc.\n\n    Args:\n        multihead (bool, optional): Set to True if the backbone is multi-headed. Defaults to False.\n        classes_per_task (Optional[int], optional): The number of classes per task. Defaults to None.\n        masking_value (float, optional): The value that replaces the logits. Only used if multihead is set to True. Defaults to -10e10.\n\n    Note:\n        Currently, the BaseBackbone only considers tasks with equal number of classes.\n    \"\"\"\n    super().__init__()\n    self.multihead = multihead\n    logging.info(f\"multihead is set to {self.multihead}\")\n    if self.multihead:\n        assert classes_per_task is not None\n    self.classes_per_task = classes_per_task\n    self.masking_value = masking_value\n</code></pre>"},{"location":"backbones/pytorch/base/#sequel.backbones.pytorch.base_backbone.BaseBackbone.forward","title":"<code>forward(x, task_ids)</code>","text":"<p>Implements the forward function of the backbone. Models must ovveride this method.</p> Example <p>Parameters:</p> Name Type Description Default <code>x</code> <code>torch.Tensor</code> <p>The batch inputs.</p> required <code>task_ids</code> <code>torch.Tensor</code> <p>The batch task ids.</p> required <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>torch.Tensor: The batch predicitons.</p> Source code in <code>sequel/backbones/pytorch/base_backbone.py</code> <pre><code>def forward(self, x: torch.Tensor, task_ids: torch.Tensor) -&gt; torch.Tensor:\n\"\"\"Implements the forward function of the backbone. Models must ovveride this method.\n\n    Example:\n        # perform the forward.\n        x = ...\n        # select the correct output head.\n        if self.multihead:\n            return self.select_output_head(x, task_ids)\n\n    Args:\n        x (torch.Tensor): The batch inputs.\n        task_ids (torch.Tensor): The batch task ids.\n\n    Returns:\n        torch.Tensor: The batch predicitons.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"backbones/pytorch/base/#sequel.backbones.pytorch.base_backbone.BaseBackbone.forward--perform-the-forward","title":"perform the forward.","text":"<p>x = ...</p>"},{"location":"backbones/pytorch/base/#sequel.backbones.pytorch.base_backbone.BaseBackbone.forward--select-the-correct-output-head","title":"select the correct output head.","text":"<p>if self.multihead:     return self.select_output_head(x, task_ids)</p>"},{"location":"backbones/pytorch/base/#sequel.backbones.pytorch.base_backbone.BaseBackbone.select_output_head","title":"<code>select_output_head(x, task_ids)</code>","text":"<p>Utility function in case <code>multihead=True</code> that replaces the original logits by a low value so that almost zero probability is given to the corresponding classes.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>torch.Tensor</code> <p>The original logits.</p> required <code>task_ids</code> <code>torch.Tensor</code> <p>The task id for each sample in the batch.</p> required <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>torch.Tensor: the manipulated logits.</p> Source code in <code>sequel/backbones/pytorch/base_backbone.py</code> <pre><code>def select_output_head(self, x: torch.Tensor, task_ids: torch.Tensor) -&gt; torch.Tensor:\n\"\"\"Utility function in case `multihead=True` that replaces the original logits by a low value so that almost\n    zero probability is given to the corresponding classes.\n\n    Args:\n        x (torch.Tensor): The original logits.\n        task_ids (torch.Tensor): The task id for each sample in the batch.\n\n    Returns:\n        torch.Tensor: the manipulated logits.\n    \"\"\"\n    assert self.multihead\n    assert isinstance(x, torch.Tensor)\n    for i, task_id in enumerate(task_ids):\n        task_id = task_id - 1\n        if isinstance(task_id, torch.Tensor):\n            task_id = task_id.cpu().int().item()\n        start = task_id * self.classes_per_task\n        end = (task_id + 1) * self.classes_per_task\n        x[i, :start].data.fill_(self.masking_value)\n        x[i, end:].data.fill_(self.masking_value)\n    return x\n</code></pre>"},{"location":"backbones/pytorch/cnn/","title":"CNN","text":""},{"location":"backbones/pytorch/cnn/#sequel.backbones.pytorch.cnn.CNN","title":"<code>CNN</code>","text":"<p>         Bases: <code>BaseBackbone</code></p> Source code in <code>sequel/backbones/pytorch/cnn.py</code> <pre><code>class CNN(BaseBackbone):\n    def __init__(\n        self,\n        channels: List[int],\n        linear_layers: Optional[Union[List, int]] = None,\n        num_classes: int = 10,\n        multiplier: int = 1,\n        kernel_size: int = 3,\n        activation=\"relu\",\n        stride: int = 2,\n        use_maxpool: bool = False,\n    ) -&gt; None:\n\"\"\"Inits the CNN backbone.\n\n        Args:\n            channels (int): The number if in channels.\n            linear_layers (Optional[Union[List, int]], optional): The linear layers' widths. These linear layers suceed\n                the convolutional layers. If set to None, no linear layers are used except the output layer, whose\n                width is defined by `num_classes`. Defaults to None.\n            num_classes (int, optional): The number of output logits. Defaults to 10.\n            multiplier (int, optional): Multiplies the number of channels for all layers,\n                making the model wider. Defaults to 1.\n            kernel_size (int, optional): The kernel size of the convolutions. Currenrly all convolutions\n                have the share kernel size. Defaults to 3.\n            activation (str, optional): The type of activation used. Defaults to \"relu\".\n            stride (int, optional): The convolutional stride. Defaults to 2.\n            use_maxpool (bool, optional): If set, the model uses maxpool layers. Defaults to False.\n\n        Raises:\n            ValueError: If stride is not equal to 1 or 2.\n            ValueError: If maxpool and stride of 2 are used at the same time.\n            ValueError: If `num_classes` is not a positive integer.\n        \"\"\"\n        super().__init__()\n        if not (stride == 1 or stride == 2):\n            raise ValueError(\"Only strides of 1 or 2 are supported.\")\n        if int(stride == 2) + int(use_maxpool) != 1:\n            raise ValueError(\"You cannot use a stride of 2 and maxpool concurrently!\")\n        if not isinstance(num_classes, int) and num_classes &lt; 1:\n            raise ValueError(\"The number of output classes must be positive integer.\")\n\n        warnings.warn(\"The CNN class does not include Batch Normalization.\")\n        self.num_classes = num_classes\n\n        self.multiplier = multiplier\n        self.kernel_size = kernel_size\n        self.activation = activation\n\n        if linear_layers is not None:\n            self.linear_layers = linear_layers if isinstance(linear_layers, list) else [linear_layers]\n        else:\n            self.linear_layers = []\n\n        # multiply number of channels\n        self.channels = [c * multiplier for c in channels]\n\n        # construct convolutional encoder layers\n        layers = []\n        for i, c in enumerate(self.channels):\n            layers.append(nn.LazyConv2d(c, kernel_size=kernel_size, stride=stride, padding=1))\n            layers.append(ACTIVATION_MAP[activation])\n            if use_maxpool:\n                layers.append(nn.MaxPool2d(kernel_size=2))\n\n        layers.append(nn.Flatten())\n        # construct fully-connected layers\n        for feats in self.linear_layers:\n            layers.append(nn.LazyLinear(feats))\n            layers.append(ACTIVATION_MAP[activation])\n        self.encoder = nn.Sequential(*layers)\n\n        self.classifier = nn.LazyLinear(num_classes)\n\n    def forward(self, x: torch.Tensor, task_ids: Optional[torch.Tensor] = None) -&gt; torch.Tensor:\n        x = self.encoder(x)\n        x = self.classifier(x)\n        if self.multihead:\n            x = self.select_output_head(x, task_ids=task_ids)\n        return x\n\n    @classmethod\n    def from_config(cls, config: omegaconf.ListConfig):\n        linear_layers = config.backbone.linear_layers\n        channels = config.backbone.channels\n        multiplier = getattr(config.backbone, \"multiplier\", 1)\n        kernel_size = getattr(config.backbone, \"kernel_size\", 3)\n        activation = getattr(config.backbone, \"activation\", \"relu\")\n        stride = getattr(config.backbone, \"stride\", 2)\n        use_maxpool = getattr(config.backbone, \"use_maxpool\", False)\n\n        return cls(\n            linear_layers=linear_layers,\n            channels=channels,\n            multiplier=multiplier,\n            kernel_size=kernel_size,\n            activation=activation,\n            stride=stride,\n            use_maxpool=use_maxpool,\n        )\n</code></pre>"},{"location":"backbones/pytorch/cnn/#sequel.backbones.pytorch.cnn.CNN.__init__","title":"<code>__init__(channels, linear_layers=None, num_classes=10, multiplier=1, kernel_size=3, activation='relu', stride=2, use_maxpool=False)</code>","text":"<p>Inits the CNN backbone.</p> <p>Parameters:</p> Name Type Description Default <code>channels</code> <code>int</code> <p>The number if in channels.</p> required <code>linear_layers</code> <code>Optional[Union[List, int]]</code> <p>The linear layers' widths. These linear layers suceed the convolutional layers. If set to None, no linear layers are used except the output layer, whose width is defined by <code>num_classes</code>. Defaults to None.</p> <code>None</code> <code>num_classes</code> <code>int</code> <p>The number of output logits. Defaults to 10.</p> <code>10</code> <code>multiplier</code> <code>int</code> <p>Multiplies the number of channels for all layers, making the model wider. Defaults to 1.</p> <code>1</code> <code>kernel_size</code> <code>int</code> <p>The kernel size of the convolutions. Currenrly all convolutions have the share kernel size. Defaults to 3.</p> <code>3</code> <code>activation</code> <code>str</code> <p>The type of activation used. Defaults to \"relu\".</p> <code>'relu'</code> <code>stride</code> <code>int</code> <p>The convolutional stride. Defaults to 2.</p> <code>2</code> <code>use_maxpool</code> <code>bool</code> <p>If set, the model uses maxpool layers. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If stride is not equal to 1 or 2.</p> <code>ValueError</code> <p>If maxpool and stride of 2 are used at the same time.</p> <code>ValueError</code> <p>If <code>num_classes</code> is not a positive integer.</p> Source code in <code>sequel/backbones/pytorch/cnn.py</code> <pre><code>def __init__(\n    self,\n    channels: List[int],\n    linear_layers: Optional[Union[List, int]] = None,\n    num_classes: int = 10,\n    multiplier: int = 1,\n    kernel_size: int = 3,\n    activation=\"relu\",\n    stride: int = 2,\n    use_maxpool: bool = False,\n) -&gt; None:\n\"\"\"Inits the CNN backbone.\n\n    Args:\n        channels (int): The number if in channels.\n        linear_layers (Optional[Union[List, int]], optional): The linear layers' widths. These linear layers suceed\n            the convolutional layers. If set to None, no linear layers are used except the output layer, whose\n            width is defined by `num_classes`. Defaults to None.\n        num_classes (int, optional): The number of output logits. Defaults to 10.\n        multiplier (int, optional): Multiplies the number of channels for all layers,\n            making the model wider. Defaults to 1.\n        kernel_size (int, optional): The kernel size of the convolutions. Currenrly all convolutions\n            have the share kernel size. Defaults to 3.\n        activation (str, optional): The type of activation used. Defaults to \"relu\".\n        stride (int, optional): The convolutional stride. Defaults to 2.\n        use_maxpool (bool, optional): If set, the model uses maxpool layers. Defaults to False.\n\n    Raises:\n        ValueError: If stride is not equal to 1 or 2.\n        ValueError: If maxpool and stride of 2 are used at the same time.\n        ValueError: If `num_classes` is not a positive integer.\n    \"\"\"\n    super().__init__()\n    if not (stride == 1 or stride == 2):\n        raise ValueError(\"Only strides of 1 or 2 are supported.\")\n    if int(stride == 2) + int(use_maxpool) != 1:\n        raise ValueError(\"You cannot use a stride of 2 and maxpool concurrently!\")\n    if not isinstance(num_classes, int) and num_classes &lt; 1:\n        raise ValueError(\"The number of output classes must be positive integer.\")\n\n    warnings.warn(\"The CNN class does not include Batch Normalization.\")\n    self.num_classes = num_classes\n\n    self.multiplier = multiplier\n    self.kernel_size = kernel_size\n    self.activation = activation\n\n    if linear_layers is not None:\n        self.linear_layers = linear_layers if isinstance(linear_layers, list) else [linear_layers]\n    else:\n        self.linear_layers = []\n\n    # multiply number of channels\n    self.channels = [c * multiplier for c in channels]\n\n    # construct convolutional encoder layers\n    layers = []\n    for i, c in enumerate(self.channels):\n        layers.append(nn.LazyConv2d(c, kernel_size=kernel_size, stride=stride, padding=1))\n        layers.append(ACTIVATION_MAP[activation])\n        if use_maxpool:\n            layers.append(nn.MaxPool2d(kernel_size=2))\n\n    layers.append(nn.Flatten())\n    # construct fully-connected layers\n    for feats in self.linear_layers:\n        layers.append(nn.LazyLinear(feats))\n        layers.append(ACTIVATION_MAP[activation])\n    self.encoder = nn.Sequential(*layers)\n\n    self.classifier = nn.LazyLinear(num_classes)\n</code></pre>"},{"location":"backbones/pytorch/cnn/#sequel.backbones.pytorch.cnn.get_model_output_features","title":"<code>get_model_output_features(config, model)</code>","text":"<p>Calculates the output dimension of a model. This method is used to infer he number of out features of an encoder, which serve as <code>in_features</code> of the decoders (task-specific layers).</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>omegaconf.ListConfig</code> <p>The hydra config for the current experiment.</p> required <code>model</code> <code>torch.nn.Module</code> <p>The PyTorch model (the encoder of the Shared-Bottom architecture.)</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of out_features of the model.</p> Source code in <code>sequel/backbones/pytorch/cnn.py</code> <pre><code>def get_model_output_features(config: omegaconf.ListConfig, model: torch.nn.Module) -&gt; int:\n\"\"\"Calculates the output dimension of a model. This method is used to infer he number of out features of an\n    encoder, which serve as `in_features` of the decoders (task-specific layers).\n\n    Args:\n        config (omegaconf.ListConfig): The hydra config for the current experiment.\n        model (torch.nn.Module): The PyTorch model (the encoder of the Shared-Bottom architecture.)\n\n    Returns:\n        int: The number of out_features of the model.\n    \"\"\"\n    c = getattr(config.benchmark, \"channels\", 1)\n    h, w = getattr(config.benchmark, \"dimensions\")\n\n    # generate a random sample.\n    x = torch.rand(1, c, h, w)\n    with torch.no_grad():\n        x = model(x)\n    assert x.dim() == 2\n    return x.size(1)\n</code></pre>"},{"location":"backbones/pytorch/mlp/","title":"MLP","text":""},{"location":"backbones/pytorch/mlp/#sequel.backbones.pytorch.mlp.MLP","title":"<code>MLP</code>","text":"<p>         Bases: <code>BaseBackbone</code></p> Source code in <code>sequel/backbones/pytorch/mlp.py</code> <pre><code>class MLP(BaseBackbone):\n    def __init__(\n        self,\n        width: int,\n        n_hidden_layers: int,\n        dropout: Optional[float] = None,\n        num_classes: int = 10,\n        *args,\n        **kwargs,\n    ) -&gt; None:\n\"\"\"A Multi-Layer Peceptron of `n_hidden_layers`, each of which has `width` neurons. This class is used as the\n        encoder for the SharedBottom architecture.\n\n        Args:\n            n_hidden_layers (int): Number of hidden layers\n            width (int): Width of (all) hidden layers\n            dropout (Optional[float], optional): If set, the model includes a dropout layer after\n                every Linear with probability equal to the set value. Defaults to None.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self.widths = width\n        self.num_classes = num_classes\n        self.n_hidden_layers = n_hidden_layers\n        layers = [nn.Flatten()]\n        for w in range(n_hidden_layers):\n            layers.append(nn.LazyLinear(width))\n            layers.append(nn.ReLU(inplace=True))\n            if dropout:\n                layers.append(nn.Dropout(p=dropout))\n\n        self.encoder = nn.Sequential(*layers)\n        self.classifier = nn.LazyLinear(self.num_classes)\n\n    def forward(self, x: torch.Tensor, task_ids: Optional[torch.Tensor] = None) -&gt; torch.Tensor:\n        x = self.encoder(x)\n        x = self.classifier(x)\n        if self.multihead:\n            x = self.select_output_head(x, task_ids)\n        return x\n\n    @classmethod\n    def from_config(cls, config: omegaconf.ListConfig) -&gt; BaseBackbone:\n        n_hidden_layers = config.backbone.n_hidden_layers\n        width = config.backbone.width\n        dropout = getattr(config.backbone, \"dropout\", None)\n        num_classes = getattr(config.backbone, \"num_classes\", 10)\n\n        return cls(\n            widths=n_hidden_layers,\n            width=width,\n            dropout=dropout,\n            num_classes=num_classes,\n        )\n</code></pre>"},{"location":"backbones/pytorch/mlp/#sequel.backbones.pytorch.mlp.MLP.__init__","title":"<code>__init__(width, n_hidden_layers, dropout=None, num_classes=10, *args, **kwargs)</code>","text":"<p>A Multi-Layer Peceptron of <code>n_hidden_layers</code>, each of which has <code>width</code> neurons. This class is used as the encoder for the SharedBottom architecture.</p> <p>Parameters:</p> Name Type Description Default <code>n_hidden_layers</code> <code>int</code> <p>Number of hidden layers</p> required <code>width</code> <code>int</code> <p>Width of (all) hidden layers</p> required <code>dropout</code> <code>Optional[float]</code> <p>If set, the model includes a dropout layer after every Linear with probability equal to the set value. Defaults to None.</p> <code>None</code> Source code in <code>sequel/backbones/pytorch/mlp.py</code> <pre><code>def __init__(\n    self,\n    width: int,\n    n_hidden_layers: int,\n    dropout: Optional[float] = None,\n    num_classes: int = 10,\n    *args,\n    **kwargs,\n) -&gt; None:\n\"\"\"A Multi-Layer Peceptron of `n_hidden_layers`, each of which has `width` neurons. This class is used as the\n    encoder for the SharedBottom architecture.\n\n    Args:\n        n_hidden_layers (int): Number of hidden layers\n        width (int): Width of (all) hidden layers\n        dropout (Optional[float], optional): If set, the model includes a dropout layer after\n            every Linear with probability equal to the set value. Defaults to None.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n    self.widths = width\n    self.num_classes = num_classes\n    self.n_hidden_layers = n_hidden_layers\n    layers = [nn.Flatten()]\n    for w in range(n_hidden_layers):\n        layers.append(nn.LazyLinear(width))\n        layers.append(nn.ReLU(inplace=True))\n        if dropout:\n            layers.append(nn.Dropout(p=dropout))\n\n    self.encoder = nn.Sequential(*layers)\n    self.classifier = nn.LazyLinear(self.num_classes)\n</code></pre>"},{"location":"backbones/pytorch/resnet/","title":"ResNet","text":""},{"location":"backbones/pytorch/resnet/#sequel.backbones.pytorch.resnet.ResNet","title":"<code>ResNet</code>","text":"<p>         Bases: <code>BaseBackbone</code></p> <p>ResNet18 backbone with the number of features as an arguments. For <code>nf=20</code>, the ResNet has 1/3 of the features of the original. Code adapted from:     1.  https://github.com/facebookresearch/GradientEpisodicMemory     2.  https://worksheets.codalab.org/rest/bundles/0xaf60b5ed6a4a44c89d296aae9bc6a0f1/contents/blob/models.py</p> Source code in <code>sequel/backbones/pytorch/resnet.py</code> <pre><code>class ResNet(BaseBackbone):\n\"\"\"ResNet18 backbone with the number of features as an arguments. For `nf=20`, the ResNet has 1/3 of the features\n    of the original. Code adapted from:\n        1.  https://github.com/facebookresearch/GradientEpisodicMemory\n        2.  https://worksheets.codalab.org/rest/bundles/0xaf60b5ed6a4a44c89d296aae9bc6a0f1/contents/blob/models.py\n    \"\"\"\n\n    def __init__(self, block, num_blocks, num_classes, nf=20, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.encoder = ResNetEncoder(block, num_blocks, num_classes, nf)\n        self.classifier = nn.Linear(nf * 8 * block.expansion, num_classes)\n\n    def forward(self, inp: torch.Tensor, head_ids: Optional[Iterable] = None):\n        out = self.encoder(inp)\n        out = self.classifier(out)\n\n        if self.multihead:\n            out = self.select_output_head(out, head_ids)\n        return out\n</code></pre>"},{"location":"benchmarks/base_benchmark/","title":"base_benchmark","text":""},{"location":"benchmarks/base_benchmark/#sequel.benchmarks.base_benchmark.Benchmark","title":"<code>Benchmark</code>","text":"<p>Base class for Continual Learning datasets (called benchmarks).</p> <p>All benchmarks (e.g. PermutedMNIST, SplitCifar100 etc) inherit from this class. It implements basic dataset and memory handling, such as splitting the original dataset into task datasets (train+val), constructing dataloaders which include one or multiple task datasets, dataloaders only for memory samples, dataloaders for one or multiple task datasets augmented with memory samples and more!</p> Source code in <code>sequel/benchmarks/base_benchmark.py</code> <pre><code>class Benchmark:\n\"\"\"Base class for Continual Learning datasets (called benchmarks).\n\n    All benchmarks (e.g. PermutedMNIST, SplitCifar100 etc) inherit from this class. It implements basic dataset and\n    memory handling, such as splitting the original dataset into task datasets (train+val), constructing dataloaders\n    which include one or multiple task datasets, dataloaders only for memory samples, dataloaders for one or multiple\n    task datasets augmented with memory samples and more!\n    \"\"\"\n\n    @staticmethod\n    def get_default_kwargs(config: omegaconf.ListConfig) -&gt; dict:\n\"\"\"Utility function that covers the standard arguments for the construction of a benchmark. Used implicilty by\n        benchmark selectors.\n\n        Args:\n            config (omegaconf.ListConfig): The user-specified experiment configuration.\n\n        Returns:\n            dict: a dictionary with argument key and value pairs for the construction of the benchmark.\n        \"\"\"\n        kwargs = {}\n        kwargs[\"num_tasks\"] = config.num_tasks\n        kwargs[\"batch_size\"] = config.batch_size\n        kwargs[\"eval_batch_size\"] = getattr(config, \"eval_batch_size\", None)\n        kwargs[\"num_workers\"] = getattr(config, \"num_workers\", 2)\n        kwargs[\"pin_memory\"] = getattr(config, \"pin_memory\", True)\n        kwargs[\"subset\"] = getattr(config, \"subset\", None)\n\n        return kwargs\n\n    @property\n    def dimensions(self) -&gt; List[int]:\n        raise NotImplementedError\n\n    @property\n    def num_classes(self) -&gt; int:\n        raise NotImplementedError\n\n    def __init__(\n        self,\n        num_tasks: int,\n        batch_size: int,\n        eval_batch_size: int = None,\n        num_workers: int = 0,\n        pin_memory: bool = True,\n        subset: Optional[int] = None,\n    ):\n\"\"\"Inits the base Benchmark class.\n\n        Args:\n            num_tasks (int): the number of tasks in the benchmark.\n            batch_size (int, optional): The train dataloader batch size. Defaults to 256.\n            eval_batch_size (int, optional): The validation dataloader batch size. If None, `eval_batch_size` is set to\n                `batch_size`. Defaults to None.\n            num_workers (int, optional): Dataloader number of workers. Defaults to 0.\n            pin_memory (bool, optional): pin_memory argument for dataloaders. Defaults to True.\n        \"\"\"\n\n        self.num_tasks = num_tasks\n\n        # dataloader arguments\n        self.batch_size = batch_size\n        self.eval_batch_size = eval_batch_size if eval_batch_size is not None else batch_size\n        self.num_workers = num_workers\n        self.pin_memory = pin_memory\n        self.subset = subset\n        self.dl_kwargs = dict(pin_memory=pin_memory, num_workers=num_workers)\n\n        # set up\n        self.trains, self.tests = self.prepare_datasets()\n        self.memory_indices = {}\n\n        if subset is not None:\n            logging.info(\"Setting up the subset indices.\")\n            assert isinstance(subset, int) and subset &gt; 0\n            self.subset_indices = {}\n            for k, v in self.trains.items():\n                indices = list(range(len(v)))\n                random.shuffle(indices)\n                self.subset_indices[k] = indices[:subset]\n\n    def __check_valid_task__(self, task: int):\n        if task &gt; self.num_tasks:\n            raise ValueError(f\"Asked to load task {task} but the benchmark has {self.num_tasks} tasks\")\n\n    @classmethod\n    def from_config(cls, config: omegaconf.OmegaConf, *args, **kwargs):\n        raise NotImplementedError\n\n    def prepare_datasets(self) -&gt; Tuple[ContinualDataset, ContinualDataset]:\n        raise NotImplementedError\n\n    def get_memory_indices(self, task: int) -&gt; torch.Tensor:\n        return self.memory_indices[task]\n\n    def set_memory_indices(self, task: int, indices: List[int]) -&gt; None:\n        self.memory_indices[task] = indices\n\n    def get_train_dataset(self, task: int) -&gt; ContinualDataset:\n        return self.trains[task]\n\n    def get_test_dataset(self, task: int) -&gt; ContinualDataset:\n        return self.tests[task]\n\n    def get_memories(self, task: int) -&gt; ContinualConcatDataset:\n\"\"\"Returns a `ContinualConcatDataset` containing all the memory samples for tasks up to `task`.\n\n        Args:\n            task (int): The current task. The final dataset consists of all memory samples up to the specified id.\n\n        Returns:\n            ContinualConcatDataset: The constructed concatenated dataset.\n        \"\"\"\n        self.__check_valid_task__(task)\n        memories = [\n            ContinualSubsetDataset(self.get_train_dataset(t), self.memory_indices[t]) for t in range(1, task + 1)\n        ]\n        return ContinualConcatDataset(memories)\n\n    def train_dataloader(self, task: int, batch_size: Optional[int] = None) -&gt; DataLoader:\n\"\"\"Constructs the train dataloader for the current task.\n\n        Args:\n            task (int): the current task id\n            batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the\n                benchmark batch size is used. Defaults to None.\n\n        Returns:\n            DataLoader: the constructed DataLoader\n        \"\"\"\n        self.__check_valid_task__(task)\n\n        if batch_size is None:\n            batch_size = self.batch_size\n\n        dataset = self.get_train_dataset(task)\n        if self.subset:\n            indices = self.subset_indices[task]\n            logging.info(f\"Extracting subset [{len(indices)}/{len(dataset)} samples] for train dataset of task {task}\")\n            dataset = ContinualSubsetDataset(dataset, indices)\n        return DataLoader(dataset, batch_size, shuffle=True, **self.dl_kwargs)\n\n    def val_dataloader(self, task: int, batch_size: Optional[int] = None) -&gt; DataLoader:\n\"\"\"Constructs the val dataloader for the current task.\n\n        Args:\n            task (int): the current task id\n            batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the\n                benchmark batch size is used. Defaults to None.\n\n        Returns:\n            DataLoader: the constructed DataLoader\n        \"\"\"\n        self.__check_valid_task__(task)\n\n        if batch_size is None:\n            batch_size = self.eval_batch_size\n\n        dataset = self.get_test_dataset(task)\n        return DataLoader(dataset, batch_size, **self.dl_kwargs)\n\n    def train_dataloader_subset(\n        self, task: int, subset_size: Optional[int] = None, batch_size: Optional[int] = None\n    ) -&gt; DataLoader:\n\"\"\"Constructs a dataloader containing a random subset from the dataset indexed by id `task`.\n\n        Args:\n            task (int): the dataset task id.\n            batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the\n                benchmark batch size is used. Defaults to None.\n\n        Returns:\n            DataLoader: the constructed dataloader.\n        \"\"\"\n\n        self.__check_valid_task__(task)\n\n        if batch_size is None:\n            batch_size = self.batch_size\n\n        if subset_size is None:\n            assert self.subset is not None\n            subset_size = self.subset\n\n        train_dataset = self.get_train_dataset(task)\n        indices = torch.randperm(len(train_dataset))[:subset_size]\n        # sampler = RandomSampler(train_dataset, replacement=True, num_samples=subset_size)\n        train_dataset = ContinualSubsetDataset(train_dataset, indices=indices)\n        return DataLoader(train_dataset, batch_size, **self.dl_kwargs)\n\n    def train_dataloader_joint(self, task: int, batch_size: Optional[int] = None) -&gt; DataLoader:\n\"\"\"Constructs the train dataloader for the current task.\n\n        Args:\n            task (int): the current task id\n            batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the\n                benchmark batch size is used. Defaults to None.\n\n        Returns:\n            DataLoader: the constructed DataLoader\n        \"\"\"\n        self.__check_valid_task__(task)\n\n        if batch_size is None:\n            batch_size = self.batch_size\n\n        dataset = ContinualConcatDataset([self.get_train_dataset(t) for t in range(1, task + 1)])\n        return DataLoader(dataset, batch_size, shuffle=True, **self.dl_kwargs)\n\n    def memory_dataloader(\n        self, task: int, batch_size: Optional[int] = None, return_infinite_stream: bool = True\n    ) -&gt; DataLoader:\n        self.__check_valid_task__(task)\n        dataset = self.get_memories(task)\n\n        if batch_size is None:\n            batch_size = self.batch_size\n\n        if batch_size &gt; len(dataset):\n            batch_size = len(dataset)\n\n        if return_infinite_stream:\n            sampler = RandomSampler(dataset, replacement=True, num_samples=100**100)\n            return DataLoader(dataset, batch_size, shuffle=False, sampler=sampler, **self.dl_kwargs)\n        else:\n            return DataLoader(dataset, batch_size, shuffle=True, **self.dl_kwargs)\n\n    def train_dataloader_with_memory(\n        self, task: int, batch_size: Optional[int] = None, verbose: bool = False\n    ) -&gt; DataLoader:\n\"\"\"Constructs a dataloader consisting of samples coming from the current task as well as the memory samples for\n        all previous tasks.\n\n        Args:\n            task (int): the current task id\n            batch_size (Optional[int], optional): The dataloader batch size. If set to None, the benchmark batch size is used. Defaults to None.\n            verbose (bool, optional): boolean indicating if the method will print additional information to the console. Defaults to False.\n\n        Returns:\n            Dataloader: the constructed PyTorch dataloader.\n        \"\"\"\n        self.__check_valid_task__(task)\n\n        current_train_dataset = self.get_train_dataset(task)\n        memory = self.get_memories(task)\n        dataset = ContinualConcatDataset([current_train_dataset, memory])\n        if verbose:\n            logging.info(\"Samples of train dataset:\\t{}\".format(len(current_train_dataset)))\n            logging.info(\"Samples of memory:\\t{}\".format(len(memory)))\n            logging.info(\"Samples of overall dataset:\\t{}\".format(len(dataset)))\n\n        if batch_size is None:\n            batch_size = self.batch_size\n        return DataLoader(dataset, batch_size, **self.dl_kwargs)\n</code></pre>"},{"location":"benchmarks/base_benchmark/#sequel.benchmarks.base_benchmark.Benchmark.__init__","title":"<code>__init__(num_tasks, batch_size, eval_batch_size=None, num_workers=0, pin_memory=True, subset=None)</code>","text":"<p>Inits the base Benchmark class.</p> <p>Parameters:</p> Name Type Description Default <code>num_tasks</code> <code>int</code> <p>the number of tasks in the benchmark.</p> required <code>batch_size</code> <code>int</code> <p>The train dataloader batch size. Defaults to 256.</p> required <code>eval_batch_size</code> <code>int</code> <p>The validation dataloader batch size. If None, <code>eval_batch_size</code> is set to <code>batch_size</code>. Defaults to None.</p> <code>None</code> <code>num_workers</code> <code>int</code> <p>Dataloader number of workers. Defaults to 0.</p> <code>0</code> <code>pin_memory</code> <code>bool</code> <p>pin_memory argument for dataloaders. Defaults to True.</p> <code>True</code> Source code in <code>sequel/benchmarks/base_benchmark.py</code> <pre><code>def __init__(\n    self,\n    num_tasks: int,\n    batch_size: int,\n    eval_batch_size: int = None,\n    num_workers: int = 0,\n    pin_memory: bool = True,\n    subset: Optional[int] = None,\n):\n\"\"\"Inits the base Benchmark class.\n\n    Args:\n        num_tasks (int): the number of tasks in the benchmark.\n        batch_size (int, optional): The train dataloader batch size. Defaults to 256.\n        eval_batch_size (int, optional): The validation dataloader batch size. If None, `eval_batch_size` is set to\n            `batch_size`. Defaults to None.\n        num_workers (int, optional): Dataloader number of workers. Defaults to 0.\n        pin_memory (bool, optional): pin_memory argument for dataloaders. Defaults to True.\n    \"\"\"\n\n    self.num_tasks = num_tasks\n\n    # dataloader arguments\n    self.batch_size = batch_size\n    self.eval_batch_size = eval_batch_size if eval_batch_size is not None else batch_size\n    self.num_workers = num_workers\n    self.pin_memory = pin_memory\n    self.subset = subset\n    self.dl_kwargs = dict(pin_memory=pin_memory, num_workers=num_workers)\n\n    # set up\n    self.trains, self.tests = self.prepare_datasets()\n    self.memory_indices = {}\n\n    if subset is not None:\n        logging.info(\"Setting up the subset indices.\")\n        assert isinstance(subset, int) and subset &gt; 0\n        self.subset_indices = {}\n        for k, v in self.trains.items():\n            indices = list(range(len(v)))\n            random.shuffle(indices)\n            self.subset_indices[k] = indices[:subset]\n</code></pre>"},{"location":"benchmarks/base_benchmark/#sequel.benchmarks.base_benchmark.Benchmark.get_default_kwargs","title":"<code>get_default_kwargs(config)</code>  <code>staticmethod</code>","text":"<p>Utility function that covers the standard arguments for the construction of a benchmark. Used implicilty by benchmark selectors.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>omegaconf.ListConfig</code> <p>The user-specified experiment configuration.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>a dictionary with argument key and value pairs for the construction of the benchmark.</p> Source code in <code>sequel/benchmarks/base_benchmark.py</code> <pre><code>@staticmethod\ndef get_default_kwargs(config: omegaconf.ListConfig) -&gt; dict:\n\"\"\"Utility function that covers the standard arguments for the construction of a benchmark. Used implicilty by\n    benchmark selectors.\n\n    Args:\n        config (omegaconf.ListConfig): The user-specified experiment configuration.\n\n    Returns:\n        dict: a dictionary with argument key and value pairs for the construction of the benchmark.\n    \"\"\"\n    kwargs = {}\n    kwargs[\"num_tasks\"] = config.num_tasks\n    kwargs[\"batch_size\"] = config.batch_size\n    kwargs[\"eval_batch_size\"] = getattr(config, \"eval_batch_size\", None)\n    kwargs[\"num_workers\"] = getattr(config, \"num_workers\", 2)\n    kwargs[\"pin_memory\"] = getattr(config, \"pin_memory\", True)\n    kwargs[\"subset\"] = getattr(config, \"subset\", None)\n\n    return kwargs\n</code></pre>"},{"location":"benchmarks/base_benchmark/#sequel.benchmarks.base_benchmark.Benchmark.get_memories","title":"<code>get_memories(task)</code>","text":"<p>Returns a <code>ContinualConcatDataset</code> containing all the memory samples for tasks up to <code>task</code>.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>int</code> <p>The current task. The final dataset consists of all memory samples up to the specified id.</p> required <p>Returns:</p> Name Type Description <code>ContinualConcatDataset</code> <code>ContinualConcatDataset</code> <p>The constructed concatenated dataset.</p> Source code in <code>sequel/benchmarks/base_benchmark.py</code> <pre><code>def get_memories(self, task: int) -&gt; ContinualConcatDataset:\n\"\"\"Returns a `ContinualConcatDataset` containing all the memory samples for tasks up to `task`.\n\n    Args:\n        task (int): The current task. The final dataset consists of all memory samples up to the specified id.\n\n    Returns:\n        ContinualConcatDataset: The constructed concatenated dataset.\n    \"\"\"\n    self.__check_valid_task__(task)\n    memories = [\n        ContinualSubsetDataset(self.get_train_dataset(t), self.memory_indices[t]) for t in range(1, task + 1)\n    ]\n    return ContinualConcatDataset(memories)\n</code></pre>"},{"location":"benchmarks/base_benchmark/#sequel.benchmarks.base_benchmark.Benchmark.train_dataloader","title":"<code>train_dataloader(task, batch_size=None)</code>","text":"<p>Constructs the train dataloader for the current task.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>int</code> <p>the current task id</p> required <code>batch_size</code> <code>Optional[int]</code> <p>The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DataLoader</code> <code>DataLoader</code> <p>the constructed DataLoader</p> Source code in <code>sequel/benchmarks/base_benchmark.py</code> <pre><code>def train_dataloader(self, task: int, batch_size: Optional[int] = None) -&gt; DataLoader:\n\"\"\"Constructs the train dataloader for the current task.\n\n    Args:\n        task (int): the current task id\n        batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the\n            benchmark batch size is used. Defaults to None.\n\n    Returns:\n        DataLoader: the constructed DataLoader\n    \"\"\"\n    self.__check_valid_task__(task)\n\n    if batch_size is None:\n        batch_size = self.batch_size\n\n    dataset = self.get_train_dataset(task)\n    if self.subset:\n        indices = self.subset_indices[task]\n        logging.info(f\"Extracting subset [{len(indices)}/{len(dataset)} samples] for train dataset of task {task}\")\n        dataset = ContinualSubsetDataset(dataset, indices)\n    return DataLoader(dataset, batch_size, shuffle=True, **self.dl_kwargs)\n</code></pre>"},{"location":"benchmarks/base_benchmark/#sequel.benchmarks.base_benchmark.Benchmark.train_dataloader_joint","title":"<code>train_dataloader_joint(task, batch_size=None)</code>","text":"<p>Constructs the train dataloader for the current task.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>int</code> <p>the current task id</p> required <code>batch_size</code> <code>Optional[int]</code> <p>The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DataLoader</code> <code>DataLoader</code> <p>the constructed DataLoader</p> Source code in <code>sequel/benchmarks/base_benchmark.py</code> <pre><code>def train_dataloader_joint(self, task: int, batch_size: Optional[int] = None) -&gt; DataLoader:\n\"\"\"Constructs the train dataloader for the current task.\n\n    Args:\n        task (int): the current task id\n        batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the\n            benchmark batch size is used. Defaults to None.\n\n    Returns:\n        DataLoader: the constructed DataLoader\n    \"\"\"\n    self.__check_valid_task__(task)\n\n    if batch_size is None:\n        batch_size = self.batch_size\n\n    dataset = ContinualConcatDataset([self.get_train_dataset(t) for t in range(1, task + 1)])\n    return DataLoader(dataset, batch_size, shuffle=True, **self.dl_kwargs)\n</code></pre>"},{"location":"benchmarks/base_benchmark/#sequel.benchmarks.base_benchmark.Benchmark.train_dataloader_subset","title":"<code>train_dataloader_subset(task, subset_size=None, batch_size=None)</code>","text":"<p>Constructs a dataloader containing a random subset from the dataset indexed by id <code>task</code>.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>int</code> <p>the dataset task id.</p> required <code>batch_size</code> <code>Optional[int]</code> <p>The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DataLoader</code> <code>DataLoader</code> <p>the constructed dataloader.</p> Source code in <code>sequel/benchmarks/base_benchmark.py</code> <pre><code>def train_dataloader_subset(\n    self, task: int, subset_size: Optional[int] = None, batch_size: Optional[int] = None\n) -&gt; DataLoader:\n\"\"\"Constructs a dataloader containing a random subset from the dataset indexed by id `task`.\n\n    Args:\n        task (int): the dataset task id.\n        batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the\n            benchmark batch size is used. Defaults to None.\n\n    Returns:\n        DataLoader: the constructed dataloader.\n    \"\"\"\n\n    self.__check_valid_task__(task)\n\n    if batch_size is None:\n        batch_size = self.batch_size\n\n    if subset_size is None:\n        assert self.subset is not None\n        subset_size = self.subset\n\n    train_dataset = self.get_train_dataset(task)\n    indices = torch.randperm(len(train_dataset))[:subset_size]\n    # sampler = RandomSampler(train_dataset, replacement=True, num_samples=subset_size)\n    train_dataset = ContinualSubsetDataset(train_dataset, indices=indices)\n    return DataLoader(train_dataset, batch_size, **self.dl_kwargs)\n</code></pre>"},{"location":"benchmarks/base_benchmark/#sequel.benchmarks.base_benchmark.Benchmark.train_dataloader_with_memory","title":"<code>train_dataloader_with_memory(task, batch_size=None, verbose=False)</code>","text":"<p>Constructs a dataloader consisting of samples coming from the current task as well as the memory samples for all previous tasks.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>int</code> <p>the current task id</p> required <code>batch_size</code> <code>Optional[int]</code> <p>The dataloader batch size. If set to None, the benchmark batch size is used. Defaults to None.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>boolean indicating if the method will print additional information to the console. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Dataloader</code> <code>DataLoader</code> <p>the constructed PyTorch dataloader.</p> Source code in <code>sequel/benchmarks/base_benchmark.py</code> <pre><code>def train_dataloader_with_memory(\n    self, task: int, batch_size: Optional[int] = None, verbose: bool = False\n) -&gt; DataLoader:\n\"\"\"Constructs a dataloader consisting of samples coming from the current task as well as the memory samples for\n    all previous tasks.\n\n    Args:\n        task (int): the current task id\n        batch_size (Optional[int], optional): The dataloader batch size. If set to None, the benchmark batch size is used. Defaults to None.\n        verbose (bool, optional): boolean indicating if the method will print additional information to the console. Defaults to False.\n\n    Returns:\n        Dataloader: the constructed PyTorch dataloader.\n    \"\"\"\n    self.__check_valid_task__(task)\n\n    current_train_dataset = self.get_train_dataset(task)\n    memory = self.get_memories(task)\n    dataset = ContinualConcatDataset([current_train_dataset, memory])\n    if verbose:\n        logging.info(\"Samples of train dataset:\\t{}\".format(len(current_train_dataset)))\n        logging.info(\"Samples of memory:\\t{}\".format(len(memory)))\n        logging.info(\"Samples of overall dataset:\\t{}\".format(len(dataset)))\n\n    if batch_size is None:\n        batch_size = self.batch_size\n    return DataLoader(dataset, batch_size, **self.dl_kwargs)\n</code></pre>"},{"location":"benchmarks/base_benchmark/#sequel.benchmarks.base_benchmark.Benchmark.val_dataloader","title":"<code>val_dataloader(task, batch_size=None)</code>","text":"<p>Constructs the val dataloader for the current task.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>int</code> <p>the current task id</p> required <code>batch_size</code> <code>Optional[int]</code> <p>The batch size used for both dataloaders. If set to None, the benchmark batch size is used. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DataLoader</code> <code>DataLoader</code> <p>the constructed DataLoader</p> Source code in <code>sequel/benchmarks/base_benchmark.py</code> <pre><code>def val_dataloader(self, task: int, batch_size: Optional[int] = None) -&gt; DataLoader:\n\"\"\"Constructs the val dataloader for the current task.\n\n    Args:\n        task (int): the current task id\n        batch_size (Optional[int], optional): The batch size used for both dataloaders. If set to None, the\n            benchmark batch size is used. Defaults to None.\n\n    Returns:\n        DataLoader: the constructed DataLoader\n    \"\"\"\n    self.__check_valid_task__(task)\n\n    if batch_size is None:\n        batch_size = self.eval_batch_size\n\n    dataset = self.get_test_dataset(task)\n    return DataLoader(dataset, batch_size, **self.dl_kwargs)\n</code></pre>"},{"location":"benchmarks/cifar/","title":"CIFAR","text":""},{"location":"benchmarks/cifar/#sequel.benchmarks.cifar.SplitCIFAR","title":"<code>SplitCIFAR</code>","text":"<p>         Bases: <code>Benchmark</code></p> <p>SplitCIFAR benchmarks.</p> Source code in <code>sequel/benchmarks/cifar.py</code> <pre><code>class SplitCIFAR(Benchmark):\n\"\"\"SplitCIFAR benchmarks.\"\"\"\n\n    @property\n    def num_classes(self) -&gt; int:\n        return 100 if self.is_cifar_100 else 10\n\n    @property\n    def MEAN(self):\n        if self.is_cifar_100:\n            return CIFAR100_MEAN\n        else:\n            return CIFAR10_MEAN\n\n    @property\n    def STD(self):\n        if self.is_cifar_100:\n            return CIFAR100_STD\n        else:\n            return CIFAR10_STD\n\n    @property\n    def dimensions(self) -&gt; List[int]:\n        return [3, 32, 32]\n\n    @property\n    def num_classes(self):\n        num_classes = 100 if self.is_cifar_100 else 10\n        return num_classes\n\n    @property\n    def classes_per_task(self):\n        assert self.num_classes % self.num_tasks == 0\n        return self.num_classes // self.num_tasks\n\n    def __init__(\n        self,\n        num_tasks: int,\n        batch_size: int,\n        fixed_class_order: Optional[List[int]] = None,\n        is_cifar_100: bool = True,\n        eval_batch_size: int = None,\n        num_workers: int = 0,\n        pin_memory: bool = True,\n        subset: Optional[int] = None,\n    ):\n\"\"\"Inits the SplitCIFAR100/100 class. The `is_cifar100` boolean flag denotes which dataset is instantiated.\n\n        Args:\n            num_tasks (int): the number of tasks in the benchmark. Usually 20 for SplitCIFAR100 and 5 for SplitCIFAR10.\n                Must be divisible by the number of classes.\n            batch_size (int, optional): The train dataloader batch size. Defaults to 256.\n            fixed_class_order (Optional[List[int]], optional): A list of integers denoting a custom fixed_class_order.\n                If None, the alphabetical order is used. Defaults to None.\n            is_cifar_100 (bool, optional): Boolean denoting whether SplitCIFAR100 or SplitCIFAR10 is selected. Defaults\n                to True.\n            eval_batch_size (int, optional): The validation dataloader batch size. If None, `eval_batch_size` is set to\n                `batch_size`. Defaults to None.\n            num_workers (int, optional): Dataloader number of workers. Defaults to 0.\n            pin_memory (bool, optional): pin_memory argument for dataloaders. Defaults to True.\n        \"\"\"\n\n        self.is_cifar_100 = is_cifar_100\n\n        if fixed_class_order is None:\n            fixed_class_order = list(range(self.num_classes))\n        assert (\n            torch.tensor(fixed_class_order).sort()[0] == torch.arange(0, self.num_classes)\n        ).all(), \"The fixed_class_order argument muct contain exactly once all integers from 0 to (num_classes-1).\"\n\n        self.fixed_class_order = fixed_class_order\n        super().__init__(\n            num_tasks=num_tasks,\n            batch_size=batch_size,\n            eval_batch_size=eval_batch_size,\n            num_workers=num_workers,\n            pin_memory=pin_memory,\n            subset=subset,\n        )\n\n    def prepare_datasets(self) -&gt; Tuple[ContinualDataset, ContinualDataset]:\n        transform = T.Compose([T.ToTensor(), T.Normalize(self.MEAN, self.STD)])\n        CIFAR_dataset = torchvision.datasets.CIFAR100 if self.is_cifar_100 else torchvision.datasets.CIFAR10\n        self.cifar_train = CIFAR_dataset(DEFAULT_DATASET_DIR, train=True, download=True, transform=transform)\n        self.cifar_test = CIFAR_dataset(DEFAULT_DATASET_DIR, train=False, download=True, transform=transform)\n\n        self.trains, self.tests = {}, {}\n        for t in range(1, self.num_tasks + 1):\n            self.trains[t] = SplitDataset(t, self.classes_per_task, self.cifar_train, self.fixed_class_order)\n            self.tests[t] = SplitDataset(t, self.classes_per_task, self.cifar_test, self.fixed_class_order)\n\n        return self.trains, self.tests\n\n    @classmethod\n    def from_config(cls, config):\n        # breakpoint()\n        kwargs = cls.get_default_kwargs(config)\n        kwargs[\"is_cifar_100\"] = \"100\" in config.name\n        kwargs[\"fixed_class_order\"] = getattr(config, \"fixed_class_order\", None)\n        return cls(**kwargs)\n\n    def __repr__(self) -&gt; str:\n        return f\"SplitCIFAR{self.num_classes}(num_tasks={self.num_tasks}, batch_size={self.batch_size})\"\n</code></pre>"},{"location":"benchmarks/cifar/#sequel.benchmarks.cifar.SplitCIFAR.__init__","title":"<code>__init__(num_tasks, batch_size, fixed_class_order=None, is_cifar_100=True, eval_batch_size=None, num_workers=0, pin_memory=True, subset=None)</code>","text":"<p>Inits the SplitCIFAR100/100 class. The <code>is_cifar100</code> boolean flag denotes which dataset is instantiated.</p> <p>Parameters:</p> Name Type Description Default <code>num_tasks</code> <code>int</code> <p>the number of tasks in the benchmark. Usually 20 for SplitCIFAR100 and 5 for SplitCIFAR10. Must be divisible by the number of classes.</p> required <code>batch_size</code> <code>int</code> <p>The train dataloader batch size. Defaults to 256.</p> required <code>fixed_class_order</code> <code>Optional[List[int]]</code> <p>A list of integers denoting a custom fixed_class_order. If None, the alphabetical order is used. Defaults to None.</p> <code>None</code> <code>is_cifar_100</code> <code>bool</code> <p>Boolean denoting whether SplitCIFAR100 or SplitCIFAR10 is selected. Defaults to True.</p> <code>True</code> <code>eval_batch_size</code> <code>int</code> <p>The validation dataloader batch size. If None, <code>eval_batch_size</code> is set to <code>batch_size</code>. Defaults to None.</p> <code>None</code> <code>num_workers</code> <code>int</code> <p>Dataloader number of workers. Defaults to 0.</p> <code>0</code> <code>pin_memory</code> <code>bool</code> <p>pin_memory argument for dataloaders. Defaults to True.</p> <code>True</code> Source code in <code>sequel/benchmarks/cifar.py</code> <pre><code>def __init__(\n    self,\n    num_tasks: int,\n    batch_size: int,\n    fixed_class_order: Optional[List[int]] = None,\n    is_cifar_100: bool = True,\n    eval_batch_size: int = None,\n    num_workers: int = 0,\n    pin_memory: bool = True,\n    subset: Optional[int] = None,\n):\n\"\"\"Inits the SplitCIFAR100/100 class. The `is_cifar100` boolean flag denotes which dataset is instantiated.\n\n    Args:\n        num_tasks (int): the number of tasks in the benchmark. Usually 20 for SplitCIFAR100 and 5 for SplitCIFAR10.\n            Must be divisible by the number of classes.\n        batch_size (int, optional): The train dataloader batch size. Defaults to 256.\n        fixed_class_order (Optional[List[int]], optional): A list of integers denoting a custom fixed_class_order.\n            If None, the alphabetical order is used. Defaults to None.\n        is_cifar_100 (bool, optional): Boolean denoting whether SplitCIFAR100 or SplitCIFAR10 is selected. Defaults\n            to True.\n        eval_batch_size (int, optional): The validation dataloader batch size. If None, `eval_batch_size` is set to\n            `batch_size`. Defaults to None.\n        num_workers (int, optional): Dataloader number of workers. Defaults to 0.\n        pin_memory (bool, optional): pin_memory argument for dataloaders. Defaults to True.\n    \"\"\"\n\n    self.is_cifar_100 = is_cifar_100\n\n    if fixed_class_order is None:\n        fixed_class_order = list(range(self.num_classes))\n    assert (\n        torch.tensor(fixed_class_order).sort()[0] == torch.arange(0, self.num_classes)\n    ).all(), \"The fixed_class_order argument muct contain exactly once all integers from 0 to (num_classes-1).\"\n\n    self.fixed_class_order = fixed_class_order\n    super().__init__(\n        num_tasks=num_tasks,\n        batch_size=batch_size,\n        eval_batch_size=eval_batch_size,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        subset=subset,\n    )\n</code></pre>"},{"location":"benchmarks/cifar/#sequel.benchmarks.cifar.SplitCIFAR10","title":"<code>SplitCIFAR10</code>","text":"<p>         Bases: <code>SplitCIFAR</code></p> Source code in <code>sequel/benchmarks/cifar.py</code> <pre><code>class SplitCIFAR10(SplitCIFAR):\n    def __init__(self, is_cifar_100=False, *args, **kwargs):\n\"\"\"Helper class for SplitCIFAR10. Inherits from SplitCIFAR. Look at the parent class for a description of the\n        class arguments.\n\n        Args:\n            is_cifar_100 (bool, optional): Set to False.\n        \"\"\"\n        super().__init__(is_cifar_100=is_cifar_100, *args, **kwargs)\n</code></pre>"},{"location":"benchmarks/cifar/#sequel.benchmarks.cifar.SplitCIFAR10.__init__","title":"<code>__init__(is_cifar_100=False, *args, **kwargs)</code>","text":"<p>Helper class for SplitCIFAR10. Inherits from SplitCIFAR. Look at the parent class for a description of the class arguments.</p> <p>Parameters:</p> Name Type Description Default <code>is_cifar_100</code> <code>bool</code> <p>Set to False.</p> <code>False</code> Source code in <code>sequel/benchmarks/cifar.py</code> <pre><code>def __init__(self, is_cifar_100=False, *args, **kwargs):\n\"\"\"Helper class for SplitCIFAR10. Inherits from SplitCIFAR. Look at the parent class for a description of the\n    class arguments.\n\n    Args:\n        is_cifar_100 (bool, optional): Set to False.\n    \"\"\"\n    super().__init__(is_cifar_100=is_cifar_100, *args, **kwargs)\n</code></pre>"},{"location":"benchmarks/cifar/#sequel.benchmarks.cifar.SplitCIFAR100","title":"<code>SplitCIFAR100</code>","text":"<p>         Bases: <code>SplitCIFAR</code></p> Source code in <code>sequel/benchmarks/cifar.py</code> <pre><code>class SplitCIFAR100(SplitCIFAR):\n    def __init__(self, is_cifar_100=True, *args, **kwargs):\n\"\"\"Helper class for SplitCIFAR100. Inherits from SplitCIFAR. Look at the parent class for a description of the\n        class arguments.\n\n        Args:\n            is_cifar_100 (bool, optional): Set to True.\n        \"\"\"\n        super().__init__(is_cifar_100=is_cifar_100, *args, **kwargs)\n</code></pre>"},{"location":"benchmarks/cifar/#sequel.benchmarks.cifar.SplitCIFAR100.__init__","title":"<code>__init__(is_cifar_100=True, *args, **kwargs)</code>","text":"<p>Helper class for SplitCIFAR100. Inherits from SplitCIFAR. Look at the parent class for a description of the class arguments.</p> <p>Parameters:</p> Name Type Description Default <code>is_cifar_100</code> <code>bool</code> <p>Set to True.</p> <code>True</code> Source code in <code>sequel/benchmarks/cifar.py</code> <pre><code>def __init__(self, is_cifar_100=True, *args, **kwargs):\n\"\"\"Helper class for SplitCIFAR100. Inherits from SplitCIFAR. Look at the parent class for a description of the\n    class arguments.\n\n    Args:\n        is_cifar_100 (bool, optional): Set to True.\n    \"\"\"\n    super().__init__(is_cifar_100=is_cifar_100, *args, **kwargs)\n</code></pre>"},{"location":"benchmarks/memory/","title":"memory","text":""},{"location":"benchmarks/memory/#sequel.benchmarks.memory.MemoryMechanism","title":"<code>MemoryMechanism</code>","text":"<p>Implements the memory handling/manipulation for continual learning algorithms.</p> Source code in <code>sequel/benchmarks/memory.py</code> <pre><code>class MemoryMechanism:\n\"\"\"Implements the memory handling/manipulation for continual learning algorithms.\"\"\"\n\n    def __init__(self, per_task_memory_samples: int, groupby: str = \"class\"):\n        logging.info(\"Initializing MemoryCallback\")\n        self.per_task_memory_samples = per_task_memory_samples\n\n        if groupby not in (\"task\", \"class\"):\n            raise ValueError(\"Only class and task are supported as options for groupby argument.\")\n\n        self.groupby = groupby\n\n    def update_memory(self, algo: \"BaseAlgorithm\"):\n\"\"\"Updates the memory by selecting `per_task_memory_samples` samples from the current dataset. The selection\n        process is defined by the `groupby` instance attribute.\n\n        Args:\n            algo (BaseAlgorithm): the algorithm instance.\n        \"\"\"\n        logging.info(\"Setting memory indices for task {}\".format(algo.task_counter))\n        task = algo.task_counter\n        dataset = algo.benchmark.get_train_dataset(task)\n        if self.groupby == \"class\":\n            memory_indices = MemoryMechanism.sample_uniform_class_indices(dataset, self.per_task_memory_samples)\n        else:\n            memory_indices = MemoryMechanism.sample_uniform_task_indices(dataset, self.per_task_memory_samples)\n        algo.benchmark.set_memory_indices(task, memory_indices)\n\n    def update_memory_(self, benchmark, task):\n\"\"\"Updates the memory by selecting `per_task_memory_samples` samples from the current dataset. The selection\n        process is defined by the `groupby` instance attribute.\n        \"\"\"\n        logging.info(\"Setting memory indices for task {}\".format(task))\n        dataset = benchmark.get_train_dataset(task)\n        if self.groupby == \"class\":\n            memory_indices = MemoryMechanism.sample_uniform_class_indices(dataset, self.per_task_memory_samples)\n        else:\n            memory_indices = MemoryMechanism.sample_uniform_task_indices(dataset, self.per_task_memory_samples)\n        benchmark.set_memory_indices(task, memory_indices)\n\n    @staticmethod\n    def sample_uniform_task_indices(dataset: ContinualDataset, num_samples: int) -&gt; List[int]:\n\"\"\"Selects a specified number of indices uniformly at random.\n\n        Args:\n            dataset (ContinualDataset): The dataset that is sampled.\n            num_samples (int): the number of samples to draw.\n\n        Returns:\n            List[int]: The selected dataset indices.\n        \"\"\"\n        to_remove = len(dataset) - num_samples\n        dataset, _ = random_split(dataset, [num_samples, to_remove])\n        return dataset.indices\n\n    @staticmethod\n    def sample_uniform_class_indices(dataset: ContinualDataset, num_samples: int) -&gt; List[int]:\n\"\"\"Selects an approximately equal (ties broken arbitrarily) number of indices corresponding to each class from\n        the input dataset. Each dataset yields ~num_samples // num_classes samples.\n\n        Args:\n            dataset (ContinualDataset): The dataset that is sampled.\n            num_samples (int): the number of samples to draw.\n\n        Returns:\n            List[int]: The selected dataset indices.\n        \"\"\"\n        target_classes = dataset.targets.clone().detach().numpy()\n        classes = np.unique(target_classes).tolist()\n        num_classes = len(classes)\n        num_examples_per_class = MemoryMechanism.pack_bins_uniformly(num_samples * num_classes, num_classes)\n        class_indices = []\n\n        for class_id, cls_number in enumerate(classes):\n            candidates = np.array([i for i, t in enumerate(target_classes) if t == cls_number])\n            np.random.shuffle(candidates)\n\n            selected_indices = candidates[: num_examples_per_class[class_id]]\n            class_indices += list(selected_indices)\n        return class_indices\n\n    @staticmethod\n    def pack_bins_uniformly(num_samples: int, num_categories: int) -&gt; List[int]:\n\"\"\"Splits an integer to a specified number of bins so that bins have approximately the same size. If\n        `num_categories` is not a divisor of `num_samples`, the reminder is split an equal number of bins selectrd\n        uniformly at random.\n\n        Args:\n            num_samples (int): The number of items.\n            num_categories (int): the number of bins.\n\n        Returns:\n            List[int]: a list containing the number of items corresponding to each bin.\n        \"\"\"\n        num_samples_per_cat = np.ones(num_categories) * num_samples // num_categories\n        remaining = num_samples % num_categories\n        correction_vector = np.array([0] * (num_categories - remaining) + [1] * remaining)\n        np.random.shuffle(correction_vector)\n        num_samples_per_cat += correction_vector\n        return num_samples_per_cat.astype(\"int\").tolist()\n</code></pre>"},{"location":"benchmarks/memory/#sequel.benchmarks.memory.MemoryMechanism.pack_bins_uniformly","title":"<code>pack_bins_uniformly(num_samples, num_categories)</code>  <code>staticmethod</code>","text":"<p>Splits an integer to a specified number of bins so that bins have approximately the same size. If <code>num_categories</code> is not a divisor of <code>num_samples</code>, the reminder is split an equal number of bins selectrd uniformly at random.</p> <p>Parameters:</p> Name Type Description Default <code>num_samples</code> <code>int</code> <p>The number of items.</p> required <code>num_categories</code> <code>int</code> <p>the number of bins.</p> required <p>Returns:</p> Type Description <code>List[int]</code> <p>List[int]: a list containing the number of items corresponding to each bin.</p> Source code in <code>sequel/benchmarks/memory.py</code> <pre><code>@staticmethod\ndef pack_bins_uniformly(num_samples: int, num_categories: int) -&gt; List[int]:\n\"\"\"Splits an integer to a specified number of bins so that bins have approximately the same size. If\n    `num_categories` is not a divisor of `num_samples`, the reminder is split an equal number of bins selectrd\n    uniformly at random.\n\n    Args:\n        num_samples (int): The number of items.\n        num_categories (int): the number of bins.\n\n    Returns:\n        List[int]: a list containing the number of items corresponding to each bin.\n    \"\"\"\n    num_samples_per_cat = np.ones(num_categories) * num_samples // num_categories\n    remaining = num_samples % num_categories\n    correction_vector = np.array([0] * (num_categories - remaining) + [1] * remaining)\n    np.random.shuffle(correction_vector)\n    num_samples_per_cat += correction_vector\n    return num_samples_per_cat.astype(\"int\").tolist()\n</code></pre>"},{"location":"benchmarks/memory/#sequel.benchmarks.memory.MemoryMechanism.sample_uniform_class_indices","title":"<code>sample_uniform_class_indices(dataset, num_samples)</code>  <code>staticmethod</code>","text":"<p>Selects an approximately equal (ties broken arbitrarily) number of indices corresponding to each class from the input dataset. Each dataset yields ~num_samples // num_classes samples.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>ContinualDataset</code> <p>The dataset that is sampled.</p> required <code>num_samples</code> <code>int</code> <p>the number of samples to draw.</p> required <p>Returns:</p> Type Description <code>List[int]</code> <p>List[int]: The selected dataset indices.</p> Source code in <code>sequel/benchmarks/memory.py</code> <pre><code>@staticmethod\ndef sample_uniform_class_indices(dataset: ContinualDataset, num_samples: int) -&gt; List[int]:\n\"\"\"Selects an approximately equal (ties broken arbitrarily) number of indices corresponding to each class from\n    the input dataset. Each dataset yields ~num_samples // num_classes samples.\n\n    Args:\n        dataset (ContinualDataset): The dataset that is sampled.\n        num_samples (int): the number of samples to draw.\n\n    Returns:\n        List[int]: The selected dataset indices.\n    \"\"\"\n    target_classes = dataset.targets.clone().detach().numpy()\n    classes = np.unique(target_classes).tolist()\n    num_classes = len(classes)\n    num_examples_per_class = MemoryMechanism.pack_bins_uniformly(num_samples * num_classes, num_classes)\n    class_indices = []\n\n    for class_id, cls_number in enumerate(classes):\n        candidates = np.array([i for i, t in enumerate(target_classes) if t == cls_number])\n        np.random.shuffle(candidates)\n\n        selected_indices = candidates[: num_examples_per_class[class_id]]\n        class_indices += list(selected_indices)\n    return class_indices\n</code></pre>"},{"location":"benchmarks/memory/#sequel.benchmarks.memory.MemoryMechanism.sample_uniform_task_indices","title":"<code>sample_uniform_task_indices(dataset, num_samples)</code>  <code>staticmethod</code>","text":"<p>Selects a specified number of indices uniformly at random.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>ContinualDataset</code> <p>The dataset that is sampled.</p> required <code>num_samples</code> <code>int</code> <p>the number of samples to draw.</p> required <p>Returns:</p> Type Description <code>List[int]</code> <p>List[int]: The selected dataset indices.</p> Source code in <code>sequel/benchmarks/memory.py</code> <pre><code>@staticmethod\ndef sample_uniform_task_indices(dataset: ContinualDataset, num_samples: int) -&gt; List[int]:\n\"\"\"Selects a specified number of indices uniformly at random.\n\n    Args:\n        dataset (ContinualDataset): The dataset that is sampled.\n        num_samples (int): the number of samples to draw.\n\n    Returns:\n        List[int]: The selected dataset indices.\n    \"\"\"\n    to_remove = len(dataset) - num_samples\n    dataset, _ = random_split(dataset, [num_samples, to_remove])\n    return dataset.indices\n</code></pre>"},{"location":"benchmarks/memory/#sequel.benchmarks.memory.MemoryMechanism.update_memory","title":"<code>update_memory(algo)</code>","text":"<p>Updates the memory by selecting <code>per_task_memory_samples</code> samples from the current dataset. The selection process is defined by the <code>groupby</code> instance attribute.</p> <p>Parameters:</p> Name Type Description Default <code>algo</code> <code>BaseAlgorithm</code> <p>the algorithm instance.</p> required Source code in <code>sequel/benchmarks/memory.py</code> <pre><code>def update_memory(self, algo: \"BaseAlgorithm\"):\n\"\"\"Updates the memory by selecting `per_task_memory_samples` samples from the current dataset. The selection\n    process is defined by the `groupby` instance attribute.\n\n    Args:\n        algo (BaseAlgorithm): the algorithm instance.\n    \"\"\"\n    logging.info(\"Setting memory indices for task {}\".format(algo.task_counter))\n    task = algo.task_counter\n    dataset = algo.benchmark.get_train_dataset(task)\n    if self.groupby == \"class\":\n        memory_indices = MemoryMechanism.sample_uniform_class_indices(dataset, self.per_task_memory_samples)\n    else:\n        memory_indices = MemoryMechanism.sample_uniform_task_indices(dataset, self.per_task_memory_samples)\n    algo.benchmark.set_memory_indices(task, memory_indices)\n</code></pre>"},{"location":"benchmarks/memory/#sequel.benchmarks.memory.MemoryMechanism.update_memory_","title":"<code>update_memory_(benchmark, task)</code>","text":"<p>Updates the memory by selecting <code>per_task_memory_samples</code> samples from the current dataset. The selection process is defined by the <code>groupby</code> instance attribute.</p> Source code in <code>sequel/benchmarks/memory.py</code> <pre><code>def update_memory_(self, benchmark, task):\n\"\"\"Updates the memory by selecting `per_task_memory_samples` samples from the current dataset. The selection\n    process is defined by the `groupby` instance attribute.\n    \"\"\"\n    logging.info(\"Setting memory indices for task {}\".format(task))\n    dataset = benchmark.get_train_dataset(task)\n    if self.groupby == \"class\":\n        memory_indices = MemoryMechanism.sample_uniform_class_indices(dataset, self.per_task_memory_samples)\n    else:\n        memory_indices = MemoryMechanism.sample_uniform_task_indices(dataset, self.per_task_memory_samples)\n    benchmark.set_memory_indices(task, memory_indices)\n</code></pre>"},{"location":"benchmarks/mnist/","title":"MNIST","text":""},{"location":"benchmarks/mnist/#sequel.benchmarks.mnist.ContinualMNIST","title":"<code>ContinualMNIST</code>","text":"<p>         Bases: <code>Benchmark</code></p> <p>Base class for (Permuted/Rotated/Split)-MNIST benchmarks.</p> Source code in <code>sequel/benchmarks/mnist.py</code> <pre><code>class ContinualMNIST(Benchmark):\n\"\"\"Base class for (Permuted/Rotated/Split)-MNIST benchmarks.\"\"\"\n\n    @property\n    def dimensions(self) -&gt; List[int]:\n        return [1, 28, 28]\n\n    @property\n    def num_classes(self) -&gt; int:\n        return 10\n\n    MEAN = (0.1307,)\n    STD = (0.3081,)\n</code></pre>"},{"location":"benchmarks/mnist/#sequel.benchmarks.mnist.PermutedMNIST","title":"<code>PermutedMNIST</code>","text":"<p>         Bases: <code>ContinualMNIST</code></p> <p>Permuted MNIST benchmark.</p> Source code in <code>sequel/benchmarks/mnist.py</code> <pre><code>class PermutedMNIST(ContinualMNIST):\n\"\"\"Permuted MNIST benchmark.\"\"\"\n\n    classes_per_task = 10\n\n    @classmethod\n    def from_config(cls, config):\n        kwargs = cls.get_default_kwargs(config)\n        return cls(**kwargs)\n\n    def __repr__(self) -&gt; str:\n        return f\"PermutedMNIST(num_tasks={self.num_tasks}, batch_size={self.batch_size})\"\n\n    def prepare_datasets(self):\n        mnist_train = torchvision.datasets.MNIST(DEFAULT_DATASET_DIR, train=True, download=True)\n        mnist_test = torchvision.datasets.MNIST(DEFAULT_DATASET_DIR, train=False, download=True)\n        transforms = self.get_transforms(self.num_tasks)\n        trains, tests = {}, {}\n        for task in range(1, self.num_tasks + 1):\n            trains[task] = ContinualVisionDataset(task, mnist_train.data, mnist_train.targets, transforms[task - 1])\n            tests[task] = ContinualVisionDataset(task, mnist_test.data, mnist_test.targets, transforms[task - 1])\n        return trains, tests\n\n    def get_transforms(self, num_tasks):\n        transforms = []\n        for task in range(1, num_tasks + 1):\n            transform = [T.ToTensor()]\n            if task &gt; 1:\n                transform.append(PermuteTransform(torch.randperm(28 * 28)))\n            transform.append(T.Normalize(self.MEAN, self.STD))\n            transforms.append(T.Compose(transform))\n        return transforms\n</code></pre>"},{"location":"benchmarks/mnist/#sequel.benchmarks.mnist.RotatedMNIST","title":"<code>RotatedMNIST</code>","text":"<p>         Bases: <code>ContinualMNIST</code></p> <p>Rotated MNIST benchmark.</p> Source code in <code>sequel/benchmarks/mnist.py</code> <pre><code>class RotatedMNIST(ContinualMNIST):\n\"\"\"Rotated MNIST benchmark.\"\"\"\n\n    classes_per_task = 10\n\n    def __init__(self, num_tasks: int, per_task_rotation: Optional[float] = None, *args, **kwargs):\n        self.per_task_rotation = per_task_rotation\n        super().__init__(num_tasks=num_tasks, *args, **kwargs)\n\n    @classmethod\n    def from_config(cls, config):\n        kwargs = cls.get_default_kwargs(config)\n        kwargs[\"per_task_rotation\"] = config.per_task_rotation\n        return cls(**kwargs)\n\n    def __repr__(self) -&gt; str:\n        return f\"RotatedMNIST(num_tasks={self.num_tasks}, per_task_rotation={self.per_task_rotation}, batch_size={self.batch_size})\"\n\n    def get_transforms(self, num_tasks: int, per_task_rotation: float = None):\n        warnings.warn(\n            \"The RotatedMNIST benchmark currently supports fixed rotations of `per_task_rotation` degrees. \"\n            \"Randomly sampling degrees will be added.\"\n        )\n        if not per_task_rotation:\n            per_task_rotation = 180.0 / num_tasks\n        transforms = []\n        for t in range(1, num_tasks + 1):\n            rotation_degree = (t - 1) * per_task_rotation\n            transform = T.Compose([RotationTransform(rotation_degree), T.ToTensor(), T.Normalize(self.MEAN, self.STD)])\n            transforms.append(transform)\n        return transforms\n\n    def prepare_datasets(self):\n        trains, tests = {}, {}\n        mnist_train = torchvision.datasets.MNIST(DEFAULT_DATASET_DIR, train=True, download=True)\n        mnist_test = torchvision.datasets.MNIST(DEFAULT_DATASET_DIR, train=False, download=True)\n        transforms = self.get_transforms(self.num_tasks, self.per_task_rotation)\n        for task in range(1, self.num_tasks + 1):\n            trains[task] = ContinualVisionDataset(task, mnist_train.data, mnist_train.targets, transforms[task - 1])\n            tests[task] = ContinualVisionDataset(task, mnist_test.data, mnist_test.targets, transforms[task - 1])\n        return trains, tests\n</code></pre>"},{"location":"benchmarks/mnist/#sequel.benchmarks.mnist.SplitMNIST","title":"<code>SplitMNIST</code>","text":"<p>         Bases: <code>ContinualMNIST</code></p> <p>Split MNIST benchmark.</p> <p>The benchmark can have at most 5 tasks, each a binary classification on MNIST digits.</p> Source code in <code>sequel/benchmarks/mnist.py</code> <pre><code>class SplitMNIST(ContinualMNIST):\n\"\"\"Split MNIST benchmark.\n\n    The benchmark can have at most 5 tasks, each a binary classification on MNIST digits.\n    \"\"\"\n\n    @property\n    def classes_per_task(self):\n        if self.num_tasks not in [2, 5]:\n            raise ValueError(\"Split MNIST benchmark can have at most 5 tasks (i.e., 10 classes, 2 per task)\")\n        return 10 // self.num_tasks\n\n    def prepare_datasets(self):\n        transform = T.Compose([T.ToTensor(), T.Normalize(self.MEAN, self.STD)])\n        mnist_train = torchvision.datasets.MNIST(DEFAULT_DATASET_DIR, train=True, download=True, transform=transform)\n        mnist_test = torchvision.datasets.MNIST(DEFAULT_DATASET_DIR, train=False, download=True, transform=transform)\n\n        trains, tests = {}, {}\n        for task in range(1, self.num_tasks + 1):\n            trains[task] = SplitDataset(task, self.classes_per_task, mnist_train)\n            tests[task] = SplitDataset(task, self.classes_per_task, mnist_test)\n\n        return trains, tests\n\n    @classmethod\n    def from_config(cls, config):\n        kwargs = cls.get_default_kwargs(config)\n        return cls(**kwargs)\n\n    def __repr__(self) -&gt; str:\n        return f\"SplitMNIST(num_tasks={self.num_tasks}, batch_size={self.batch_size})\"\n</code></pre>"},{"location":"benchmarks/tinyimagenet/","title":"TinyImageNet","text":""},{"location":"benchmarks/tinyimagenet/#sequel.benchmarks.tinyimagenet.SplitTinyImagenet","title":"<code>SplitTinyImagenet</code>","text":"<p>         Bases: <code>Benchmark</code></p> Source code in <code>sequel/benchmarks/tinyimagenet.py</code> <pre><code>class SplitTinyImagenet(Benchmark):\n\n    root = DEFAULT_DATASET_DIR\n\n    @property\n    def num_classes(self) -&gt; int:\n        return 200\n\n    def __init__(\n        self,\n        num_tasks: int = 10,\n        task_input_transforms: Optional[list] = _default_input_transform,\n        task_target_transforms: Optional[list] = None,\n    ):\n\"\"\"Inits the SplitTinyImagenet class. The number of `classes_per_task` is equal to the ratio of 200 and\n        `num_tasks`.\n\n        Args:\n            num_tasks (int, optional): The number of tasks. Defaults to 10.\n            task_input_transforms (Optional[list], optional): If set, the benchmark will use the\n                provided torchvision input transform. Defaults to _default_input_transform.\n            task_target_transforms (Optional[list], optional): If set, the benchmark will use the\n                provided torchvision target transform. Defaults to None.\n\n        Raises:\n            ValueError: The number of tasks must be divisible by the number of classes (200).\n        \"\"\"\n        if self.num_classes % num_tasks != 0:\n            raise ValueError(\"The number of tasks must be divisible by the number of classes (200).\")\n        self.classes_per_task = self.num_classes // num_tasks\n\n        super().__init__(\n            num_tasks=num_tasks,\n            task_input_transforms=task_input_transforms,\n            task_target_transforms=task_target_transforms,\n        )\n\n        logging.info(f\"Classes_per_task={self.classes_per_task}\")\n        logging.info(f\"num_tasks={self.num_tasks}\")\n\n    @classmethod\n    def from_config(cls, config):\n        num_tasks = config.benchmark.num_tasks\n        return cls(num_tasks=num_tasks)\n\n    def prepare_datasets(self):\n        trains, tests = {}, {}\n        self.__load_tinyimagenet()\n        for task in range(1, self.num_tasks + 1):\n            trains[task] = SplitDataset(task, self.classes_per_task, self.tiny_train)\n            tests[task] = SplitDataset(task, self.classes_per_task, self.tiny_test)\n\n        return trains, tests\n\n    def __load_tinyimagenet(self):\n\"\"\"Loads the tinyimagenet dataset.\n\n        The original dataset does not have labels for the test dataset. For this reason, the validation dataset is\n        used.\n        \"\"\"\n        self.tiny_train = torchvision.datasets.ImageFolder(self.root + \"train\", transform=self.task_input_transforms)\n        tiny_val = torchvision.datasets.ImageFolder(self.root + \"val\", transform=self.task_input_transforms)\n        self.tiny_test = tiny_val\n\n    def __repr__(self) -&gt; str:\n        return f\"SplitTinyImageNet(num_tasks={self.num_tasks}, batch_size={self.batch_size})\"\n</code></pre>"},{"location":"benchmarks/tinyimagenet/#sequel.benchmarks.tinyimagenet.SplitTinyImagenet.__init__","title":"<code>__init__(num_tasks=10, task_input_transforms=_default_input_transform, task_target_transforms=None)</code>","text":"<p>Inits the SplitTinyImagenet class. The number of <code>classes_per_task</code> is equal to the ratio of 200 and <code>num_tasks</code>.</p> <p>Parameters:</p> Name Type Description Default <code>num_tasks</code> <code>int</code> <p>The number of tasks. Defaults to 10.</p> <code>10</code> <code>task_input_transforms</code> <code>Optional[list]</code> <p>If set, the benchmark will use the provided torchvision input transform. Defaults to _default_input_transform.</p> <code>_default_input_transform</code> <code>task_target_transforms</code> <code>Optional[list]</code> <p>If set, the benchmark will use the provided torchvision target transform. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>The number of tasks must be divisible by the number of classes (200).</p> Source code in <code>sequel/benchmarks/tinyimagenet.py</code> <pre><code>def __init__(\n    self,\n    num_tasks: int = 10,\n    task_input_transforms: Optional[list] = _default_input_transform,\n    task_target_transforms: Optional[list] = None,\n):\n\"\"\"Inits the SplitTinyImagenet class. The number of `classes_per_task` is equal to the ratio of 200 and\n    `num_tasks`.\n\n    Args:\n        num_tasks (int, optional): The number of tasks. Defaults to 10.\n        task_input_transforms (Optional[list], optional): If set, the benchmark will use the\n            provided torchvision input transform. Defaults to _default_input_transform.\n        task_target_transforms (Optional[list], optional): If set, the benchmark will use the\n            provided torchvision target transform. Defaults to None.\n\n    Raises:\n        ValueError: The number of tasks must be divisible by the number of classes (200).\n    \"\"\"\n    if self.num_classes % num_tasks != 0:\n        raise ValueError(\"The number of tasks must be divisible by the number of classes (200).\")\n    self.classes_per_task = self.num_classes // num_tasks\n\n    super().__init__(\n        num_tasks=num_tasks,\n        task_input_transforms=task_input_transforms,\n        task_target_transforms=task_target_transforms,\n    )\n\n    logging.info(f\"Classes_per_task={self.classes_per_task}\")\n    logging.info(f\"num_tasks={self.num_tasks}\")\n</code></pre>"},{"location":"benchmarks/tinyimagenet/#sequel.benchmarks.tinyimagenet.SplitTinyImagenet.__load_tinyimagenet","title":"<code>__load_tinyimagenet()</code>","text":"<p>Loads the tinyimagenet dataset.</p> <p>The original dataset does not have labels for the test dataset. For this reason, the validation dataset is used.</p> Source code in <code>sequel/benchmarks/tinyimagenet.py</code> <pre><code>def __load_tinyimagenet(self):\n\"\"\"Loads the tinyimagenet dataset.\n\n    The original dataset does not have labels for the test dataset. For this reason, the validation dataset is\n    used.\n    \"\"\"\n    self.tiny_train = torchvision.datasets.ImageFolder(self.root + \"train\", transform=self.task_input_transforms)\n    tiny_val = torchvision.datasets.ImageFolder(self.root + \"val\", transform=self.task_input_transforms)\n    self.tiny_test = tiny_val\n</code></pre>"},{"location":"benchmarks/utils/","title":"utils","text":""},{"location":"benchmarks/utils/#sequel.benchmarks.utils.ContinualDataset","title":"<code>ContinualDataset</code>","text":"<p>         Bases: <code>torch.utils.data.Dataset</code></p> Source code in <code>sequel/benchmarks/utils.py</code> <pre><code>class ContinualDataset(torch.utils.data.Dataset):\n    def __init__(self, task_id: int, *args, **kwargs) -&gt; None:\n\"\"\"Inits the ContinualDataset class.\n\n        Args:\n            task_id (int): The id of the current task.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self.task_id = task_id\n\n    def __getitem__(self, index: int) -&gt; Tuple[Tensor, Union[Tensor, int], int]:\n        x, y = super().__getitem__(index=index)\n        return x, y, self.task_id\n</code></pre>"},{"location":"benchmarks/utils/#sequel.benchmarks.utils.ContinualDataset.__init__","title":"<code>__init__(task_id, *args, **kwargs)</code>","text":"<p>Inits the ContinualDataset class.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>int</code> <p>The id of the current task.</p> required Source code in <code>sequel/benchmarks/utils.py</code> <pre><code>def __init__(self, task_id: int, *args, **kwargs) -&gt; None:\n\"\"\"Inits the ContinualDataset class.\n\n    Args:\n        task_id (int): The id of the current task.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n    self.task_id = task_id\n</code></pre>"},{"location":"utils/callbacks/base_callback/","title":"base_callback","text":""},{"location":"utils/callbacks/base_callback/#sequel.utils.callbacks.base_callback.BaseCallback","title":"<code>BaseCallback</code>","text":"<p>Base class for callbacks.</p> <p>Defines methods for all the various callback points in the trainer.</p> Source code in <code>sequel/utils/callbacks/base_callback.py</code> <pre><code>class BaseCallback:\n\"\"\"Base class for callbacks.\n\n    Defines methods for all the various callback points in the trainer.\n    \"\"\"\n\n    def __init__(self):\n        pass\n\n    def connect(self, *args, **kwargs):\n        pass\n\n    def on_before_setup(self, *args, **kwargs):\n        pass\n\n    def on_after_setup(self, *args, **kwargs):\n        pass\n\n    def on_before_teardown(self, *args, **kwargs):\n        pass\n\n    def on_after_teardown(self, *args, **kwargs):\n        pass\n\n    def on_before_fit(self, *args, **kwargs):\n        pass\n\n    def on_after_fit(self, *args, **kwargs):\n        pass\n\n    def on_before_training_epoch(self, *args, **kwargs):\n        pass\n\n    def on_after_training_epoch(self, *args, **kwargs):\n        pass\n\n    def on_before_val_epoch(self, *args, **kwargs):\n        pass\n\n    def on_after_val_epoch(self, *args, **kwargs):\n        pass\n\n    def on_before_testing_epoch(self, *args, **kwargs):\n        pass\n\n    def on_after_testing_epoch(self, *args, **kwargs):\n        pass\n\n    def on_before_training_step(self, *args, **kwargs):\n        pass\n\n    def on_after_training_step(self, *args, **kwargs):\n        pass\n\n    def on_before_backward(self, *args, **kwargs):\n        pass\n\n    def on_after_backward(self, *args, **kwargs):\n        pass\n\n    def on_before_forward(self, *args, **kwargs):\n        pass\n\n    def on_after_forward(self, *args, **kwargs):\n        pass\n\n    def on_before_optimizer_step(self, *args, **kwargs):\n        pass\n\n    def on_after_optimizer_step(self, *args, **kwargs):\n        pass\n\n    def on_before_val_step(self, *args, **kwargs):\n        pass\n\n    def on_after_val_step(self, *args, **kwargs):\n        pass\n\n    def on_before_testing_step(self, *args, **kwargs):\n        pass\n\n    def on_after_testing_step(self, *args, **kwargs):\n        pass\n\n    def on_before_training_task(self, *args, **kwargs):\n        pass\n\n    def on_after_training_task(self, *args, **kwargs):\n        pass\n\n    def on_before_validating_algorithm_on_all_tasks(self, *args, **kwargs):\n        pass\n\n    def on_after_validating_algorithm_on_all_tasks(self, *args, **kwargs):\n        pass\n</code></pre>"},{"location":"utils/callbacks/input_visualization_callback/","title":"InputVisualizationCallback","text":""},{"location":"utils/callbacks/input_visualization_callback/#sequel.utils.callbacks.input_visualization_callback.InputVisualizationCallback","title":"<code>InputVisualizationCallback</code>","text":"<p>         Bases: <code>AlgoCallback</code></p> <p>Visualizes random samples from each task and uses the loggers to save the plots.</p> Source code in <code>sequel/utils/callbacks/input_visualization_callback.py</code> <pre><code>class InputVisualizationCallback(AlgoCallback):\n\"\"\"Visualizes random samples from each task and uses the loggers to save the plots.\"\"\"\n\n    def __init__(self, samples_per_task=5):\n\"\"\"Inits the InputVisualizationCallback.\n\n        Args:\n            samples_per_task (int, optional): number of samples to be saved for each tasks. Defaults to 5.\n        \"\"\"\n        super().__init__()\n        self.samples_per_task = samples_per_task\n\n    def select_random_samples(self, dataset: torch.utils.data.Dataset) -&gt; List[torch.Tensor]:\n\"\"\"Selects a prefefined number of samples per each CL dataset. Each task corresponds to a different dataset.\n\n        Args:\n            dataset (torch.data.utils.Dataset): The PyTorch Datatet.\n\n        Returns:\n            List[torch.Tensor]: The Tensors corresponding to the selected input samples.\n        \"\"\"\n        indices = np.random.choice(len(dataset), self.samples_per_task, replace=False)\n        samples = [dataset[i] for i in indices]\n        return samples\n\n    def on_before_fit(self, algo: \"BaseAlgorithm\", *args, **kwargs) -&gt; None:\n\"\"\"Retrieves and diplays in a single plot the input images from all tasks of the benchmark that the algorithm\n        has been initialized with. The final plot is saved via the loggers.\n\n        Args:\n            algo (BaseAlgorithm): The BaseAlgorithm instance.\n        \"\"\"\n        datasets = algo.benchmark.trains\n        num_tasks = algo.num_tasks\n\n        samples = []\n        for dataset in datasets.values():\n            task_samples = self.select_random_samples(dataset)\n            samples.append(task_samples)\n\n        s = 2\n        figure, axes = plt.subplots(\n            nrows=num_tasks,\n            ncols=self.samples_per_task,\n            figsize=(s * self.samples_per_task, s * num_tasks),\n        )\n\n        for i, task_samples in enumerate(samples):\n            for j, (x, y, t) in enumerate(task_samples):\n                if x.dim() == 2:\n                    x = x.unsqueeze(0)\n                axes[i][j].imshow(x.permute(1, 2, 0))\n                axes[i][j].title.set_text(f\"t={t}: y={y}\")\n\n        plt.setp(axes, xticks=[], yticks=[])\n        figure.subplots_adjust(wspace=0.5)\n\n        # save the plot via the algorithm loggers\n        algo.log_figure(name=\"input/viz\", figure=figure)\n</code></pre>"},{"location":"utils/callbacks/input_visualization_callback/#sequel.utils.callbacks.input_visualization_callback.InputVisualizationCallback.__init__","title":"<code>__init__(samples_per_task=5)</code>","text":"<p>Inits the InputVisualizationCallback.</p> <p>Parameters:</p> Name Type Description Default <code>samples_per_task</code> <code>int</code> <p>number of samples to be saved for each tasks. Defaults to 5.</p> <code>5</code> Source code in <code>sequel/utils/callbacks/input_visualization_callback.py</code> <pre><code>def __init__(self, samples_per_task=5):\n\"\"\"Inits the InputVisualizationCallback.\n\n    Args:\n        samples_per_task (int, optional): number of samples to be saved for each tasks. Defaults to 5.\n    \"\"\"\n    super().__init__()\n    self.samples_per_task = samples_per_task\n</code></pre>"},{"location":"utils/callbacks/input_visualization_callback/#sequel.utils.callbacks.input_visualization_callback.InputVisualizationCallback.on_before_fit","title":"<code>on_before_fit(algo, *args, **kwargs)</code>","text":"<p>Retrieves and diplays in a single plot the input images from all tasks of the benchmark that the algorithm has been initialized with. The final plot is saved via the loggers.</p> <p>Parameters:</p> Name Type Description Default <code>algo</code> <code>BaseAlgorithm</code> <p>The BaseAlgorithm instance.</p> required Source code in <code>sequel/utils/callbacks/input_visualization_callback.py</code> <pre><code>def on_before_fit(self, algo: \"BaseAlgorithm\", *args, **kwargs) -&gt; None:\n\"\"\"Retrieves and diplays in a single plot the input images from all tasks of the benchmark that the algorithm\n    has been initialized with. The final plot is saved via the loggers.\n\n    Args:\n        algo (BaseAlgorithm): The BaseAlgorithm instance.\n    \"\"\"\n    datasets = algo.benchmark.trains\n    num_tasks = algo.num_tasks\n\n    samples = []\n    for dataset in datasets.values():\n        task_samples = self.select_random_samples(dataset)\n        samples.append(task_samples)\n\n    s = 2\n    figure, axes = plt.subplots(\n        nrows=num_tasks,\n        ncols=self.samples_per_task,\n        figsize=(s * self.samples_per_task, s * num_tasks),\n    )\n\n    for i, task_samples in enumerate(samples):\n        for j, (x, y, t) in enumerate(task_samples):\n            if x.dim() == 2:\n                x = x.unsqueeze(0)\n            axes[i][j].imshow(x.permute(1, 2, 0))\n            axes[i][j].title.set_text(f\"t={t}: y={y}\")\n\n    plt.setp(axes, xticks=[], yticks=[])\n    figure.subplots_adjust(wspace=0.5)\n\n    # save the plot via the algorithm loggers\n    algo.log_figure(name=\"input/viz\", figure=figure)\n</code></pre>"},{"location":"utils/callbacks/input_visualization_callback/#sequel.utils.callbacks.input_visualization_callback.InputVisualizationCallback.select_random_samples","title":"<code>select_random_samples(dataset)</code>","text":"<p>Selects a prefefined number of samples per each CL dataset. Each task corresponds to a different dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>torch.data.utils.Dataset</code> <p>The PyTorch Datatet.</p> required <p>Returns:</p> Type Description <code>List[torch.Tensor]</code> <p>List[torch.Tensor]: The Tensors corresponding to the selected input samples.</p> Source code in <code>sequel/utils/callbacks/input_visualization_callback.py</code> <pre><code>def select_random_samples(self, dataset: torch.utils.data.Dataset) -&gt; List[torch.Tensor]:\n\"\"\"Selects a prefefined number of samples per each CL dataset. Each task corresponds to a different dataset.\n\n    Args:\n        dataset (torch.data.utils.Dataset): The PyTorch Datatet.\n\n    Returns:\n        List[torch.Tensor]: The Tensors corresponding to the selected input samples.\n    \"\"\"\n    indices = np.random.choice(len(dataset), self.samples_per_task, replace=False)\n    samples = [dataset[i] for i in indices]\n    return samples\n</code></pre>"},{"location":"utils/callbacks/memory_callback/","title":"MemoryCallback","text":""},{"location":"utils/callbacks/memory_callback/#sequel.utils.callbacks.memory_callback.MemoryMechanismCallback","title":"<code>MemoryMechanismCallback</code>","text":"<p>         Bases: <code>AlgoCallback</code></p> <p>Wraps an AlgoCallback around the MemoryMechanism for ease of use.</p> Source code in <code>sequel/utils/callbacks/memory_callback.py</code> <pre><code>class MemoryMechanismCallback(AlgoCallback):\n\"\"\"Wraps an AlgoCallback around the MemoryMechanism for ease of use.\"\"\"\n\n    def __init__(self, per_task_memory_samples: int, groupby: str = \"class\"):\n        super().__init__()\n        self.memory = MemoryMechanism(per_task_memory_samples, groupby)\n        self.per_task_memory_samples = per_task_memory_samples\n        self.groupby = groupby\n\n    def on_after_training_task(self, algo: \"BaseAlgorithm\", *args, **kwargs):\n\"\"\"Updates the memory Mechanism.\n\n        Args:\n            algo (BaseAlgorithm): The current BaseAlgorithm instance.\n        \"\"\"\n        self.memory.update_memory(algo)\n        algo.update_episodic_memory()\n</code></pre>"},{"location":"utils/callbacks/memory_callback/#sequel.utils.callbacks.memory_callback.MemoryMechanismCallback.on_after_training_task","title":"<code>on_after_training_task(algo, *args, **kwargs)</code>","text":"<p>Updates the memory Mechanism.</p> <p>Parameters:</p> Name Type Description Default <code>algo</code> <code>BaseAlgorithm</code> <p>The current BaseAlgorithm instance.</p> required Source code in <code>sequel/utils/callbacks/memory_callback.py</code> <pre><code>def on_after_training_task(self, algo: \"BaseAlgorithm\", *args, **kwargs):\n\"\"\"Updates the memory Mechanism.\n\n    Args:\n        algo (BaseAlgorithm): The current BaseAlgorithm instance.\n    \"\"\"\n    self.memory.update_memory(algo)\n    algo.update_episodic_memory()\n</code></pre>"},{"location":"utils/callbacks/metric_callback/","title":"MetricCallback","text":""},{"location":"utils/loggers/loggers/","title":"loggers","text":""}]}